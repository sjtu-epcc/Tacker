#pragma once
typedef signed char int8_t;
typedef signed short int16_t;
typedef signed int int32_t;
typedef signed long int int64_t;
typedef unsigned char uint8_t;
typedef unsigned short uint16_t;
typedef unsigned int uint32_t;
typedef unsigned long int uint64_t;

#include <cuda.h>
#include <cuda_runtime.h>
// Copyright (c) Microsoft Corporation.
// Licensed under the MIT License.

#include <cudnn.h>
#include <cublas_v2.h>
#include <cuda.h>
#include <cuda_runtime.h>

#include <sstream>
#include <fstream>
#include <stdexcept>
#include <assert.h>
#include <stdio.h>
#include <vector>
#define CUDNN_SAFE_CALL(func)                                                                      \
    do                                                                                             \
    {                                                                                              \
        cudnnStatus_t e = (func);                                                                  \
        if (e != CUDNN_STATUS_SUCCESS)                                                             \
        {                                                                                          \
            const char* msg = cudnnGetErrorString(e);                                              \
            std::stringstream safe_call_ss;                                                        \
            safe_call_ss << "\nerror: " #func " failed with error"                                 \
                         << "\nfile: " << __FILE__ << "\nline: " << __LINE__ << "\nmsg: " << msg;  \
            throw std::runtime_error(safe_call_ss.str());                                          \
        }                                                                                          \
    } while (0)
#define CUBLAS_SAFE_CALL(func)                                                                     \
    do                                                                                             \
    {                                                                                              \
        cublasStatus_t e = (func);                                                                 \
        if (e != CUBLAS_STATUS_SUCCESS)                                                            \
        {                                                                                          \
            std::stringstream safe_call_ss;                                                        \
            safe_call_ss << "\nerror: " #func " failed with error"                                 \
                         << "\nfile: " << __FILE__ << "\nline: " << __LINE__ << "\nmsg: " << e;    \
            throw std::runtime_error(safe_call_ss.str());                                          \
        }                                                                                          \
    } while (0)
   #define CUDA_SAFE_CALL(x)                                                                          \
    do                                                                                             \
    {                                                                                              \
        cudaError_t result = (x);                                                                  \
        if (result != cudaSuccess)                                                                 \
        {                                                                                          \
            const char* msg = cudaGetErrorString(result);                                          \
            std::stringstream safe_call_ss;                                                        \
            safe_call_ss << "\nerror: " #x " failed with error"                                    \
                         << "\nfile: " << __FILE__ << "\nline: " << __LINE__ << "\nmsg: " << msg;  \
            throw std::runtime_error(safe_call_ss.str());                                          \
        }                                                                                          \
    } while (0)
char* inception3_group_0_CUDA_GPU0_allocator_memory_pool;
float* inception3_Reshape_486_0;
float* inception3_Reshape_487_0;
float* inception3_Convolution_488_0;
float* inception3_BatchNormInference_489_0;
float* inception3_Relu_490_0;
float* inception3_Reshape_491_0;
float* inception3_Convolution_492_0;
float* inception3_BatchNormInference_493_0;
float* inception3_Relu_494_0;
float* inception3_Reshape_495_0;
float* inception3_Convolution_496_0;
float* inception3_BatchNormInference_497_0;
float* inception3_Relu_498_0;
float* inception3_MaxPool_499_0;
float* inception3_Reshape_500_0;
float* inception3_Convolution_501_0;
float* inception3_BatchNormInference_502_0;
float* inception3_Relu_503_0;
float* inception3_Reshape_504_0;
float* inception3_Convolution_505_0;
float* inception3_BatchNormInference_506_0;
float* inception3_Relu_507_0;
float* inception3_MaxPool_508_0;
float* inception3_Reshape_511_0;
float* inception3_Convolution_512_0;
float* inception3_BatchNormInference_517_0;
float* inception3_Relu_522_0;
float* inception3_Reshape_525_0;
float* inception3_Convolution_526_0;
float* inception3_BatchNormInference_530_0;
float* inception3_Relu_532_0;
float* inception3_Reshape_509_0;
float* inception3_Convolution_510_0;
float* inception3_BatchNormInference_516_0;
float* inception3_Relu_521_0;
float* inception3_AvgPool_515_0;
float* inception3_Reshape_519_0;
float* inception3_Convolution_520_0;
float* inception3_BatchNormInference_524_0;
float* inception3_Relu_529_0;
float* inception3_Reshape_513_0;
float* inception3_Convolution_514_0;
float* inception3_BatchNormInference_518_0;
float* inception3_Relu_523_0;
float* inception3_Reshape_527_0;
float* inception3_Convolution_528_0;
float* inception3_BatchNormInference_531_0;
float* inception3_Relu_533_0;
float* inception3_Reshape_534_0;
float* inception3_Convolution_535_0;
float* inception3_BatchNormInference_536_0;
float* inception3_Relu_537_0;
float* inception3_Concat_538_0;
float* inception3_AvgPool_545_0;
float* inception3_Reshape_549_0;
float* inception3_Convolution_550_0;
float* inception3_BatchNormInference_554_0;
float* inception3_Relu_559_0;
float* inception3_Reshape_543_0;
float* inception3_Convolution_544_0;
float* inception3_BatchNormInference_548_0;
float* inception3_Relu_553_0;
float* inception3_Reshape_557_0;
float* inception3_Convolution_558_0;
float* inception3_BatchNormInference_561_0;
float* inception3_Relu_563_0;
float* inception3_Reshape_564_0;
float* inception3_Convolution_565_0;
float* inception3_BatchNormInference_566_0;
float* inception3_Relu_567_0;
float* inception3_Reshape_541_0;
float* inception3_Convolution_542_0;
float* inception3_BatchNormInference_547_0;
float* inception3_Relu_552_0;
float* inception3_Reshape_555_0;
float* inception3_Convolution_556_0;
float* inception3_BatchNormInference_560_0;
float* inception3_Relu_562_0;
float* inception3_Reshape_539_0;
float* inception3_Convolution_540_0;
float* inception3_BatchNormInference_546_0;
float* inception3_Relu_551_0;
float* inception3_Concat_568_0;
float* inception3_AvgPool_575_0;
float* inception3_Reshape_579_0;
float* inception3_Convolution_580_0;
float* inception3_BatchNormInference_584_0;
float* inception3_Relu_589_0;
float* inception3_Reshape_573_0;
float* inception3_Convolution_574_0;
float* inception3_BatchNormInference_578_0;
float* inception3_Relu_583_0;
float* inception3_Reshape_587_0;
float* inception3_Convolution_588_0;
float* inception3_BatchNormInference_591_0;
float* inception3_Relu_593_0;
float* inception3_Reshape_594_0;
float* inception3_Convolution_595_0;
float* inception3_BatchNormInference_596_0;
float* inception3_Relu_597_0;
float* inception3_Reshape_571_0;
float* inception3_Convolution_572_0;
float* inception3_BatchNormInference_577_0;
float* inception3_Relu_582_0;
float* inception3_Reshape_585_0;
float* inception3_Convolution_586_0;
float* inception3_BatchNormInference_590_0;
float* inception3_Relu_592_0;
float* inception3_Reshape_569_0;
float* inception3_Convolution_570_0;
float* inception3_BatchNormInference_576_0;
float* inception3_Relu_581_0;
float* inception3_Concat_598_0;
float* inception3_MaxPool_603_0;
float* inception3_Reshape_601_0;
float* inception3_Convolution_602_0;
float* inception3_BatchNormInference_605_0;
float* inception3_Relu_607_0;
float* inception3_Reshape_608_0;
float* inception3_Convolution_609_0;
float* inception3_BatchNormInference_610_0;
float* inception3_Relu_611_0;
float* inception3_Reshape_612_0;
float* inception3_Convolution_613_0;
float* inception3_BatchNormInference_614_0;
float* inception3_Relu_615_0;
float* inception3_Reshape_599_0;
float* inception3_Convolution_600_0;
float* inception3_BatchNormInference_604_0;
float* inception3_Relu_606_0;
float* inception3_Concat_616_0;
float* inception3_AvgPool_623_0;
float* inception3_Reshape_627_0;
float* inception3_Convolution_628_0;
float* inception3_BatchNormInference_632_0;
float* inception3_Relu_637_0;
float* inception3_Reshape_621_0;
float* inception3_Convolution_622_0;
float* inception3_BatchNormInference_626_0;
float* inception3_Relu_631_0;
float* inception3_Reshape_635_0;
float* inception3_Convolution_636_0;
float* inception3_BatchNormInference_639_0;
float* inception3_Relu_641_0;
float* inception3_Reshape_644_0;
float* inception3_Convolution_645_0;
float* inception3_BatchNormInference_647_0;
float* inception3_Relu_649_0;
float* inception3_Reshape_650_0;
float* inception3_Convolution_651_0;
float* inception3_BatchNormInference_652_0;
float* inception3_Relu_653_0;
float* inception3_Reshape_654_0;
float* inception3_Convolution_655_0;
float* inception3_BatchNormInference_656_0;
float* inception3_Relu_657_0;
float* inception3_Reshape_619_0;
float* inception3_Convolution_620_0;
float* inception3_BatchNormInference_625_0;
float* inception3_Relu_630_0;
float* inception3_Reshape_633_0;
float* inception3_Convolution_634_0;
float* inception3_BatchNormInference_638_0;
float* inception3_Relu_640_0;
float* inception3_Reshape_642_0;
float* inception3_Convolution_643_0;
float* inception3_BatchNormInference_646_0;
float* inception3_Relu_648_0;
float* inception3_Reshape_617_0;
float* inception3_Convolution_618_0;
float* inception3_BatchNormInference_624_0;
float* inception3_Relu_629_0;
float* inception3_Concat_658_0;
float* inception3_AvgPool_665_0;
float* inception3_Reshape_669_0;
float* inception3_Convolution_670_0;
float* inception3_BatchNormInference_674_0;
float* inception3_Relu_679_0;
float* inception3_Reshape_663_0;
float* inception3_Convolution_664_0;
float* inception3_BatchNormInference_668_0;
float* inception3_Relu_673_0;
float* inception3_Reshape_677_0;
float* inception3_Convolution_678_0;
float* inception3_BatchNormInference_681_0;
float* inception3_Relu_683_0;
float* inception3_Reshape_686_0;
float* inception3_Convolution_687_0;
float* inception3_BatchNormInference_689_0;
float* inception3_Relu_691_0;
float* inception3_Reshape_692_0;
float* inception3_Convolution_693_0;
float* inception3_BatchNormInference_694_0;
float* inception3_Relu_695_0;
float* inception3_Reshape_696_0;
float* inception3_Convolution_697_0;
float* inception3_BatchNormInference_698_0;
float* inception3_Relu_699_0;
float* inception3_Reshape_661_0;
float* inception3_Convolution_662_0;
float* inception3_BatchNormInference_667_0;
float* inception3_Relu_672_0;
float* inception3_Reshape_675_0;
float* inception3_Convolution_676_0;
float* inception3_BatchNormInference_680_0;
float* inception3_Relu_682_0;
float* inception3_Reshape_684_0;
float* inception3_Convolution_685_0;
float* inception3_BatchNormInference_688_0;
float* inception3_Relu_690_0;
float* inception3_Reshape_659_0;
float* inception3_Convolution_660_0;
float* inception3_BatchNormInference_666_0;
float* inception3_Relu_671_0;
float* inception3_Concat_700_0;
float* inception3_AvgPool_707_0;
float* inception3_Reshape_711_0;
float* inception3_Convolution_712_0;
float* inception3_BatchNormInference_716_0;
float* inception3_Relu_721_0;
float* inception3_Reshape_705_0;
float* inception3_Convolution_706_0;
float* inception3_BatchNormInference_710_0;
float* inception3_Relu_715_0;
float* inception3_Reshape_719_0;
float* inception3_Convolution_720_0;
float* inception3_BatchNormInference_723_0;
float* inception3_Relu_725_0;
float* inception3_Reshape_728_0;
float* inception3_Convolution_729_0;
float* inception3_BatchNormInference_731_0;
float* inception3_Relu_733_0;
float* inception3_Reshape_734_0;
float* inception3_Convolution_735_0;
float* inception3_BatchNormInference_736_0;
float* inception3_Relu_737_0;
float* inception3_Reshape_738_0;
float* inception3_Convolution_739_0;
float* inception3_BatchNormInference_740_0;
float* inception3_Relu_741_0;
float* inception3_Reshape_703_0;
float* inception3_Convolution_704_0;
float* inception3_BatchNormInference_709_0;
float* inception3_Relu_714_0;
float* inception3_Reshape_717_0;
float* inception3_Convolution_718_0;
float* inception3_BatchNormInference_722_0;
float* inception3_Relu_724_0;
float* inception3_Reshape_726_0;
float* inception3_Convolution_727_0;
float* inception3_BatchNormInference_730_0;
float* inception3_Relu_732_0;
float* inception3_Reshape_701_0;
float* inception3_Convolution_702_0;
float* inception3_BatchNormInference_708_0;
float* inception3_Relu_713_0;
float* inception3_Concat_742_0;
float* inception3_AvgPool_749_0;
float* inception3_Reshape_753_0;
float* inception3_Convolution_754_0;
float* inception3_BatchNormInference_758_0;
float* inception3_Relu_763_0;
float* inception3_Reshape_747_0;
float* inception3_Convolution_748_0;
float* inception3_BatchNormInference_752_0;
float* inception3_Relu_757_0;
float* inception3_Reshape_761_0;
float* inception3_Convolution_762_0;
float* inception3_BatchNormInference_765_0;
float* inception3_Relu_767_0;
float* inception3_Reshape_770_0;
float* inception3_Convolution_771_0;
float* inception3_BatchNormInference_773_0;
float* inception3_Relu_775_0;
float* inception3_Reshape_776_0;
float* inception3_Convolution_777_0;
float* inception3_BatchNormInference_778_0;
float* inception3_Relu_779_0;
float* inception3_Reshape_780_0;
float* inception3_Convolution_781_0;
float* inception3_BatchNormInference_782_0;
float* inception3_Relu_783_0;
float* inception3_Reshape_745_0;
float* inception3_Convolution_746_0;
float* inception3_BatchNormInference_751_0;
float* inception3_Relu_756_0;
float* inception3_Reshape_759_0;
float* inception3_Convolution_760_0;
float* inception3_BatchNormInference_764_0;
float* inception3_Relu_766_0;
float* inception3_Reshape_768_0;
float* inception3_Convolution_769_0;
float* inception3_BatchNormInference_772_0;
float* inception3_Relu_774_0;
float* inception3_Reshape_743_0;
float* inception3_Convolution_744_0;
float* inception3_BatchNormInference_750_0;
float* inception3_Relu_755_0;
float* inception3_Concat_784_0;
float* inception3_MaxPool_789_0;
float* inception3_Reshape_787_0;
float* inception3_Convolution_788_0;
float* inception3_BatchNormInference_791_0;
float* inception3_Relu_793_0;
float* inception3_Reshape_796_0;
float* inception3_Convolution_797_0;
float* inception3_BatchNormInference_799_0;
float* inception3_Relu_801_0;
float* inception3_Reshape_802_0;
float* inception3_Convolution_803_0;
float* inception3_BatchNormInference_804_0;
float* inception3_Relu_805_0;
float* inception3_Reshape_806_0;
float* inception3_Convolution_807_0;
float* inception3_BatchNormInference_808_0;
float* inception3_Relu_809_0;
float* inception3_Reshape_785_0;
float* inception3_Convolution_786_0;
float* inception3_BatchNormInference_790_0;
float* inception3_Relu_792_0;
float* inception3_Reshape_794_0;
float* inception3_Convolution_795_0;
float* inception3_BatchNormInference_798_0;
float* inception3_Relu_800_0;
float* inception3_Concat_810_0;
float* inception3_AvgPool_817_0;
float* inception3_Reshape_821_0;
float* inception3_Convolution_822_0;
float* inception3_BatchNormInference_826_0;
float* inception3_Relu_833_0;
float* inception3_Reshape_815_0;
float* inception3_Convolution_816_0;
float* inception3_BatchNormInference_820_0;
float* inception3_Relu_825_0;
float* inception3_Reshape_831_0;
float* inception3_Convolution_832_0;
float* inception3_BatchNormInference_836_0;
float* inception3_Relu_839_0;
float* inception3_Reshape_842_0;
float* inception3_Convolution_843_0;
float* inception3_BatchNormInference_845_0;
float* inception3_Relu_847_0;
float* inception3_Reshape_840_0;
float* inception3_Convolution_841_0;
float* inception3_BatchNormInference_844_0;
float* inception3_Relu_846_0;
float* inception3_Reshape_813_0;
float* inception3_Convolution_814_0;
float* inception3_BatchNormInference_819_0;
float* inception3_Relu_824_0;
float* inception3_Reshape_829_0;
float* inception3_Convolution_830_0;
float* inception3_BatchNormInference_835_0;
float* inception3_Relu_838_0;
float* inception3_Reshape_827_0;
float* inception3_Convolution_828_0;
float* inception3_BatchNormInference_834_0;
float* inception3_Relu_837_0;
float* inception3_Reshape_811_0;
float* inception3_Convolution_812_0;
float* inception3_BatchNormInference_818_0;
float* inception3_Relu_823_0;
float* inception3_Concat_848_0;
float* inception3_MaxPool_855_0;
float* inception3_Reshape_859_0;
float* inception3_Convolution_860_0;
float* inception3_BatchNormInference_864_0;
float* inception3_Relu_871_0;
float* inception3_Reshape_853_0;
float* inception3_Convolution_854_0;
float* inception3_BatchNormInference_858_0;
float* inception3_Relu_863_0;
float* inception3_Reshape_869_0;
float* inception3_Convolution_870_0;
float* inception3_BatchNormInference_874_0;
float* inception3_Relu_877_0;
float* inception3_Reshape_880_0;
float* inception3_Convolution_881_0;
float* inception3_BatchNormInference_883_0;
float* inception3_Relu_885_0;
float* inception3_Reshape_878_0;
float* inception3_Convolution_879_0;
float* inception3_BatchNormInference_882_0;
float* inception3_Relu_884_0;
float* inception3_Reshape_851_0;
float* inception3_Convolution_852_0;
float* inception3_BatchNormInference_857_0;
float* inception3_Relu_862_0;
float* inception3_Reshape_867_0;
float* inception3_Convolution_868_0;
float* inception3_BatchNormInference_873_0;
float* inception3_Relu_876_0;
float* inception3_Reshape_865_0;
float* inception3_Convolution_866_0;
float* inception3_BatchNormInference_872_0;
float* inception3_Relu_875_0;
float* inception3_Reshape_849_0;
float* inception3_Convolution_850_0;
float* inception3_BatchNormInference_856_0;
float* inception3_Relu_861_0;
float* inception3_Concat_886_0;
float* inception3_AvgPool_887_0;
float* inception3_Reshape_888_0;
float* inception3_Dot_889_0;
float* inception3_Broadcast_890_0;
float* inception3_Add_891_0;
__device__ __forceinline__ float add(float x0, float x1)
{
    return x0 + x1;
}
__device__ __forceinline__ int division_by_invariant_multiplication(int value, int magic, int shift)
{
    int result;
    asm("{\n\t"
        ".reg .pred p;\n\t"
        ".reg .u64 res64;\n\t"
        ".reg .u32 lo32, hi32;\n\t"
        "setp.ne.s32 p, %2, 1;\n\t"
        "mul.wide.u32 res64, %1, %2;\n\t"
        "mov.b64 {lo32, hi32}, res64;\n\t"
        "selp.u32 hi32, hi32, %1, p;\n\t"
        "shr.u32 %0, hi32, %3;\n\t"
        "}" : "=r"(result) : "r"(value), "r"(magic), "r"(shift));
    return result;
}
__device__ __forceinline__ char  load(const char*  __restrict__ in, int i=0, bool b=true)
{
    char v = 0;
    if (b)
    {
        v = __ldg(in + i);
    }
    return v;
} 
__device__ __forceinline__ float  load(const float*  __restrict__ in, int i=0, bool b=true)
{
    float v = 0.0f;
    if (b)
    {
        v = __ldg(in + i);
    }
    return v;
}
__device__ __forceinline__ int32_t  load(const int32_t*  __restrict__ in, int i=0, bool b=true)
{
    int32_t v = 0;
    if (b)
    {
        v = __ldg(in + i);
    }
    return v;
}
__device__ __forceinline__ int64_t  load(const int64_t*  __restrict__ in, int i=0, bool b=true)
{
    int64_t v = 0;
    if (b)
    {
        v = __ldg(in + i);
    }
    return v;
}
__device__ __forceinline__ float relu(float x0)
{
    return fmaxf(0,x0);
}

typedef signed char int8_t;
typedef signed short int16_t;
typedef signed int int32_t;
typedef signed long int int64_t;
typedef unsigned char uint8_t;
typedef unsigned short uint16_t;
typedef unsigned int uint32_t;
typedef unsigned long int uint64_t;
cublasHandle_t inception3_cublas_handle_0;
cudnnHandle_t inception3_cudnn_handle_0;
char* inception3_group_persist_CUDA_GPU0_allocator_memory_pool;
float* inception3_Constant_484_0;
float* inception3_Constant_2_0;
float* inception3_Constant_6_0;
float* inception3_Constant_5_0;
float* inception3_Constant_4_0;
float* inception3_Constant_3_0;
float* inception3_Constant_7_0;
float* inception3_Constant_11_0;
float* inception3_Constant_10_0;
float* inception3_Constant_9_0;
float* inception3_Constant_8_0;
float* inception3_Constant_12_0;
float* inception3_Constant_16_0;
float* inception3_Constant_15_0;
float* inception3_Constant_14_0;
float* inception3_Constant_13_0;
float* inception3_Constant_17_0;
float* inception3_Constant_21_0;
float* inception3_Constant_20_0;
float* inception3_Constant_19_0;
float* inception3_Constant_18_0;
float* inception3_Constant_22_0;
float* inception3_Constant_26_0;
float* inception3_Constant_25_0;
float* inception3_Constant_24_0;
float* inception3_Constant_23_0;
float* inception3_Constant_32_0;
float* inception3_Constant_36_0;
float* inception3_Constant_35_0;
float* inception3_Constant_34_0;
float* inception3_Constant_33_0;
float* inception3_Constant_37_0;
float* inception3_Constant_41_0;
float* inception3_Constant_40_0;
float* inception3_Constant_39_0;
float* inception3_Constant_38_0;
float* inception3_Constant_27_0;
float* inception3_Constant_31_0;
float* inception3_Constant_30_0;
float* inception3_Constant_29_0;
float* inception3_Constant_28_0;
float* inception3_Constant_57_0;
float* inception3_Constant_61_0;
float* inception3_Constant_60_0;
float* inception3_Constant_59_0;
float* inception3_Constant_58_0;
float* inception3_Constant_42_0;
float* inception3_Constant_46_0;
float* inception3_Constant_45_0;
float* inception3_Constant_44_0;
float* inception3_Constant_43_0;
float* inception3_Constant_47_0;
float* inception3_Constant_51_0;
float* inception3_Constant_50_0;
float* inception3_Constant_49_0;
float* inception3_Constant_48_0;
float* inception3_Constant_52_0;
float* inception3_Constant_56_0;
float* inception3_Constant_55_0;
float* inception3_Constant_54_0;
float* inception3_Constant_53_0;
float* inception3_Constant_93_0;
float* inception3_Constant_94_0;
float* inception3_Constant_97_0;
float* inception3_Constant_96_0;
float* inception3_Constant_95_0;
float* inception3_Constant_78_0;
float* inception3_Constant_79_0;
float* inception3_Constant_82_0;
float* inception3_Constant_81_0;
float* inception3_Constant_80_0;
float* inception3_Constant_83_0;
float* inception3_Constant_84_0;
float* inception3_Constant_87_0;
float* inception3_Constant_86_0;
float* inception3_Constant_85_0;
float* inception3_Constant_88_0;
float* inception3_Constant_89_0;
float* inception3_Constant_92_0;
float* inception3_Constant_91_0;
float* inception3_Constant_90_0;
float* inception3_Constant_68_0;
float* inception3_Constant_69_0;
float* inception3_Constant_72_0;
float* inception3_Constant_71_0;
float* inception3_Constant_70_0;
float* inception3_Constant_73_0;
float* inception3_Constant_74_0;
float* inception3_Constant_77_0;
float* inception3_Constant_76_0;
float* inception3_Constant_75_0;
float* inception3_Constant_63_0;
float* inception3_Constant_64_0;
float* inception3_Constant_67_0;
float* inception3_Constant_66_0;
float* inception3_Constant_65_0;
float* inception3_Constant_129_0;
float* inception3_Constant_130_0;
float* inception3_Constant_133_0;
float* inception3_Constant_132_0;
float* inception3_Constant_131_0;
float* inception3_Constant_114_0;
float* inception3_Constant_115_0;
float* inception3_Constant_118_0;
float* inception3_Constant_117_0;
float* inception3_Constant_116_0;
float* inception3_Constant_119_0;
float* inception3_Constant_120_0;
float* inception3_Constant_123_0;
float* inception3_Constant_122_0;
float* inception3_Constant_121_0;
float* inception3_Constant_124_0;
float* inception3_Constant_125_0;
float* inception3_Constant_128_0;
float* inception3_Constant_127_0;
float* inception3_Constant_126_0;
float* inception3_Constant_104_0;
float* inception3_Constant_105_0;
float* inception3_Constant_108_0;
float* inception3_Constant_107_0;
float* inception3_Constant_106_0;
float* inception3_Constant_109_0;
float* inception3_Constant_110_0;
float* inception3_Constant_113_0;
float* inception3_Constant_112_0;
float* inception3_Constant_111_0;
float* inception3_Constant_99_0;
float* inception3_Constant_100_0;
float* inception3_Constant_103_0;
float* inception3_Constant_102_0;
float* inception3_Constant_101_0;
float* inception3_Constant_140_0;
float* inception3_Constant_144_0;
float* inception3_Constant_143_0;
float* inception3_Constant_142_0;
float* inception3_Constant_141_0;
float* inception3_Constant_145_0;
float* inception3_Constant_149_0;
float* inception3_Constant_148_0;
float* inception3_Constant_147_0;
float* inception3_Constant_146_0;
float* inception3_Constant_150_0;
float* inception3_Constant_154_0;
float* inception3_Constant_153_0;
float* inception3_Constant_152_0;
float* inception3_Constant_151_0;
float* inception3_Constant_135_0;
float* inception3_Constant_139_0;
float* inception3_Constant_138_0;
float* inception3_Constant_137_0;
float* inception3_Constant_136_0;
float* inception3_Constant_201_0;
float* inception3_Constant_205_0;
float* inception3_Constant_204_0;
float* inception3_Constant_203_0;
float* inception3_Constant_202_0;
float* inception3_Constant_176_0;
float* inception3_Constant_180_0;
float* inception3_Constant_179_0;
float* inception3_Constant_178_0;
float* inception3_Constant_177_0;
float* inception3_Constant_181_0;
float* inception3_Constant_185_0;
float* inception3_Constant_184_0;
float* inception3_Constant_183_0;
float* inception3_Constant_182_0;
float* inception3_Constant_186_0;
float* inception3_Constant_190_0;
float* inception3_Constant_189_0;
float* inception3_Constant_188_0;
float* inception3_Constant_187_0;
float* inception3_Constant_191_0;
float* inception3_Constant_195_0;
float* inception3_Constant_194_0;
float* inception3_Constant_193_0;
float* inception3_Constant_192_0;
float* inception3_Constant_196_0;
float* inception3_Constant_200_0;
float* inception3_Constant_199_0;
float* inception3_Constant_198_0;
float* inception3_Constant_197_0;
float* inception3_Constant_161_0;
float* inception3_Constant_165_0;
float* inception3_Constant_164_0;
float* inception3_Constant_163_0;
float* inception3_Constant_162_0;
float* inception3_Constant_166_0;
float* inception3_Constant_170_0;
float* inception3_Constant_169_0;
float* inception3_Constant_168_0;
float* inception3_Constant_167_0;
float* inception3_Constant_171_0;
float* inception3_Constant_175_0;
float* inception3_Constant_174_0;
float* inception3_Constant_173_0;
float* inception3_Constant_172_0;
float* inception3_Constant_156_0;
float* inception3_Constant_160_0;
float* inception3_Constant_159_0;
float* inception3_Constant_158_0;
float* inception3_Constant_157_0;
float* inception3_Constant_252_0;
float* inception3_Constant_253_0;
float* inception3_Constant_256_0;
float* inception3_Constant_255_0;
float* inception3_Constant_254_0;
float* inception3_Constant_227_0;
float* inception3_Constant_228_0;
float* inception3_Constant_231_0;
float* inception3_Constant_230_0;
float* inception3_Constant_229_0;
float* inception3_Constant_232_0;
float* inception3_Constant_233_0;
float* inception3_Constant_236_0;
float* inception3_Constant_235_0;
float* inception3_Constant_234_0;
float* inception3_Constant_237_0;
float* inception3_Constant_238_0;
float* inception3_Constant_241_0;
float* inception3_Constant_240_0;
float* inception3_Constant_239_0;
float* inception3_Constant_242_0;
float* inception3_Constant_243_0;
float* inception3_Constant_246_0;
float* inception3_Constant_245_0;
float* inception3_Constant_244_0;
float* inception3_Constant_247_0;
float* inception3_Constant_248_0;
float* inception3_Constant_251_0;
float* inception3_Constant_250_0;
float* inception3_Constant_249_0;
float* inception3_Constant_212_0;
float* inception3_Constant_213_0;
float* inception3_Constant_216_0;
float* inception3_Constant_215_0;
float* inception3_Constant_214_0;
float* inception3_Constant_217_0;
float* inception3_Constant_218_0;
float* inception3_Constant_221_0;
float* inception3_Constant_220_0;
float* inception3_Constant_219_0;
float* inception3_Constant_222_0;
float* inception3_Constant_223_0;
float* inception3_Constant_226_0;
float* inception3_Constant_225_0;
float* inception3_Constant_224_0;
float* inception3_Constant_207_0;
float* inception3_Constant_208_0;
float* inception3_Constant_211_0;
float* inception3_Constant_210_0;
float* inception3_Constant_209_0;
float* inception3_Constant_303_0;
float* inception3_Constant_304_0;
float* inception3_Constant_307_0;
float* inception3_Constant_306_0;
float* inception3_Constant_305_0;
float* inception3_Constant_278_0;
float* inception3_Constant_279_0;
float* inception3_Constant_282_0;
float* inception3_Constant_281_0;
float* inception3_Constant_280_0;
float* inception3_Constant_283_0;
float* inception3_Constant_284_0;
float* inception3_Constant_287_0;
float* inception3_Constant_286_0;
float* inception3_Constant_285_0;
float* inception3_Constant_288_0;
float* inception3_Constant_289_0;
float* inception3_Constant_292_0;
float* inception3_Constant_291_0;
float* inception3_Constant_290_0;
float* inception3_Constant_293_0;
float* inception3_Constant_294_0;
float* inception3_Constant_297_0;
float* inception3_Constant_296_0;
float* inception3_Constant_295_0;
float* inception3_Constant_298_0;
float* inception3_Constant_299_0;
float* inception3_Constant_302_0;
float* inception3_Constant_301_0;
float* inception3_Constant_300_0;
float* inception3_Constant_263_0;
float* inception3_Constant_264_0;
float* inception3_Constant_267_0;
float* inception3_Constant_266_0;
float* inception3_Constant_265_0;
float* inception3_Constant_268_0;
float* inception3_Constant_269_0;
float* inception3_Constant_272_0;
float* inception3_Constant_271_0;
float* inception3_Constant_270_0;
float* inception3_Constant_273_0;
float* inception3_Constant_274_0;
float* inception3_Constant_277_0;
float* inception3_Constant_276_0;
float* inception3_Constant_275_0;
float* inception3_Constant_258_0;
float* inception3_Constant_259_0;
float* inception3_Constant_262_0;
float* inception3_Constant_261_0;
float* inception3_Constant_260_0;
float* inception3_Constant_354_0;
float* inception3_Constant_355_0;
float* inception3_Constant_358_0;
float* inception3_Constant_357_0;
float* inception3_Constant_356_0;
float* inception3_Constant_329_0;
float* inception3_Constant_330_0;
float* inception3_Constant_333_0;
float* inception3_Constant_332_0;
float* inception3_Constant_331_0;
float* inception3_Constant_334_0;
float* inception3_Constant_335_0;
float* inception3_Constant_338_0;
float* inception3_Constant_337_0;
float* inception3_Constant_336_0;
float* inception3_Constant_339_0;
float* inception3_Constant_340_0;
float* inception3_Constant_343_0;
float* inception3_Constant_342_0;
float* inception3_Constant_341_0;
float* inception3_Constant_344_0;
float* inception3_Constant_345_0;
float* inception3_Constant_348_0;
float* inception3_Constant_347_0;
float* inception3_Constant_346_0;
float* inception3_Constant_349_0;
float* inception3_Constant_350_0;
float* inception3_Constant_353_0;
float* inception3_Constant_352_0;
float* inception3_Constant_351_0;
float* inception3_Constant_314_0;
float* inception3_Constant_315_0;
float* inception3_Constant_318_0;
float* inception3_Constant_317_0;
float* inception3_Constant_316_0;
float* inception3_Constant_319_0;
float* inception3_Constant_320_0;
float* inception3_Constant_323_0;
float* inception3_Constant_322_0;
float* inception3_Constant_321_0;
float* inception3_Constant_324_0;
float* inception3_Constant_325_0;
float* inception3_Constant_328_0;
float* inception3_Constant_327_0;
float* inception3_Constant_326_0;
float* inception3_Constant_309_0;
float* inception3_Constant_310_0;
float* inception3_Constant_313_0;
float* inception3_Constant_312_0;
float* inception3_Constant_311_0;
float* inception3_Constant_370_0;
float* inception3_Constant_374_0;
float* inception3_Constant_373_0;
float* inception3_Constant_372_0;
float* inception3_Constant_371_0;
float* inception3_Constant_375_0;
float* inception3_Constant_379_0;
float* inception3_Constant_378_0;
float* inception3_Constant_377_0;
float* inception3_Constant_376_0;
float* inception3_Constant_380_0;
float* inception3_Constant_384_0;
float* inception3_Constant_383_0;
float* inception3_Constant_382_0;
float* inception3_Constant_381_0;
float* inception3_Constant_385_0;
float* inception3_Constant_389_0;
float* inception3_Constant_388_0;
float* inception3_Constant_387_0;
float* inception3_Constant_386_0;
float* inception3_Constant_360_0;
float* inception3_Constant_364_0;
float* inception3_Constant_363_0;
float* inception3_Constant_362_0;
float* inception3_Constant_361_0;
float* inception3_Constant_365_0;
float* inception3_Constant_369_0;
float* inception3_Constant_368_0;
float* inception3_Constant_367_0;
float* inception3_Constant_366_0;
float* inception3_Constant_431_0;
float* inception3_Constant_435_0;
float* inception3_Constant_434_0;
float* inception3_Constant_433_0;
float* inception3_Constant_432_0;
float* inception3_Constant_411_0;
float* inception3_Constant_415_0;
float* inception3_Constant_414_0;
float* inception3_Constant_413_0;
float* inception3_Constant_412_0;
float* inception3_Constant_416_0;
float* inception3_Constant_420_0;
float* inception3_Constant_419_0;
float* inception3_Constant_418_0;
float* inception3_Constant_417_0;
float* inception3_Constant_426_0;
float* inception3_Constant_430_0;
float* inception3_Constant_429_0;
float* inception3_Constant_428_0;
float* inception3_Constant_427_0;
float* inception3_Constant_421_0;
float* inception3_Constant_425_0;
float* inception3_Constant_424_0;
float* inception3_Constant_423_0;
float* inception3_Constant_422_0;
float* inception3_Constant_396_0;
float* inception3_Constant_400_0;
float* inception3_Constant_399_0;
float* inception3_Constant_398_0;
float* inception3_Constant_397_0;
float* inception3_Constant_406_0;
float* inception3_Constant_410_0;
float* inception3_Constant_409_0;
float* inception3_Constant_408_0;
float* inception3_Constant_407_0;
float* inception3_Constant_401_0;
float* inception3_Constant_405_0;
float* inception3_Constant_404_0;
float* inception3_Constant_403_0;
float* inception3_Constant_402_0;
float* inception3_Constant_391_0;
float* inception3_Constant_395_0;
float* inception3_Constant_394_0;
float* inception3_Constant_393_0;
float* inception3_Constant_392_0;
float* inception3_Constant_477_0;
float* inception3_Constant_478_0;
float* inception3_Constant_481_0;
float* inception3_Constant_480_0;
float* inception3_Constant_479_0;
float* inception3_Constant_457_0;
float* inception3_Constant_458_0;
float* inception3_Constant_461_0;
float* inception3_Constant_460_0;
float* inception3_Constant_459_0;
float* inception3_Constant_462_0;
float* inception3_Constant_463_0;
float* inception3_Constant_466_0;
float* inception3_Constant_465_0;
float* inception3_Constant_464_0;
float* inception3_Constant_472_0;
float* inception3_Constant_473_0;
float* inception3_Constant_476_0;
float* inception3_Constant_475_0;
float* inception3_Constant_474_0;
float* inception3_Constant_467_0;
float* inception3_Constant_468_0;
float* inception3_Constant_471_0;
float* inception3_Constant_470_0;
float* inception3_Constant_469_0;
float* inception3_Constant_442_0;
float* inception3_Constant_443_0;
float* inception3_Constant_446_0;
float* inception3_Constant_445_0;
float* inception3_Constant_444_0;
float* inception3_Constant_452_0;
float* inception3_Constant_453_0;
float* inception3_Constant_456_0;
float* inception3_Constant_455_0;
float* inception3_Constant_454_0;
float* inception3_Constant_447_0;
float* inception3_Constant_448_0;
float* inception3_Constant_451_0;
float* inception3_Constant_450_0;
float* inception3_Constant_449_0;
float* inception3_Constant_437_0;
float* inception3_Constant_438_0;
float* inception3_Constant_441_0;
float* inception3_Constant_440_0;
float* inception3_Constant_439_0;
float* inception3_Constant_485_0;
// Node name:	Convolution_685
// Description:	Convolution
// Input:
//	- name: inception3_Relu_682_0	type: float	shape: Shape{64, 160, 17, 17}
//	- name: inception3_Reshape_684_0	type: float	shape: Shape{192, 160, 7, 1}
// Output:
//	- name: inception3_Convolution_685_0	type: float	shape: Shape{64, 192, 17, 17}
void Convolution_float_float_float_cuda_lib_Convolution_685(cudnnHandle_t cudnn_handle, float* input0, float* input1, float* output0)
{
    cudnnTensorDescriptor_t tensor_desc_0;
    CUDNN_SAFE_CALL(cudnnCreateTensorDescriptor(&tensor_desc_0));
    CUDNN_SAFE_CALL(cudnnSetTensor4dDescriptor(tensor_desc_0, CUDNN_TENSOR_NCHW, CUDNN_DATA_FLOAT, 64, 160, 17, 17));
    cudnnTensorDescriptor_t tensor_desc_1;
    CUDNN_SAFE_CALL(cudnnCreateTensorDescriptor(&tensor_desc_1));
    CUDNN_SAFE_CALL(cudnnSetTensor4dDescriptor(tensor_desc_1, CUDNN_TENSOR_NCHW, CUDNN_DATA_FLOAT, 64, 192, 17, 17));
    cudnnFilterDescriptor_t filter_desc;
    CUDNN_SAFE_CALL(cudnnCreateFilterDescriptor(&filter_desc));
    CUDNN_SAFE_CALL(cudnnSetFilter4dDescriptor(filter_desc, CUDNN_DATA_FLOAT, CUDNN_TENSOR_NCHW, 192, 160, 7, 1));
    cudnnConvolutionDescriptor_t conv_desc;
    CUDNN_SAFE_CALL(cudnnCreateConvolutionDescriptor(&conv_desc));
    CUDNN_SAFE_CALL(cudnnSetConvolution2dDescriptor(conv_desc, 3, 0, 1, 1, 1, 1, CUDNN_CROSS_CORRELATION, CUDNN_DATA_FLOAT));

    static bool selected_algo = true;
    static cudnnConvolutionFwdAlgo_t conv_fwd_algo = CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM;

    if (!selected_algo) {
        int num_algos;
        int max_algos = 0;
        // cudnnGetConvolutionForwardAlgorithm_v7;
        CUDNN_SAFE_CALL(
            cudnnGetConvolutionForwardAlgorithmMaxCount(cudnn_handle, &max_algos));
        std::vector<cudnnConvolutionFwdAlgoPerf_t> results(max_algos);
        CUDNN_SAFE_CALL(cudnnFindConvolutionForwardAlgorithm(cudnn_handle,
                                                tensor_desc_0,
                                                filter_desc,
                                                conv_desc,
                                                tensor_desc_1,
                                                static_cast<int>(results.size()),
                                                &num_algos,
                                                results.data()));
        results.resize(num_algos);
        for (size_t i = 0; i != results.size(); ++i) {
            cudnnConvolutionFwdAlgoPerf_t const& result = results[i];
            if (result.status == CUDNN_STATUS_SUCCESS) {
                conv_fwd_algo = result.algo;
                break;
            }
        }
        selected_algo = true;
    }
    const float alpha = 1.0;
    const float beta = 0.0;
    static void *workspace_ptr_0 = NULL;
    static size_t workspace_size_in_bytes = 0;
    if (!workspace_ptr_0)
    {
        CUDNN_SAFE_CALL(cudnnGetConvolutionForwardWorkspaceSize(cudnn_handle, tensor_desc_0, filter_desc, conv_desc, tensor_desc_1, conv_fwd_algo, &workspace_size_in_bytes));
        CUDA_SAFE_CALL(cudaMalloc(&workspace_ptr_0, workspace_size_in_bytes));
    }
    CUDNN_SAFE_CALL(cudnnConvolutionForward(cudnn_handle, &alpha, tensor_desc_0, input0,filter_desc, input1, conv_desc, conv_fwd_algo, workspace_ptr_0, workspace_size_in_bytes, &beta, tensor_desc_1, output0));
    CUDNN_SAFE_CALL(cudnnDestroyTensorDescriptor(tensor_desc_0));
    CUDNN_SAFE_CALL(cudnnDestroyTensorDescriptor(tensor_desc_1));
    CUDNN_SAFE_CALL(cudnnDestroyFilterDescriptor(filter_desc));
    CUDNN_SAFE_CALL(cudnnDestroyConvolutionDescriptor(conv_desc));

}
// Node name:	BatchNormInference_506
// Description:	BatchNormInference
// Input:
//	- name: inception3_Constant_23_0	type: float	shape: Shape{192}
//	- name: inception3_Constant_24_0	type: float	shape: Shape{192}
//	- name: inception3_Convolution_505_0	type: float	shape: Shape{64, 192, 71, 71}
//	- name: inception3_Constant_25_0	type: float	shape: Shape{192}
//	- name: inception3_Constant_26_0	type: float	shape: Shape{192}
// Output:
//	- name: inception3_BatchNormInference_506_0	type: float	shape: Shape{64, 192, 71, 71}
extern "C" __launch_bounds__(512) __global__ void inception3_BatchNormInference_float_float_float_float_float_float_cuda_BatchNormInference_506(float* input0, float* input1, float* input2, float* input3, float* input4, float* output0)
{
    const int st = blockIdx.x * 71 * 71;
    const int c_id = blockIdx.x % 192;
    #pragma unroll 1
    for (int i = threadIdx.x; i < 71 * 71; i += blockDim.x)
    {
        output0[st + i] = (input1[c_id] + (input0[c_id] * (input2[st + i] - input3[c_id]) / sqrtf(0.001 + input4[c_id])));
    }

}
extern void inception3_BatchNormInference_float_float_float_float_float_float_cuda_BatchNormInference_506_Call(const dim3 &grids, const dim3 &blocks, unsigned mem, cudaStream_t stream, float* input0, float* input1, float* input2, float* input3, float* input4, float* output0) {
    inception3_BatchNormInference_float_float_float_float_float_float_cuda_BatchNormInference_506<<<grids, blocks, mem, stream>>>(input0, input1, input2, input3, input4, output0);
}
// Node name:	Convolution_600
// Description:	Convolution
// Input:
//	- name: inception3_Concat_598_0	type: float	shape: Shape{64, 288, 35, 35}
//	- name: inception3_Reshape_599_0	type: float	shape: Shape{384, 288, 3, 3}
// Output:
//	- name: inception3_Convolution_600_0	type: float	shape: Shape{64, 384, 17, 17}
void Convolution_float_float_float_cuda_lib_Convolution_600(cudnnHandle_t cudnn_handle, float* input0, float* input1, float* output0)
{
    cudnnTensorDescriptor_t tensor_desc_0;
    CUDNN_SAFE_CALL(cudnnCreateTensorDescriptor(&tensor_desc_0));
    CUDNN_SAFE_CALL(cudnnSetTensor4dDescriptor(tensor_desc_0, CUDNN_TENSOR_NCHW, CUDNN_DATA_FLOAT, 64, 288, 35, 35));
    cudnnTensorDescriptor_t tensor_desc_1;
    CUDNN_SAFE_CALL(cudnnCreateTensorDescriptor(&tensor_desc_1));
    CUDNN_SAFE_CALL(cudnnSetTensor4dDescriptor(tensor_desc_1, CUDNN_TENSOR_NCHW, CUDNN_DATA_FLOAT, 64, 384, 17, 17));
    cudnnFilterDescriptor_t filter_desc;
    CUDNN_SAFE_CALL(cudnnCreateFilterDescriptor(&filter_desc));
    CUDNN_SAFE_CALL(cudnnSetFilter4dDescriptor(filter_desc, CUDNN_DATA_FLOAT, CUDNN_TENSOR_NCHW, 384, 288, 3, 3));
    cudnnConvolutionDescriptor_t conv_desc;
    CUDNN_SAFE_CALL(cudnnCreateConvolutionDescriptor(&conv_desc));
    CUDNN_SAFE_CALL(cudnnSetConvolution2dDescriptor(conv_desc, 0, 0, 2, 2, 1, 1, CUDNN_CROSS_CORRELATION, CUDNN_DATA_FLOAT));

    static bool selected_algo = true;
    static cudnnConvolutionFwdAlgo_t conv_fwd_algo = CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM;

    if (!selected_algo) {
        int num_algos;
        int max_algos = 0;
        // cudnnGetConvolutionForwardAlgorithm_v7;
        CUDNN_SAFE_CALL(
            cudnnGetConvolutionForwardAlgorithmMaxCount(cudnn_handle, &max_algos));
        std::vector<cudnnConvolutionFwdAlgoPerf_t> results(max_algos);
        CUDNN_SAFE_CALL(cudnnFindConvolutionForwardAlgorithm(cudnn_handle,
                                                tensor_desc_0,
                                                filter_desc,
                                                conv_desc,
                                                tensor_desc_1,
                                                static_cast<int>(results.size()),
                                                &num_algos,
                                                results.data()));
        results.resize(num_algos);
        for (size_t i = 0; i != results.size(); ++i) {
            cudnnConvolutionFwdAlgoPerf_t const& result = results[i];
            if (result.status == CUDNN_STATUS_SUCCESS) {
                conv_fwd_algo = result.algo;
                break;
            }
        }
        selected_algo = true;
    }
    const float alpha = 1.0;
    const float beta = 0.0;
    static void *workspace_ptr_0 = NULL;
    static size_t workspace_size_in_bytes = 0;
    if (!workspace_ptr_0)
    {
        CUDNN_SAFE_CALL(cudnnGetConvolutionForwardWorkspaceSize(cudnn_handle, tensor_desc_0, filter_desc, conv_desc, tensor_desc_1, conv_fwd_algo, &workspace_size_in_bytes));
        CUDA_SAFE_CALL(cudaMalloc(&workspace_ptr_0, workspace_size_in_bytes));
    }
    CUDNN_SAFE_CALL(cudnnConvolutionForward(cudnn_handle, &alpha, tensor_desc_0, input0,filter_desc, input1, conv_desc, conv_fwd_algo, workspace_ptr_0, workspace_size_in_bytes, &beta, tensor_desc_1, output0));
    CUDNN_SAFE_CALL(cudnnDestroyTensorDescriptor(tensor_desc_0));
    CUDNN_SAFE_CALL(cudnnDestroyTensorDescriptor(tensor_desc_1));
    CUDNN_SAFE_CALL(cudnnDestroyFilterDescriptor(filter_desc));
    CUDNN_SAFE_CALL(cudnnDestroyConvolutionDescriptor(conv_desc));

}
// Node name:	Concat_658
// Description:	Concat
// Input:
//	- name: inception3_Relu_629_0	type: float	shape: Shape{64, 192, 17, 17}
//	- name: inception3_Relu_648_0	type: float	shape: Shape{64, 192, 17, 17}
//	- name: inception3_Relu_657_0	type: float	shape: Shape{64, 192, 17, 17}
//	- name: inception3_Relu_637_0	type: float	shape: Shape{64, 192, 17, 17}
// Output:
//	- name: inception3_Concat_658_0	type: float	shape: Shape{64, 768, 17, 17}
extern "C" __launch_bounds__(512) __global__ void inception3_Concat_float_float_float_float_float_cuda_Concat_658(float* input0, float* input1, float* input2, float* input3, float* output0)
{
    uint32_t inputs_strides[] = {55488, 55488, 55488, 55488};
    uint32_t tid = blockIdx.x * blockDim.x + threadIdx.x;
    if(tid < 14204928)
    {
        uint32_t block_id = tid / 221952;
        uint32_t block_idx = tid % 221952;
        uint32_t output_idx = block_id * 221952 + block_idx;
        if(block_idx < inputs_strides[0])
        {
            output0[output_idx] = input0[block_id * inputs_strides[0] + block_idx];
            return;
        }
        block_idx -= inputs_strides[0];
        if(block_idx < inputs_strides[1])
        {
            output0[output_idx] = input1[block_id * inputs_strides[1] + block_idx];
            return;
        }
        block_idx -= inputs_strides[1];
        if(block_idx < inputs_strides[2])
        {
            output0[output_idx] = input2[block_id * inputs_strides[2] + block_idx];
            return;
        }
        block_idx -= inputs_strides[2];
        if(block_idx < inputs_strides[3])
        {
            output0[output_idx] = input3[block_id * inputs_strides[3] + block_idx];
            return;
        }
        block_idx -= inputs_strides[3];
    }

}
extern void inception3_Concat_float_float_float_float_float_cuda_Concat_658_Call(const dim3 &grids, const dim3 &blocks, unsigned mem, cudaStream_t stream, float* input0, float* input1, float* input2, float* input3, float* output0) {
    inception3_Concat_float_float_float_float_float_cuda_Concat_658<<<grids, blocks, mem, stream>>>(input0, input1, input2, input3, output0);
}
// Node name:	Constant_350
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_350_0	type: float	shape: Shape{192}
void inception3_Constant_float_cuda_Constant_350(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_350_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_350_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[768];
    bin_file.read(tmp_mem, 768);
    cudaMemcpyAsync(output0, tmp_mem, 768, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_163
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_163_0	type: float	shape: Shape{128}
void inception3_Constant_float_cuda_Constant_163(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_163_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_163_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[512];
    bin_file.read(tmp_mem, 512);
    cudaMemcpyAsync(output0, tmp_mem, 512, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_7
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_7_0	type: float	shape: Shape{3, 3, 32, 32}
void inception3_Constant_float_cuda_Constant_7(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_7_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_7_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[36864];
    bin_file.read(tmp_mem, 36864);
    cudaMemcpyAsync(output0, tmp_mem, 36864, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_186
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_186_0	type: float	shape: Shape{1, 7, 128, 128}
void inception3_Constant_float_cuda_Constant_186(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_186_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_186_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[458752];
    bin_file.read(tmp_mem, 458752);
    cudaMemcpyAsync(output0, tmp_mem, 458752, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_345
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_345_0	type: float	shape: Shape{192}
void inception3_Constant_float_cuda_Constant_345(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_345_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_345_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[768];
    bin_file.read(tmp_mem, 768);
    cudaMemcpyAsync(output0, tmp_mem, 768, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_89
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_89_0	type: float	shape: Shape{96}
void inception3_Constant_float_cuda_Constant_89(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_89_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_89_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[384];
    bin_file.read(tmp_mem, 384);
    cudaMemcpyAsync(output0, tmp_mem, 384, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_74
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_74_0	type: float	shape: Shape{64}
void inception3_Constant_float_cuda_Constant_74(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_74_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_74_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[256];
    bin_file.read(tmp_mem, 256);
    cudaMemcpyAsync(output0, tmp_mem, 256, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_162
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_162_0	type: float	shape: Shape{128}
void inception3_Constant_float_cuda_Constant_162(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_162_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_162_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[512];
    bin_file.read(tmp_mem, 512);
    cudaMemcpyAsync(output0, tmp_mem, 512, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_4
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_4_0	type: float	shape: Shape{32}
void inception3_Constant_float_cuda_Constant_4(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_4_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_4_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[128];
    bin_file.read(tmp_mem, 128);
    cudaMemcpyAsync(output0, tmp_mem, 128, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_83
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_83_0	type: float	shape: Shape{3, 3, 64, 96}
void inception3_Constant_float_cuda_Constant_83(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_83_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_83_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[221184];
    bin_file.read(tmp_mem, 221184);
    cudaMemcpyAsync(output0, tmp_mem, 221184, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_383
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_383_0	type: float	shape: Shape{192}
void inception3_Constant_float_cuda_Constant_383(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_383_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_383_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[768];
    bin_file.read(tmp_mem, 768);
    cudaMemcpyAsync(output0, tmp_mem, 768, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_280
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_280_0	type: float	shape: Shape{160}
void inception3_Constant_float_cuda_Constant_280(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_280_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_280_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[640];
    bin_file.read(tmp_mem, 640);
    cudaMemcpyAsync(output0, tmp_mem, 640, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_64
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_64_0	type: float	shape: Shape{64}
void inception3_Constant_float_cuda_Constant_64(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_64_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_64_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[256];
    bin_file.read(tmp_mem, 256);
    cudaMemcpyAsync(output0, tmp_mem, 256, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_123
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_123_0	type: float	shape: Shape{96}
void inception3_Constant_float_cuda_Constant_123(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_123_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_123_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[384];
    bin_file.read(tmp_mem, 384);
    cudaMemcpyAsync(output0, tmp_mem, 384, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_100
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_100_0	type: float	shape: Shape{64}
void inception3_Constant_float_cuda_Constant_100(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_100_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_100_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[256];
    bin_file.read(tmp_mem, 256);
    cudaMemcpyAsync(output0, tmp_mem, 256, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_53
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_53_0	type: float	shape: Shape{96}
void inception3_Constant_float_cuda_Constant_53(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_53_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_53_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[384];
    bin_file.read(tmp_mem, 384);
    cudaMemcpyAsync(output0, tmp_mem, 384, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_168
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_168_0	type: float	shape: Shape{128}
void inception3_Constant_float_cuda_Constant_168(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_168_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_168_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[512];
    bin_file.read(tmp_mem, 512);
    cudaMemcpyAsync(output0, tmp_mem, 512, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_157
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_157_0	type: float	shape: Shape{192}
void inception3_Constant_float_cuda_Constant_157(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_157_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_157_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[768];
    bin_file.read(tmp_mem, 768);
    cudaMemcpyAsync(output0, tmp_mem, 768, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_148
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_148_0	type: float	shape: Shape{96}
void inception3_Constant_float_cuda_Constant_148(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_148_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_148_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[384];
    bin_file.read(tmp_mem, 384);
    cudaMemcpyAsync(output0, tmp_mem, 384, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_13
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_13_0	type: float	shape: Shape{64}
void inception3_Constant_float_cuda_Constant_13(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_13_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_13_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[256];
    bin_file.read(tmp_mem, 256);
    cudaMemcpyAsync(output0, tmp_mem, 256, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_202
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_202_0	type: float	shape: Shape{192}
void inception3_Constant_float_cuda_Constant_202(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_202_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_202_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[768];
    bin_file.read(tmp_mem, 768);
    cudaMemcpyAsync(output0, tmp_mem, 768, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_167
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_167_0	type: float	shape: Shape{128}
void inception3_Constant_float_cuda_Constant_167(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_167_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_167_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[512];
    bin_file.read(tmp_mem, 512);
    cudaMemcpyAsync(output0, tmp_mem, 512, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_40
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_40_0	type: float	shape: Shape{64}
void inception3_Constant_float_cuda_Constant_40(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_40_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_40_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[256];
    bin_file.read(tmp_mem, 256);
    cudaMemcpyAsync(output0, tmp_mem, 256, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_55
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_55_0	type: float	shape: Shape{96}
void inception3_Constant_float_cuda_Constant_55(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_55_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_55_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[384];
    bin_file.read(tmp_mem, 384);
    cudaMemcpyAsync(output0, tmp_mem, 384, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_68
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_68_0	type: float	shape: Shape{1, 1, 256, 48}
void inception3_Constant_float_cuda_Constant_68(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_68_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_68_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[49152];
    bin_file.read(tmp_mem, 49152);
    cudaMemcpyAsync(output0, tmp_mem, 49152, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_50
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_50_0	type: float	shape: Shape{96}
void inception3_Constant_float_cuda_Constant_50(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_50_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_50_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[384];
    bin_file.read(tmp_mem, 384);
    cudaMemcpyAsync(output0, tmp_mem, 384, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_48
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_48_0	type: float	shape: Shape{96}
void inception3_Constant_float_cuda_Constant_48(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_48_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_48_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[384];
    bin_file.read(tmp_mem, 384);
    cudaMemcpyAsync(output0, tmp_mem, 384, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_49
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_49_0	type: float	shape: Shape{96}
void inception3_Constant_float_cuda_Constant_49(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_49_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_49_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[384];
    bin_file.read(tmp_mem, 384);
    cudaMemcpyAsync(output0, tmp_mem, 384, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_331
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_331_0	type: float	shape: Shape{192}
void inception3_Constant_float_cuda_Constant_331(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_331_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_331_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[768];
    bin_file.read(tmp_mem, 768);
    cudaMemcpyAsync(output0, tmp_mem, 768, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_377
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_377_0	type: float	shape: Shape{192}
void inception3_Constant_float_cuda_Constant_377(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_377_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_377_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[768];
    bin_file.read(tmp_mem, 768);
    cudaMemcpyAsync(output0, tmp_mem, 768, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_47
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_47_0	type: float	shape: Shape{3, 3, 64, 96}
void inception3_Constant_float_cuda_Constant_47(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_47_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_47_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[221184];
    bin_file.read(tmp_mem, 221184);
    cudaMemcpyAsync(output0, tmp_mem, 221184, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_96
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_96_0	type: float	shape: Shape{64}
void inception3_Constant_float_cuda_Constant_96(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_96_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_96_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[256];
    bin_file.read(tmp_mem, 256);
    cudaMemcpyAsync(output0, tmp_mem, 256, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_272
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_272_0	type: float	shape: Shape{160}
void inception3_Constant_float_cuda_Constant_272(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_272_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_272_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[640];
    bin_file.read(tmp_mem, 640);
    cudaMemcpyAsync(output0, tmp_mem, 640, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_80
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_80_0	type: float	shape: Shape{64}
void inception3_Constant_float_cuda_Constant_80(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_80_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_80_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[256];
    bin_file.read(tmp_mem, 256);
    cudaMemcpyAsync(output0, tmp_mem, 256, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_5
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_5_0	type: float	shape: Shape{32}
void inception3_Constant_float_cuda_Constant_5(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_5_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_5_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[128];
    bin_file.read(tmp_mem, 128);
    cudaMemcpyAsync(output0, tmp_mem, 128, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_221
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_221_0	type: float	shape: Shape{160}
void inception3_Constant_float_cuda_Constant_221(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_221_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_221_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[640];
    bin_file.read(tmp_mem, 640);
    cudaMemcpyAsync(output0, tmp_mem, 640, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_122
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_122_0	type: float	shape: Shape{96}
void inception3_Constant_float_cuda_Constant_122(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_122_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_122_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[384];
    bin_file.read(tmp_mem, 384);
    cudaMemcpyAsync(output0, tmp_mem, 384, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_190
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_190_0	type: float	shape: Shape{128}
void inception3_Constant_float_cuda_Constant_190(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_190_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_190_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[512];
    bin_file.read(tmp_mem, 512);
    cudaMemcpyAsync(output0, tmp_mem, 512, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_25
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_25_0	type: float	shape: Shape{192}
void inception3_Constant_float_cuda_Constant_25(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_25_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_25_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[768];
    bin_file.read(tmp_mem, 768);
    cudaMemcpyAsync(output0, tmp_mem, 768, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_43
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_43_0	type: float	shape: Shape{64}
void inception3_Constant_float_cuda_Constant_43(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_43_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_43_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[256];
    bin_file.read(tmp_mem, 256);
    cudaMemcpyAsync(output0, tmp_mem, 256, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_395
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_395_0	type: float	shape: Shape{320}
void inception3_Constant_float_cuda_Constant_395(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_395_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_395_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[1280];
    bin_file.read(tmp_mem, 1280);
    cudaMemcpyAsync(output0, tmp_mem, 1280, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_236
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_236_0	type: float	shape: Shape{160}
void inception3_Constant_float_cuda_Constant_236(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_236_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_236_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[640];
    bin_file.read(tmp_mem, 640);
    cudaMemcpyAsync(output0, tmp_mem, 640, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_46
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_46_0	type: float	shape: Shape{64}
void inception3_Constant_float_cuda_Constant_46(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_46_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_46_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[256];
    bin_file.read(tmp_mem, 256);
    cudaMemcpyAsync(output0, tmp_mem, 256, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_320
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_320_0	type: float	shape: Shape{192}
void inception3_Constant_float_cuda_Constant_320(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_320_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_320_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[768];
    bin_file.read(tmp_mem, 768);
    cudaMemcpyAsync(output0, tmp_mem, 768, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_286
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_286_0	type: float	shape: Shape{160}
void inception3_Constant_float_cuda_Constant_286(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_286_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_286_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[640];
    bin_file.read(tmp_mem, 640);
    cudaMemcpyAsync(output0, tmp_mem, 640, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_82
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_82_0	type: float	shape: Shape{64}
void inception3_Constant_float_cuda_Constant_82(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_82_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_82_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[256];
    bin_file.read(tmp_mem, 256);
    cudaMemcpyAsync(output0, tmp_mem, 256, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_125
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_125_0	type: float	shape: Shape{96}
void inception3_Constant_float_cuda_Constant_125(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_125_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_125_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[384];
    bin_file.read(tmp_mem, 384);
    cudaMemcpyAsync(output0, tmp_mem, 384, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_42
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_42_0	type: float	shape: Shape{1, 1, 192, 64}
void inception3_Constant_float_cuda_Constant_42(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_42_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_42_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[49152];
    bin_file.read(tmp_mem, 49152);
    cudaMemcpyAsync(output0, tmp_mem, 49152, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_161
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_161_0	type: float	shape: Shape{1, 1, 768, 128}
void inception3_Constant_float_cuda_Constant_161(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_161_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_161_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[393216];
    bin_file.read(tmp_mem, 393216);
    cudaMemcpyAsync(output0, tmp_mem, 393216, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_351
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_351_0	type: float	shape: Shape{192}
void inception3_Constant_float_cuda_Constant_351(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_351_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_351_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[768];
    bin_file.read(tmp_mem, 768);
    cudaMemcpyAsync(output0, tmp_mem, 768, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_60
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_60_0	type: float	shape: Shape{32}
void inception3_Constant_float_cuda_Constant_60(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_60_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_60_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[128];
    bin_file.read(tmp_mem, 128);
    cudaMemcpyAsync(output0, tmp_mem, 128, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_33
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_33_0	type: float	shape: Shape{48}
void inception3_Constant_float_cuda_Constant_33(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_33_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_33_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[192];
    bin_file.read(tmp_mem, 192);
    cudaMemcpyAsync(output0, tmp_mem, 192, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_140
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_140_0	type: float	shape: Shape{1, 1, 288, 64}
void inception3_Constant_float_cuda_Constant_140(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_140_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_140_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[73728];
    bin_file.read(tmp_mem, 73728);
    cudaMemcpyAsync(output0, tmp_mem, 73728, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_94
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_94_0	type: float	shape: Shape{64}
void inception3_Constant_float_cuda_Constant_94(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_94_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_94_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[256];
    bin_file.read(tmp_mem, 256);
    cudaMemcpyAsync(output0, tmp_mem, 256, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_57
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_57_0	type: float	shape: Shape{1, 1, 192, 32}
void inception3_Constant_float_cuda_Constant_57(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_57_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_57_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[24576];
    bin_file.read(tmp_mem, 24576);
    cudaMemcpyAsync(output0, tmp_mem, 24576, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_340
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_340_0	type: float	shape: Shape{192}
void inception3_Constant_float_cuda_Constant_340(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_340_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_340_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[768];
    bin_file.read(tmp_mem, 768);
    cudaMemcpyAsync(output0, tmp_mem, 768, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_197
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_197_0	type: float	shape: Shape{192}
void inception3_Constant_float_cuda_Constant_197(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_197_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_197_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[768];
    bin_file.read(tmp_mem, 768);
    cudaMemcpyAsync(output0, tmp_mem, 768, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_37
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_37_0	type: float	shape: Shape{5, 5, 48, 64}
void inception3_Constant_float_cuda_Constant_37(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_37_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_37_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[307200];
    bin_file.read(tmp_mem, 307200);
    cudaMemcpyAsync(output0, tmp_mem, 307200, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_31
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_31_0	type: float	shape: Shape{64}
void inception3_Constant_float_cuda_Constant_31(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_31_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_31_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[256];
    bin_file.read(tmp_mem, 256);
    cudaMemcpyAsync(output0, tmp_mem, 256, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_66
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_66_0	type: float	shape: Shape{64}
void inception3_Constant_float_cuda_Constant_66(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_66_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_66_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[256];
    bin_file.read(tmp_mem, 256);
    cudaMemcpyAsync(output0, tmp_mem, 256, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_59
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_59_0	type: float	shape: Shape{32}
void inception3_Constant_float_cuda_Constant_59(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_59_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_59_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[128];
    bin_file.read(tmp_mem, 128);
    cudaMemcpyAsync(output0, tmp_mem, 128, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_432
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_432_0	type: float	shape: Shape{192}
void inception3_Constant_float_cuda_Constant_432(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_432_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_432_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[768];
    bin_file.read(tmp_mem, 768);
    cudaMemcpyAsync(output0, tmp_mem, 768, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_20
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_20_0	type: float	shape: Shape{80}
void inception3_Constant_float_cuda_Constant_20(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_20_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_20_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[320];
    bin_file.read(tmp_mem, 320);
    cudaMemcpyAsync(output0, tmp_mem, 320, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_207
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_207_0	type: float	shape: Shape{1, 1, 768, 192}
void inception3_Constant_float_cuda_Constant_207(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_207_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_207_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[589824];
    bin_file.read(tmp_mem, 589824);
    cudaMemcpyAsync(output0, tmp_mem, 589824, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_78
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_78_0	type: float	shape: Shape{1, 1, 256, 64}
void inception3_Constant_float_cuda_Constant_78(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_78_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_78_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[65536];
    bin_file.read(tmp_mem, 65536);
    cudaMemcpyAsync(output0, tmp_mem, 65536, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_24
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_24_0	type: float	shape: Shape{192}
void inception3_Constant_float_cuda_Constant_24(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_24_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_24_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[768];
    bin_file.read(tmp_mem, 768);
    cudaMemcpyAsync(output0, tmp_mem, 768, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_219
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_219_0	type: float	shape: Shape{160}
void inception3_Constant_float_cuda_Constant_219(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_219_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_219_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[640];
    bin_file.read(tmp_mem, 640);
    cudaMemcpyAsync(output0, tmp_mem, 640, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_290
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_290_0	type: float	shape: Shape{160}
void inception3_Constant_float_cuda_Constant_290(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_290_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_290_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[640];
    bin_file.read(tmp_mem, 640);
    cudaMemcpyAsync(output0, tmp_mem, 640, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_284
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_284_0	type: float	shape: Shape{160}
void inception3_Constant_float_cuda_Constant_284(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_284_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_284_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[640];
    bin_file.read(tmp_mem, 640);
    cudaMemcpyAsync(output0, tmp_mem, 640, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_226
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_226_0	type: float	shape: Shape{192}
void inception3_Constant_float_cuda_Constant_226(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_226_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_226_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[768];
    bin_file.read(tmp_mem, 768);
    cudaMemcpyAsync(output0, tmp_mem, 768, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_398
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_398_0	type: float	shape: Shape{384}
void inception3_Constant_float_cuda_Constant_398(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_398_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_398_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[1536];
    bin_file.read(tmp_mem, 1536);
    cudaMemcpyAsync(output0, tmp_mem, 1536, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_2
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_2_0	type: float	shape: Shape{3, 3, 3, 32}
void inception3_Constant_float_cuda_Constant_2(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_2_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_2_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[3456];
    bin_file.read(tmp_mem, 3456);
    cudaMemcpyAsync(output0, tmp_mem, 3456, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_327
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_327_0	type: float	shape: Shape{192}
void inception3_Constant_float_cuda_Constant_327(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_327_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_327_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[768];
    bin_file.read(tmp_mem, 768);
    cudaMemcpyAsync(output0, tmp_mem, 768, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_99
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_99_0	type: float	shape: Shape{1, 1, 288, 64}
void inception3_Constant_float_cuda_Constant_99(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_99_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_99_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[73728];
    bin_file.read(tmp_mem, 73728);
    cudaMemcpyAsync(output0, tmp_mem, 73728, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_326
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_326_0	type: float	shape: Shape{192}
void inception3_Constant_float_cuda_Constant_326(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_326_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_326_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[768];
    bin_file.read(tmp_mem, 768);
    cudaMemcpyAsync(output0, tmp_mem, 768, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_185
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_185_0	type: float	shape: Shape{128}
void inception3_Constant_float_cuda_Constant_185(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_185_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_185_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[512];
    bin_file.read(tmp_mem, 512);
    cudaMemcpyAsync(output0, tmp_mem, 512, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_251
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_251_0	type: float	shape: Shape{192}
void inception3_Constant_float_cuda_Constant_251(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_251_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_251_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[768];
    bin_file.read(tmp_mem, 768);
    cudaMemcpyAsync(output0, tmp_mem, 768, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_229
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_229_0	type: float	shape: Shape{160}
void inception3_Constant_float_cuda_Constant_229(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_229_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_229_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[640];
    bin_file.read(tmp_mem, 640);
    cudaMemcpyAsync(output0, tmp_mem, 640, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_139
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_139_0	type: float	shape: Shape{384}
void inception3_Constant_float_cuda_Constant_139(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_139_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_139_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[1536];
    bin_file.read(tmp_mem, 1536);
    cudaMemcpyAsync(output0, tmp_mem, 1536, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_27
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_27_0	type: float	shape: Shape{1, 1, 192, 64}
void inception3_Constant_float_cuda_Constant_27(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_27_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_27_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[49152];
    bin_file.read(tmp_mem, 49152);
    cudaMemcpyAsync(output0, tmp_mem, 49152, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_15
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_15_0	type: float	shape: Shape{64}
void inception3_Constant_float_cuda_Constant_15(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_15_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_15_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[256];
    bin_file.read(tmp_mem, 256);
    cudaMemcpyAsync(output0, tmp_mem, 256, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_310
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_310_0	type: float	shape: Shape{192}
void inception3_Constant_float_cuda_Constant_310(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_310_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_310_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[768];
    bin_file.read(tmp_mem, 768);
    cudaMemcpyAsync(output0, tmp_mem, 768, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_379
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_379_0	type: float	shape: Shape{192}
void inception3_Constant_float_cuda_Constant_379(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_379_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_379_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[768];
    bin_file.read(tmp_mem, 768);
    cudaMemcpyAsync(output0, tmp_mem, 768, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_228
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_228_0	type: float	shape: Shape{160}
void inception3_Constant_float_cuda_Constant_228(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_228_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_228_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[640];
    bin_file.read(tmp_mem, 640);
    cudaMemcpyAsync(output0, tmp_mem, 640, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_201
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_201_0	type: float	shape: Shape{1, 1, 768, 192}
void inception3_Constant_float_cuda_Constant_201(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_201_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_201_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[589824];
    bin_file.read(tmp_mem, 589824);
    cudaMemcpyAsync(output0, tmp_mem, 589824, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_6
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_6_0	type: float	shape: Shape{32}
void inception3_Constant_float_cuda_Constant_6(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_6_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_6_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[128];
    bin_file.read(tmp_mem, 128);
    cudaMemcpyAsync(output0, tmp_mem, 128, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_16
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_16_0	type: float	shape: Shape{64}
void inception3_Constant_float_cuda_Constant_16(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_16_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_16_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[256];
    bin_file.read(tmp_mem, 256);
    cudaMemcpyAsync(output0, tmp_mem, 256, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_261
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_261_0	type: float	shape: Shape{192}
void inception3_Constant_float_cuda_Constant_261(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_261_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_261_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[768];
    bin_file.read(tmp_mem, 768);
    cudaMemcpyAsync(output0, tmp_mem, 768, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_416
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_416_0	type: float	shape: Shape{3, 3, 448, 384}
void inception3_Constant_float_cuda_Constant_416(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_416_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_416_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[6193152];
    bin_file.read(tmp_mem, 6193152);
    cudaMemcpyAsync(output0, tmp_mem, 6193152, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_72
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_72_0	type: float	shape: Shape{48}
void inception3_Constant_float_cuda_Constant_72(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_72_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_72_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[192];
    bin_file.read(tmp_mem, 192);
    cudaMemcpyAsync(output0, tmp_mem, 192, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_198
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_198_0	type: float	shape: Shape{192}
void inception3_Constant_float_cuda_Constant_198(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_198_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_198_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[768];
    bin_file.read(tmp_mem, 768);
    cudaMemcpyAsync(output0, tmp_mem, 768, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_45
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_45_0	type: float	shape: Shape{64}
void inception3_Constant_float_cuda_Constant_45(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_45_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_45_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[256];
    bin_file.read(tmp_mem, 256);
    cudaMemcpyAsync(output0, tmp_mem, 256, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_56
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_56_0	type: float	shape: Shape{96}
void inception3_Constant_float_cuda_Constant_56(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_56_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_56_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[384];
    bin_file.read(tmp_mem, 384);
    cudaMemcpyAsync(output0, tmp_mem, 384, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_3
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_3_0	type: float	shape: Shape{32}
void inception3_Constant_float_cuda_Constant_3(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_3_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_3_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[128];
    bin_file.read(tmp_mem, 128);
    cudaMemcpyAsync(output0, tmp_mem, 128, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_192
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_192_0	type: float	shape: Shape{128}
void inception3_Constant_float_cuda_Constant_192(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_192_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_192_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[512];
    bin_file.read(tmp_mem, 512);
    cudaMemcpyAsync(output0, tmp_mem, 512, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_14
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_14_0	type: float	shape: Shape{64}
void inception3_Constant_float_cuda_Constant_14(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_14_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_14_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[256];
    bin_file.read(tmp_mem, 256);
    cudaMemcpyAsync(output0, tmp_mem, 256, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_196
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_196_0	type: float	shape: Shape{1, 7, 128, 192}
void inception3_Constant_float_cuda_Constant_196(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_196_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_196_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[688128];
    bin_file.read(tmp_mem, 688128);
    cudaMemcpyAsync(output0, tmp_mem, 688128, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_34
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_34_0	type: float	shape: Shape{48}
void inception3_Constant_float_cuda_Constant_34(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_34_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_34_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[192];
    bin_file.read(tmp_mem, 192);
    cudaMemcpyAsync(output0, tmp_mem, 192, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_469
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_469_0	type: float	shape: Shape{384}
void inception3_Constant_float_cuda_Constant_469(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_469_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_469_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[1536];
    bin_file.read(tmp_mem, 1536);
    cudaMemcpyAsync(output0, tmp_mem, 1536, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_384
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_384_0	type: float	shape: Shape{192}
void inception3_Constant_float_cuda_Constant_384(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_384_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_384_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[768];
    bin_file.read(tmp_mem, 768);
    cudaMemcpyAsync(output0, tmp_mem, 768, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_38
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_38_0	type: float	shape: Shape{64}
void inception3_Constant_float_cuda_Constant_38(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_38_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_38_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[256];
    bin_file.read(tmp_mem, 256);
    cudaMemcpyAsync(output0, tmp_mem, 256, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_17
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_17_0	type: float	shape: Shape{1, 1, 64, 80}
void inception3_Constant_float_cuda_Constant_17(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_17_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_17_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[20480];
    bin_file.read(tmp_mem, 20480);
    cudaMemcpyAsync(output0, tmp_mem, 20480, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_18
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_18_0	type: float	shape: Shape{80}
void inception3_Constant_float_cuda_Constant_18(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_18_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_18_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[320];
    bin_file.read(tmp_mem, 320);
    cudaMemcpyAsync(output0, tmp_mem, 320, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_246
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_246_0	type: float	shape: Shape{160}
void inception3_Constant_float_cuda_Constant_246(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_246_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_246_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[640];
    bin_file.read(tmp_mem, 640);
    cudaMemcpyAsync(output0, tmp_mem, 640, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_129
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_129_0	type: float	shape: Shape{1, 1, 288, 64}
void inception3_Constant_float_cuda_Constant_129(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_129_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_129_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[73728];
    bin_file.read(tmp_mem, 73728);
    cudaMemcpyAsync(output0, tmp_mem, 73728, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_304
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_304_0	type: float	shape: Shape{192}
void inception3_Constant_float_cuda_Constant_304(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_304_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_304_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[768];
    bin_file.read(tmp_mem, 768);
    cudaMemcpyAsync(output0, tmp_mem, 768, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_11
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_11_0	type: float	shape: Shape{32}
void inception3_Constant_float_cuda_Constant_11(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_11_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_11_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[128];
    bin_file.read(tmp_mem, 128);
    cudaMemcpyAsync(output0, tmp_mem, 128, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_480
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_480_0	type: float	shape: Shape{192}
void inception3_Constant_float_cuda_Constant_480(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_480_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_480_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[768];
    bin_file.read(tmp_mem, 768);
    cudaMemcpyAsync(output0, tmp_mem, 768, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_259
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_259_0	type: float	shape: Shape{192}
void inception3_Constant_float_cuda_Constant_259(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_259_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_259_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[768];
    bin_file.read(tmp_mem, 768);
    cudaMemcpyAsync(output0, tmp_mem, 768, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_44
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_44_0	type: float	shape: Shape{64}
void inception3_Constant_float_cuda_Constant_44(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_44_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_44_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[256];
    bin_file.read(tmp_mem, 256);
    cudaMemcpyAsync(output0, tmp_mem, 256, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_399
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_399_0	type: float	shape: Shape{384}
void inception3_Constant_float_cuda_Constant_399(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_399_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_399_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[1536];
    bin_file.read(tmp_mem, 1536);
    cudaMemcpyAsync(output0, tmp_mem, 1536, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_332
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_332_0	type: float	shape: Shape{192}
void inception3_Constant_float_cuda_Constant_332(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_332_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_332_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[768];
    bin_file.read(tmp_mem, 768);
    cudaMemcpyAsync(output0, tmp_mem, 768, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_39
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_39_0	type: float	shape: Shape{64}
void inception3_Constant_float_cuda_Constant_39(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_39_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_39_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[256];
    bin_file.read(tmp_mem, 256);
    cudaMemcpyAsync(output0, tmp_mem, 256, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_22
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_22_0	type: float	shape: Shape{3, 3, 80, 192}
void inception3_Constant_float_cuda_Constant_22(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_22_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_22_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[552960];
    bin_file.read(tmp_mem, 552960);
    cudaMemcpyAsync(output0, tmp_mem, 552960, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_58
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_58_0	type: float	shape: Shape{32}
void inception3_Constant_float_cuda_Constant_58(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_58_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_58_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[128];
    bin_file.read(tmp_mem, 128);
    cudaMemcpyAsync(output0, tmp_mem, 128, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_165
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_165_0	type: float	shape: Shape{128}
void inception3_Constant_float_cuda_Constant_165(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_165_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_165_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[512];
    bin_file.read(tmp_mem, 512);
    cudaMemcpyAsync(output0, tmp_mem, 512, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_21
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_21_0	type: float	shape: Shape{80}
void inception3_Constant_float_cuda_Constant_21(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_21_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_21_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[320];
    bin_file.read(tmp_mem, 320);
    cudaMemcpyAsync(output0, tmp_mem, 320, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_382
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_382_0	type: float	shape: Shape{192}
void inception3_Constant_float_cuda_Constant_382(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_382_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_382_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[768];
    bin_file.read(tmp_mem, 768);
    cudaMemcpyAsync(output0, tmp_mem, 768, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_169
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_169_0	type: float	shape: Shape{128}
void inception3_Constant_float_cuda_Constant_169(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_169_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_169_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[512];
    bin_file.read(tmp_mem, 512);
    cudaMemcpyAsync(output0, tmp_mem, 512, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_29
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_29_0	type: float	shape: Shape{64}
void inception3_Constant_float_cuda_Constant_29(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_29_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_29_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[256];
    bin_file.read(tmp_mem, 256);
    cudaMemcpyAsync(output0, tmp_mem, 256, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_205
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_205_0	type: float	shape: Shape{192}
void inception3_Constant_float_cuda_Constant_205(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_205_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_205_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[768];
    bin_file.read(tmp_mem, 768);
    cudaMemcpyAsync(output0, tmp_mem, 768, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_12
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_12_0	type: float	shape: Shape{3, 3, 32, 64}
void inception3_Constant_float_cuda_Constant_12(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_12_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_12_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[73728];
    bin_file.read(tmp_mem, 73728);
    cudaMemcpyAsync(output0, tmp_mem, 73728, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_178
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_178_0	type: float	shape: Shape{128}
void inception3_Constant_float_cuda_Constant_178(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_178_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_178_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[512];
    bin_file.read(tmp_mem, 512);
    cudaMemcpyAsync(output0, tmp_mem, 512, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_423
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_423_0	type: float	shape: Shape{384}
void inception3_Constant_float_cuda_Constant_423(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_423_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_423_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[1536];
    bin_file.read(tmp_mem, 1536);
    cudaMemcpyAsync(output0, tmp_mem, 1536, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_88
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_88_0	type: float	shape: Shape{3, 3, 96, 96}
void inception3_Constant_float_cuda_Constant_88(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_88_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_88_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[331776];
    bin_file.read(tmp_mem, 331776);
    cudaMemcpyAsync(output0, tmp_mem, 331776, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_317
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_317_0	type: float	shape: Shape{192}
void inception3_Constant_float_cuda_Constant_317(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_317_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_317_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[768];
    bin_file.read(tmp_mem, 768);
    cudaMemcpyAsync(output0, tmp_mem, 768, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_323
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_323_0	type: float	shape: Shape{192}
void inception3_Constant_float_cuda_Constant_323(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_323_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_323_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[768];
    bin_file.read(tmp_mem, 768);
    cudaMemcpyAsync(output0, tmp_mem, 768, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_133
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_133_0	type: float	shape: Shape{64}
void inception3_Constant_float_cuda_Constant_133(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_133_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_133_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[256];
    bin_file.read(tmp_mem, 256);
    cudaMemcpyAsync(output0, tmp_mem, 256, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_10
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_10_0	type: float	shape: Shape{32}
void inception3_Constant_float_cuda_Constant_10(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_10_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_10_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[128];
    bin_file.read(tmp_mem, 128);
    cudaMemcpyAsync(output0, tmp_mem, 128, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_36
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_36_0	type: float	shape: Shape{48}
void inception3_Constant_float_cuda_Constant_36(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_36_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_36_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[192];
    bin_file.read(tmp_mem, 192);
    cudaMemcpyAsync(output0, tmp_mem, 192, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_422
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_422_0	type: float	shape: Shape{384}
void inception3_Constant_float_cuda_Constant_422(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_422_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_422_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[1536];
    bin_file.read(tmp_mem, 1536);
    cudaMemcpyAsync(output0, tmp_mem, 1536, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_337
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_337_0	type: float	shape: Shape{192}
void inception3_Constant_float_cuda_Constant_337(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_337_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_337_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[768];
    bin_file.read(tmp_mem, 768);
    cudaMemcpyAsync(output0, tmp_mem, 768, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_51
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_51_0	type: float	shape: Shape{96}
void inception3_Constant_float_cuda_Constant_51(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_51_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_51_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[384];
    bin_file.read(tmp_mem, 384);
    cudaMemcpyAsync(output0, tmp_mem, 384, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_8
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_8_0	type: float	shape: Shape{32}
void inception3_Constant_float_cuda_Constant_8(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_8_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_8_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[128];
    bin_file.read(tmp_mem, 128);
    cudaMemcpyAsync(output0, tmp_mem, 128, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_179
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_179_0	type: float	shape: Shape{128}
void inception3_Constant_float_cuda_Constant_179(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_179_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_179_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[512];
    bin_file.read(tmp_mem, 512);
    cudaMemcpyAsync(output0, tmp_mem, 512, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_35
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_35_0	type: float	shape: Shape{48}
void inception3_Constant_float_cuda_Constant_35(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_35_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_35_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[192];
    bin_file.read(tmp_mem, 192);
    cudaMemcpyAsync(output0, tmp_mem, 192, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_417
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_417_0	type: float	shape: Shape{384}
void inception3_Constant_float_cuda_Constant_417(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_417_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_417_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[1536];
    bin_file.read(tmp_mem, 1536);
    cudaMemcpyAsync(output0, tmp_mem, 1536, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_465
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_465_0	type: float	shape: Shape{384}
void inception3_Constant_float_cuda_Constant_465(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_465_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_465_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[1536];
    bin_file.read(tmp_mem, 1536);
    cudaMemcpyAsync(output0, tmp_mem, 1536, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_458
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_458_0	type: float	shape: Shape{448}
void inception3_Constant_float_cuda_Constant_458(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_458_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_458_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[1792];
    bin_file.read(tmp_mem, 1792);
    cudaMemcpyAsync(output0, tmp_mem, 1792, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_54
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_54_0	type: float	shape: Shape{96}
void inception3_Constant_float_cuda_Constant_54(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_54_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_54_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[384];
    bin_file.read(tmp_mem, 384);
    cudaMemcpyAsync(output0, tmp_mem, 384, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_30
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_30_0	type: float	shape: Shape{64}
void inception3_Constant_float_cuda_Constant_30(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_30_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_30_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[256];
    bin_file.read(tmp_mem, 256);
    cudaMemcpyAsync(output0, tmp_mem, 256, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_102
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_102_0	type: float	shape: Shape{64}
void inception3_Constant_float_cuda_Constant_102(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_102_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_102_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[256];
    bin_file.read(tmp_mem, 256);
    cudaMemcpyAsync(output0, tmp_mem, 256, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_143
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_143_0	type: float	shape: Shape{64}
void inception3_Constant_float_cuda_Constant_143(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_143_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_143_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[256];
    bin_file.read(tmp_mem, 256);
    cudaMemcpyAsync(output0, tmp_mem, 256, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_447
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_447_0	type: float	shape: Shape{1, 3, 384, 384}
void inception3_Constant_float_cuda_Constant_447(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_447_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_447_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[1769472];
    bin_file.read(tmp_mem, 1769472);
    cudaMemcpyAsync(output0, tmp_mem, 1769472, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_380
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_380_0	type: float	shape: Shape{7, 1, 192, 192}
void inception3_Constant_float_cuda_Constant_380(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_380_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_380_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[1032192];
    bin_file.read(tmp_mem, 1032192);
    cudaMemcpyAsync(output0, tmp_mem, 1032192, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_391
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_391_0	type: float	shape: Shape{1, 1, 1280, 320}
void inception3_Constant_float_cuda_Constant_391(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_391_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_391_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[1638400];
    bin_file.read(tmp_mem, 1638400);
    cudaMemcpyAsync(output0, tmp_mem, 1638400, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_450
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_450_0	type: float	shape: Shape{384}
void inception3_Constant_float_cuda_Constant_450(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_450_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_450_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[1536];
    bin_file.read(tmp_mem, 1536);
    cudaMemcpyAsync(output0, tmp_mem, 1536, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_368
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_368_0	type: float	shape: Shape{320}
void inception3_Constant_float_cuda_Constant_368(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_368_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_368_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[1280];
    bin_file.read(tmp_mem, 1280);
    cudaMemcpyAsync(output0, tmp_mem, 1280, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_387
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_387_0	type: float	shape: Shape{192}
void inception3_Constant_float_cuda_Constant_387(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_387_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_387_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[768];
    bin_file.read(tmp_mem, 768);
    cudaMemcpyAsync(output0, tmp_mem, 768, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_441
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_441_0	type: float	shape: Shape{320}
void inception3_Constant_float_cuda_Constant_441(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_441_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_441_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[1280];
    bin_file.read(tmp_mem, 1280);
    cudaMemcpyAsync(output0, tmp_mem, 1280, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_405
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_405_0	type: float	shape: Shape{384}
void inception3_Constant_float_cuda_Constant_405(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_405_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_405_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[1536];
    bin_file.read(tmp_mem, 1536);
    cudaMemcpyAsync(output0, tmp_mem, 1536, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_176
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_176_0	type: float	shape: Shape{1, 1, 768, 128}
void inception3_Constant_float_cuda_Constant_176(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_176_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_176_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[393216];
    bin_file.read(tmp_mem, 393216);
    cudaMemcpyAsync(output0, tmp_mem, 393216, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_265
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_265_0	type: float	shape: Shape{160}
void inception3_Constant_float_cuda_Constant_265(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_265_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_265_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[640];
    bin_file.read(tmp_mem, 640);
    cudaMemcpyAsync(output0, tmp_mem, 640, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_364
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_364_0	type: float	shape: Shape{192}
void inception3_Constant_float_cuda_Constant_364(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_364_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_364_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[768];
    bin_file.read(tmp_mem, 768);
    cudaMemcpyAsync(output0, tmp_mem, 768, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_32
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_32_0	type: float	shape: Shape{1, 1, 192, 48}
void inception3_Constant_float_cuda_Constant_32(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_32_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_32_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[36864];
    bin_file.read(tmp_mem, 36864);
    cudaMemcpyAsync(output0, tmp_mem, 36864, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_263
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_263_0	type: float	shape: Shape{1, 1, 768, 160}
void inception3_Constant_float_cuda_Constant_263(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_263_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_263_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[491520];
    bin_file.read(tmp_mem, 491520);
    cudaMemcpyAsync(output0, tmp_mem, 491520, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_128
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_128_0	type: float	shape: Shape{96}
void inception3_Constant_float_cuda_Constant_128(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_128_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_128_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[384];
    bin_file.read(tmp_mem, 384);
    cudaMemcpyAsync(output0, tmp_mem, 384, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_314
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_314_0	type: float	shape: Shape{1, 1, 768, 192}
void inception3_Constant_float_cuda_Constant_314(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_314_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_314_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[589824];
    bin_file.read(tmp_mem, 589824);
    cudaMemcpyAsync(output0, tmp_mem, 589824, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_135
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_135_0	type: float	shape: Shape{3, 3, 288, 384}
void inception3_Constant_float_cuda_Constant_135(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_135_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_135_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[3981312];
    bin_file.read(tmp_mem, 3981312);
    cudaMemcpyAsync(output0, tmp_mem, 3981312, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_369
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_369_0	type: float	shape: Shape{320}
void inception3_Constant_float_cuda_Constant_369(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_369_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_369_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[1280];
    bin_file.read(tmp_mem, 1280);
    cudaMemcpyAsync(output0, tmp_mem, 1280, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_459
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_459_0	type: float	shape: Shape{448}
void inception3_Constant_float_cuda_Constant_459(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_459_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_459_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[1792];
    bin_file.read(tmp_mem, 1792);
    cudaMemcpyAsync(output0, tmp_mem, 1792, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_370
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_370_0	type: float	shape: Shape{1, 1, 768, 192}
void inception3_Constant_float_cuda_Constant_370(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_370_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_370_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[589824];
    bin_file.read(tmp_mem, 589824);
    cudaMemcpyAsync(output0, tmp_mem, 589824, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_385
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_385_0	type: float	shape: Shape{3, 3, 192, 192}
void inception3_Constant_float_cuda_Constant_385(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_385_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_385_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[1327104];
    bin_file.read(tmp_mem, 1327104);
    cudaMemcpyAsync(output0, tmp_mem, 1327104, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_460
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_460_0	type: float	shape: Shape{448}
void inception3_Constant_float_cuda_Constant_460(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_460_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_460_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[1792];
    bin_file.read(tmp_mem, 1792);
    cudaMemcpyAsync(output0, tmp_mem, 1792, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_367
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_367_0	type: float	shape: Shape{320}
void inception3_Constant_float_cuda_Constant_367(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_367_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_367_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[1280];
    bin_file.read(tmp_mem, 1280);
    cudaMemcpyAsync(output0, tmp_mem, 1280, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_366
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_366_0	type: float	shape: Shape{320}
void inception3_Constant_float_cuda_Constant_366(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_366_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_366_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[1280];
    bin_file.read(tmp_mem, 1280);
    cudaMemcpyAsync(output0, tmp_mem, 1280, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_374
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_374_0	type: float	shape: Shape{192}
void inception3_Constant_float_cuda_Constant_374(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_374_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_374_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[768];
    bin_file.read(tmp_mem, 768);
    cudaMemcpyAsync(output0, tmp_mem, 768, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_421
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_421_0	type: float	shape: Shape{1, 3, 384, 384}
void inception3_Constant_float_cuda_Constant_421(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_421_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_421_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[1769472];
    bin_file.read(tmp_mem, 1769472);
    cudaMemcpyAsync(output0, tmp_mem, 1769472, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_484
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_484_0	type: float	shape: Shape{2048, 1001}
void inception3_Constant_float_cuda_Constant_484(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_484_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_484_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[8200192];
    bin_file.read(tmp_mem, 8200192);
    cudaMemcpyAsync(output0, tmp_mem, 8200192, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_376
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_376_0	type: float	shape: Shape{192}
void inception3_Constant_float_cuda_Constant_376(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_376_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_376_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[768];
    bin_file.read(tmp_mem, 768);
    cudaMemcpyAsync(output0, tmp_mem, 768, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_330
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_330_0	type: float	shape: Shape{192}
void inception3_Constant_float_cuda_Constant_330(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_330_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_330_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[768];
    bin_file.read(tmp_mem, 768);
    cudaMemcpyAsync(output0, tmp_mem, 768, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_410
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_410_0	type: float	shape: Shape{384}
void inception3_Constant_float_cuda_Constant_410(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_410_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_410_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[1536];
    bin_file.read(tmp_mem, 1536);
    cudaMemcpyAsync(output0, tmp_mem, 1536, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_420
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_420_0	type: float	shape: Shape{384}
void inception3_Constant_float_cuda_Constant_420(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_420_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_420_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[1536];
    bin_file.read(tmp_mem, 1536);
    cudaMemcpyAsync(output0, tmp_mem, 1536, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_347
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_347_0	type: float	shape: Shape{192}
void inception3_Constant_float_cuda_Constant_347(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_347_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_347_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[768];
    bin_file.read(tmp_mem, 768);
    cudaMemcpyAsync(output0, tmp_mem, 768, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_118
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_118_0	type: float	shape: Shape{64}
void inception3_Constant_float_cuda_Constant_118(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_118_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_118_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[256];
    bin_file.read(tmp_mem, 256);
    cudaMemcpyAsync(output0, tmp_mem, 256, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_408
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_408_0	type: float	shape: Shape{384}
void inception3_Constant_float_cuda_Constant_408(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_408_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_408_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[1536];
    bin_file.read(tmp_mem, 1536);
    cudaMemcpyAsync(output0, tmp_mem, 1536, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_132
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_132_0	type: float	shape: Shape{64}
void inception3_Constant_float_cuda_Constant_132(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_132_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_132_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[256];
    bin_file.read(tmp_mem, 256);
    cudaMemcpyAsync(output0, tmp_mem, 256, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_414
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_414_0	type: float	shape: Shape{448}
void inception3_Constant_float_cuda_Constant_414(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_414_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_414_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[1792];
    bin_file.read(tmp_mem, 1792);
    cudaMemcpyAsync(output0, tmp_mem, 1792, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_404
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_404_0	type: float	shape: Shape{384}
void inception3_Constant_float_cuda_Constant_404(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_404_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_404_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[1536];
    bin_file.read(tmp_mem, 1536);
    cudaMemcpyAsync(output0, tmp_mem, 1536, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_403
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_403_0	type: float	shape: Shape{384}
void inception3_Constant_float_cuda_Constant_403(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_403_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_403_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[1536];
    bin_file.read(tmp_mem, 1536);
    cudaMemcpyAsync(output0, tmp_mem, 1536, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_454
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_454_0	type: float	shape: Shape{384}
void inception3_Constant_float_cuda_Constant_454(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_454_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_454_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[1536];
    bin_file.read(tmp_mem, 1536);
    cudaMemcpyAsync(output0, tmp_mem, 1536, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_444
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_444_0	type: float	shape: Shape{384}
void inception3_Constant_float_cuda_Constant_444(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_444_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_444_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[1536];
    bin_file.read(tmp_mem, 1536);
    cudaMemcpyAsync(output0, tmp_mem, 1536, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_438
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_438_0	type: float	shape: Shape{320}
void inception3_Constant_float_cuda_Constant_438(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_438_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_438_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[1280];
    bin_file.read(tmp_mem, 1280);
    cudaMemcpyAsync(output0, tmp_mem, 1280, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_358
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_358_0	type: float	shape: Shape{192}
void inception3_Constant_float_cuda_Constant_358(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_358_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_358_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[768];
    bin_file.read(tmp_mem, 768);
    cudaMemcpyAsync(output0, tmp_mem, 768, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_107
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_107_0	type: float	shape: Shape{48}
void inception3_Constant_float_cuda_Constant_107(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_107_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_107_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[192];
    bin_file.read(tmp_mem, 192);
    cudaMemcpyAsync(output0, tmp_mem, 192, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_434
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_434_0	type: float	shape: Shape{192}
void inception3_Constant_float_cuda_Constant_434(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_434_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_434_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[768];
    bin_file.read(tmp_mem, 768);
    cudaMemcpyAsync(output0, tmp_mem, 768, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_397
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_397_0	type: float	shape: Shape{384}
void inception3_Constant_float_cuda_Constant_397(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_397_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_397_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[1536];
    bin_file.read(tmp_mem, 1536);
    cudaMemcpyAsync(output0, tmp_mem, 1536, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_449
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_449_0	type: float	shape: Shape{384}
void inception3_Constant_float_cuda_Constant_449(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_449_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_449_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[1536];
    bin_file.read(tmp_mem, 1536);
    cudaMemcpyAsync(output0, tmp_mem, 1536, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_109
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_109_0	type: float	shape: Shape{5, 5, 48, 64}
void inception3_Constant_float_cuda_Constant_109(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_109_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_109_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[307200];
    bin_file.read(tmp_mem, 307200);
    cudaMemcpyAsync(output0, tmp_mem, 307200, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_363
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_363_0	type: float	shape: Shape{192}
void inception3_Constant_float_cuda_Constant_363(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_363_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_363_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[768];
    bin_file.read(tmp_mem, 768);
    cudaMemcpyAsync(output0, tmp_mem, 768, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_418
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_418_0	type: float	shape: Shape{384}
void inception3_Constant_float_cuda_Constant_418(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_418_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_418_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[1536];
    bin_file.read(tmp_mem, 1536);
    cudaMemcpyAsync(output0, tmp_mem, 1536, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_401
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_401_0	type: float	shape: Shape{1, 3, 384, 384}
void inception3_Constant_float_cuda_Constant_401(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_401_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_401_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[1769472];
    bin_file.read(tmp_mem, 1769472);
    cudaMemcpyAsync(output0, tmp_mem, 1769472, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_411
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_411_0	type: float	shape: Shape{1, 1, 1280, 448}
void inception3_Constant_float_cuda_Constant_411(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_411_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_411_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[2293760];
    bin_file.read(tmp_mem, 2293760);
    cudaMemcpyAsync(output0, tmp_mem, 2293760, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_142
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_142_0	type: float	shape: Shape{64}
void inception3_Constant_float_cuda_Constant_142(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_142_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_142_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[256];
    bin_file.read(tmp_mem, 256);
    cudaMemcpyAsync(output0, tmp_mem, 256, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_180
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_180_0	type: float	shape: Shape{128}
void inception3_Constant_float_cuda_Constant_180(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_180_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_180_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[512];
    bin_file.read(tmp_mem, 512);
    cudaMemcpyAsync(output0, tmp_mem, 512, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_443
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_443_0	type: float	shape: Shape{384}
void inception3_Constant_float_cuda_Constant_443(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_443_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_443_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[1536];
    bin_file.read(tmp_mem, 1536);
    cudaMemcpyAsync(output0, tmp_mem, 1536, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_116
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_116_0	type: float	shape: Shape{64}
void inception3_Constant_float_cuda_Constant_116(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_116_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_116_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[256];
    bin_file.read(tmp_mem, 256);
    cudaMemcpyAsync(output0, tmp_mem, 256, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_462
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_462_0	type: float	shape: Shape{3, 3, 448, 384}
void inception3_Constant_float_cuda_Constant_462(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_462_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_462_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[6193152];
    bin_file.read(tmp_mem, 6193152);
    cudaMemcpyAsync(output0, tmp_mem, 6193152, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_171
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_171_0	type: float	shape: Shape{7, 1, 128, 192}
void inception3_Constant_float_cuda_Constant_171(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_171_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_171_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[688128];
    bin_file.read(tmp_mem, 688128);
    cudaMemcpyAsync(output0, tmp_mem, 688128, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_84
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_84_0	type: float	shape: Shape{96}
void inception3_Constant_float_cuda_Constant_84(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_84_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_84_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[384];
    bin_file.read(tmp_mem, 384);
    cudaMemcpyAsync(output0, tmp_mem, 384, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_481
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_481_0	type: float	shape: Shape{192}
void inception3_Constant_float_cuda_Constant_481(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_481_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_481_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[768];
    bin_file.read(tmp_mem, 768);
    cudaMemcpyAsync(output0, tmp_mem, 768, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_455
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_455_0	type: float	shape: Shape{384}
void inception3_Constant_float_cuda_Constant_455(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_455_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_455_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[1536];
    bin_file.read(tmp_mem, 1536);
    cudaMemcpyAsync(output0, tmp_mem, 1536, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_81
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_81_0	type: float	shape: Shape{64}
void inception3_Constant_float_cuda_Constant_81(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_81_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_81_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[256];
    bin_file.read(tmp_mem, 256);
    cudaMemcpyAsync(output0, tmp_mem, 256, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_113
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_113_0	type: float	shape: Shape{64}
void inception3_Constant_float_cuda_Constant_113(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_113_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_113_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[256];
    bin_file.read(tmp_mem, 256);
    cudaMemcpyAsync(output0, tmp_mem, 256, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_448
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_448_0	type: float	shape: Shape{384}
void inception3_Constant_float_cuda_Constant_448(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_448_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_448_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[1536];
    bin_file.read(tmp_mem, 1536);
    cudaMemcpyAsync(output0, tmp_mem, 1536, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_472
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_472_0	type: float	shape: Shape{3, 1, 384, 384}
void inception3_Constant_float_cuda_Constant_472(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_472_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_472_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[1769472];
    bin_file.read(tmp_mem, 1769472);
    cudaMemcpyAsync(output0, tmp_mem, 1769472, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_437
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_437_0	type: float	shape: Shape{1, 1, 2048, 320}
void inception3_Constant_float_cuda_Constant_437(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_437_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_437_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[2621440];
    bin_file.read(tmp_mem, 2621440);
    cudaMemcpyAsync(output0, tmp_mem, 2621440, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_386
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_386_0	type: float	shape: Shape{192}
void inception3_Constant_float_cuda_Constant_386(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_386_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_386_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[768];
    bin_file.read(tmp_mem, 768);
    cudaMemcpyAsync(output0, tmp_mem, 768, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_464
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_464_0	type: float	shape: Shape{384}
void inception3_Constant_float_cuda_Constant_464(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_464_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_464_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[1536];
    bin_file.read(tmp_mem, 1536);
    cudaMemcpyAsync(output0, tmp_mem, 1536, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_452
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_452_0	type: float	shape: Shape{3, 1, 384, 384}
void inception3_Constant_float_cuda_Constant_452(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_452_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_452_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[1769472];
    bin_file.read(tmp_mem, 1769472);
    cudaMemcpyAsync(output0, tmp_mem, 1769472, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_478
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_478_0	type: float	shape: Shape{192}
void inception3_Constant_float_cuda_Constant_478(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_478_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_478_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[768];
    bin_file.read(tmp_mem, 768);
    cudaMemcpyAsync(output0, tmp_mem, 768, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_365
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_365_0	type: float	shape: Shape{3, 3, 192, 320}
void inception3_Constant_float_cuda_Constant_365(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_365_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_365_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[2211840];
    bin_file.read(tmp_mem, 2211840);
    cudaMemcpyAsync(output0, tmp_mem, 2211840, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_451
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_451_0	type: float	shape: Shape{384}
void inception3_Constant_float_cuda_Constant_451(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_451_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_451_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[1536];
    bin_file.read(tmp_mem, 1536);
    cudaMemcpyAsync(output0, tmp_mem, 1536, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_453
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_453_0	type: float	shape: Shape{384}
void inception3_Constant_float_cuda_Constant_453(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_453_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_453_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[1536];
    bin_file.read(tmp_mem, 1536);
    cudaMemcpyAsync(output0, tmp_mem, 1536, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_164
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_164_0	type: float	shape: Shape{128}
void inception3_Constant_float_cuda_Constant_164(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_164_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_164_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[512];
    bin_file.read(tmp_mem, 512);
    cudaMemcpyAsync(output0, tmp_mem, 512, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_19
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_19_0	type: float	shape: Shape{80}
void inception3_Constant_float_cuda_Constant_19(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_19_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_19_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[320];
    bin_file.read(tmp_mem, 320);
    cudaMemcpyAsync(output0, tmp_mem, 320, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_471
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_471_0	type: float	shape: Shape{384}
void inception3_Constant_float_cuda_Constant_471(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_471_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_471_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[1536];
    bin_file.read(tmp_mem, 1536);
    cudaMemcpyAsync(output0, tmp_mem, 1536, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_445
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_445_0	type: float	shape: Shape{384}
void inception3_Constant_float_cuda_Constant_445(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_445_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_445_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[1536];
    bin_file.read(tmp_mem, 1536);
    cudaMemcpyAsync(output0, tmp_mem, 1536, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_61
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_61_0	type: float	shape: Shape{32}
void inception3_Constant_float_cuda_Constant_61(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_61_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_61_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[128];
    bin_file.read(tmp_mem, 128);
    cudaMemcpyAsync(output0, tmp_mem, 128, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_429
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_429_0	type: float	shape: Shape{384}
void inception3_Constant_float_cuda_Constant_429(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_429_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_429_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[1536];
    bin_file.read(tmp_mem, 1536);
    cudaMemcpyAsync(output0, tmp_mem, 1536, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_150
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_150_0	type: float	shape: Shape{3, 3, 96, 96}
void inception3_Constant_float_cuda_Constant_150(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_150_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_150_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[331776];
    bin_file.read(tmp_mem, 331776);
    cudaMemcpyAsync(output0, tmp_mem, 331776, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_141
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_141_0	type: float	shape: Shape{64}
void inception3_Constant_float_cuda_Constant_141(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_141_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_141_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[256];
    bin_file.read(tmp_mem, 256);
    cudaMemcpyAsync(output0, tmp_mem, 256, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_264
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_264_0	type: float	shape: Shape{160}
void inception3_Constant_float_cuda_Constant_264(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_264_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_264_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[640];
    bin_file.read(tmp_mem, 640);
    cudaMemcpyAsync(output0, tmp_mem, 640, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_468
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_468_0	type: float	shape: Shape{384}
void inception3_Constant_float_cuda_Constant_468(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_468_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_468_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[1536];
    bin_file.read(tmp_mem, 1536);
    cudaMemcpyAsync(output0, tmp_mem, 1536, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_400
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_400_0	type: float	shape: Shape{384}
void inception3_Constant_float_cuda_Constant_400(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_400_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_400_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[1536];
    bin_file.read(tmp_mem, 1536);
    cudaMemcpyAsync(output0, tmp_mem, 1536, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_402
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_402_0	type: float	shape: Shape{384}
void inception3_Constant_float_cuda_Constant_402(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_402_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_402_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[1536];
    bin_file.read(tmp_mem, 1536);
    cudaMemcpyAsync(output0, tmp_mem, 1536, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_278
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_278_0	type: float	shape: Shape{1, 1, 768, 160}
void inception3_Constant_float_cuda_Constant_278(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_278_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_278_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[491520];
    bin_file.read(tmp_mem, 491520);
    cudaMemcpyAsync(output0, tmp_mem, 491520, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_373
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_373_0	type: float	shape: Shape{192}
void inception3_Constant_float_cuda_Constant_373(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_373_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_373_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[768];
    bin_file.read(tmp_mem, 768);
    cudaMemcpyAsync(output0, tmp_mem, 768, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_378
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_378_0	type: float	shape: Shape{192}
void inception3_Constant_float_cuda_Constant_378(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_378_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_378_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[768];
    bin_file.read(tmp_mem, 768);
    cudaMemcpyAsync(output0, tmp_mem, 768, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_92
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_92_0	type: float	shape: Shape{96}
void inception3_Constant_float_cuda_Constant_92(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_92_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_92_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[384];
    bin_file.read(tmp_mem, 384);
    cudaMemcpyAsync(output0, tmp_mem, 384, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_144
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_144_0	type: float	shape: Shape{64}
void inception3_Constant_float_cuda_Constant_144(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_144_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_144_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[256];
    bin_file.read(tmp_mem, 256);
    cudaMemcpyAsync(output0, tmp_mem, 256, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_439
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_439_0	type: float	shape: Shape{320}
void inception3_Constant_float_cuda_Constant_439(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_439_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_439_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[1280];
    bin_file.read(tmp_mem, 1280);
    cudaMemcpyAsync(output0, tmp_mem, 1280, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_485
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_485_0	type: float	shape: Shape{1001}
void inception3_Constant_float_cuda_Constant_485(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_485_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_485_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[4004];
    bin_file.read(tmp_mem, 4004);
    cudaMemcpyAsync(output0, tmp_mem, 4004, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_426
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_426_0	type: float	shape: Shape{3, 1, 384, 384}
void inception3_Constant_float_cuda_Constant_426(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_426_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_426_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[1769472];
    bin_file.read(tmp_mem, 1769472);
    cudaMemcpyAsync(output0, tmp_mem, 1769472, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_360
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_360_0	type: float	shape: Shape{1, 1, 768, 192}
void inception3_Constant_float_cuda_Constant_360(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_360_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_360_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[589824];
    bin_file.read(tmp_mem, 589824);
    cudaMemcpyAsync(output0, tmp_mem, 589824, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_430
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_430_0	type: float	shape: Shape{384}
void inception3_Constant_float_cuda_Constant_430(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_430_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_430_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[1536];
    bin_file.read(tmp_mem, 1536);
    cudaMemcpyAsync(output0, tmp_mem, 1536, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_137
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_137_0	type: float	shape: Shape{384}
void inception3_Constant_float_cuda_Constant_137(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_137_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_137_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[1536];
    bin_file.read(tmp_mem, 1536);
    cudaMemcpyAsync(output0, tmp_mem, 1536, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_389
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_389_0	type: float	shape: Shape{192}
void inception3_Constant_float_cuda_Constant_389(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_389_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_389_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[768];
    bin_file.read(tmp_mem, 768);
    cudaMemcpyAsync(output0, tmp_mem, 768, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_477
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_477_0	type: float	shape: Shape{1, 1, 2048, 192}
void inception3_Constant_float_cuda_Constant_477(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_477_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_477_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[1572864];
    bin_file.read(tmp_mem, 1572864);
    cudaMemcpyAsync(output0, tmp_mem, 1572864, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_267
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_267_0	type: float	shape: Shape{160}
void inception3_Constant_float_cuda_Constant_267(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_267_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_267_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[640];
    bin_file.read(tmp_mem, 640);
    cudaMemcpyAsync(output0, tmp_mem, 640, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_23
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_23_0	type: float	shape: Shape{192}
void inception3_Constant_float_cuda_Constant_23(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_23_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_23_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[768];
    bin_file.read(tmp_mem, 768);
    cudaMemcpyAsync(output0, tmp_mem, 768, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_91
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_91_0	type: float	shape: Shape{96}
void inception3_Constant_float_cuda_Constant_91(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_91_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_91_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[384];
    bin_file.read(tmp_mem, 384);
    cudaMemcpyAsync(output0, tmp_mem, 384, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_470
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_470_0	type: float	shape: Shape{384}
void inception3_Constant_float_cuda_Constant_470(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_470_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_470_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[1536];
    bin_file.read(tmp_mem, 1536);
    cudaMemcpyAsync(output0, tmp_mem, 1536, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_467
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_467_0	type: float	shape: Shape{1, 3, 384, 384}
void inception3_Constant_float_cuda_Constant_467(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_467_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_467_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[1769472];
    bin_file.read(tmp_mem, 1769472);
    cudaMemcpyAsync(output0, tmp_mem, 1769472, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_283
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_283_0	type: float	shape: Shape{7, 1, 160, 160}
void inception3_Constant_float_cuda_Constant_283(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_283_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_283_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[716800];
    bin_file.read(tmp_mem, 716800);
    cudaMemcpyAsync(output0, tmp_mem, 716800, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_204
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_204_0	type: float	shape: Shape{192}
void inception3_Constant_float_cuda_Constant_204(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_204_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_204_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[768];
    bin_file.read(tmp_mem, 768);
    cudaMemcpyAsync(output0, tmp_mem, 768, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_392
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_392_0	type: float	shape: Shape{320}
void inception3_Constant_float_cuda_Constant_392(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_392_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_392_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[1280];
    bin_file.read(tmp_mem, 1280);
    cudaMemcpyAsync(output0, tmp_mem, 1280, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_409
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_409_0	type: float	shape: Shape{384}
void inception3_Constant_float_cuda_Constant_409(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_409_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_409_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[1536];
    bin_file.read(tmp_mem, 1536);
    cudaMemcpyAsync(output0, tmp_mem, 1536, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_475
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_475_0	type: float	shape: Shape{384}
void inception3_Constant_float_cuda_Constant_475(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_475_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_475_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[1536];
    bin_file.read(tmp_mem, 1536);
    cudaMemcpyAsync(output0, tmp_mem, 1536, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_121
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_121_0	type: float	shape: Shape{96}
void inception3_Constant_float_cuda_Constant_121(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_121_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_121_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[384];
    bin_file.read(tmp_mem, 384);
    cudaMemcpyAsync(output0, tmp_mem, 384, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_120
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_120_0	type: float	shape: Shape{96}
void inception3_Constant_float_cuda_Constant_120(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_120_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_120_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[384];
    bin_file.read(tmp_mem, 384);
    cudaMemcpyAsync(output0, tmp_mem, 384, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_111
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_111_0	type: float	shape: Shape{64}
void inception3_Constant_float_cuda_Constant_111(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_111_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_111_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[256];
    bin_file.read(tmp_mem, 256);
    cudaMemcpyAsync(output0, tmp_mem, 256, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_476
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_476_0	type: float	shape: Shape{384}
void inception3_Constant_float_cuda_Constant_476(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_476_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_476_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[1536];
    bin_file.read(tmp_mem, 1536);
    cudaMemcpyAsync(output0, tmp_mem, 1536, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_318
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_318_0	type: float	shape: Shape{192}
void inception3_Constant_float_cuda_Constant_318(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_318_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_318_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[768];
    bin_file.read(tmp_mem, 768);
    cudaMemcpyAsync(output0, tmp_mem, 768, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_301
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_301_0	type: float	shape: Shape{192}
void inception3_Constant_float_cuda_Constant_301(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_301_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_301_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[768];
    bin_file.read(tmp_mem, 768);
    cudaMemcpyAsync(output0, tmp_mem, 768, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_86
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_86_0	type: float	shape: Shape{96}
void inception3_Constant_float_cuda_Constant_86(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_86_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_86_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[384];
    bin_file.read(tmp_mem, 384);
    cudaMemcpyAsync(output0, tmp_mem, 384, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_473
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_473_0	type: float	shape: Shape{384}
void inception3_Constant_float_cuda_Constant_473(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_473_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_473_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[1536];
    bin_file.read(tmp_mem, 1536);
    cudaMemcpyAsync(output0, tmp_mem, 1536, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_146
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_146_0	type: float	shape: Shape{96}
void inception3_Constant_float_cuda_Constant_146(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_146_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_146_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[384];
    bin_file.read(tmp_mem, 384);
    cudaMemcpyAsync(output0, tmp_mem, 384, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_456
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_456_0	type: float	shape: Shape{384}
void inception3_Constant_float_cuda_Constant_456(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_456_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_456_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[1536];
    bin_file.read(tmp_mem, 1536);
    cudaMemcpyAsync(output0, tmp_mem, 1536, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_110
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_110_0	type: float	shape: Shape{64}
void inception3_Constant_float_cuda_Constant_110(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_110_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_110_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[256];
    bin_file.read(tmp_mem, 256);
    cudaMemcpyAsync(output0, tmp_mem, 256, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_474
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_474_0	type: float	shape: Shape{384}
void inception3_Constant_float_cuda_Constant_474(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_474_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_474_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[1536];
    bin_file.read(tmp_mem, 1536);
    cudaMemcpyAsync(output0, tmp_mem, 1536, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_126
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_126_0	type: float	shape: Shape{96}
void inception3_Constant_float_cuda_Constant_126(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_126_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_126_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[384];
    bin_file.read(tmp_mem, 384);
    cudaMemcpyAsync(output0, tmp_mem, 384, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_428
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_428_0	type: float	shape: Shape{384}
void inception3_Constant_float_cuda_Constant_428(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_428_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_428_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[1536];
    bin_file.read(tmp_mem, 1536);
    cudaMemcpyAsync(output0, tmp_mem, 1536, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_463
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_463_0	type: float	shape: Shape{384}
void inception3_Constant_float_cuda_Constant_463(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_463_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_463_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[1536];
    bin_file.read(tmp_mem, 1536);
    cudaMemcpyAsync(output0, tmp_mem, 1536, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_250
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_250_0	type: float	shape: Shape{192}
void inception3_Constant_float_cuda_Constant_250(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_250_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_250_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[768];
    bin_file.read(tmp_mem, 768);
    cudaMemcpyAsync(output0, tmp_mem, 768, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_65
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_65_0	type: float	shape: Shape{64}
void inception3_Constant_float_cuda_Constant_65(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_65_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_65_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[256];
    bin_file.read(tmp_mem, 256);
    cudaMemcpyAsync(output0, tmp_mem, 256, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_461
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_461_0	type: float	shape: Shape{448}
void inception3_Constant_float_cuda_Constant_461(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_461_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_461_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[1792];
    bin_file.read(tmp_mem, 1792);
    cudaMemcpyAsync(output0, tmp_mem, 1792, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_361
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_361_0	type: float	shape: Shape{192}
void inception3_Constant_float_cuda_Constant_361(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_361_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_361_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[768];
    bin_file.read(tmp_mem, 768);
    cudaMemcpyAsync(output0, tmp_mem, 768, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_108
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_108_0	type: float	shape: Shape{48}
void inception3_Constant_float_cuda_Constant_108(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_108_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_108_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[192];
    bin_file.read(tmp_mem, 192);
    cudaMemcpyAsync(output0, tmp_mem, 192, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_212
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_212_0	type: float	shape: Shape{1, 1, 768, 160}
void inception3_Constant_float_cuda_Constant_212(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_212_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_212_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[491520];
    bin_file.read(tmp_mem, 491520);
    cudaMemcpyAsync(output0, tmp_mem, 491520, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_393
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_393_0	type: float	shape: Shape{320}
void inception3_Constant_float_cuda_Constant_393(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_393_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_393_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[1280];
    bin_file.read(tmp_mem, 1280);
    cudaMemcpyAsync(output0, tmp_mem, 1280, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_124
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_124_0	type: float	shape: Shape{3, 3, 96, 96}
void inception3_Constant_float_cuda_Constant_124(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_124_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_124_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[331776];
    bin_file.read(tmp_mem, 331776);
    cudaMemcpyAsync(output0, tmp_mem, 331776, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_76
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_76_0	type: float	shape: Shape{64}
void inception3_Constant_float_cuda_Constant_76(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_76_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_76_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[256];
    bin_file.read(tmp_mem, 256);
    cudaMemcpyAsync(output0, tmp_mem, 256, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_479
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_479_0	type: float	shape: Shape{192}
void inception3_Constant_float_cuda_Constant_479(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_479_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_479_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[768];
    bin_file.read(tmp_mem, 768);
    cudaMemcpyAsync(output0, tmp_mem, 768, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_396
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_396_0	type: float	shape: Shape{1, 1, 1280, 384}
void inception3_Constant_float_cuda_Constant_396(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_396_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_396_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[1966080];
    bin_file.read(tmp_mem, 1966080);
    cudaMemcpyAsync(output0, tmp_mem, 1966080, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_311
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_311_0	type: float	shape: Shape{192}
void inception3_Constant_float_cuda_Constant_311(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_311_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_311_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[768];
    bin_file.read(tmp_mem, 768);
    cudaMemcpyAsync(output0, tmp_mem, 768, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_328
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_328_0	type: float	shape: Shape{192}
void inception3_Constant_float_cuda_Constant_328(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_328_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_328_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[768];
    bin_file.read(tmp_mem, 768);
    cudaMemcpyAsync(output0, tmp_mem, 768, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_343
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_343_0	type: float	shape: Shape{192}
void inception3_Constant_float_cuda_Constant_343(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_343_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_343_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[768];
    bin_file.read(tmp_mem, 768);
    cudaMemcpyAsync(output0, tmp_mem, 768, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_232
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_232_0	type: float	shape: Shape{7, 1, 160, 160}
void inception3_Constant_float_cuda_Constant_232(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_232_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_232_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[716800];
    bin_file.read(tmp_mem, 716800);
    cudaMemcpyAsync(output0, tmp_mem, 716800, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_187
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_187_0	type: float	shape: Shape{128}
void inception3_Constant_float_cuda_Constant_187(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_187_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_187_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[512];
    bin_file.read(tmp_mem, 512);
    cudaMemcpyAsync(output0, tmp_mem, 512, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_325
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_325_0	type: float	shape: Shape{192}
void inception3_Constant_float_cuda_Constant_325(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_325_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_325_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[768];
    bin_file.read(tmp_mem, 768);
    cudaMemcpyAsync(output0, tmp_mem, 768, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_321
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_321_0	type: float	shape: Shape{192}
void inception3_Constant_float_cuda_Constant_321(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_321_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_321_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[768];
    bin_file.read(tmp_mem, 768);
    cudaMemcpyAsync(output0, tmp_mem, 768, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_322
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_322_0	type: float	shape: Shape{192}
void inception3_Constant_float_cuda_Constant_322(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_322_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_322_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[768];
    bin_file.read(tmp_mem, 768);
    cudaMemcpyAsync(output0, tmp_mem, 768, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_433
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_433_0	type: float	shape: Shape{192}
void inception3_Constant_float_cuda_Constant_433(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_433_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_433_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[768];
    bin_file.read(tmp_mem, 768);
    cudaMemcpyAsync(output0, tmp_mem, 768, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_457
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_457_0	type: float	shape: Shape{1, 1, 2048, 448}
void inception3_Constant_float_cuda_Constant_457(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_457_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_457_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[3670016];
    bin_file.read(tmp_mem, 3670016);
    cudaMemcpyAsync(output0, tmp_mem, 3670016, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_105
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_105_0	type: float	shape: Shape{48}
void inception3_Constant_float_cuda_Constant_105(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_105_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_105_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[192];
    bin_file.read(tmp_mem, 192);
    cudaMemcpyAsync(output0, tmp_mem, 192, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_319
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_319_0	type: float	shape: Shape{1, 7, 192, 192}
void inception3_Constant_float_cuda_Constant_319(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_319_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_319_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[1032192];
    bin_file.read(tmp_mem, 1032192);
    cudaMemcpyAsync(output0, tmp_mem, 1032192, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_189
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_189_0	type: float	shape: Shape{128}
void inception3_Constant_float_cuda_Constant_189(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_189_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_189_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[512];
    bin_file.read(tmp_mem, 512);
    cudaMemcpyAsync(output0, tmp_mem, 512, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_183
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_183_0	type: float	shape: Shape{128}
void inception3_Constant_float_cuda_Constant_183(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_183_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_183_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[512];
    bin_file.read(tmp_mem, 512);
    cudaMemcpyAsync(output0, tmp_mem, 512, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_295
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_295_0	type: float	shape: Shape{160}
void inception3_Constant_float_cuda_Constant_295(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_295_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_295_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[640];
    bin_file.read(tmp_mem, 640);
    cudaMemcpyAsync(output0, tmp_mem, 640, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_300
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_300_0	type: float	shape: Shape{192}
void inception3_Constant_float_cuda_Constant_300(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_300_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_300_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[768];
    bin_file.read(tmp_mem, 768);
    cudaMemcpyAsync(output0, tmp_mem, 768, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_353
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_353_0	type: float	shape: Shape{192}
void inception3_Constant_float_cuda_Constant_353(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_353_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_353_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[768];
    bin_file.read(tmp_mem, 768);
    cudaMemcpyAsync(output0, tmp_mem, 768, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_138
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_138_0	type: float	shape: Shape{384}
void inception3_Constant_float_cuda_Constant_138(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_138_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_138_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[1536];
    bin_file.read(tmp_mem, 1536);
    cudaMemcpyAsync(output0, tmp_mem, 1536, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_193
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_193_0	type: float	shape: Shape{128}
void inception3_Constant_float_cuda_Constant_193(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_193_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_193_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[512];
    bin_file.read(tmp_mem, 512);
    cudaMemcpyAsync(output0, tmp_mem, 512, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_101
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_101_0	type: float	shape: Shape{64}
void inception3_Constant_float_cuda_Constant_101(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_101_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_101_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[256];
    bin_file.read(tmp_mem, 256);
    cudaMemcpyAsync(output0, tmp_mem, 256, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_136
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_136_0	type: float	shape: Shape{384}
void inception3_Constant_float_cuda_Constant_136(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_136_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_136_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[1536];
    bin_file.read(tmp_mem, 1536);
    cudaMemcpyAsync(output0, tmp_mem, 1536, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_87
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_87_0	type: float	shape: Shape{96}
void inception3_Constant_float_cuda_Constant_87(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_87_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_87_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[384];
    bin_file.read(tmp_mem, 384);
    cudaMemcpyAsync(output0, tmp_mem, 384, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_166
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_166_0	type: float	shape: Shape{1, 7, 128, 128}
void inception3_Constant_float_cuda_Constant_166(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_166_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_166_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[458752];
    bin_file.read(tmp_mem, 458752);
    cudaMemcpyAsync(output0, tmp_mem, 458752, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_425
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_425_0	type: float	shape: Shape{384}
void inception3_Constant_float_cuda_Constant_425(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_425_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_425_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[1536];
    bin_file.read(tmp_mem, 1536);
    cudaMemcpyAsync(output0, tmp_mem, 1536, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_240
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_240_0	type: float	shape: Shape{160}
void inception3_Constant_float_cuda_Constant_240(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_240_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_240_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[640];
    bin_file.read(tmp_mem, 640);
    cudaMemcpyAsync(output0, tmp_mem, 640, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_285
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_285_0	type: float	shape: Shape{160}
void inception3_Constant_float_cuda_Constant_285(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_285_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_285_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[640];
    bin_file.read(tmp_mem, 640);
    cudaMemcpyAsync(output0, tmp_mem, 640, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_26
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_26_0	type: float	shape: Shape{192}
void inception3_Constant_float_cuda_Constant_26(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_26_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_26_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[768];
    bin_file.read(tmp_mem, 768);
    cudaMemcpyAsync(output0, tmp_mem, 768, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_352
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_352_0	type: float	shape: Shape{192}
void inception3_Constant_float_cuda_Constant_352(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_352_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_352_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[768];
    bin_file.read(tmp_mem, 768);
    cudaMemcpyAsync(output0, tmp_mem, 768, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_73
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_73_0	type: float	shape: Shape{5, 5, 48, 64}
void inception3_Constant_float_cuda_Constant_73(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_73_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_73_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[307200];
    bin_file.read(tmp_mem, 307200);
    cudaMemcpyAsync(output0, tmp_mem, 307200, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_52
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_52_0	type: float	shape: Shape{3, 3, 96, 96}
void inception3_Constant_float_cuda_Constant_52(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_52_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_52_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[331776];
    bin_file.read(tmp_mem, 331776);
    cudaMemcpyAsync(output0, tmp_mem, 331776, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_119
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_119_0	type: float	shape: Shape{3, 3, 64, 96}
void inception3_Constant_float_cuda_Constant_119(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_119_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_119_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[221184];
    bin_file.read(tmp_mem, 221184);
    cudaMemcpyAsync(output0, tmp_mem, 221184, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_115
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_115_0	type: float	shape: Shape{64}
void inception3_Constant_float_cuda_Constant_115(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_115_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_115_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[256];
    bin_file.read(tmp_mem, 256);
    cudaMemcpyAsync(output0, tmp_mem, 256, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_315
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_315_0	type: float	shape: Shape{192}
void inception3_Constant_float_cuda_Constant_315(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_315_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_315_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[768];
    bin_file.read(tmp_mem, 768);
    cudaMemcpyAsync(output0, tmp_mem, 768, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_208
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_208_0	type: float	shape: Shape{192}
void inception3_Constant_float_cuda_Constant_208(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_208_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_208_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[768];
    bin_file.read(tmp_mem, 768);
    cudaMemcpyAsync(output0, tmp_mem, 768, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_104
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_104_0	type: float	shape: Shape{1, 1, 288, 48}
void inception3_Constant_float_cuda_Constant_104(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_104_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_104_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[55296];
    bin_file.read(tmp_mem, 55296);
    cudaMemcpyAsync(output0, tmp_mem, 55296, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_466
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_466_0	type: float	shape: Shape{384}
void inception3_Constant_float_cuda_Constant_466(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_466_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_466_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[1536];
    bin_file.read(tmp_mem, 1536);
    cudaMemcpyAsync(output0, tmp_mem, 1536, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_114
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_114_0	type: float	shape: Shape{1, 1, 288, 64}
void inception3_Constant_float_cuda_Constant_114(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_114_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_114_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[73728];
    bin_file.read(tmp_mem, 73728);
    cudaMemcpyAsync(output0, tmp_mem, 73728, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_375
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_375_0	type: float	shape: Shape{1, 7, 192, 192}
void inception3_Constant_float_cuda_Constant_375(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_375_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_375_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[1032192];
    bin_file.read(tmp_mem, 1032192);
    cudaMemcpyAsync(output0, tmp_mem, 1032192, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_339
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_339_0	type: float	shape: Shape{1, 7, 192, 192}
void inception3_Constant_float_cuda_Constant_339(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_339_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_339_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[1032192];
    bin_file.read(tmp_mem, 1032192);
    cudaMemcpyAsync(output0, tmp_mem, 1032192, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_213
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_213_0	type: float	shape: Shape{160}
void inception3_Constant_float_cuda_Constant_213(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_213_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_213_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[640];
    bin_file.read(tmp_mem, 640);
    cudaMemcpyAsync(output0, tmp_mem, 640, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_344
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_344_0	type: float	shape: Shape{7, 1, 192, 192}
void inception3_Constant_float_cuda_Constant_344(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_344_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_344_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[1032192];
    bin_file.read(tmp_mem, 1032192);
    cudaMemcpyAsync(output0, tmp_mem, 1032192, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_112
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_112_0	type: float	shape: Shape{64}
void inception3_Constant_float_cuda_Constant_112(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_112_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_112_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[256];
    bin_file.read(tmp_mem, 256);
    cudaMemcpyAsync(output0, tmp_mem, 256, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_77
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_77_0	type: float	shape: Shape{64}
void inception3_Constant_float_cuda_Constant_77(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_77_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_77_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[256];
    bin_file.read(tmp_mem, 256);
    cudaMemcpyAsync(output0, tmp_mem, 256, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_95
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_95_0	type: float	shape: Shape{64}
void inception3_Constant_float_cuda_Constant_95(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_95_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_95_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[256];
    bin_file.read(tmp_mem, 256);
    cudaMemcpyAsync(output0, tmp_mem, 256, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_158
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_158_0	type: float	shape: Shape{192}
void inception3_Constant_float_cuda_Constant_158(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_158_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_158_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[768];
    bin_file.read(tmp_mem, 768);
    cudaMemcpyAsync(output0, tmp_mem, 768, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_154
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_154_0	type: float	shape: Shape{96}
void inception3_Constant_float_cuda_Constant_154(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_154_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_154_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[384];
    bin_file.read(tmp_mem, 384);
    cudaMemcpyAsync(output0, tmp_mem, 384, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_117
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_117_0	type: float	shape: Shape{64}
void inception3_Constant_float_cuda_Constant_117(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_117_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_117_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[256];
    bin_file.read(tmp_mem, 256);
    cudaMemcpyAsync(output0, tmp_mem, 256, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_70
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_70_0	type: float	shape: Shape{48}
void inception3_Constant_float_cuda_Constant_70(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_70_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_70_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[192];
    bin_file.read(tmp_mem, 192);
    cudaMemcpyAsync(output0, tmp_mem, 192, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_177
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_177_0	type: float	shape: Shape{128}
void inception3_Constant_float_cuda_Constant_177(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_177_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_177_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[512];
    bin_file.read(tmp_mem, 512);
    cudaMemcpyAsync(output0, tmp_mem, 512, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_71
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_71_0	type: float	shape: Shape{48}
void inception3_Constant_float_cuda_Constant_71(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_71_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_71_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[192];
    bin_file.read(tmp_mem, 192);
    cudaMemcpyAsync(output0, tmp_mem, 192, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_442
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_442_0	type: float	shape: Shape{1, 1, 2048, 384}
void inception3_Constant_float_cuda_Constant_442(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_442_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_442_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[3145728];
    bin_file.read(tmp_mem, 3145728);
    cudaMemcpyAsync(output0, tmp_mem, 3145728, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_69
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_69_0	type: float	shape: Shape{48}
void inception3_Constant_float_cuda_Constant_69(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_69_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_69_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[192];
    bin_file.read(tmp_mem, 192);
    cudaMemcpyAsync(output0, tmp_mem, 192, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_85
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_85_0	type: float	shape: Shape{96}
void inception3_Constant_float_cuda_Constant_85(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_85_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_85_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[384];
    bin_file.read(tmp_mem, 384);
    cudaMemcpyAsync(output0, tmp_mem, 384, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_371
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_371_0	type: float	shape: Shape{192}
void inception3_Constant_float_cuda_Constant_371(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_371_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_371_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[768];
    bin_file.read(tmp_mem, 768);
    cudaMemcpyAsync(output0, tmp_mem, 768, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_90
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_90_0	type: float	shape: Shape{96}
void inception3_Constant_float_cuda_Constant_90(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_90_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_90_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[384];
    bin_file.read(tmp_mem, 384);
    cudaMemcpyAsync(output0, tmp_mem, 384, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_173
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_173_0	type: float	shape: Shape{192}
void inception3_Constant_float_cuda_Constant_173(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_173_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_173_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[768];
    bin_file.read(tmp_mem, 768);
    cudaMemcpyAsync(output0, tmp_mem, 768, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_130
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_130_0	type: float	shape: Shape{64}
void inception3_Constant_float_cuda_Constant_130(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_130_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_130_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[256];
    bin_file.read(tmp_mem, 256);
    cudaMemcpyAsync(output0, tmp_mem, 256, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_255
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_255_0	type: float	shape: Shape{192}
void inception3_Constant_float_cuda_Constant_255(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_255_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_255_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[768];
    bin_file.read(tmp_mem, 768);
    cudaMemcpyAsync(output0, tmp_mem, 768, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_67
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_67_0	type: float	shape: Shape{64}
void inception3_Constant_float_cuda_Constant_67(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_67_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_67_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[256];
    bin_file.read(tmp_mem, 256);
    cudaMemcpyAsync(output0, tmp_mem, 256, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_147
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_147_0	type: float	shape: Shape{96}
void inception3_Constant_float_cuda_Constant_147(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_147_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_147_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[384];
    bin_file.read(tmp_mem, 384);
    cudaMemcpyAsync(output0, tmp_mem, 384, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_156
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_156_0	type: float	shape: Shape{1, 1, 768, 192}
void inception3_Constant_float_cuda_Constant_156(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_156_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_156_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[589824];
    bin_file.read(tmp_mem, 589824);
    cudaMemcpyAsync(output0, tmp_mem, 589824, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_191
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_191_0	type: float	shape: Shape{7, 1, 128, 128}
void inception3_Constant_float_cuda_Constant_191(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_191_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_191_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[458752];
    bin_file.read(tmp_mem, 458752);
    cudaMemcpyAsync(output0, tmp_mem, 458752, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_145
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_145_0	type: float	shape: Shape{3, 3, 64, 96}
void inception3_Constant_float_cuda_Constant_145(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_145_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_145_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[221184];
    bin_file.read(tmp_mem, 221184);
    cudaMemcpyAsync(output0, tmp_mem, 221184, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_9
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_9_0	type: float	shape: Shape{32}
void inception3_Constant_float_cuda_Constant_9(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_9_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_9_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[128];
    bin_file.read(tmp_mem, 128);
    cudaMemcpyAsync(output0, tmp_mem, 128, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_211
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_211_0	type: float	shape: Shape{192}
void inception3_Constant_float_cuda_Constant_211(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_211_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_211_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[768];
    bin_file.read(tmp_mem, 768);
    cudaMemcpyAsync(output0, tmp_mem, 768, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_181
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_181_0	type: float	shape: Shape{7, 1, 128, 128}
void inception3_Constant_float_cuda_Constant_181(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_181_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_181_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[458752];
    bin_file.read(tmp_mem, 458752);
    cudaMemcpyAsync(output0, tmp_mem, 458752, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_160
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_160_0	type: float	shape: Shape{192}
void inception3_Constant_float_cuda_Constant_160(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_160_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_160_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[768];
    bin_file.read(tmp_mem, 768);
    cudaMemcpyAsync(output0, tmp_mem, 768, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_200
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_200_0	type: float	shape: Shape{192}
void inception3_Constant_float_cuda_Constant_200(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_200_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_200_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[768];
    bin_file.read(tmp_mem, 768);
    cudaMemcpyAsync(output0, tmp_mem, 768, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_170
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_170_0	type: float	shape: Shape{128}
void inception3_Constant_float_cuda_Constant_170(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_170_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_170_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[512];
    bin_file.read(tmp_mem, 512);
    cudaMemcpyAsync(output0, tmp_mem, 512, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_199
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_199_0	type: float	shape: Shape{192}
void inception3_Constant_float_cuda_Constant_199(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_199_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_199_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[768];
    bin_file.read(tmp_mem, 768);
    cudaMemcpyAsync(output0, tmp_mem, 768, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_406
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_406_0	type: float	shape: Shape{3, 1, 384, 384}
void inception3_Constant_float_cuda_Constant_406(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_406_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_406_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[1769472];
    bin_file.read(tmp_mem, 1769472);
    cudaMemcpyAsync(output0, tmp_mem, 1769472, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_316
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_316_0	type: float	shape: Shape{192}
void inception3_Constant_float_cuda_Constant_316(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_316_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_316_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[768];
    bin_file.read(tmp_mem, 768);
    cudaMemcpyAsync(output0, tmp_mem, 768, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_175
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_175_0	type: float	shape: Shape{192}
void inception3_Constant_float_cuda_Constant_175(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_175_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_175_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[768];
    bin_file.read(tmp_mem, 768);
    cudaMemcpyAsync(output0, tmp_mem, 768, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_174
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_174_0	type: float	shape: Shape{192}
void inception3_Constant_float_cuda_Constant_174(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_174_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_174_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[768];
    bin_file.read(tmp_mem, 768);
    cudaMemcpyAsync(output0, tmp_mem, 768, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_407
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_407_0	type: float	shape: Shape{384}
void inception3_Constant_float_cuda_Constant_407(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_407_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_407_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[1536];
    bin_file.read(tmp_mem, 1536);
    cudaMemcpyAsync(output0, tmp_mem, 1536, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_413
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_413_0	type: float	shape: Shape{448}
void inception3_Constant_float_cuda_Constant_413(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_413_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_413_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[1792];
    bin_file.read(tmp_mem, 1792);
    cudaMemcpyAsync(output0, tmp_mem, 1792, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_172
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_172_0	type: float	shape: Shape{192}
void inception3_Constant_float_cuda_Constant_172(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_172_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_172_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[768];
    bin_file.read(tmp_mem, 768);
    cudaMemcpyAsync(output0, tmp_mem, 768, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_203
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_203_0	type: float	shape: Shape{192}
void inception3_Constant_float_cuda_Constant_203(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_203_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_203_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[768];
    bin_file.read(tmp_mem, 768);
    cudaMemcpyAsync(output0, tmp_mem, 768, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_159
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_159_0	type: float	shape: Shape{192}
void inception3_Constant_float_cuda_Constant_159(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_159_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_159_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[768];
    bin_file.read(tmp_mem, 768);
    cudaMemcpyAsync(output0, tmp_mem, 768, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_293
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_293_0	type: float	shape: Shape{7, 1, 160, 160}
void inception3_Constant_float_cuda_Constant_293(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_293_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_293_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[716800];
    bin_file.read(tmp_mem, 716800);
    cudaMemcpyAsync(output0, tmp_mem, 716800, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_209
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_209_0	type: float	shape: Shape{192}
void inception3_Constant_float_cuda_Constant_209(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_209_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_209_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[768];
    bin_file.read(tmp_mem, 768);
    cudaMemcpyAsync(output0, tmp_mem, 768, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_151
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_151_0	type: float	shape: Shape{96}
void inception3_Constant_float_cuda_Constant_151(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_151_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_151_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[384];
    bin_file.read(tmp_mem, 384);
    cudaMemcpyAsync(output0, tmp_mem, 384, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_253
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_253_0	type: float	shape: Shape{192}
void inception3_Constant_float_cuda_Constant_253(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_253_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_253_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[768];
    bin_file.read(tmp_mem, 768);
    cudaMemcpyAsync(output0, tmp_mem, 768, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_184
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_184_0	type: float	shape: Shape{128}
void inception3_Constant_float_cuda_Constant_184(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_184_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_184_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[512];
    bin_file.read(tmp_mem, 512);
    cudaMemcpyAsync(output0, tmp_mem, 512, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_256
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_256_0	type: float	shape: Shape{192}
void inception3_Constant_float_cuda_Constant_256(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_256_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_256_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[768];
    bin_file.read(tmp_mem, 768);
    cudaMemcpyAsync(output0, tmp_mem, 768, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_254
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_254_0	type: float	shape: Shape{192}
void inception3_Constant_float_cuda_Constant_254(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_254_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_254_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[768];
    bin_file.read(tmp_mem, 768);
    cudaMemcpyAsync(output0, tmp_mem, 768, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_194
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_194_0	type: float	shape: Shape{128}
void inception3_Constant_float_cuda_Constant_194(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_194_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_194_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[512];
    bin_file.read(tmp_mem, 512);
    cudaMemcpyAsync(output0, tmp_mem, 512, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_227
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_227_0	type: float	shape: Shape{1, 1, 768, 160}
void inception3_Constant_float_cuda_Constant_227(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_227_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_227_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[491520];
    bin_file.read(tmp_mem, 491520);
    cudaMemcpyAsync(output0, tmp_mem, 491520, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_412
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_412_0	type: float	shape: Shape{448}
void inception3_Constant_float_cuda_Constant_412(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_412_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_412_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[1792];
    bin_file.read(tmp_mem, 1792);
    cudaMemcpyAsync(output0, tmp_mem, 1792, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_388
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_388_0	type: float	shape: Shape{192}
void inception3_Constant_float_cuda_Constant_388(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_388_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_388_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[768];
    bin_file.read(tmp_mem, 768);
    cudaMemcpyAsync(output0, tmp_mem, 768, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_188
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_188_0	type: float	shape: Shape{128}
void inception3_Constant_float_cuda_Constant_188(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_188_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_188_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[512];
    bin_file.read(tmp_mem, 512);
    cudaMemcpyAsync(output0, tmp_mem, 512, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_233
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_233_0	type: float	shape: Shape{160}
void inception3_Constant_float_cuda_Constant_233(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_233_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_233_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[640];
    bin_file.read(tmp_mem, 640);
    cudaMemcpyAsync(output0, tmp_mem, 640, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_235
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_235_0	type: float	shape: Shape{160}
void inception3_Constant_float_cuda_Constant_235(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_235_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_235_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[640];
    bin_file.read(tmp_mem, 640);
    cudaMemcpyAsync(output0, tmp_mem, 640, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_234
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_234_0	type: float	shape: Shape{160}
void inception3_Constant_float_cuda_Constant_234(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_234_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_234_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[640];
    bin_file.read(tmp_mem, 640);
    cudaMemcpyAsync(output0, tmp_mem, 640, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_237
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_237_0	type: float	shape: Shape{1, 7, 160, 160}
void inception3_Constant_float_cuda_Constant_237(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_237_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_237_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[716800];
    bin_file.read(tmp_mem, 716800);
    cudaMemcpyAsync(output0, tmp_mem, 716800, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_131
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_131_0	type: float	shape: Shape{64}
void inception3_Constant_float_cuda_Constant_131(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_131_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_131_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[256];
    bin_file.read(tmp_mem, 256);
    cudaMemcpyAsync(output0, tmp_mem, 256, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_238
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_238_0	type: float	shape: Shape{160}
void inception3_Constant_float_cuda_Constant_238(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_238_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_238_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[640];
    bin_file.read(tmp_mem, 640);
    cudaMemcpyAsync(output0, tmp_mem, 640, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_241
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_241_0	type: float	shape: Shape{160}
void inception3_Constant_float_cuda_Constant_241(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_241_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_241_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[640];
    bin_file.read(tmp_mem, 640);
    cudaMemcpyAsync(output0, tmp_mem, 640, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_239
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_239_0	type: float	shape: Shape{160}
void inception3_Constant_float_cuda_Constant_239(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_239_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_239_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[640];
    bin_file.read(tmp_mem, 640);
    cudaMemcpyAsync(output0, tmp_mem, 640, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_242
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_242_0	type: float	shape: Shape{7, 1, 160, 160}
void inception3_Constant_float_cuda_Constant_242(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_242_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_242_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[716800];
    bin_file.read(tmp_mem, 716800);
    cudaMemcpyAsync(output0, tmp_mem, 716800, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_282
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_282_0	type: float	shape: Shape{160}
void inception3_Constant_float_cuda_Constant_282(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_282_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_282_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[640];
    bin_file.read(tmp_mem, 640);
    cudaMemcpyAsync(output0, tmp_mem, 640, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_354
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_354_0	type: float	shape: Shape{1, 1, 768, 192}
void inception3_Constant_float_cuda_Constant_354(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_354_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_354_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[589824];
    bin_file.read(tmp_mem, 589824);
    cudaMemcpyAsync(output0, tmp_mem, 589824, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_243
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_243_0	type: float	shape: Shape{160}
void inception3_Constant_float_cuda_Constant_243(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_243_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_243_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[640];
    bin_file.read(tmp_mem, 640);
    cudaMemcpyAsync(output0, tmp_mem, 640, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_309
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_309_0	type: float	shape: Shape{1, 1, 768, 192}
void inception3_Constant_float_cuda_Constant_309(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_309_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_309_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[589824];
    bin_file.read(tmp_mem, 589824);
    cudaMemcpyAsync(output0, tmp_mem, 589824, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_97
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_97_0	type: float	shape: Shape{64}
void inception3_Constant_float_cuda_Constant_97(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_97_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_97_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[256];
    bin_file.read(tmp_mem, 256);
    cudaMemcpyAsync(output0, tmp_mem, 256, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_245
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_245_0	type: float	shape: Shape{160}
void inception3_Constant_float_cuda_Constant_245(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_245_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_245_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[640];
    bin_file.read(tmp_mem, 640);
    cudaMemcpyAsync(output0, tmp_mem, 640, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_440
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_440_0	type: float	shape: Shape{320}
void inception3_Constant_float_cuda_Constant_440(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_440_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_440_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[1280];
    bin_file.read(tmp_mem, 1280);
    cudaMemcpyAsync(output0, tmp_mem, 1280, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_248
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_248_0	type: float	shape: Shape{192}
void inception3_Constant_float_cuda_Constant_248(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_248_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_248_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[768];
    bin_file.read(tmp_mem, 768);
    cudaMemcpyAsync(output0, tmp_mem, 768, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_152
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_152_0	type: float	shape: Shape{96}
void inception3_Constant_float_cuda_Constant_152(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_152_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_152_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[384];
    bin_file.read(tmp_mem, 384);
    cudaMemcpyAsync(output0, tmp_mem, 384, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_231
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_231_0	type: float	shape: Shape{160}
void inception3_Constant_float_cuda_Constant_231(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_231_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_231_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[640];
    bin_file.read(tmp_mem, 640);
    cudaMemcpyAsync(output0, tmp_mem, 640, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_288
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_288_0	type: float	shape: Shape{1, 7, 160, 160}
void inception3_Constant_float_cuda_Constant_288(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_288_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_288_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[716800];
    bin_file.read(tmp_mem, 716800);
    cudaMemcpyAsync(output0, tmp_mem, 716800, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_312
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_312_0	type: float	shape: Shape{192}
void inception3_Constant_float_cuda_Constant_312(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_312_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_312_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[768];
    bin_file.read(tmp_mem, 768);
    cudaMemcpyAsync(output0, tmp_mem, 768, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_244
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_244_0	type: float	shape: Shape{160}
void inception3_Constant_float_cuda_Constant_244(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_244_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_244_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[640];
    bin_file.read(tmp_mem, 640);
    cudaMemcpyAsync(output0, tmp_mem, 640, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_289
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_289_0	type: float	shape: Shape{160}
void inception3_Constant_float_cuda_Constant_289(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_289_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_289_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[640];
    bin_file.read(tmp_mem, 640);
    cudaMemcpyAsync(output0, tmp_mem, 640, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_271
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_271_0	type: float	shape: Shape{160}
void inception3_Constant_float_cuda_Constant_271(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_271_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_271_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[640];
    bin_file.read(tmp_mem, 640);
    cudaMemcpyAsync(output0, tmp_mem, 640, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_247
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_247_0	type: float	shape: Shape{1, 7, 160, 192}
void inception3_Constant_float_cuda_Constant_247(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_247_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_247_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[860160];
    bin_file.read(tmp_mem, 860160);
    cudaMemcpyAsync(output0, tmp_mem, 860160, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_252
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_252_0	type: float	shape: Shape{1, 1, 768, 192}
void inception3_Constant_float_cuda_Constant_252(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_252_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_252_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[589824];
    bin_file.read(tmp_mem, 589824);
    cudaMemcpyAsync(output0, tmp_mem, 589824, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_249
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_249_0	type: float	shape: Shape{192}
void inception3_Constant_float_cuda_Constant_249(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_249_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_249_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[768];
    bin_file.read(tmp_mem, 768);
    cudaMemcpyAsync(output0, tmp_mem, 768, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_313
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_313_0	type: float	shape: Shape{192}
void inception3_Constant_float_cuda_Constant_313(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_313_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_313_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[768];
    bin_file.read(tmp_mem, 768);
    cudaMemcpyAsync(output0, tmp_mem, 768, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_216
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_216_0	type: float	shape: Shape{160}
void inception3_Constant_float_cuda_Constant_216(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_216_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_216_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[640];
    bin_file.read(tmp_mem, 640);
    cudaMemcpyAsync(output0, tmp_mem, 640, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_269
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_269_0	type: float	shape: Shape{160}
void inception3_Constant_float_cuda_Constant_269(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_269_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_269_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[640];
    bin_file.read(tmp_mem, 640);
    cudaMemcpyAsync(output0, tmp_mem, 640, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_224
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_224_0	type: float	shape: Shape{192}
void inception3_Constant_float_cuda_Constant_224(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_224_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_224_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[768];
    bin_file.read(tmp_mem, 768);
    cudaMemcpyAsync(output0, tmp_mem, 768, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_215
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_215_0	type: float	shape: Shape{160}
void inception3_Constant_float_cuda_Constant_215(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_215_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_215_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[640];
    bin_file.read(tmp_mem, 640);
    cudaMemcpyAsync(output0, tmp_mem, 640, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_214
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_214_0	type: float	shape: Shape{160}
void inception3_Constant_float_cuda_Constant_214(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_214_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_214_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[640];
    bin_file.read(tmp_mem, 640);
    cudaMemcpyAsync(output0, tmp_mem, 640, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_277
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_277_0	type: float	shape: Shape{192}
void inception3_Constant_float_cuda_Constant_277(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_277_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_277_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[768];
    bin_file.read(tmp_mem, 768);
    cudaMemcpyAsync(output0, tmp_mem, 768, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_217
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_217_0	type: float	shape: Shape{1, 7, 160, 160}
void inception3_Constant_float_cuda_Constant_217(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_217_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_217_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[716800];
    bin_file.read(tmp_mem, 716800);
    cudaMemcpyAsync(output0, tmp_mem, 716800, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_218
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_218_0	type: float	shape: Shape{160}
void inception3_Constant_float_cuda_Constant_218(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_218_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_218_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[640];
    bin_file.read(tmp_mem, 640);
    cudaMemcpyAsync(output0, tmp_mem, 640, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_220
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_220_0	type: float	shape: Shape{160}
void inception3_Constant_float_cuda_Constant_220(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_220_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_220_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[640];
    bin_file.read(tmp_mem, 640);
    cudaMemcpyAsync(output0, tmp_mem, 640, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_222
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_222_0	type: float	shape: Shape{7, 1, 160, 192}
void inception3_Constant_float_cuda_Constant_222(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_222_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_222_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[860160];
    bin_file.read(tmp_mem, 860160);
    cudaMemcpyAsync(output0, tmp_mem, 860160, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_103
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_103_0	type: float	shape: Shape{64}
void inception3_Constant_float_cuda_Constant_103(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_103_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_103_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[256];
    bin_file.read(tmp_mem, 256);
    cudaMemcpyAsync(output0, tmp_mem, 256, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_292
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_292_0	type: float	shape: Shape{160}
void inception3_Constant_float_cuda_Constant_292(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_292_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_292_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[640];
    bin_file.read(tmp_mem, 640);
    cudaMemcpyAsync(output0, tmp_mem, 640, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_324
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_324_0	type: float	shape: Shape{7, 1, 192, 192}
void inception3_Constant_float_cuda_Constant_324(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_324_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_324_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[1032192];
    bin_file.read(tmp_mem, 1032192);
    cudaMemcpyAsync(output0, tmp_mem, 1032192, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_182
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_182_0	type: float	shape: Shape{128}
void inception3_Constant_float_cuda_Constant_182(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_182_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_182_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[512];
    bin_file.read(tmp_mem, 512);
    cudaMemcpyAsync(output0, tmp_mem, 512, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_225
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_225_0	type: float	shape: Shape{192}
void inception3_Constant_float_cuda_Constant_225(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_225_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_225_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[768];
    bin_file.read(tmp_mem, 768);
    cudaMemcpyAsync(output0, tmp_mem, 768, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_431
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_431_0	type: float	shape: Shape{1, 1, 1280, 192}
void inception3_Constant_float_cuda_Constant_431(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_431_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_431_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[983040];
    bin_file.read(tmp_mem, 983040);
    cudaMemcpyAsync(output0, tmp_mem, 983040, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_63
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_63_0	type: float	shape: Shape{1, 1, 256, 64}
void inception3_Constant_float_cuda_Constant_63(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_63_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_63_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[65536];
    bin_file.read(tmp_mem, 65536);
    cudaMemcpyAsync(output0, tmp_mem, 65536, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_210
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_210_0	type: float	shape: Shape{192}
void inception3_Constant_float_cuda_Constant_210(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_210_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_210_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[768];
    bin_file.read(tmp_mem, 768);
    cudaMemcpyAsync(output0, tmp_mem, 768, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_303
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_303_0	type: float	shape: Shape{1, 1, 768, 192}
void inception3_Constant_float_cuda_Constant_303(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_303_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_303_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[589824];
    bin_file.read(tmp_mem, 589824);
    cudaMemcpyAsync(output0, tmp_mem, 589824, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_427
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_427_0	type: float	shape: Shape{384}
void inception3_Constant_float_cuda_Constant_427(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_427_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_427_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[1536];
    bin_file.read(tmp_mem, 1536);
    cudaMemcpyAsync(output0, tmp_mem, 1536, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_307
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_307_0	type: float	shape: Shape{192}
void inception3_Constant_float_cuda_Constant_307(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_307_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_307_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[768];
    bin_file.read(tmp_mem, 768);
    cudaMemcpyAsync(output0, tmp_mem, 768, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_149
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_149_0	type: float	shape: Shape{96}
void inception3_Constant_float_cuda_Constant_149(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_149_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_149_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[384];
    bin_file.read(tmp_mem, 384);
    cudaMemcpyAsync(output0, tmp_mem, 384, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_306
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_306_0	type: float	shape: Shape{192}
void inception3_Constant_float_cuda_Constant_306(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_306_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_306_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[768];
    bin_file.read(tmp_mem, 768);
    cudaMemcpyAsync(output0, tmp_mem, 768, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_305
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_305_0	type: float	shape: Shape{192}
void inception3_Constant_float_cuda_Constant_305(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_305_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_305_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[768];
    bin_file.read(tmp_mem, 768);
    cudaMemcpyAsync(output0, tmp_mem, 768, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_372
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_372_0	type: float	shape: Shape{192}
void inception3_Constant_float_cuda_Constant_372(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_372_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_372_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[768];
    bin_file.read(tmp_mem, 768);
    cudaMemcpyAsync(output0, tmp_mem, 768, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_279
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_279_0	type: float	shape: Shape{160}
void inception3_Constant_float_cuda_Constant_279(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_279_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_279_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[640];
    bin_file.read(tmp_mem, 640);
    cudaMemcpyAsync(output0, tmp_mem, 640, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_127
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_127_0	type: float	shape: Shape{96}
void inception3_Constant_float_cuda_Constant_127(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_127_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_127_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[384];
    bin_file.read(tmp_mem, 384);
    cudaMemcpyAsync(output0, tmp_mem, 384, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_281
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_281_0	type: float	shape: Shape{160}
void inception3_Constant_float_cuda_Constant_281(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_281_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_281_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[640];
    bin_file.read(tmp_mem, 640);
    cudaMemcpyAsync(output0, tmp_mem, 640, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_302
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_302_0	type: float	shape: Shape{192}
void inception3_Constant_float_cuda_Constant_302(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_302_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_302_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[768];
    bin_file.read(tmp_mem, 768);
    cudaMemcpyAsync(output0, tmp_mem, 768, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_287
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_287_0	type: float	shape: Shape{160}
void inception3_Constant_float_cuda_Constant_287(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_287_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_287_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[640];
    bin_file.read(tmp_mem, 640);
    cudaMemcpyAsync(output0, tmp_mem, 640, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_435
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_435_0	type: float	shape: Shape{192}
void inception3_Constant_float_cuda_Constant_435(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_435_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_435_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[768];
    bin_file.read(tmp_mem, 768);
    cudaMemcpyAsync(output0, tmp_mem, 768, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_291
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_291_0	type: float	shape: Shape{160}
void inception3_Constant_float_cuda_Constant_291(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_291_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_291_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[640];
    bin_file.read(tmp_mem, 640);
    cudaMemcpyAsync(output0, tmp_mem, 640, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_394
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_394_0	type: float	shape: Shape{320}
void inception3_Constant_float_cuda_Constant_394(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_394_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_394_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[1280];
    bin_file.read(tmp_mem, 1280);
    cudaMemcpyAsync(output0, tmp_mem, 1280, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_41
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_41_0	type: float	shape: Shape{64}
void inception3_Constant_float_cuda_Constant_41(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_41_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_41_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[256];
    bin_file.read(tmp_mem, 256);
    cudaMemcpyAsync(output0, tmp_mem, 256, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_294
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_294_0	type: float	shape: Shape{160}
void inception3_Constant_float_cuda_Constant_294(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_294_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_294_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[640];
    bin_file.read(tmp_mem, 640);
    cudaMemcpyAsync(output0, tmp_mem, 640, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_297
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_297_0	type: float	shape: Shape{160}
void inception3_Constant_float_cuda_Constant_297(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_297_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_297_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[640];
    bin_file.read(tmp_mem, 640);
    cudaMemcpyAsync(output0, tmp_mem, 640, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_298
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_298_0	type: float	shape: Shape{1, 7, 160, 192}
void inception3_Constant_float_cuda_Constant_298(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_298_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_298_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[860160];
    bin_file.read(tmp_mem, 860160);
    cudaMemcpyAsync(output0, tmp_mem, 860160, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_93
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_93_0	type: float	shape: Shape{1, 1, 256, 64}
void inception3_Constant_float_cuda_Constant_93(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_93_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_93_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[65536];
    bin_file.read(tmp_mem, 65536);
    cudaMemcpyAsync(output0, tmp_mem, 65536, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_299
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_299_0	type: float	shape: Shape{192}
void inception3_Constant_float_cuda_Constant_299(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_299_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_299_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[768];
    bin_file.read(tmp_mem, 768);
    cudaMemcpyAsync(output0, tmp_mem, 768, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_79
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_79_0	type: float	shape: Shape{64}
void inception3_Constant_float_cuda_Constant_79(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_79_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_79_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[256];
    bin_file.read(tmp_mem, 256);
    cudaMemcpyAsync(output0, tmp_mem, 256, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_266
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_266_0	type: float	shape: Shape{160}
void inception3_Constant_float_cuda_Constant_266(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_266_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_266_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[640];
    bin_file.read(tmp_mem, 640);
    cudaMemcpyAsync(output0, tmp_mem, 640, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_268
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_268_0	type: float	shape: Shape{1, 7, 160, 160}
void inception3_Constant_float_cuda_Constant_268(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_268_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_268_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[716800];
    bin_file.read(tmp_mem, 716800);
    cudaMemcpyAsync(output0, tmp_mem, 716800, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_270
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_270_0	type: float	shape: Shape{160}
void inception3_Constant_float_cuda_Constant_270(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_270_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_270_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[640];
    bin_file.read(tmp_mem, 640);
    cudaMemcpyAsync(output0, tmp_mem, 640, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_273
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_273_0	type: float	shape: Shape{7, 1, 160, 192}
void inception3_Constant_float_cuda_Constant_273(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_273_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_273_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[860160];
    bin_file.read(tmp_mem, 860160);
    cudaMemcpyAsync(output0, tmp_mem, 860160, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_424
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_424_0	type: float	shape: Shape{384}
void inception3_Constant_float_cuda_Constant_424(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_424_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_424_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[1536];
    bin_file.read(tmp_mem, 1536);
    cudaMemcpyAsync(output0, tmp_mem, 1536, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_333
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_333_0	type: float	shape: Shape{192}
void inception3_Constant_float_cuda_Constant_333(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_333_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_333_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[768];
    bin_file.read(tmp_mem, 768);
    cudaMemcpyAsync(output0, tmp_mem, 768, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_28
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_28_0	type: float	shape: Shape{64}
void inception3_Constant_float_cuda_Constant_28(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_28_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_28_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[256];
    bin_file.read(tmp_mem, 256);
    cudaMemcpyAsync(output0, tmp_mem, 256, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_274
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_274_0	type: float	shape: Shape{192}
void inception3_Constant_float_cuda_Constant_274(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_274_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_274_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[768];
    bin_file.read(tmp_mem, 768);
    cudaMemcpyAsync(output0, tmp_mem, 768, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_276
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_276_0	type: float	shape: Shape{192}
void inception3_Constant_float_cuda_Constant_276(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_276_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_276_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[768];
    bin_file.read(tmp_mem, 768);
    cudaMemcpyAsync(output0, tmp_mem, 768, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_275
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_275_0	type: float	shape: Shape{192}
void inception3_Constant_float_cuda_Constant_275(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_275_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_275_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[768];
    bin_file.read(tmp_mem, 768);
    cudaMemcpyAsync(output0, tmp_mem, 768, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_419
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_419_0	type: float	shape: Shape{384}
void inception3_Constant_float_cuda_Constant_419(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_419_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_419_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[1536];
    bin_file.read(tmp_mem, 1536);
    cudaMemcpyAsync(output0, tmp_mem, 1536, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_195
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_195_0	type: float	shape: Shape{128}
void inception3_Constant_float_cuda_Constant_195(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_195_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_195_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[512];
    bin_file.read(tmp_mem, 512);
    cudaMemcpyAsync(output0, tmp_mem, 512, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_258
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_258_0	type: float	shape: Shape{1, 1, 768, 192}
void inception3_Constant_float_cuda_Constant_258(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_258_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_258_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[589824];
    bin_file.read(tmp_mem, 589824);
    cudaMemcpyAsync(output0, tmp_mem, 589824, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_262
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_262_0	type: float	shape: Shape{192}
void inception3_Constant_float_cuda_Constant_262(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_262_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_262_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[768];
    bin_file.read(tmp_mem, 768);
    cudaMemcpyAsync(output0, tmp_mem, 768, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_260
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_260_0	type: float	shape: Shape{192}
void inception3_Constant_float_cuda_Constant_260(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_260_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_260_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[768];
    bin_file.read(tmp_mem, 768);
    cudaMemcpyAsync(output0, tmp_mem, 768, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_355
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_355_0	type: float	shape: Shape{192}
void inception3_Constant_float_cuda_Constant_355(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_355_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_355_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[768];
    bin_file.read(tmp_mem, 768);
    cudaMemcpyAsync(output0, tmp_mem, 768, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_362
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_362_0	type: float	shape: Shape{192}
void inception3_Constant_float_cuda_Constant_362(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_362_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_362_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[768];
    bin_file.read(tmp_mem, 768);
    cudaMemcpyAsync(output0, tmp_mem, 768, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_357
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_357_0	type: float	shape: Shape{192}
void inception3_Constant_float_cuda_Constant_357(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_357_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_357_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[768];
    bin_file.read(tmp_mem, 768);
    cudaMemcpyAsync(output0, tmp_mem, 768, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_230
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_230_0	type: float	shape: Shape{160}
void inception3_Constant_float_cuda_Constant_230(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_230_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_230_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[640];
    bin_file.read(tmp_mem, 640);
    cudaMemcpyAsync(output0, tmp_mem, 640, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_356
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_356_0	type: float	shape: Shape{192}
void inception3_Constant_float_cuda_Constant_356(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_356_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_356_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[768];
    bin_file.read(tmp_mem, 768);
    cudaMemcpyAsync(output0, tmp_mem, 768, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_329
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_329_0	type: float	shape: Shape{1, 1, 768, 192}
void inception3_Constant_float_cuda_Constant_329(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_329_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_329_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[589824];
    bin_file.read(tmp_mem, 589824);
    cudaMemcpyAsync(output0, tmp_mem, 589824, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_334
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_334_0	type: float	shape: Shape{7, 1, 192, 192}
void inception3_Constant_float_cuda_Constant_334(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_334_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_334_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[1032192];
    bin_file.read(tmp_mem, 1032192);
    cudaMemcpyAsync(output0, tmp_mem, 1032192, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_335
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_335_0	type: float	shape: Shape{192}
void inception3_Constant_float_cuda_Constant_335(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_335_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_335_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[768];
    bin_file.read(tmp_mem, 768);
    cudaMemcpyAsync(output0, tmp_mem, 768, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_106
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_106_0	type: float	shape: Shape{48}
void inception3_Constant_float_cuda_Constant_106(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_106_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_106_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[192];
    bin_file.read(tmp_mem, 192);
    cudaMemcpyAsync(output0, tmp_mem, 192, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_338
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_338_0	type: float	shape: Shape{192}
void inception3_Constant_float_cuda_Constant_338(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_338_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_338_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[768];
    bin_file.read(tmp_mem, 768);
    cudaMemcpyAsync(output0, tmp_mem, 768, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_336
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_336_0	type: float	shape: Shape{192}
void inception3_Constant_float_cuda_Constant_336(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_336_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_336_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[768];
    bin_file.read(tmp_mem, 768);
    cudaMemcpyAsync(output0, tmp_mem, 768, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_415
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_415_0	type: float	shape: Shape{448}
void inception3_Constant_float_cuda_Constant_415(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_415_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_415_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[1792];
    bin_file.read(tmp_mem, 1792);
    cudaMemcpyAsync(output0, tmp_mem, 1792, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_342
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_342_0	type: float	shape: Shape{192}
void inception3_Constant_float_cuda_Constant_342(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_342_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_342_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[768];
    bin_file.read(tmp_mem, 768);
    cudaMemcpyAsync(output0, tmp_mem, 768, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_75
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_75_0	type: float	shape: Shape{64}
void inception3_Constant_float_cuda_Constant_75(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_75_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_75_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[256];
    bin_file.read(tmp_mem, 256);
    cudaMemcpyAsync(output0, tmp_mem, 256, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_341
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_341_0	type: float	shape: Shape{192}
void inception3_Constant_float_cuda_Constant_341(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_341_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_341_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[768];
    bin_file.read(tmp_mem, 768);
    cudaMemcpyAsync(output0, tmp_mem, 768, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_348
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_348_0	type: float	shape: Shape{192}
void inception3_Constant_float_cuda_Constant_348(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_348_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_348_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[768];
    bin_file.read(tmp_mem, 768);
    cudaMemcpyAsync(output0, tmp_mem, 768, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_446
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_446_0	type: float	shape: Shape{384}
void inception3_Constant_float_cuda_Constant_446(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_446_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_446_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[1536];
    bin_file.read(tmp_mem, 1536);
    cudaMemcpyAsync(output0, tmp_mem, 1536, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_153
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_153_0	type: float	shape: Shape{96}
void inception3_Constant_float_cuda_Constant_153(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_153_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_153_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[384];
    bin_file.read(tmp_mem, 384);
    cudaMemcpyAsync(output0, tmp_mem, 384, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_346
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_346_0	type: float	shape: Shape{192}
void inception3_Constant_float_cuda_Constant_346(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_346_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_346_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[768];
    bin_file.read(tmp_mem, 768);
    cudaMemcpyAsync(output0, tmp_mem, 768, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_381
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_381_0	type: float	shape: Shape{192}
void inception3_Constant_float_cuda_Constant_381(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_381_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_381_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[768];
    bin_file.read(tmp_mem, 768);
    cudaMemcpyAsync(output0, tmp_mem, 768, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Constant_296
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_296_0	type: float	shape: Shape{160}
void inception3_Constant_float_cuda_Constant_296(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_296_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_296_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[640];
    bin_file.read(tmp_mem, 640);
    cudaMemcpyAsync(output0, tmp_mem, 640, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Convolution_814
// Description:	Convolution
// Input:
//	- name: inception3_Concat_810_0	type: float	shape: Shape{64, 1280, 8, 8}
//	- name: inception3_Reshape_813_0	type: float	shape: Shape{384, 1280, 1, 1}
// Output:
//	- name: inception3_Convolution_814_0	type: float	shape: Shape{64, 384, 8, 8}
void Convolution_float_float_float_cuda_lib_Convolution_814(cudnnHandle_t cudnn_handle, float* input0, float* input1, float* output0)
{
    cudnnTensorDescriptor_t tensor_desc_0;
    CUDNN_SAFE_CALL(cudnnCreateTensorDescriptor(&tensor_desc_0));
    CUDNN_SAFE_CALL(cudnnSetTensor4dDescriptor(tensor_desc_0, CUDNN_TENSOR_NCHW, CUDNN_DATA_FLOAT, 64, 1280, 8, 8));
    cudnnTensorDescriptor_t tensor_desc_1;
    CUDNN_SAFE_CALL(cudnnCreateTensorDescriptor(&tensor_desc_1));
    CUDNN_SAFE_CALL(cudnnSetTensor4dDescriptor(tensor_desc_1, CUDNN_TENSOR_NCHW, CUDNN_DATA_FLOAT, 64, 384, 8, 8));
    cudnnFilterDescriptor_t filter_desc;
    CUDNN_SAFE_CALL(cudnnCreateFilterDescriptor(&filter_desc));
    CUDNN_SAFE_CALL(cudnnSetFilter4dDescriptor(filter_desc, CUDNN_DATA_FLOAT, CUDNN_TENSOR_NCHW, 384, 1280, 1, 1));
    cudnnConvolutionDescriptor_t conv_desc;
    CUDNN_SAFE_CALL(cudnnCreateConvolutionDescriptor(&conv_desc));
    CUDNN_SAFE_CALL(cudnnSetConvolution2dDescriptor(conv_desc, 0, 0, 1, 1, 1, 1, CUDNN_CROSS_CORRELATION, CUDNN_DATA_FLOAT));

    static bool selected_algo = true;
    static cudnnConvolutionFwdAlgo_t conv_fwd_algo = CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM;

    if (!selected_algo) {
        int num_algos;
        int max_algos = 0;
        // cudnnGetConvolutionForwardAlgorithm_v7;
        CUDNN_SAFE_CALL(
            cudnnGetConvolutionForwardAlgorithmMaxCount(cudnn_handle, &max_algos));
        std::vector<cudnnConvolutionFwdAlgoPerf_t> results(max_algos);
        CUDNN_SAFE_CALL(cudnnFindConvolutionForwardAlgorithm(cudnn_handle,
                                                tensor_desc_0,
                                                filter_desc,
                                                conv_desc,
                                                tensor_desc_1,
                                                static_cast<int>(results.size()),
                                                &num_algos,
                                                results.data()));
        results.resize(num_algos);
        for (size_t i = 0; i != results.size(); ++i) {
            cudnnConvolutionFwdAlgoPerf_t const& result = results[i];
            if (result.status == CUDNN_STATUS_SUCCESS) {
                conv_fwd_algo = result.algo;
                break;
            }
        }
        selected_algo = true;
    }
    const float alpha = 1.0;
    const float beta = 0.0;
    static void *workspace_ptr_0 = NULL;
    static size_t workspace_size_in_bytes = 0;
    if (!workspace_ptr_0)
    {
        CUDNN_SAFE_CALL(cudnnGetConvolutionForwardWorkspaceSize(cudnn_handle, tensor_desc_0, filter_desc, conv_desc, tensor_desc_1, conv_fwd_algo, &workspace_size_in_bytes));
        CUDA_SAFE_CALL(cudaMalloc(&workspace_ptr_0, workspace_size_in_bytes));
    }
    CUDNN_SAFE_CALL(cudnnConvolutionForward(cudnn_handle, &alpha, tensor_desc_0, input0,filter_desc, input1, conv_desc, conv_fwd_algo, workspace_ptr_0, workspace_size_in_bytes, &beta, tensor_desc_1, output0));
    CUDNN_SAFE_CALL(cudnnDestroyTensorDescriptor(tensor_desc_0));
    CUDNN_SAFE_CALL(cudnnDestroyTensorDescriptor(tensor_desc_1));
    CUDNN_SAFE_CALL(cudnnDestroyFilterDescriptor(filter_desc));
    CUDNN_SAFE_CALL(cudnnDestroyConvolutionDescriptor(conv_desc));

}
// Node name:	Constant_349
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_349_0	type: float	shape: Shape{1, 7, 192, 192}
void inception3_Constant_float_cuda_Constant_349(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_349_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_349_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[1032192];
    bin_file.read(tmp_mem, 1032192);
    cudaMemcpyAsync(output0, tmp_mem, 1032192, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	Convolution_697
// Description:	Convolution
// Input:
//	- name: inception3_Relu_695_0	type: float	shape: Shape{64, 160, 17, 17}
//	- name: inception3_Reshape_696_0	type: float	shape: Shape{192, 160, 1, 7}
// Output:
//	- name: inception3_Convolution_697_0	type: float	shape: Shape{64, 192, 17, 17}
void Convolution_float_float_float_cuda_lib_Convolution_697(cudnnHandle_t cudnn_handle, float* input0, float* input1, float* output0)
{
    cudnnTensorDescriptor_t tensor_desc_0;
    CUDNN_SAFE_CALL(cudnnCreateTensorDescriptor(&tensor_desc_0));
    CUDNN_SAFE_CALL(cudnnSetTensor4dDescriptor(tensor_desc_0, CUDNN_TENSOR_NCHW, CUDNN_DATA_FLOAT, 64, 160, 17, 17));
    cudnnTensorDescriptor_t tensor_desc_1;
    CUDNN_SAFE_CALL(cudnnCreateTensorDescriptor(&tensor_desc_1));
    CUDNN_SAFE_CALL(cudnnSetTensor4dDescriptor(tensor_desc_1, CUDNN_TENSOR_NCHW, CUDNN_DATA_FLOAT, 64, 192, 17, 17));
    cudnnFilterDescriptor_t filter_desc;
    CUDNN_SAFE_CALL(cudnnCreateFilterDescriptor(&filter_desc));
    CUDNN_SAFE_CALL(cudnnSetFilter4dDescriptor(filter_desc, CUDNN_DATA_FLOAT, CUDNN_TENSOR_NCHW, 192, 160, 1, 7));
    cudnnConvolutionDescriptor_t conv_desc;
    CUDNN_SAFE_CALL(cudnnCreateConvolutionDescriptor(&conv_desc));
    CUDNN_SAFE_CALL(cudnnSetConvolution2dDescriptor(conv_desc, 0, 3, 1, 1, 1, 1, CUDNN_CROSS_CORRELATION, CUDNN_DATA_FLOAT));

    static bool selected_algo = true;
    static cudnnConvolutionFwdAlgo_t conv_fwd_algo = CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM;

    if (!selected_algo) {
        int num_algos;
        int max_algos = 0;
        // cudnnGetConvolutionForwardAlgorithm_v7;
        CUDNN_SAFE_CALL(
            cudnnGetConvolutionForwardAlgorithmMaxCount(cudnn_handle, &max_algos));
        std::vector<cudnnConvolutionFwdAlgoPerf_t> results(max_algos);
        CUDNN_SAFE_CALL(cudnnFindConvolutionForwardAlgorithm(cudnn_handle,
                                                tensor_desc_0,
                                                filter_desc,
                                                conv_desc,
                                                tensor_desc_1,
                                                static_cast<int>(results.size()),
                                                &num_algos,
                                                results.data()));
        results.resize(num_algos);
        for (size_t i = 0; i != results.size(); ++i) {
            cudnnConvolutionFwdAlgoPerf_t const& result = results[i];
            if (result.status == CUDNN_STATUS_SUCCESS) {
                conv_fwd_algo = result.algo;
                break;
            }
        }
        selected_algo = true;
    }
    const float alpha = 1.0;
    const float beta = 0.0;
    static void *workspace_ptr_0 = NULL;
    static size_t workspace_size_in_bytes = 0;
    if (!workspace_ptr_0)
    {
        CUDNN_SAFE_CALL(cudnnGetConvolutionForwardWorkspaceSize(cudnn_handle, tensor_desc_0, filter_desc, conv_desc, tensor_desc_1, conv_fwd_algo, &workspace_size_in_bytes));
        CUDA_SAFE_CALL(cudaMalloc(&workspace_ptr_0, workspace_size_in_bytes));
    }
    CUDNN_SAFE_CALL(cudnnConvolutionForward(cudnn_handle, &alpha, tensor_desc_0, input0,filter_desc, input1, conv_desc, conv_fwd_algo, workspace_ptr_0, workspace_size_in_bytes, &beta, tensor_desc_1, output0));
    CUDNN_SAFE_CALL(cudnnDestroyTensorDescriptor(tensor_desc_0));
    CUDNN_SAFE_CALL(cudnnDestroyTensorDescriptor(tensor_desc_1));
    CUDNN_SAFE_CALL(cudnnDestroyFilterDescriptor(filter_desc));
    CUDNN_SAFE_CALL(cudnnDestroyConvolutionDescriptor(conv_desc));

}
// Node name:	Concat_538
// Description:	Concat
// Input:
//	- name: inception3_Relu_521_0	type: float	shape: Shape{64, 64, 35, 35}
//	- name: inception3_Relu_532_0	type: float	shape: Shape{64, 64, 35, 35}
//	- name: inception3_Relu_537_0	type: float	shape: Shape{64, 96, 35, 35}
//	- name: inception3_Relu_529_0	type: float	shape: Shape{64, 32, 35, 35}
// Output:
//	- name: inception3_Concat_538_0	type: float	shape: Shape{64, 256, 35, 35}
extern "C" __launch_bounds__(512) __global__ void inception3_Concat_float_float_float_float_float_cuda_Concat_538(float* input0, float* input1, float* input2, float* input3, float* output0)
{
    uint32_t inputs_strides[] = {78400, 78400, 117600, 39200};
    uint32_t tid = blockIdx.x * blockDim.x + threadIdx.x;
    if(tid < 20070400)
    {
        uint32_t block_id = tid / 313600;
        uint32_t block_idx = tid % 313600;
        uint32_t output_idx = block_id * 313600 + block_idx;
        if(block_idx < inputs_strides[0])
        {
            output0[output_idx] = input0[block_id * inputs_strides[0] + block_idx];
            return;
        }
        block_idx -= inputs_strides[0];
        if(block_idx < inputs_strides[1])
        {
            output0[output_idx] = input1[block_id * inputs_strides[1] + block_idx];
            return;
        }
        block_idx -= inputs_strides[1];
        if(block_idx < inputs_strides[2])
        {
            output0[output_idx] = input2[block_id * inputs_strides[2] + block_idx];
            return;
        }
        block_idx -= inputs_strides[2];
        if(block_idx < inputs_strides[3])
        {
            output0[output_idx] = input3[block_id * inputs_strides[3] + block_idx];
            return;
        }
        block_idx -= inputs_strides[3];
    }

}
extern void inception3_Concat_float_float_float_float_float_cuda_Concat_538_Call(const dim3 &grids, const dim3 &blocks, unsigned mem, cudaStream_t stream, float* input0, float* input1, float* input2, float* input3, float* output0) {
    inception3_Concat_float_float_float_float_float_cuda_Concat_538<<<grids, blocks, mem, stream>>>(input0, input1, input2, input3, output0);
}
// Node name:	Reshape_696
// Description:	Reshape
// Input:
//	- name: inception3_Constant_247_0	type: float	shape: Shape{1, 7, 160, 192}
// Output:
//	- name: inception3_Reshape_696_0	type: float	shape: Shape{192, 160, 1, 7}
extern "C" __launch_bounds__(256) __global__ void inception3_Reshape_float_float_cuda_Reshape_696(float* input0, float* output0)
{
    uint32_t input_strides0 = 30720;
    uint32_t input_strides1 = 192;
    uint32_t input_strides2 = 1;
    uint32_t trans_strides0 = 1;
    uint32_t trans_strides1 = 7;
    uint32_t trans_strides2 = 1120;
    size_t nx = 192;
    size_t ny = 160;
    size_t nz = 7;
    __shared__ float tile[16][1][17];
    uint32_t base2 = blockIdx.x * blockDim.x;
    uint32_t base1 = blockIdx.y * blockDim.y;
    uint32_t base0 = blockIdx.z * blockDim.z;
    uint32_t tid2 = threadIdx.x;
    uint32_t tid1 = threadIdx.y;
    uint32_t tid0 = threadIdx.z;
    uint32_t otid2 = tid2;
    uint32_t otid1 = tid1;
    uint32_t otid0 = tid0;
    uint32_t idx2 = base2 + tid2;
    uint32_t idx1 = base1 + tid1;
    uint32_t idx0 = base0 + tid0;
    if (idx2 < nx && idx1 < ny && idx0 < nz)
    {
        uint32_t input_idx = 0;
        input_idx += input_strides0* idx0;
        input_idx += input_strides1* idx1;
        input_idx += input_strides2* idx2;
        tile[tid0][tid1][tid2] = input0[input_idx];
    }
    otid2 = tid0;
    otid0 = tid2;
    idx2 = base2 + otid2;
    idx1 = base1 + otid1;
    idx0 = base0 + otid0;
    __syncthreads();
    if (idx2 < nx && idx1 < ny && idx0 < nz)
    {
        uint32_t output_idx = 0;
        output_idx += trans_strides0* idx0;
        output_idx += trans_strides1* idx1;
        output_idx += trans_strides2* idx2;
        output0[output_idx] = tile[otid0][otid1][otid2];
    }

}
extern void inception3_Reshape_float_float_cuda_Reshape_696_Call(const dim3 &grids, const dim3 &blocks, unsigned mem, cudaStream_t stream, float* input0, float* output0) {
    inception3_Reshape_float_float_cuda_Reshape_696<<<grids, blocks, mem, stream>>>(input0, output0);
}
// Node name:	BatchNormInference_626
// Description:	BatchNormInference
// Input:
//	- name: inception3_Constant_177_0	type: float	shape: Shape{128}
//	- name: inception3_Constant_178_0	type: float	shape: Shape{128}
//	- name: inception3_Convolution_622_0	type: float	shape: Shape{64, 128, 17, 17}
//	- name: inception3_Constant_179_0	type: float	shape: Shape{128}
//	- name: inception3_Constant_180_0	type: float	shape: Shape{128}
// Output:
//	- name: inception3_BatchNormInference_626_0	type: float	shape: Shape{64, 128, 17, 17}
extern "C" __launch_bounds__(289) __global__ void inception3_BatchNormInference_float_float_float_float_float_float_cuda_BatchNormInference_626(float* input0, float* input1, float* input2, float* input3, float* input4, float* output0)
{
    const int st = blockIdx.x * 17 * 17;
    const int c_id = blockIdx.x % 128;
    #pragma unroll 1
    for (int i = threadIdx.x; i < 17 * 17; i += blockDim.x)
    {
        output0[st + i] = (input1[c_id] + (input0[c_id] * (input2[st + i] - input3[c_id]) / sqrtf(0.001 + input4[c_id])));
    }

}
extern void inception3_BatchNormInference_float_float_float_float_float_float_cuda_BatchNormInference_626_Call(const dim3 &grids, const dim3 &blocks, unsigned mem, cudaStream_t stream, float* input0, float* input1, float* input2, float* input3, float* input4, float* output0) {
    inception3_BatchNormInference_float_float_float_float_float_float_cuda_BatchNormInference_626<<<grids, blocks, mem, stream>>>(input0, input1, input2, input3, input4, output0);
}
// Node name:	Convolution_643
// Description:	Convolution
// Input:
//	- name: inception3_Relu_640_0	type: float	shape: Shape{64, 128, 17, 17}
//	- name: inception3_Reshape_642_0	type: float	shape: Shape{192, 128, 7, 1}
// Output:
//	- name: inception3_Convolution_643_0	type: float	shape: Shape{64, 192, 17, 17}
void Convolution_float_float_float_cuda_lib_Convolution_643(cudnnHandle_t cudnn_handle, float* input0, float* input1, float* output0)
{
    cudnnTensorDescriptor_t tensor_desc_0;
    CUDNN_SAFE_CALL(cudnnCreateTensorDescriptor(&tensor_desc_0));
    CUDNN_SAFE_CALL(cudnnSetTensor4dDescriptor(tensor_desc_0, CUDNN_TENSOR_NCHW, CUDNN_DATA_FLOAT, 64, 128, 17, 17));
    cudnnTensorDescriptor_t tensor_desc_1;
    CUDNN_SAFE_CALL(cudnnCreateTensorDescriptor(&tensor_desc_1));
    CUDNN_SAFE_CALL(cudnnSetTensor4dDescriptor(tensor_desc_1, CUDNN_TENSOR_NCHW, CUDNN_DATA_FLOAT, 64, 192, 17, 17));
    cudnnFilterDescriptor_t filter_desc;
    CUDNN_SAFE_CALL(cudnnCreateFilterDescriptor(&filter_desc));
    CUDNN_SAFE_CALL(cudnnSetFilter4dDescriptor(filter_desc, CUDNN_DATA_FLOAT, CUDNN_TENSOR_NCHW, 192, 128, 7, 1));
    cudnnConvolutionDescriptor_t conv_desc;
    CUDNN_SAFE_CALL(cudnnCreateConvolutionDescriptor(&conv_desc));
    CUDNN_SAFE_CALL(cudnnSetConvolution2dDescriptor(conv_desc, 3, 0, 1, 1, 1, 1, CUDNN_CROSS_CORRELATION, CUDNN_DATA_FLOAT));

    static bool selected_algo = true;
    static cudnnConvolutionFwdAlgo_t conv_fwd_algo = CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM;

    if (!selected_algo) {
        int num_algos;
        int max_algos = 0;
        // cudnnGetConvolutionForwardAlgorithm_v7;
        CUDNN_SAFE_CALL(
            cudnnGetConvolutionForwardAlgorithmMaxCount(cudnn_handle, &max_algos));
        std::vector<cudnnConvolutionFwdAlgoPerf_t> results(max_algos);
        CUDNN_SAFE_CALL(cudnnFindConvolutionForwardAlgorithm(cudnn_handle,
                                                tensor_desc_0,
                                                filter_desc,
                                                conv_desc,
                                                tensor_desc_1,
                                                static_cast<int>(results.size()),
                                                &num_algos,
                                                results.data()));
        results.resize(num_algos);
        for (size_t i = 0; i != results.size(); ++i) {
            cudnnConvolutionFwdAlgoPerf_t const& result = results[i];
            if (result.status == CUDNN_STATUS_SUCCESS) {
                conv_fwd_algo = result.algo;
                break;
            }
        }
        selected_algo = true;
    }
    const float alpha = 1.0;
    const float beta = 0.0;
    static void *workspace_ptr_0 = NULL;
    static size_t workspace_size_in_bytes = 0;
    if (!workspace_ptr_0)
    {
        CUDNN_SAFE_CALL(cudnnGetConvolutionForwardWorkspaceSize(cudnn_handle, tensor_desc_0, filter_desc, conv_desc, tensor_desc_1, conv_fwd_algo, &workspace_size_in_bytes));
        CUDA_SAFE_CALL(cudaMalloc(&workspace_ptr_0, workspace_size_in_bytes));
    }
    CUDNN_SAFE_CALL(cudnnConvolutionForward(cudnn_handle, &alpha, tensor_desc_0, input0,filter_desc, input1, conv_desc, conv_fwd_algo, workspace_ptr_0, workspace_size_in_bytes, &beta, tensor_desc_1, output0));
    CUDNN_SAFE_CALL(cudnnDestroyTensorDescriptor(tensor_desc_0));
    CUDNN_SAFE_CALL(cudnnDestroyTensorDescriptor(tensor_desc_1));
    CUDNN_SAFE_CALL(cudnnDestroyFilterDescriptor(filter_desc));
    CUDNN_SAFE_CALL(cudnnDestroyConvolutionDescriptor(conv_desc));

}
// Node name:	Convolution_580
// Description:	Convolution
// Input:
//	- name: inception3_AvgPool_575_0	type: float	shape: Shape{64, 288, 35, 35}
//	- name: inception3_Reshape_579_0	type: float	shape: Shape{64, 288, 1, 1}
// Output:
//	- name: inception3_Convolution_580_0	type: float	shape: Shape{64, 64, 35, 35}
void Convolution_float_float_float_cuda_lib_Convolution_580(cudnnHandle_t cudnn_handle, float* input0, float* input1, float* output0)
{
    cudnnTensorDescriptor_t tensor_desc_0;
    CUDNN_SAFE_CALL(cudnnCreateTensorDescriptor(&tensor_desc_0));
    CUDNN_SAFE_CALL(cudnnSetTensor4dDescriptor(tensor_desc_0, CUDNN_TENSOR_NCHW, CUDNN_DATA_FLOAT, 64, 288, 35, 35));
    cudnnTensorDescriptor_t tensor_desc_1;
    CUDNN_SAFE_CALL(cudnnCreateTensorDescriptor(&tensor_desc_1));
    CUDNN_SAFE_CALL(cudnnSetTensor4dDescriptor(tensor_desc_1, CUDNN_TENSOR_NCHW, CUDNN_DATA_FLOAT, 64, 64, 35, 35));
    cudnnFilterDescriptor_t filter_desc;
    CUDNN_SAFE_CALL(cudnnCreateFilterDescriptor(&filter_desc));
    CUDNN_SAFE_CALL(cudnnSetFilter4dDescriptor(filter_desc, CUDNN_DATA_FLOAT, CUDNN_TENSOR_NCHW, 64, 288, 1, 1));
    cudnnConvolutionDescriptor_t conv_desc;
    CUDNN_SAFE_CALL(cudnnCreateConvolutionDescriptor(&conv_desc));
    CUDNN_SAFE_CALL(cudnnSetConvolution2dDescriptor(conv_desc, 0, 0, 1, 1, 1, 1, CUDNN_CROSS_CORRELATION, CUDNN_DATA_FLOAT));

    static bool selected_algo = true;
    static cudnnConvolutionFwdAlgo_t conv_fwd_algo = CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM;

    if (!selected_algo) {
        int num_algos;
        int max_algos = 0;
        // cudnnGetConvolutionForwardAlgorithm_v7;
        CUDNN_SAFE_CALL(
            cudnnGetConvolutionForwardAlgorithmMaxCount(cudnn_handle, &max_algos));
        std::vector<cudnnConvolutionFwdAlgoPerf_t> results(max_algos);
        CUDNN_SAFE_CALL(cudnnFindConvolutionForwardAlgorithm(cudnn_handle,
                                                tensor_desc_0,
                                                filter_desc,
                                                conv_desc,
                                                tensor_desc_1,
                                                static_cast<int>(results.size()),
                                                &num_algos,
                                                results.data()));
        results.resize(num_algos);
        for (size_t i = 0; i != results.size(); ++i) {
            cudnnConvolutionFwdAlgoPerf_t const& result = results[i];
            if (result.status == CUDNN_STATUS_SUCCESS) {
                conv_fwd_algo = result.algo;
                break;
            }
        }
        selected_algo = true;
    }
    const float alpha = 1.0;
    const float beta = 0.0;
    static void *workspace_ptr_0 = NULL;
    static size_t workspace_size_in_bytes = 0;
    if (!workspace_ptr_0)
    {
        CUDNN_SAFE_CALL(cudnnGetConvolutionForwardWorkspaceSize(cudnn_handle, tensor_desc_0, filter_desc, conv_desc, tensor_desc_1, conv_fwd_algo, &workspace_size_in_bytes));
        CUDA_SAFE_CALL(cudaMalloc(&workspace_ptr_0, workspace_size_in_bytes));
    }
    CUDNN_SAFE_CALL(cudnnConvolutionForward(cudnn_handle, &alpha, tensor_desc_0, input0,filter_desc, input1, conv_desc, conv_fwd_algo, workspace_ptr_0, workspace_size_in_bytes, &beta, tensor_desc_1, output0));
    CUDNN_SAFE_CALL(cudnnDestroyTensorDescriptor(tensor_desc_0));
    CUDNN_SAFE_CALL(cudnnDestroyTensorDescriptor(tensor_desc_1));
    CUDNN_SAFE_CALL(cudnnDestroyFilterDescriptor(filter_desc));
    CUDNN_SAFE_CALL(cudnnDestroyConvolutionDescriptor(conv_desc));

}
// Node name:	Convolution_492
// Description:	Convolution
// Input:
//	- name: inception3_Relu_490_0	type: float	shape: Shape{64, 32, 149, 149}
//	- name: inception3_Reshape_491_0	type: float	shape: Shape{32, 32, 3, 3}
// Output:
//	- name: inception3_Convolution_492_0	type: float	shape: Shape{64, 32, 147, 147}
void Convolution_float_float_float_cuda_lib_Convolution_492(cudnnHandle_t cudnn_handle, float* input0, float* input1, float* output0)
{
    cudnnTensorDescriptor_t tensor_desc_0;
    CUDNN_SAFE_CALL(cudnnCreateTensorDescriptor(&tensor_desc_0));
    CUDNN_SAFE_CALL(cudnnSetTensor4dDescriptor(tensor_desc_0, CUDNN_TENSOR_NCHW, CUDNN_DATA_FLOAT, 64, 32, 149, 149));
    cudnnTensorDescriptor_t tensor_desc_1;
    CUDNN_SAFE_CALL(cudnnCreateTensorDescriptor(&tensor_desc_1));
    CUDNN_SAFE_CALL(cudnnSetTensor4dDescriptor(tensor_desc_1, CUDNN_TENSOR_NCHW, CUDNN_DATA_FLOAT, 64, 32, 147, 147));
    cudnnFilterDescriptor_t filter_desc;
    CUDNN_SAFE_CALL(cudnnCreateFilterDescriptor(&filter_desc));
    CUDNN_SAFE_CALL(cudnnSetFilter4dDescriptor(filter_desc, CUDNN_DATA_FLOAT, CUDNN_TENSOR_NCHW, 32, 32, 3, 3));
    cudnnConvolutionDescriptor_t conv_desc;
    CUDNN_SAFE_CALL(cudnnCreateConvolutionDescriptor(&conv_desc));
    CUDNN_SAFE_CALL(cudnnSetConvolution2dDescriptor(conv_desc, 0, 0, 1, 1, 1, 1, CUDNN_CROSS_CORRELATION, CUDNN_DATA_FLOAT));

    static bool selected_algo = true;
    static cudnnConvolutionFwdAlgo_t conv_fwd_algo = CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM;

    if (!selected_algo) {
        int num_algos;
        int max_algos = 0;
        // cudnnGetConvolutionForwardAlgorithm_v7;
        CUDNN_SAFE_CALL(
            cudnnGetConvolutionForwardAlgorithmMaxCount(cudnn_handle, &max_algos));
        std::vector<cudnnConvolutionFwdAlgoPerf_t> results(max_algos);
        CUDNN_SAFE_CALL(cudnnFindConvolutionForwardAlgorithm(cudnn_handle,
                                                tensor_desc_0,
                                                filter_desc,
                                                conv_desc,
                                                tensor_desc_1,
                                                static_cast<int>(results.size()),
                                                &num_algos,
                                                results.data()));
        results.resize(num_algos);
        for (size_t i = 0; i != results.size(); ++i) {
            cudnnConvolutionFwdAlgoPerf_t const& result = results[i];
            if (result.status == CUDNN_STATUS_SUCCESS) {
                conv_fwd_algo = result.algo;
                break;
            }
        }
        selected_algo = true;
    }
    const float alpha = 1.0;
    const float beta = 0.0;
    static void *workspace_ptr_0 = NULL;
    static size_t workspace_size_in_bytes = 0;
    if (!workspace_ptr_0)
    {
        CUDNN_SAFE_CALL(cudnnGetConvolutionForwardWorkspaceSize(cudnn_handle, tensor_desc_0, filter_desc, conv_desc, tensor_desc_1, conv_fwd_algo, &workspace_size_in_bytes));
        CUDA_SAFE_CALL(cudaMalloc(&workspace_ptr_0, workspace_size_in_bytes));
    }
    CUDNN_SAFE_CALL(cudnnConvolutionForward(cudnn_handle, &alpha, tensor_desc_0, input0,filter_desc, input1, conv_desc, conv_fwd_algo, workspace_ptr_0, workspace_size_in_bytes, &beta, tensor_desc_1, output0));
    CUDNN_SAFE_CALL(cudnnDestroyTensorDescriptor(tensor_desc_0));
    CUDNN_SAFE_CALL(cudnnDestroyTensorDescriptor(tensor_desc_1));
    CUDNN_SAFE_CALL(cudnnDestroyFilterDescriptor(filter_desc));
    CUDNN_SAFE_CALL(cudnnDestroyConvolutionDescriptor(conv_desc));

}
// Node name:	BatchNormInference_497
// Description:	BatchNormInference
// Input:
//	- name: inception3_Constant_13_0	type: float	shape: Shape{64}
//	- name: inception3_Constant_14_0	type: float	shape: Shape{64}
//	- name: inception3_Convolution_496_0	type: float	shape: Shape{64, 64, 147, 147}
//	- name: inception3_Constant_15_0	type: float	shape: Shape{64}
//	- name: inception3_Constant_16_0	type: float	shape: Shape{64}
// Output:
//	- name: inception3_BatchNormInference_497_0	type: float	shape: Shape{64, 64, 147, 147}
extern "C" __launch_bounds__(512) __global__ void inception3_BatchNormInference_float_float_float_float_float_float_cuda_BatchNormInference_497(float* input0, float* input1, float* input2, float* input3, float* input4, float* output0)
{
    const int st = blockIdx.x * 147 * 147;
    const int c_id = blockIdx.x % 64;
    #pragma unroll 1
    for (int i = threadIdx.x; i < 147 * 147; i += blockDim.x)
    {
        output0[st + i] = (input1[c_id] + (input0[c_id] * (input2[st + i] - input3[c_id]) / sqrtf(0.001 + input4[c_id])));
    }

}
extern void inception3_BatchNormInference_float_float_float_float_float_float_cuda_BatchNormInference_497_Call(const dim3 &grids, const dim3 &blocks, unsigned mem, cudaStream_t stream, float* input0, float* input1, float* input2, float* input3, float* input4, float* output0) {
    inception3_BatchNormInference_float_float_float_float_float_float_cuda_BatchNormInference_497<<<grids, blocks, mem, stream>>>(input0, input1, input2, input3, input4, output0);
}
// Node name:	MaxPool_499
// Description:	MaxPool
// Input:
//	- name: inception3_Relu_498_0	type: float	shape: Shape{64, 64, 147, 147}
// Output:
//	- name: inception3_MaxPool_499_0	type: float	shape: Shape{64, 64, 73, 73}
void MaxPool_float_float_cuda_lib_MaxPool_499(cudnnHandle_t cudnn_handle, float* input0, float* output0)
{
    cudnnTensorDescriptor_t input_desc;
    CUDNN_SAFE_CALL(cudnnCreateTensorDescriptor(&input_desc));
    CUDNN_SAFE_CALL(cudnnSetTensor4dDescriptor(input_desc, CUDNN_TENSOR_NCHW, CUDNN_DATA_FLOAT, 64, 64, 147, 147));
    cudnnTensorDescriptor_t output_desc;
    CUDNN_SAFE_CALL(cudnnCreateTensorDescriptor(&output_desc));
    CUDNN_SAFE_CALL(cudnnSetTensor4dDescriptor(output_desc, CUDNN_TENSOR_NCHW, CUDNN_DATA_FLOAT, 64, 64, 73, 73));
    cudnnPoolingDescriptor_t desc;
    cudnnCreatePoolingDescriptor(&desc);
    CUDNN_SAFE_CALL(cudnnSetPooling2dDescriptor(desc, CUDNN_POOLING_MAX, CUDNN_NOT_PROPAGATE_NAN,3, 3, 0, 0, 2, 2));
    const float alpha = 1.0;
    const float beta = 0.0;
    CUDNN_SAFE_CALL(cudnnPoolingForward(cudnn_handle, desc, &alpha, input_desc, input0, &beta, output_desc, output0));
    CUDNN_SAFE_CALL(cudnnDestroyTensorDescriptor(input_desc));
    CUDNN_SAFE_CALL(cudnnDestroyTensorDescriptor(output_desc));
    CUDNN_SAFE_CALL(cudnnDestroyPoolingDescriptor(desc));

}
// Node name:	Reshape_525
// Description:	Reshape
// Input:
//	- name: inception3_Constant_37_0	type: float	shape: Shape{5, 5, 48, 64}
// Output:
//	- name: inception3_Reshape_525_0	type: float	shape: Shape{64, 48, 5, 5}
extern "C" __launch_bounds__(256) __global__ void inception3_Reshape_float_float_cuda_Reshape_525(float* input0, float* output0)
{
    uint32_t input_strides0 = 3072;
    uint32_t input_strides1 = 64;
    uint32_t input_strides2 = 1;
    uint32_t trans_strides0 = 1;
    uint32_t trans_strides1 = 25;
    uint32_t trans_strides2 = 1200;
    size_t nx = 64;
    size_t ny = 48;
    size_t nz = 25;
    __shared__ float tile[16][1][17];
    uint32_t base2 = blockIdx.x * blockDim.x;
    uint32_t base1 = blockIdx.y * blockDim.y;
    uint32_t base0 = blockIdx.z * blockDim.z;
    uint32_t tid2 = threadIdx.x;
    uint32_t tid1 = threadIdx.y;
    uint32_t tid0 = threadIdx.z;
    uint32_t otid2 = tid2;
    uint32_t otid1 = tid1;
    uint32_t otid0 = tid0;
    uint32_t idx2 = base2 + tid2;
    uint32_t idx1 = base1 + tid1;
    uint32_t idx0 = base0 + tid0;
    if (idx2 < nx && idx1 < ny && idx0 < nz)
    {
        uint32_t input_idx = 0;
        input_idx += input_strides0* idx0;
        input_idx += input_strides1* idx1;
        input_idx += input_strides2* idx2;
        tile[tid0][tid1][tid2] = input0[input_idx];
    }
    otid2 = tid0;
    otid0 = tid2;
    idx2 = base2 + otid2;
    idx1 = base1 + otid1;
    idx0 = base0 + otid0;
    __syncthreads();
    if (idx2 < nx && idx1 < ny && idx0 < nz)
    {
        uint32_t output_idx = 0;
        output_idx += trans_strides0* idx0;
        output_idx += trans_strides1* idx1;
        output_idx += trans_strides2* idx2;
        output0[output_idx] = tile[otid0][otid1][otid2];
    }

}
extern void inception3_Reshape_float_float_cuda_Reshape_525_Call(const dim3 &grids, const dim3 &blocks, unsigned mem, cudaStream_t stream, float* input0, float* output0) {
    inception3_Reshape_float_float_cuda_Reshape_525<<<grids, blocks, mem, stream>>>(input0, output0);
}
// Node name:	Reshape_853
// Description:	Reshape
// Input:
//	- name: inception3_Constant_457_0	type: float	shape: Shape{1, 1, 2048, 448}
// Output:
//	- name: inception3_Reshape_853_0	type: float	shape: Shape{448, 2048, 1, 1}
extern "C" __launch_bounds__(256) __global__ void inception3_Reshape_float_float_cuda_Reshape_853(float* input0, float* output0)
{
    uint32_t input_strides0 = 448;
    uint32_t input_strides1 = 1;
    uint32_t trans_strides0 = 1;
    uint32_t trans_strides1 = 2048;
    size_t nx = 448;
    size_t ny = 2048;
    __shared__ float tile[16][17];
    uint32_t base1 = blockIdx.x * blockDim.x;
    uint32_t base0 = blockIdx.y * blockDim.y;
    uint32_t tid1 = threadIdx.x;
    uint32_t tid0 = threadIdx.y;
    uint32_t idx1 = base1 + tid1;
    uint32_t idx0 = base0 + tid0;
    if (idx1 < nx && idx0 < ny)
    {
        uint32_t input_idx = 0;
        input_idx += input_strides0* idx0;
        input_idx += input_strides1* idx1;
        tile[tid0][tid1] = input0[input_idx];
    }
    idx1 = base1 + tid0;
    idx0 = base0 + tid1;
    __syncthreads();
    if (idx1 < nx && idx0 < ny)
    {
        uint32_t output_idx = 0;
        output_idx += trans_strides0* idx0;
        output_idx += trans_strides1* idx1;
        output0[output_idx] = tile[tid1][tid0];
    }

}
extern void inception3_Reshape_float_float_cuda_Reshape_853_Call(const dim3 &grids, const dim3 &blocks, unsigned mem, cudaStream_t stream, float* input0, float* output0) {
    inception3_Reshape_float_float_cuda_Reshape_853<<<grids, blocks, mem, stream>>>(input0, output0);
}
// Node name:	AvgPool_545
// Description:	AvgPool
// Input:
//	- name: inception3_Concat_538_0	type: float	shape: Shape{64, 256, 35, 35}
// Output:
//	- name: inception3_AvgPool_545_0	type: float	shape: Shape{64, 256, 35, 35}
void AvgPool_float_float_cuda_lib_AvgPool_545(cudnnHandle_t cudnn_handle, float* input0, float* output0)
{
    cudnnTensorDescriptor_t input_desc;
    CUDNN_SAFE_CALL(cudnnCreateTensorDescriptor(&input_desc));
    CUDNN_SAFE_CALL(cudnnSetTensor4dDescriptor(input_desc, CUDNN_TENSOR_NCHW, CUDNN_DATA_FLOAT, 64, 256, 35, 35));
    cudnnTensorDescriptor_t output_desc;
    CUDNN_SAFE_CALL(cudnnCreateTensorDescriptor(&output_desc));
    CUDNN_SAFE_CALL(cudnnSetTensor4dDescriptor(output_desc, CUDNN_TENSOR_NCHW, CUDNN_DATA_FLOAT, 64, 256, 35, 35));
    cudnnPoolingDescriptor_t desc;
    cudnnCreatePoolingDescriptor(&desc);
    CUDNN_SAFE_CALL(cudnnSetPooling2dDescriptor(desc, CUDNN_POOLING_AVERAGE_COUNT_EXCLUDE_PADDING, CUDNN_NOT_PROPAGATE_NAN,3, 3, 1, 1, 1, 1));
    const float alpha = 1.0;
    const float beta = 0.0;
    CUDNN_SAFE_CALL(cudnnPoolingForward(cudnn_handle, desc, &alpha, input_desc, input0, &beta, output_desc, output0));
    CUDNN_SAFE_CALL(cudnnDestroyTensorDescriptor(input_desc));
    CUDNN_SAFE_CALL(cudnnDestroyTensorDescriptor(output_desc));
    CUDNN_SAFE_CALL(cudnnDestroyPoolingDescriptor(desc));

}
// Node name:	Convolution_807
// Description:	Convolution
// Input:
//	- name: inception3_Relu_805_0	type: float	shape: Shape{64, 192, 17, 17}
//	- name: inception3_Reshape_806_0	type: float	shape: Shape{192, 192, 3, 3}
// Output:
//	- name: inception3_Convolution_807_0	type: float	shape: Shape{64, 192, 8, 8}
void Convolution_float_float_float_cuda_lib_Convolution_807(cudnnHandle_t cudnn_handle, float* input0, float* input1, float* output0)
{
    cudnnTensorDescriptor_t tensor_desc_0;
    CUDNN_SAFE_CALL(cudnnCreateTensorDescriptor(&tensor_desc_0));
    CUDNN_SAFE_CALL(cudnnSetTensor4dDescriptor(tensor_desc_0, CUDNN_TENSOR_NCHW, CUDNN_DATA_FLOAT, 64, 192, 17, 17));
    cudnnTensorDescriptor_t tensor_desc_1;
    CUDNN_SAFE_CALL(cudnnCreateTensorDescriptor(&tensor_desc_1));
    CUDNN_SAFE_CALL(cudnnSetTensor4dDescriptor(tensor_desc_1, CUDNN_TENSOR_NCHW, CUDNN_DATA_FLOAT, 64, 192, 8, 8));
    cudnnFilterDescriptor_t filter_desc;
    CUDNN_SAFE_CALL(cudnnCreateFilterDescriptor(&filter_desc));
    CUDNN_SAFE_CALL(cudnnSetFilter4dDescriptor(filter_desc, CUDNN_DATA_FLOAT, CUDNN_TENSOR_NCHW, 192, 192, 3, 3));
    cudnnConvolutionDescriptor_t conv_desc;
    CUDNN_SAFE_CALL(cudnnCreateConvolutionDescriptor(&conv_desc));
    CUDNN_SAFE_CALL(cudnnSetConvolution2dDescriptor(conv_desc, 0, 0, 2, 2, 1, 1, CUDNN_CROSS_CORRELATION, CUDNN_DATA_FLOAT));

    static bool selected_algo = true;
    static cudnnConvolutionFwdAlgo_t conv_fwd_algo = CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM;

    if (!selected_algo) {
        int num_algos;
        int max_algos = 0;
        // cudnnGetConvolutionForwardAlgorithm_v7;
        CUDNN_SAFE_CALL(
            cudnnGetConvolutionForwardAlgorithmMaxCount(cudnn_handle, &max_algos));
        std::vector<cudnnConvolutionFwdAlgoPerf_t> results(max_algos);
        CUDNN_SAFE_CALL(cudnnFindConvolutionForwardAlgorithm(cudnn_handle,
                                                tensor_desc_0,
                                                filter_desc,
                                                conv_desc,
                                                tensor_desc_1,
                                                static_cast<int>(results.size()),
                                                &num_algos,
                                                results.data()));
        results.resize(num_algos);
        for (size_t i = 0; i != results.size(); ++i) {
            cudnnConvolutionFwdAlgoPerf_t const& result = results[i];
            if (result.status == CUDNN_STATUS_SUCCESS) {
                conv_fwd_algo = result.algo;
                break;
            }
        }
        selected_algo = true;
    }
    const float alpha = 1.0;
    const float beta = 0.0;
    static void *workspace_ptr_0 = NULL;
    static size_t workspace_size_in_bytes = 0;
    if (!workspace_ptr_0)
    {
        CUDNN_SAFE_CALL(cudnnGetConvolutionForwardWorkspaceSize(cudnn_handle, tensor_desc_0, filter_desc, conv_desc, tensor_desc_1, conv_fwd_algo, &workspace_size_in_bytes));
        CUDA_SAFE_CALL(cudaMalloc(&workspace_ptr_0, workspace_size_in_bytes));
    }
    CUDNN_SAFE_CALL(cudnnConvolutionForward(cudnn_handle, &alpha, tensor_desc_0, input0,filter_desc, input1, conv_desc, conv_fwd_algo, workspace_ptr_0, workspace_size_in_bytes, &beta, tensor_desc_1, output0));
    CUDNN_SAFE_CALL(cudnnDestroyTensorDescriptor(tensor_desc_0));
    CUDNN_SAFE_CALL(cudnnDestroyTensorDescriptor(tensor_desc_1));
    CUDNN_SAFE_CALL(cudnnDestroyFilterDescriptor(filter_desc));
    CUDNN_SAFE_CALL(cudnnDestroyConvolutionDescriptor(conv_desc));

}
// Node name:	BatchNormInference_493
// Description:	BatchNormInference
// Input:
//	- name: inception3_Constant_8_0	type: float	shape: Shape{32}
//	- name: inception3_Constant_9_0	type: float	shape: Shape{32}
//	- name: inception3_Convolution_492_0	type: float	shape: Shape{64, 32, 147, 147}
//	- name: inception3_Constant_10_0	type: float	shape: Shape{32}
//	- name: inception3_Constant_11_0	type: float	shape: Shape{32}
// Output:
//	- name: inception3_BatchNormInference_493_0	type: float	shape: Shape{64, 32, 147, 147}
extern "C" __launch_bounds__(512) __global__ void inception3_BatchNormInference_float_float_float_float_float_float_cuda_BatchNormInference_493(float* input0, float* input1, float* input2, float* input3, float* input4, float* output0)
{
    const int st = blockIdx.x * 147 * 147;
    const int c_id = blockIdx.x % 32;
    #pragma unroll 1
    for (int i = threadIdx.x; i < 147 * 147; i += blockDim.x)
    {
        output0[st + i] = (input1[c_id] + (input0[c_id] * (input2[st + i] - input3[c_id]) / sqrtf(0.001 + input4[c_id])));
    }

}
extern void inception3_BatchNormInference_float_float_float_float_float_float_cuda_BatchNormInference_493_Call(const dim3 &grids, const dim3 &blocks, unsigned mem, cudaStream_t stream, float* input0, float* input1, float* input2, float* input3, float* input4, float* output0) {
    inception3_BatchNormInference_float_float_float_float_float_float_cuda_BatchNormInference_493<<<grids, blocks, mem, stream>>>(input0, input1, input2, input3, input4, output0);
}
// Node name:	AvgPool_575
// Description:	AvgPool
// Input:
//	- name: inception3_Concat_568_0	type: float	shape: Shape{64, 288, 35, 35}
// Output:
//	- name: inception3_AvgPool_575_0	type: float	shape: Shape{64, 288, 35, 35}
void AvgPool_float_float_cuda_lib_AvgPool_575(cudnnHandle_t cudnn_handle, float* input0, float* output0)
{
    cudnnTensorDescriptor_t input_desc;
    CUDNN_SAFE_CALL(cudnnCreateTensorDescriptor(&input_desc));
    CUDNN_SAFE_CALL(cudnnSetTensor4dDescriptor(input_desc, CUDNN_TENSOR_NCHW, CUDNN_DATA_FLOAT, 64, 288, 35, 35));
    cudnnTensorDescriptor_t output_desc;
    CUDNN_SAFE_CALL(cudnnCreateTensorDescriptor(&output_desc));
    CUDNN_SAFE_CALL(cudnnSetTensor4dDescriptor(output_desc, CUDNN_TENSOR_NCHW, CUDNN_DATA_FLOAT, 64, 288, 35, 35));
    cudnnPoolingDescriptor_t desc;
    cudnnCreatePoolingDescriptor(&desc);
    CUDNN_SAFE_CALL(cudnnSetPooling2dDescriptor(desc, CUDNN_POOLING_AVERAGE_COUNT_EXCLUDE_PADDING, CUDNN_NOT_PROPAGATE_NAN,3, 3, 1, 1, 1, 1));
    const float alpha = 1.0;
    const float beta = 0.0;
    CUDNN_SAFE_CALL(cudnnPoolingForward(cudnn_handle, desc, &alpha, input_desc, input0, &beta, output_desc, output0));
    CUDNN_SAFE_CALL(cudnnDestroyTensorDescriptor(input_desc));
    CUDNN_SAFE_CALL(cudnnDestroyTensorDescriptor(output_desc));
    CUDNN_SAFE_CALL(cudnnDestroyPoolingDescriptor(desc));

}
// Node name:	Reshape_495
// Description:	Reshape
// Input:
//	- name: inception3_Constant_12_0	type: float	shape: Shape{3, 3, 32, 64}
// Output:
//	- name: inception3_Reshape_495_0	type: float	shape: Shape{64, 32, 3, 3}
extern "C" __launch_bounds__(256) __global__ void inception3_Reshape_float_float_cuda_Reshape_495(float* input0, float* output0)
{
    uint32_t input_strides0 = 2048;
    uint32_t input_strides1 = 64;
    uint32_t input_strides2 = 1;
    uint32_t trans_strides0 = 1;
    uint32_t trans_strides1 = 9;
    uint32_t trans_strides2 = 288;
    size_t nx = 64;
    size_t ny = 32;
    size_t nz = 9;
    __shared__ float tile[16][1][17];
    uint32_t base2 = blockIdx.x * blockDim.x;
    uint32_t base1 = blockIdx.y * blockDim.y;
    uint32_t base0 = blockIdx.z * blockDim.z;
    uint32_t tid2 = threadIdx.x;
    uint32_t tid1 = threadIdx.y;
    uint32_t tid0 = threadIdx.z;
    uint32_t otid2 = tid2;
    uint32_t otid1 = tid1;
    uint32_t otid0 = tid0;
    uint32_t idx2 = base2 + tid2;
    uint32_t idx1 = base1 + tid1;
    uint32_t idx0 = base0 + tid0;
    if (idx2 < nx && idx1 < ny && idx0 < nz)
    {
        uint32_t input_idx = 0;
        input_idx += input_strides0* idx0;
        input_idx += input_strides1* idx1;
        input_idx += input_strides2* idx2;
        tile[tid0][tid1][tid2] = input0[input_idx];
    }
    otid2 = tid0;
    otid0 = tid2;
    idx2 = base2 + otid2;
    idx1 = base1 + otid1;
    idx0 = base0 + otid0;
    __syncthreads();
    if (idx2 < nx && idx1 < ny && idx0 < nz)
    {
        uint32_t output_idx = 0;
        output_idx += trans_strides0* idx0;
        output_idx += trans_strides1* idx1;
        output_idx += trans_strides2* idx2;
        output0[output_idx] = tile[otid0][otid1][otid2];
    }

}
extern void inception3_Reshape_float_float_cuda_Reshape_495_Call(const dim3 &grids, const dim3 &blocks, unsigned mem, cudaStream_t stream, float* input0, float* output0) {
    inception3_Reshape_float_float_cuda_Reshape_495<<<grids, blocks, mem, stream>>>(input0, output0);
}
// Node name:	Reshape_654
// Description:	Reshape
// Input:
//	- name: inception3_Constant_196_0	type: float	shape: Shape{1, 7, 128, 192}
// Output:
//	- name: inception3_Reshape_654_0	type: float	shape: Shape{192, 128, 1, 7}
extern "C" __launch_bounds__(256) __global__ void inception3_Reshape_float_float_cuda_Reshape_654(float* input0, float* output0)
{
    uint32_t input_strides0 = 24576;
    uint32_t input_strides1 = 192;
    uint32_t input_strides2 = 1;
    uint32_t trans_strides0 = 1;
    uint32_t trans_strides1 = 7;
    uint32_t trans_strides2 = 896;
    size_t nx = 192;
    size_t ny = 128;
    size_t nz = 7;
    __shared__ float tile[16][1][17];
    uint32_t base2 = blockIdx.x * blockDim.x;
    uint32_t base1 = blockIdx.y * blockDim.y;
    uint32_t base0 = blockIdx.z * blockDim.z;
    uint32_t tid2 = threadIdx.x;
    uint32_t tid1 = threadIdx.y;
    uint32_t tid0 = threadIdx.z;
    uint32_t otid2 = tid2;
    uint32_t otid1 = tid1;
    uint32_t otid0 = tid0;
    uint32_t idx2 = base2 + tid2;
    uint32_t idx1 = base1 + tid1;
    uint32_t idx0 = base0 + tid0;
    if (idx2 < nx && idx1 < ny && idx0 < nz)
    {
        uint32_t input_idx = 0;
        input_idx += input_strides0* idx0;
        input_idx += input_strides1* idx1;
        input_idx += input_strides2* idx2;
        tile[tid0][tid1][tid2] = input0[input_idx];
    }
    otid2 = tid0;
    otid0 = tid2;
    idx2 = base2 + otid2;
    idx1 = base1 + otid1;
    idx0 = base0 + otid0;
    __syncthreads();
    if (idx2 < nx && idx1 < ny && idx0 < nz)
    {
        uint32_t output_idx = 0;
        output_idx += trans_strides0* idx0;
        output_idx += trans_strides1* idx1;
        output_idx += trans_strides2* idx2;
        output0[output_idx] = tile[otid0][otid1][otid2];
    }

}
extern void inception3_Reshape_float_float_cuda_Reshape_654_Call(const dim3 &grids, const dim3 &blocks, unsigned mem, cudaStream_t stream, float* input0, float* output0) {
    inception3_Reshape_float_float_cuda_Reshape_654<<<grids, blocks, mem, stream>>>(input0, output0);
}
// Node name:	BatchNormInference_531
// Description:	BatchNormInference
// Input:
//	- name: inception3_Constant_48_0	type: float	shape: Shape{96}
//	- name: inception3_Constant_49_0	type: float	shape: Shape{96}
//	- name: inception3_Convolution_528_0	type: float	shape: Shape{64, 96, 35, 35}
//	- name: inception3_Constant_50_0	type: float	shape: Shape{96}
//	- name: inception3_Constant_51_0	type: float	shape: Shape{96}
// Output:
//	- name: inception3_BatchNormInference_531_0	type: float	shape: Shape{64, 96, 35, 35}
extern "C" __launch_bounds__(512) __global__ void inception3_BatchNormInference_float_float_float_float_float_float_cuda_BatchNormInference_531(float* input0, float* input1, float* input2, float* input3, float* input4, float* output0)
{
    const int st = blockIdx.x * 35 * 35;
    const int c_id = blockIdx.x % 96;
    #pragma unroll 1
    for (int i = threadIdx.x; i < 35 * 35; i += blockDim.x)
    {
        output0[st + i] = (input1[c_id] + (input0[c_id] * (input2[st + i] - input3[c_id]) / sqrtf(0.001 + input4[c_id])));
    }

}
extern void inception3_BatchNormInference_float_float_float_float_float_float_cuda_BatchNormInference_531_Call(const dim3 &grids, const dim3 &blocks, unsigned mem, cudaStream_t stream, float* input0, float* input1, float* input2, float* input3, float* input4, float* output0) {
    inception3_BatchNormInference_float_float_float_float_float_float_cuda_BatchNormInference_531<<<grids, blocks, mem, stream>>>(input0, input1, input2, input3, input4, output0);
}
// Node name:	Reshape_491
// Description:	Reshape
// Input:
//	- name: inception3_Constant_7_0	type: float	shape: Shape{3, 3, 32, 32}
// Output:
//	- name: inception3_Reshape_491_0	type: float	shape: Shape{32, 32, 3, 3}
extern "C" __launch_bounds__(256) __global__ void inception3_Reshape_float_float_cuda_Reshape_491(float* input0, float* output0)
{
    uint32_t input_strides0 = 1024;
    uint32_t input_strides1 = 32;
    uint32_t input_strides2 = 1;
    uint32_t trans_strides0 = 1;
    uint32_t trans_strides1 = 9;
    uint32_t trans_strides2 = 288;
    size_t nx = 32;
    size_t ny = 32;
    size_t nz = 9;
    __shared__ float tile[16][1][17];
    uint32_t base2 = blockIdx.x * blockDim.x;
    uint32_t base1 = blockIdx.y * blockDim.y;
    uint32_t base0 = blockIdx.z * blockDim.z;
    uint32_t tid2 = threadIdx.x;
    uint32_t tid1 = threadIdx.y;
    uint32_t tid0 = threadIdx.z;
    uint32_t otid2 = tid2;
    uint32_t otid1 = tid1;
    uint32_t otid0 = tid0;
    uint32_t idx2 = base2 + tid2;
    uint32_t idx1 = base1 + tid1;
    uint32_t idx0 = base0 + tid0;
    if (idx2 < nx && idx1 < ny && idx0 < nz)
    {
        uint32_t input_idx = 0;
        input_idx += input_strides0* idx0;
        input_idx += input_strides1* idx1;
        input_idx += input_strides2* idx2;
        tile[tid0][tid1][tid2] = input0[input_idx];
    }
    otid2 = tid0;
    otid0 = tid2;
    idx2 = base2 + otid2;
    idx1 = base1 + otid1;
    idx0 = base0 + otid0;
    __syncthreads();
    if (idx2 < nx && idx1 < ny && idx0 < nz)
    {
        uint32_t output_idx = 0;
        output_idx += trans_strides0* idx0;
        output_idx += trans_strides1* idx1;
        output_idx += trans_strides2* idx2;
        output0[output_idx] = tile[otid0][otid1][otid2];
    }

}
extern void inception3_Reshape_float_float_cuda_Reshape_491_Call(const dim3 &grids, const dim3 &blocks, unsigned mem, cudaStream_t stream, float* input0, float* output0) {
    inception3_Reshape_float_float_cuda_Reshape_491<<<grids, blocks, mem, stream>>>(input0, output0);
}
// Node name:	BatchNormInference_604
// Description:	BatchNormInference
// Input:
//	- name: inception3_Constant_136_0	type: float	shape: Shape{384}
//	- name: inception3_Constant_137_0	type: float	shape: Shape{384}
//	- name: inception3_Convolution_600_0	type: float	shape: Shape{64, 384, 17, 17}
//	- name: inception3_Constant_138_0	type: float	shape: Shape{384}
//	- name: inception3_Constant_139_0	type: float	shape: Shape{384}
// Output:
//	- name: inception3_BatchNormInference_604_0	type: float	shape: Shape{64, 384, 17, 17}
extern "C" __launch_bounds__(289) __global__ void inception3_BatchNormInference_float_float_float_float_float_float_cuda_BatchNormInference_604(float* input0, float* input1, float* input2, float* input3, float* input4, float* output0)
{
    const int st = blockIdx.x * 17 * 17;
    const int c_id = blockIdx.x % 384;
    #pragma unroll 1
    for (int i = threadIdx.x; i < 17 * 17; i += blockDim.x)
    {
        output0[st + i] = (input1[c_id] + (input0[c_id] * (input2[st + i] - input3[c_id]) / sqrtf(0.001 + input4[c_id])));
    }

}
extern void inception3_BatchNormInference_float_float_float_float_float_float_cuda_BatchNormInference_604_Call(const dim3 &grids, const dim3 &blocks, unsigned mem, cudaStream_t stream, float* input0, float* input1, float* input2, float* input3, float* input4, float* output0) {
    inception3_BatchNormInference_float_float_float_float_float_float_cuda_BatchNormInference_604<<<grids, blocks, mem, stream>>>(input0, input1, input2, input3, input4, output0);
}
// Node name:	Reshape_527
// Description:	Reshape
// Input:
//	- name: inception3_Constant_47_0	type: float	shape: Shape{3, 3, 64, 96}
// Output:
//	- name: inception3_Reshape_527_0	type: float	shape: Shape{96, 64, 3, 3}
extern "C" __launch_bounds__(256) __global__ void inception3_Reshape_float_float_cuda_Reshape_527(float* input0, float* output0)
{
    uint32_t input_strides0 = 6144;
    uint32_t input_strides1 = 96;
    uint32_t input_strides2 = 1;
    uint32_t trans_strides0 = 1;
    uint32_t trans_strides1 = 9;
    uint32_t trans_strides2 = 576;
    size_t nx = 96;
    size_t ny = 64;
    size_t nz = 9;
    __shared__ float tile[16][1][17];
    uint32_t base2 = blockIdx.x * blockDim.x;
    uint32_t base1 = blockIdx.y * blockDim.y;
    uint32_t base0 = blockIdx.z * blockDim.z;
    uint32_t tid2 = threadIdx.x;
    uint32_t tid1 = threadIdx.y;
    uint32_t tid0 = threadIdx.z;
    uint32_t otid2 = tid2;
    uint32_t otid1 = tid1;
    uint32_t otid0 = tid0;
    uint32_t idx2 = base2 + tid2;
    uint32_t idx1 = base1 + tid1;
    uint32_t idx0 = base0 + tid0;
    if (idx2 < nx && idx1 < ny && idx0 < nz)
    {
        uint32_t input_idx = 0;
        input_idx += input_strides0* idx0;
        input_idx += input_strides1* idx1;
        input_idx += input_strides2* idx2;
        tile[tid0][tid1][tid2] = input0[input_idx];
    }
    otid2 = tid0;
    otid0 = tid2;
    idx2 = base2 + otid2;
    idx1 = base1 + otid1;
    idx0 = base0 + otid0;
    __syncthreads();
    if (idx2 < nx && idx1 < ny && idx0 < nz)
    {
        uint32_t output_idx = 0;
        output_idx += trans_strides0* idx0;
        output_idx += trans_strides1* idx1;
        output_idx += trans_strides2* idx2;
        output0[output_idx] = tile[otid0][otid1][otid2];
    }

}
extern void inception3_Reshape_float_float_cuda_Reshape_527_Call(const dim3 &grids, const dim3 &blocks, unsigned mem, cudaStream_t stream, float* input0, float* output0) {
    inception3_Reshape_float_float_cuda_Reshape_527<<<grids, blocks, mem, stream>>>(input0, output0);
}
// Node name:	MaxPool_508
// Description:	MaxPool
// Input:
//	- name: inception3_Relu_507_0	type: float	shape: Shape{64, 192, 71, 71}
// Output:
//	- name: inception3_MaxPool_508_0	type: float	shape: Shape{64, 192, 35, 35}
void MaxPool_float_float_cuda_lib_MaxPool_508(cudnnHandle_t cudnn_handle, float* input0, float* output0)
{
    cudnnTensorDescriptor_t input_desc;
    CUDNN_SAFE_CALL(cudnnCreateTensorDescriptor(&input_desc));
    CUDNN_SAFE_CALL(cudnnSetTensor4dDescriptor(input_desc, CUDNN_TENSOR_NCHW, CUDNN_DATA_FLOAT, 64, 192, 71, 71));
    cudnnTensorDescriptor_t output_desc;
    CUDNN_SAFE_CALL(cudnnCreateTensorDescriptor(&output_desc));
    CUDNN_SAFE_CALL(cudnnSetTensor4dDescriptor(output_desc, CUDNN_TENSOR_NCHW, CUDNN_DATA_FLOAT, 64, 192, 35, 35));
    cudnnPoolingDescriptor_t desc;
    cudnnCreatePoolingDescriptor(&desc);
    CUDNN_SAFE_CALL(cudnnSetPooling2dDescriptor(desc, CUDNN_POOLING_MAX, CUDNN_NOT_PROPAGATE_NAN,3, 3, 0, 0, 2, 2));
    const float alpha = 1.0;
    const float beta = 0.0;
    CUDNN_SAFE_CALL(cudnnPoolingForward(cudnn_handle, desc, &alpha, input_desc, input0, &beta, output_desc, output0));
    CUDNN_SAFE_CALL(cudnnDestroyTensorDescriptor(input_desc));
    CUDNN_SAFE_CALL(cudnnDestroyTensorDescriptor(output_desc));
    CUDNN_SAFE_CALL(cudnnDestroyPoolingDescriptor(desc));

}
// Node name:	Reshape_486
// Description:	Reshape
// Input:
//	- name: Parameter_0_0	type: float	shape: Shape{64, 299, 299, 3}
// Output:
//	- name: inception3_Reshape_486_0	type: float	shape: Shape{64, 3, 299, 299}
extern "C" __launch_bounds__(256) __global__ void inception3_Reshape_float_float_cuda_Reshape_486(float* input0, float* output0)
{
    uint32_t input_strides0 = 268203;
    uint32_t input_strides1 = 3;
    uint32_t input_strides2 = 1;
    uint32_t trans_strides0 = 268203;
    uint32_t trans_strides1 = 1;
    uint32_t trans_strides2 = 89401;
    size_t nx = 3;
    size_t ny = 89401;
    size_t nz = 64;
    __shared__ float tile[1][16][17];
    uint32_t base2 = blockIdx.x * blockDim.x;
    uint32_t base1 = blockIdx.y * blockDim.y;
    uint32_t base0 = blockIdx.z * blockDim.z;
    uint32_t tid2 = threadIdx.x;
    uint32_t tid1 = threadIdx.y;
    uint32_t tid0 = threadIdx.z;
    uint32_t otid2 = tid2;
    uint32_t otid1 = tid1;
    uint32_t otid0 = tid0;
    uint32_t idx2 = base2 + tid2;
    uint32_t idx1 = base1 + tid1;
    uint32_t idx0 = base0 + tid0;
    if (idx2 < nx && idx1 < ny && idx0 < nz)
    {
        uint32_t input_idx = 0;
        input_idx += input_strides0* idx0;
        input_idx += input_strides1* idx1;
        input_idx += input_strides2* idx2;
        tile[tid0][tid1][tid2] = input0[input_idx];
    }
    otid2 = tid1;
    otid1 = tid2;
    idx2 = base2 + otid2;
    idx1 = base1 + otid1;
    idx0 = base0 + otid0;
    __syncthreads();
    if (idx2 < nx && idx1 < ny && idx0 < nz)
    {
        uint32_t output_idx = 0;
        output_idx += trans_strides0* idx0;
        output_idx += trans_strides1* idx1;
        output_idx += trans_strides2* idx2;
        output0[output_idx] = tile[otid0][otid1][otid2];
    }

}
extern void inception3_Reshape_float_float_cuda_Reshape_486_Call(const dim3 &grids, const dim3 &blocks, unsigned mem, cudaStream_t stream, float* input0, float* output0) {
    inception3_Reshape_float_float_cuda_Reshape_486<<<grids, blocks, mem, stream>>>(input0, output0);
}
// Node name:	Reshape_511
// Description:	Reshape
// Input:
//	- name: inception3_Constant_32_0	type: float	shape: Shape{1, 1, 192, 48}
// Output:
//	- name: inception3_Reshape_511_0	type: float	shape: Shape{48, 192, 1, 1}
extern "C" __launch_bounds__(256) __global__ void inception3_Reshape_float_float_cuda_Reshape_511(float* input0, float* output0)
{
    uint32_t input_strides0 = 48;
    uint32_t input_strides1 = 1;
    uint32_t trans_strides0 = 1;
    uint32_t trans_strides1 = 192;
    size_t nx = 48;
    size_t ny = 192;
    __shared__ float tile[16][17];
    uint32_t base1 = blockIdx.x * blockDim.x;
    uint32_t base0 = blockIdx.y * blockDim.y;
    uint32_t tid1 = threadIdx.x;
    uint32_t tid0 = threadIdx.y;
    uint32_t idx1 = base1 + tid1;
    uint32_t idx0 = base0 + tid0;
    if (idx1 < nx && idx0 < ny)
    {
        uint32_t input_idx = 0;
        input_idx += input_strides0* idx0;
        input_idx += input_strides1* idx1;
        tile[tid0][tid1] = input0[input_idx];
    }
    idx1 = base1 + tid0;
    idx0 = base0 + tid1;
    __syncthreads();
    if (idx1 < nx && idx0 < ny)
    {
        uint32_t output_idx = 0;
        output_idx += trans_strides0* idx0;
        output_idx += trans_strides1* idx1;
        output0[output_idx] = tile[tid1][tid0];
    }

}
extern void inception3_Reshape_float_float_cuda_Reshape_511_Call(const dim3 &grids, const dim3 &blocks, unsigned mem, cudaStream_t stream, float* input0, float* output0) {
    inception3_Reshape_float_float_cuda_Reshape_511<<<grids, blocks, mem, stream>>>(input0, output0);
}
// Node name:	Convolution_510
// Description:	Convolution
// Input:
//	- name: inception3_MaxPool_508_0	type: float	shape: Shape{64, 192, 35, 35}
//	- name: inception3_Reshape_509_0	type: float	shape: Shape{64, 192, 1, 1}
// Output:
//	- name: inception3_Convolution_510_0	type: float	shape: Shape{64, 64, 35, 35}
void Convolution_float_float_float_cuda_lib_Convolution_510(cudnnHandle_t cudnn_handle, float* input0, float* input1, float* output0)
{
    cudnnTensorDescriptor_t tensor_desc_0;
    CUDNN_SAFE_CALL(cudnnCreateTensorDescriptor(&tensor_desc_0));
    CUDNN_SAFE_CALL(cudnnSetTensor4dDescriptor(tensor_desc_0, CUDNN_TENSOR_NCHW, CUDNN_DATA_FLOAT, 64, 192, 35, 35));
    cudnnTensorDescriptor_t tensor_desc_1;
    CUDNN_SAFE_CALL(cudnnCreateTensorDescriptor(&tensor_desc_1));
    CUDNN_SAFE_CALL(cudnnSetTensor4dDescriptor(tensor_desc_1, CUDNN_TENSOR_NCHW, CUDNN_DATA_FLOAT, 64, 64, 35, 35));
    cudnnFilterDescriptor_t filter_desc;
    CUDNN_SAFE_CALL(cudnnCreateFilterDescriptor(&filter_desc));
    CUDNN_SAFE_CALL(cudnnSetFilter4dDescriptor(filter_desc, CUDNN_DATA_FLOAT, CUDNN_TENSOR_NCHW, 64, 192, 1, 1));
    cudnnConvolutionDescriptor_t conv_desc;
    CUDNN_SAFE_CALL(cudnnCreateConvolutionDescriptor(&conv_desc));
    CUDNN_SAFE_CALL(cudnnSetConvolution2dDescriptor(conv_desc, 0, 0, 1, 1, 1, 1, CUDNN_CROSS_CORRELATION, CUDNN_DATA_FLOAT));

    static bool selected_algo = true;
    static cudnnConvolutionFwdAlgo_t conv_fwd_algo = CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM;

    if (!selected_algo) {
        int num_algos;
        int max_algos = 0;
        // cudnnGetConvolutionForwardAlgorithm_v7;
        CUDNN_SAFE_CALL(
            cudnnGetConvolutionForwardAlgorithmMaxCount(cudnn_handle, &max_algos));
        std::vector<cudnnConvolutionFwdAlgoPerf_t> results(max_algos);
        CUDNN_SAFE_CALL(cudnnFindConvolutionForwardAlgorithm(cudnn_handle,
                                                tensor_desc_0,
                                                filter_desc,
                                                conv_desc,
                                                tensor_desc_1,
                                                static_cast<int>(results.size()),
                                                &num_algos,
                                                results.data()));
        results.resize(num_algos);
        for (size_t i = 0; i != results.size(); ++i) {
            cudnnConvolutionFwdAlgoPerf_t const& result = results[i];
            if (result.status == CUDNN_STATUS_SUCCESS) {
                conv_fwd_algo = result.algo;
                break;
            }
        }
        selected_algo = true;
    }
    const float alpha = 1.0;
    const float beta = 0.0;
    static void *workspace_ptr_0 = NULL;
    static size_t workspace_size_in_bytes = 0;
    if (!workspace_ptr_0)
    {
        CUDNN_SAFE_CALL(cudnnGetConvolutionForwardWorkspaceSize(cudnn_handle, tensor_desc_0, filter_desc, conv_desc, tensor_desc_1, conv_fwd_algo, &workspace_size_in_bytes));
        CUDA_SAFE_CALL(cudaMalloc(&workspace_ptr_0, workspace_size_in_bytes));
    }
    CUDNN_SAFE_CALL(cudnnConvolutionForward(cudnn_handle, &alpha, tensor_desc_0, input0,filter_desc, input1, conv_desc, conv_fwd_algo, workspace_ptr_0, workspace_size_in_bytes, &beta, tensor_desc_1, output0));
    CUDNN_SAFE_CALL(cudnnDestroyTensorDescriptor(tensor_desc_0));
    CUDNN_SAFE_CALL(cudnnDestroyTensorDescriptor(tensor_desc_1));
    CUDNN_SAFE_CALL(cudnnDestroyFilterDescriptor(filter_desc));
    CUDNN_SAFE_CALL(cudnnDestroyConvolutionDescriptor(conv_desc));

}
// Node name:	Convolution_505
// Description:	Convolution
// Input:
//	- name: inception3_Relu_503_0	type: float	shape: Shape{64, 80, 73, 73}
//	- name: inception3_Reshape_504_0	type: float	shape: Shape{192, 80, 3, 3}
// Output:
//	- name: inception3_Convolution_505_0	type: float	shape: Shape{64, 192, 71, 71}
void Convolution_float_float_float_cuda_lib_Convolution_505(cudnnHandle_t cudnn_handle, float* input0, float* input1, float* output0)
{
    cudnnTensorDescriptor_t tensor_desc_0;
    CUDNN_SAFE_CALL(cudnnCreateTensorDescriptor(&tensor_desc_0));
    CUDNN_SAFE_CALL(cudnnSetTensor4dDescriptor(tensor_desc_0, CUDNN_TENSOR_NCHW, CUDNN_DATA_FLOAT, 64, 80, 73, 73));
    cudnnTensorDescriptor_t tensor_desc_1;
    CUDNN_SAFE_CALL(cudnnCreateTensorDescriptor(&tensor_desc_1));
    CUDNN_SAFE_CALL(cudnnSetTensor4dDescriptor(tensor_desc_1, CUDNN_TENSOR_NCHW, CUDNN_DATA_FLOAT, 64, 192, 71, 71));
    cudnnFilterDescriptor_t filter_desc;
    CUDNN_SAFE_CALL(cudnnCreateFilterDescriptor(&filter_desc));
    CUDNN_SAFE_CALL(cudnnSetFilter4dDescriptor(filter_desc, CUDNN_DATA_FLOAT, CUDNN_TENSOR_NCHW, 192, 80, 3, 3));
    cudnnConvolutionDescriptor_t conv_desc;
    CUDNN_SAFE_CALL(cudnnCreateConvolutionDescriptor(&conv_desc));
    CUDNN_SAFE_CALL(cudnnSetConvolution2dDescriptor(conv_desc, 0, 0, 1, 1, 1, 1, CUDNN_CROSS_CORRELATION, CUDNN_DATA_FLOAT));

    static bool selected_algo = true;
    static cudnnConvolutionFwdAlgo_t conv_fwd_algo = CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM;

    if (!selected_algo) {
        int num_algos;
        int max_algos = 0;
        // cudnnGetConvolutionForwardAlgorithm_v7;
        CUDNN_SAFE_CALL(
            cudnnGetConvolutionForwardAlgorithmMaxCount(cudnn_handle, &max_algos));
        std::vector<cudnnConvolutionFwdAlgoPerf_t> results(max_algos);
        CUDNN_SAFE_CALL(cudnnFindConvolutionForwardAlgorithm(cudnn_handle,
                                                tensor_desc_0,
                                                filter_desc,
                                                conv_desc,
                                                tensor_desc_1,
                                                static_cast<int>(results.size()),
                                                &num_algos,
                                                results.data()));
        results.resize(num_algos);
        for (size_t i = 0; i != results.size(); ++i) {
            cudnnConvolutionFwdAlgoPerf_t const& result = results[i];
            if (result.status == CUDNN_STATUS_SUCCESS) {
                conv_fwd_algo = result.algo;
                break;
            }
        }
        selected_algo = true;
    }
    const float alpha = 1.0;
    const float beta = 0.0;
    static void *workspace_ptr_0 = NULL;
    static size_t workspace_size_in_bytes = 0;
    if (!workspace_ptr_0)
    {
        CUDNN_SAFE_CALL(cudnnGetConvolutionForwardWorkspaceSize(cudnn_handle, tensor_desc_0, filter_desc, conv_desc, tensor_desc_1, conv_fwd_algo, &workspace_size_in_bytes));
        CUDA_SAFE_CALL(cudaMalloc(&workspace_ptr_0, workspace_size_in_bytes));
    }
    CUDNN_SAFE_CALL(cudnnConvolutionForward(cudnn_handle, &alpha, tensor_desc_0, input0,filter_desc, input1, conv_desc, conv_fwd_algo, workspace_ptr_0, workspace_size_in_bytes, &beta, tensor_desc_1, output0));
    CUDNN_SAFE_CALL(cudnnDestroyTensorDescriptor(tensor_desc_0));
    CUDNN_SAFE_CALL(cudnnDestroyTensorDescriptor(tensor_desc_1));
    CUDNN_SAFE_CALL(cudnnDestroyFilterDescriptor(filter_desc));
    CUDNN_SAFE_CALL(cudnnDestroyConvolutionDescriptor(conv_desc));

}
// Node name:	Convolution_850
// Description:	Convolution
// Input:
//	- name: inception3_Concat_848_0	type: float	shape: Shape{64, 2048, 8, 8}
//	- name: inception3_Reshape_849_0	type: float	shape: Shape{320, 2048, 1, 1}
// Output:
//	- name: inception3_Convolution_850_0	type: float	shape: Shape{64, 320, 8, 8}
void Convolution_float_float_float_cuda_lib_Convolution_850(cudnnHandle_t cudnn_handle, float* input0, float* input1, float* output0)
{
    cudnnTensorDescriptor_t tensor_desc_0;
    CUDNN_SAFE_CALL(cudnnCreateTensorDescriptor(&tensor_desc_0));
    CUDNN_SAFE_CALL(cudnnSetTensor4dDescriptor(tensor_desc_0, CUDNN_TENSOR_NCHW, CUDNN_DATA_FLOAT, 64, 2048, 8, 8));
    cudnnTensorDescriptor_t tensor_desc_1;
    CUDNN_SAFE_CALL(cudnnCreateTensorDescriptor(&tensor_desc_1));
    CUDNN_SAFE_CALL(cudnnSetTensor4dDescriptor(tensor_desc_1, CUDNN_TENSOR_NCHW, CUDNN_DATA_FLOAT, 64, 320, 8, 8));
    cudnnFilterDescriptor_t filter_desc;
    CUDNN_SAFE_CALL(cudnnCreateFilterDescriptor(&filter_desc));
    CUDNN_SAFE_CALL(cudnnSetFilter4dDescriptor(filter_desc, CUDNN_DATA_FLOAT, CUDNN_TENSOR_NCHW, 320, 2048, 1, 1));
    cudnnConvolutionDescriptor_t conv_desc;
    CUDNN_SAFE_CALL(cudnnCreateConvolutionDescriptor(&conv_desc));
    CUDNN_SAFE_CALL(cudnnSetConvolution2dDescriptor(conv_desc, 0, 0, 1, 1, 1, 1, CUDNN_CROSS_CORRELATION, CUDNN_DATA_FLOAT));

    static bool selected_algo = true;
    static cudnnConvolutionFwdAlgo_t conv_fwd_algo = CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM;

    if (!selected_algo) {
        int num_algos;
        int max_algos = 0;
        // cudnnGetConvolutionForwardAlgorithm_v7;
        CUDNN_SAFE_CALL(
            cudnnGetConvolutionForwardAlgorithmMaxCount(cudnn_handle, &max_algos));
        std::vector<cudnnConvolutionFwdAlgoPerf_t> results(max_algos);
        CUDNN_SAFE_CALL(cudnnFindConvolutionForwardAlgorithm(cudnn_handle,
                                                tensor_desc_0,
                                                filter_desc,
                                                conv_desc,
                                                tensor_desc_1,
                                                static_cast<int>(results.size()),
                                                &num_algos,
                                                results.data()));
        results.resize(num_algos);
        for (size_t i = 0; i != results.size(); ++i) {
            cudnnConvolutionFwdAlgoPerf_t const& result = results[i];
            if (result.status == CUDNN_STATUS_SUCCESS) {
                conv_fwd_algo = result.algo;
                break;
            }
        }
        selected_algo = true;
    }
    const float alpha = 1.0;
    const float beta = 0.0;
    static void *workspace_ptr_0 = NULL;
    static size_t workspace_size_in_bytes = 0;
    if (!workspace_ptr_0)
    {
        CUDNN_SAFE_CALL(cudnnGetConvolutionForwardWorkspaceSize(cudnn_handle, tensor_desc_0, filter_desc, conv_desc, tensor_desc_1, conv_fwd_algo, &workspace_size_in_bytes));
        CUDA_SAFE_CALL(cudaMalloc(&workspace_ptr_0, workspace_size_in_bytes));
    }
    CUDNN_SAFE_CALL(cudnnConvolutionForward(cudnn_handle, &alpha, tensor_desc_0, input0,filter_desc, input1, conv_desc, conv_fwd_algo, workspace_ptr_0, workspace_size_in_bytes, &beta, tensor_desc_1, output0));
    CUDNN_SAFE_CALL(cudnnDestroyTensorDescriptor(tensor_desc_0));
    CUDNN_SAFE_CALL(cudnnDestroyTensorDescriptor(tensor_desc_1));
    CUDNN_SAFE_CALL(cudnnDestroyFilterDescriptor(filter_desc));
    CUDNN_SAFE_CALL(cudnnDestroyConvolutionDescriptor(conv_desc));

}
// Node name:	Concat_568
// Description:	Concat
// Input:
//	- name: inception3_Relu_551_0	type: float	shape: Shape{64, 64, 35, 35}
//	- name: inception3_Relu_562_0	type: float	shape: Shape{64, 64, 35, 35}
//	- name: inception3_Relu_567_0	type: float	shape: Shape{64, 96, 35, 35}
//	- name: inception3_Relu_559_0	type: float	shape: Shape{64, 64, 35, 35}
// Output:
//	- name: inception3_Concat_568_0	type: float	shape: Shape{64, 288, 35, 35}
extern "C" __launch_bounds__(512) __global__ void inception3_Concat_float_float_float_float_float_cuda_Concat_568(float* input0, float* input1, float* input2, float* input3, float* output0)
{
    uint32_t inputs_strides[] = {78400, 78400, 117600, 78400};
    uint32_t tid = blockIdx.x * blockDim.x + threadIdx.x;
    if(tid < 22579200)
    {
        uint32_t block_id = tid / 352800;
        uint32_t block_idx = tid % 352800;
        uint32_t output_idx = block_id * 352800 + block_idx;
        if(block_idx < inputs_strides[0])
        {
            output0[output_idx] = input0[block_id * inputs_strides[0] + block_idx];
            return;
        }
        block_idx -= inputs_strides[0];
        if(block_idx < inputs_strides[1])
        {
            output0[output_idx] = input1[block_id * inputs_strides[1] + block_idx];
            return;
        }
        block_idx -= inputs_strides[1];
        if(block_idx < inputs_strides[2])
        {
            output0[output_idx] = input2[block_id * inputs_strides[2] + block_idx];
            return;
        }
        block_idx -= inputs_strides[2];
        if(block_idx < inputs_strides[3])
        {
            output0[output_idx] = input3[block_id * inputs_strides[3] + block_idx];
            return;
        }
        block_idx -= inputs_strides[3];
    }

}
extern void inception3_Concat_float_float_float_float_float_cuda_Concat_568_Call(const dim3 &grids, const dim3 &blocks, unsigned mem, cudaStream_t stream, float* input0, float* input1, float* input2, float* input3, float* output0) {
    inception3_Concat_float_float_float_float_float_cuda_Concat_568<<<grids, blocks, mem, stream>>>(input0, input1, input2, input3, output0);
}
// Node name:	Convolution_526
// Description:	Convolution
// Input:
//	- name: inception3_Relu_522_0	type: float	shape: Shape{64, 48, 35, 35}
//	- name: inception3_Reshape_525_0	type: float	shape: Shape{64, 48, 5, 5}
// Output:
//	- name: inception3_Convolution_526_0	type: float	shape: Shape{64, 64, 35, 35}
void Convolution_float_float_float_cuda_lib_Convolution_526(cudnnHandle_t cudnn_handle, float* input0, float* input1, float* output0)
{
    cudnnTensorDescriptor_t tensor_desc_0;
    CUDNN_SAFE_CALL(cudnnCreateTensorDescriptor(&tensor_desc_0));
    CUDNN_SAFE_CALL(cudnnSetTensor4dDescriptor(tensor_desc_0, CUDNN_TENSOR_NCHW, CUDNN_DATA_FLOAT, 64, 48, 35, 35));
    cudnnTensorDescriptor_t tensor_desc_1;
    CUDNN_SAFE_CALL(cudnnCreateTensorDescriptor(&tensor_desc_1));
    CUDNN_SAFE_CALL(cudnnSetTensor4dDescriptor(tensor_desc_1, CUDNN_TENSOR_NCHW, CUDNN_DATA_FLOAT, 64, 64, 35, 35));
    cudnnFilterDescriptor_t filter_desc;
    CUDNN_SAFE_CALL(cudnnCreateFilterDescriptor(&filter_desc));
    CUDNN_SAFE_CALL(cudnnSetFilter4dDescriptor(filter_desc, CUDNN_DATA_FLOAT, CUDNN_TENSOR_NCHW, 64, 48, 5, 5));
    cudnnConvolutionDescriptor_t conv_desc;
    CUDNN_SAFE_CALL(cudnnCreateConvolutionDescriptor(&conv_desc));
    CUDNN_SAFE_CALL(cudnnSetConvolution2dDescriptor(conv_desc, 2, 2, 1, 1, 1, 1, CUDNN_CROSS_CORRELATION, CUDNN_DATA_FLOAT));

    static bool selected_algo = true;
    static cudnnConvolutionFwdAlgo_t conv_fwd_algo = CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM;

    if (!selected_algo) {
        int num_algos;
        int max_algos = 0;
        // cudnnGetConvolutionForwardAlgorithm_v7;
        CUDNN_SAFE_CALL(
            cudnnGetConvolutionForwardAlgorithmMaxCount(cudnn_handle, &max_algos));
        std::vector<cudnnConvolutionFwdAlgoPerf_t> results(max_algos);
        CUDNN_SAFE_CALL(cudnnFindConvolutionForwardAlgorithm(cudnn_handle,
                                                tensor_desc_0,
                                                filter_desc,
                                                conv_desc,
                                                tensor_desc_1,
                                                static_cast<int>(results.size()),
                                                &num_algos,
                                                results.data()));
        results.resize(num_algos);
        for (size_t i = 0; i != results.size(); ++i) {
            cudnnConvolutionFwdAlgoPerf_t const& result = results[i];
            if (result.status == CUDNN_STATUS_SUCCESS) {
                conv_fwd_algo = result.algo;
                break;
            }
        }
        selected_algo = true;
    }
    const float alpha = 1.0;
    const float beta = 0.0;
    static void *workspace_ptr_0 = NULL;
    static size_t workspace_size_in_bytes = 0;
    if (!workspace_ptr_0)
    {
        CUDNN_SAFE_CALL(cudnnGetConvolutionForwardWorkspaceSize(cudnn_handle, tensor_desc_0, filter_desc, conv_desc, tensor_desc_1, conv_fwd_algo, &workspace_size_in_bytes));
        CUDA_SAFE_CALL(cudaMalloc(&workspace_ptr_0, workspace_size_in_bytes));
    }
    CUDNN_SAFE_CALL(cudnnConvolutionForward(cudnn_handle, &alpha, tensor_desc_0, input0,filter_desc, input1, conv_desc, conv_fwd_algo, workspace_ptr_0, workspace_size_in_bytes, &beta, tensor_desc_1, output0));
    CUDNN_SAFE_CALL(cudnnDestroyTensorDescriptor(tensor_desc_0));
    CUDNN_SAFE_CALL(cudnnDestroyTensorDescriptor(tensor_desc_1));
    CUDNN_SAFE_CALL(cudnnDestroyFilterDescriptor(filter_desc));
    CUDNN_SAFE_CALL(cudnnDestroyConvolutionDescriptor(conv_desc));

}
// Node name:	Reshape_811
// Description:	Reshape
// Input:
//	- name: inception3_Constant_391_0	type: float	shape: Shape{1, 1, 1280, 320}
// Output:
//	- name: inception3_Reshape_811_0	type: float	shape: Shape{320, 1280, 1, 1}
extern "C" __launch_bounds__(256) __global__ void inception3_Reshape_float_float_cuda_Reshape_811(float* input0, float* output0)
{
    uint32_t input_strides0 = 320;
    uint32_t input_strides1 = 1;
    uint32_t trans_strides0 = 1;
    uint32_t trans_strides1 = 1280;
    size_t nx = 320;
    size_t ny = 1280;
    __shared__ float tile[16][17];
    uint32_t base1 = blockIdx.x * blockDim.x;
    uint32_t base0 = blockIdx.y * blockDim.y;
    uint32_t tid1 = threadIdx.x;
    uint32_t tid0 = threadIdx.y;
    uint32_t idx1 = base1 + tid1;
    uint32_t idx0 = base0 + tid0;
    if (idx1 < nx && idx0 < ny)
    {
        uint32_t input_idx = 0;
        input_idx += input_strides0* idx0;
        input_idx += input_strides1* idx1;
        tile[tid0][tid1] = input0[input_idx];
    }
    idx1 = base1 + tid0;
    idx0 = base0 + tid1;
    __syncthreads();
    if (idx1 < nx && idx0 < ny)
    {
        uint32_t output_idx = 0;
        output_idx += trans_strides0* idx0;
        output_idx += trans_strides1* idx1;
        output0[output_idx] = tile[tid1][tid0];
    }

}
extern void inception3_Reshape_float_float_cuda_Reshape_811_Call(const dim3 &grids, const dim3 &blocks, unsigned mem, cudaStream_t stream, float* input0, float* output0) {
    inception3_Reshape_float_float_cuda_Reshape_811<<<grids, blocks, mem, stream>>>(input0, output0);
}
// Node name:	Constant_223
// Description:	Constant
// Input:
// Output:
//	- name: inception3_Constant_223_0	type: float	shape: Shape{192}
void inception3_Constant_float_cuda_Constant_223(cudaStream_t stream, float* output0)
{
    std::ifstream bin_file("../dnn/inception3/Constant/Constant_223_0.bin" , std::ios::in | std::ios::binary);
    if(bin_file.fail())
    {
    	printf("Load inception3_Constant_223_0 failed.\n");
    	exit(1);
    }
    char* tmp_mem = new char[768];
    bin_file.read(tmp_mem, 768);
    cudaMemcpyAsync(output0, tmp_mem, 768, cudaMemcpyHostToDevice, stream);
    bin_file.close();

}
// Node name:	BatchNormInference_530
// Description:	BatchNormInference
// Input:
//	- name: inception3_Constant_38_0	type: float	shape: Shape{64}
//	- name: inception3_Constant_39_0	type: float	shape: Shape{64}
//	- name: inception3_Convolution_526_0	type: float	shape: Shape{64, 64, 35, 35}
//	- name: inception3_Constant_40_0	type: float	shape: Shape{64}
//	- name: inception3_Constant_41_0	type: float	shape: Shape{64}
// Output:
//	- name: inception3_BatchNormInference_530_0	type: float	shape: Shape{64, 64, 35, 35}
extern "C" __launch_bounds__(512) __global__ void inception3_BatchNormInference_float_float_float_float_float_float_cuda_BatchNormInference_530(float* input0, float* input1, float* input2, float* input3, float* input4, float* output0)
{
    const int st = blockIdx.x * 35 * 35;
    const int c_id = blockIdx.x % 64;
    #pragma unroll 1
    for (int i = threadIdx.x; i < 35 * 35; i += blockDim.x)
    {
        output0[st + i] = (input1[c_id] + (input0[c_id] * (input2[st + i] - input3[c_id]) / sqrtf(0.001 + input4[c_id])));
    }

}
extern void inception3_BatchNormInference_float_float_float_float_float_float_cuda_BatchNormInference_530_Call(const dim3 &grids, const dim3 &blocks, unsigned mem, cudaStream_t stream, float* input0, float* input1, float* input2, float* input3, float* input4, float* output0) {
    inception3_BatchNormInference_float_float_float_float_float_float_cuda_BatchNormInference_530<<<grids, blocks, mem, stream>>>(input0, input1, input2, input3, input4, output0);
}
// Node name:	Reshape_500
// Description:	Reshape
// Input:
//	- name: inception3_Constant_17_0	type: float	shape: Shape{1, 1, 64, 80}
// Output:
//	- name: inception3_Reshape_500_0	type: float	shape: Shape{80, 64, 1, 1}
extern "C" __launch_bounds__(256) __global__ void inception3_Reshape_float_float_cuda_Reshape_500(float* input0, float* output0)
{
    uint32_t input_strides0 = 80;
    uint32_t input_strides1 = 1;
    uint32_t trans_strides0 = 1;
    uint32_t trans_strides1 = 64;
    size_t nx = 80;
    size_t ny = 64;
    __shared__ float tile[16][17];
    uint32_t base1 = blockIdx.x * blockDim.x;
    uint32_t base0 = blockIdx.y * blockDim.y;
    uint32_t tid1 = threadIdx.x;
    uint32_t tid0 = threadIdx.y;
    uint32_t idx1 = base1 + tid1;
    uint32_t idx0 = base0 + tid0;
    if (idx1 < nx && idx0 < ny)
    {
        uint32_t input_idx = 0;
        input_idx += input_strides0* idx0;
        input_idx += input_strides1* idx1;
        tile[tid0][tid1] = input0[input_idx];
    }
    idx1 = base1 + tid0;
    idx0 = base0 + tid1;
    __syncthreads();
    if (idx1 < nx && idx0 < ny)
    {
        uint32_t output_idx = 0;
        output_idx += trans_strides0* idx0;
        output_idx += trans_strides1* idx1;
        output0[output_idx] = tile[tid1][tid0];
    }

}
extern void inception3_Reshape_float_float_cuda_Reshape_500_Call(const dim3 &grids, const dim3 &blocks, unsigned mem, cudaStream_t stream, float* input0, float* output0) {
    inception3_Reshape_float_float_cuda_Reshape_500<<<grids, blocks, mem, stream>>>(input0, output0);
}
// Node name:	Reshape_534
// Description:	Reshape
// Input:
//	- name: inception3_Constant_52_0	type: float	shape: Shape{3, 3, 96, 96}
// Output:
//	- name: inception3_Reshape_534_0	type: float	shape: Shape{96, 96, 3, 3}
extern "C" __launch_bounds__(256) __global__ void inception3_Reshape_float_float_cuda_Reshape_534(float* input0, float* output0)
{
    uint32_t input_strides0 = 9216;
    uint32_t input_strides1 = 96;
    uint32_t input_strides2 = 1;
    uint32_t trans_strides0 = 1;
    uint32_t trans_strides1 = 9;
    uint32_t trans_strides2 = 864;
    size_t nx = 96;
    size_t ny = 96;
    size_t nz = 9;
    __shared__ float tile[16][1][17];
    uint32_t base2 = blockIdx.x * blockDim.x;
    uint32_t base1 = blockIdx.y * blockDim.y;
    uint32_t base0 = blockIdx.z * blockDim.z;
    uint32_t tid2 = threadIdx.x;
    uint32_t tid1 = threadIdx.y;
    uint32_t tid0 = threadIdx.z;
    uint32_t otid2 = tid2;
    uint32_t otid1 = tid1;
    uint32_t otid0 = tid0;
    uint32_t idx2 = base2 + tid2;
    uint32_t idx1 = base1 + tid1;
    uint32_t idx0 = base0 + tid0;
    if (idx2 < nx && idx1 < ny && idx0 < nz)
    {
        uint32_t input_idx = 0;
        input_idx += input_strides0* idx0;
        input_idx += input_strides1* idx1;
        input_idx += input_strides2* idx2;
        tile[tid0][tid1][tid2] = input0[input_idx];
    }
    otid2 = tid0;
    otid0 = tid2;
    idx2 = base2 + otid2;
    idx1 = base1 + otid1;
    idx0 = base0 + otid0;
    __syncthreads();
    if (idx2 < nx && idx1 < ny && idx0 < nz)
    {
        uint32_t output_idx = 0;
        output_idx += trans_strides0* idx0;
        output_idx += trans_strides1* idx1;
        output_idx += trans_strides2* idx2;
        output0[output_idx] = tile[otid0][otid1][otid2];
    }

}
extern void inception3_Reshape_float_float_cuda_Reshape_534_Call(const dim3 &grids, const dim3 &blocks, unsigned mem, cudaStream_t stream, float* input0, float* output0) {
    inception3_Reshape_float_float_cuda_Reshape_534<<<grids, blocks, mem, stream>>>(input0, output0);
}
// Node name:	MaxPool_603
// Description:	MaxPool
// Input:
//	- name: inception3_Concat_598_0	type: float	shape: Shape{64, 288, 35, 35}
// Output:
//	- name: inception3_MaxPool_603_0	type: float	shape: Shape{64, 288, 17, 17}
void MaxPool_float_float_cuda_lib_MaxPool_603(cudnnHandle_t cudnn_handle, float* input0, float* output0)
{
    cudnnTensorDescriptor_t input_desc;
    CUDNN_SAFE_CALL(cudnnCreateTensorDescriptor(&input_desc));
    CUDNN_SAFE_CALL(cudnnSetTensor4dDescriptor(input_desc, CUDNN_TENSOR_NCHW, CUDNN_DATA_FLOAT, 64, 288, 35, 35));
    cudnnTensorDescriptor_t output_desc;
    CUDNN_SAFE_CALL(cudnnCreateTensorDescriptor(&output_desc));
    CUDNN_SAFE_CALL(cudnnSetTensor4dDescriptor(output_desc, CUDNN_TENSOR_NCHW, CUDNN_DATA_FLOAT, 64, 288, 17, 17));
    cudnnPoolingDescriptor_t desc;
    cudnnCreatePoolingDescriptor(&desc);
    CUDNN_SAFE_CALL(cudnnSetPooling2dDescriptor(desc, CUDNN_POOLING_MAX, CUDNN_NOT_PROPAGATE_NAN,3, 3, 0, 0, 2, 2));
    const float alpha = 1.0;
    const float beta = 0.0;
    CUDNN_SAFE_CALL(cudnnPoolingForward(cudnn_handle, desc, &alpha, input_desc, input0, &beta, output_desc, output0));
    CUDNN_SAFE_CALL(cudnnDestroyTensorDescriptor(input_desc));
    CUDNN_SAFE_CALL(cudnnDestroyTensorDescriptor(output_desc));
    CUDNN_SAFE_CALL(cudnnDestroyPoolingDescriptor(desc));

}
// Node name:	AvgPool_515
// Description:	AvgPool
// Input:
//	- name: inception3_MaxPool_508_0	type: float	shape: Shape{64, 192, 35, 35}
// Output:
//	- name: inception3_AvgPool_515_0	type: float	shape: Shape{64, 192, 35, 35}
void AvgPool_float_float_cuda_lib_AvgPool_515(cudnnHandle_t cudnn_handle, float* input0, float* output0)
{
    cudnnTensorDescriptor_t input_desc;
    CUDNN_SAFE_CALL(cudnnCreateTensorDescriptor(&input_desc));
    CUDNN_SAFE_CALL(cudnnSetTensor4dDescriptor(input_desc, CUDNN_TENSOR_NCHW, CUDNN_DATA_FLOAT, 64, 192, 35, 35));
    cudnnTensorDescriptor_t output_desc;
    CUDNN_SAFE_CALL(cudnnCreateTensorDescriptor(&output_desc));
    CUDNN_SAFE_CALL(cudnnSetTensor4dDescriptor(output_desc, CUDNN_TENSOR_NCHW, CUDNN_DATA_FLOAT, 64, 192, 35, 35));
    cudnnPoolingDescriptor_t desc;
    cudnnCreatePoolingDescriptor(&desc);
    CUDNN_SAFE_CALL(cudnnSetPooling2dDescriptor(desc, CUDNN_POOLING_AVERAGE_COUNT_EXCLUDE_PADDING, CUDNN_NOT_PROPAGATE_NAN,3, 3, 1, 1, 1, 1));
    const float alpha = 1.0;
    const float beta = 0.0;
    CUDNN_SAFE_CALL(cudnnPoolingForward(cudnn_handle, desc, &alpha, input_desc, input0, &beta, output_desc, output0));
    CUDNN_SAFE_CALL(cudnnDestroyTensorDescriptor(input_desc));
    CUDNN_SAFE_CALL(cudnnDestroyTensorDescriptor(output_desc));
    CUDNN_SAFE_CALL(cudnnDestroyPoolingDescriptor(desc));

}
// Node name:	Reshape_831
// Description:	Reshape
// Input:
//	- name: inception3_Constant_416_0	type: float	shape: Shape{3, 3, 448, 384}
// Output:
//	- name: inception3_Reshape_831_0	type: float	shape: Shape{384, 448, 3, 3}
extern "C" __launch_bounds__(256) __global__ void inception3_Reshape_float_float_cuda_Reshape_831(float* input0, float* output0)
{
    uint32_t input_strides0 = 172032;
    uint32_t input_strides1 = 384;
    uint32_t input_strides2 = 1;
    uint32_t trans_strides0 = 1;
    uint32_t trans_strides1 = 9;
    uint32_t trans_strides2 = 4032;
    size_t nx = 384;
    size_t ny = 448;
    size_t nz = 9;
    __shared__ float tile[16][1][17];
    uint32_t base2 = blockIdx.x * blockDim.x;
    uint32_t base1 = blockIdx.y * blockDim.y;
    uint32_t base0 = blockIdx.z * blockDim.z;
    uint32_t tid2 = threadIdx.x;
    uint32_t tid1 = threadIdx.y;
    uint32_t tid0 = threadIdx.z;
    uint32_t otid2 = tid2;
    uint32_t otid1 = tid1;
    uint32_t otid0 = tid0;
    uint32_t idx2 = base2 + tid2;
    uint32_t idx1 = base1 + tid1;
    uint32_t idx0 = base0 + tid0;
    if (idx2 < nx && idx1 < ny && idx0 < nz)
    {
        uint32_t input_idx = 0;
        input_idx += input_strides0* idx0;
        input_idx += input_strides1* idx1;
        input_idx += input_strides2* idx2;
        tile[tid0][tid1][tid2] = input0[input_idx];
    }
    otid2 = tid0;
    otid0 = tid2;
    idx2 = base2 + otid2;
    idx1 = base1 + otid1;
    idx0 = base0 + otid0;
    __syncthreads();
    if (idx2 < nx && idx1 < ny && idx0 < nz)
    {
        uint32_t output_idx = 0;
        output_idx += trans_strides0* idx0;
        output_idx += trans_strides1* idx1;
        output_idx += trans_strides2* idx2;
        output0[output_idx] = tile[otid0][otid1][otid2];
    }

}
extern void inception3_Reshape_float_float_cuda_Reshape_831_Call(const dim3 &grids, const dim3 &blocks, unsigned mem, cudaStream_t stream, float* input0, float* output0) {
    inception3_Reshape_float_float_cuda_Reshape_831<<<grids, blocks, mem, stream>>>(input0, output0);
}

extern "C" void inception3_cuda_init()
{
// total memory:809331008

CUDA_SAFE_CALL(cudaMalloc((void**)&inception3_group_0_CUDA_GPU0_allocator_memory_pool,713846784));
CUDA_SAFE_CALL(cudaMemset((void*)inception3_group_0_CUDA_GPU0_allocator_memory_pool, 0, 713846784));
inception3_Reshape_486_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+0);
inception3_Reshape_487_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+68659968);
inception3_Convolution_488_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+68663424);
inception3_BatchNormInference_489_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+250534016);
inception3_Relu_490_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+250534016);
inception3_Reshape_491_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+0);
inception3_Convolution_492_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+36864);
inception3_BatchNormInference_493_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+177057792);
inception3_Relu_494_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+177057792);
inception3_Reshape_495_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+0);
inception3_Convolution_496_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+354078720);
inception3_BatchNormInference_497_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+0);
inception3_Relu_498_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+0);
inception3_MaxPool_499_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+354041856);
inception3_Reshape_500_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+0);
inception3_Convolution_501_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+20480);
inception3_BatchNormInference_502_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+109158400);
inception3_Relu_503_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+109158400);
inception3_Reshape_504_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+0);
inception3_Convolution_505_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+218296320);
inception3_BatchNormInference_506_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+466071552);
inception3_Relu_507_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+466071552);
inception3_MaxPool_508_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+0);
inception3_Reshape_511_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+60211200);
inception3_Convolution_512_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+60248064);
inception3_BatchNormInference_517_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+75300864);
inception3_Relu_522_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+75300864);
inception3_Reshape_525_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+60211200);
inception3_Convolution_526_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+90353664);
inception3_BatchNormInference_530_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+60211200);
inception3_Relu_532_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+60211200);
inception3_Reshape_509_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+80281600);
inception3_Convolution_510_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+80330752);
inception3_BatchNormInference_516_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+100401152);
inception3_Relu_521_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+100401152);
inception3_AvgPool_515_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+120471552);
inception3_Reshape_519_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+80281600);
inception3_Convolution_520_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+80306176);
inception3_BatchNormInference_524_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+90341376);
inception3_Relu_529_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+90341376);
inception3_Reshape_513_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+80281600);
inception3_Convolution_514_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+120471552);
inception3_BatchNormInference_518_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+0);
inception3_Relu_523_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+0);
inception3_Reshape_527_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+20070400);
inception3_Convolution_528_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+20291584);
inception3_BatchNormInference_531_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+120471552);
inception3_Relu_533_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+120471552);
inception3_Reshape_534_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+0);
inception3_Convolution_535_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+331776);
inception3_BatchNormInference_536_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+120471552);
inception3_Relu_537_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+120471552);
inception3_Concat_538_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+150577152);
inception3_AvgPool_545_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+0);
inception3_Reshape_549_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+80281600);
inception3_Convolution_550_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+80347136);
inception3_BatchNormInference_554_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+0);
inception3_Relu_559_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+0);
inception3_Reshape_543_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+20070400);
inception3_Convolution_544_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+20135936);
inception3_BatchNormInference_548_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+40206336);
inception3_Relu_553_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+40206336);
inception3_Reshape_557_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+20070400);
inception3_Convolution_558_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+60276736);
inception3_BatchNormInference_561_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+20070400);
inception3_Relu_563_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+20070400);
inception3_Reshape_564_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+50176000);
inception3_Convolution_565_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+50507776);
inception3_BatchNormInference_566_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+20070400);
inception3_Relu_567_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+20070400);
inception3_Reshape_541_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+50176000);
inception3_Convolution_542_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+50225152);
inception3_BatchNormInference_547_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+65277952);
inception3_Relu_552_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+65277952);
inception3_Reshape_555_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+50176000);
inception3_Convolution_556_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+80330752);
inception3_BatchNormInference_560_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+50176000);
inception3_Relu_562_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+50176000);
inception3_Reshape_539_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+70246400);
inception3_Convolution_540_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+70311936);
inception3_BatchNormInference_546_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+90382336);
inception3_Relu_551_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+90382336);
inception3_Concat_568_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+110452736);
inception3_AvgPool_575_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+0);
inception3_Reshape_579_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+90316800);
inception3_Convolution_580_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+200769536);
inception3_BatchNormInference_584_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+0);
inception3_Relu_589_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+0);
inception3_Reshape_573_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+20070400);
inception3_Convolution_574_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+20144128);
inception3_BatchNormInference_578_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+40214528);
inception3_Relu_583_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+40214528);
inception3_Reshape_587_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+20070400);
inception3_Convolution_588_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+60284928);
inception3_BatchNormInference_591_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+20070400);
inception3_Relu_593_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+20070400);
inception3_Reshape_594_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+50176000);
inception3_Convolution_595_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+50507776);
inception3_BatchNormInference_596_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+20070400);
inception3_Relu_597_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+20070400);
inception3_Reshape_571_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+50176000);
inception3_Convolution_572_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+50231296);
inception3_BatchNormInference_577_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+65284096);
inception3_Relu_582_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+65284096);
inception3_Reshape_585_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+50176000);
inception3_Convolution_586_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+80336896);
inception3_BatchNormInference_590_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+50176000);
inception3_Relu_592_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+50176000);
inception3_Reshape_569_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+70246400);
inception3_Convolution_570_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+70320128);
inception3_BatchNormInference_576_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+90390528);
inception3_Relu_581_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+90390528);
inception3_Concat_598_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+110460928);
inception3_MaxPool_603_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+0);
inception3_Reshape_601_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+21307392);
inception3_Convolution_602_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+21381120);
inception3_BatchNormInference_605_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+41451520);
inception3_Relu_607_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+41451520);
inception3_Reshape_608_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+21307392);
inception3_Convolution_609_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+61521920);
inception3_BatchNormInference_610_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+21307392);
inception3_Relu_611_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+21307392);
inception3_Reshape_612_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+51412992);
inception3_Convolution_613_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+51744768);
inception3_BatchNormInference_614_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+21307392);
inception3_Relu_615_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+21307392);
inception3_Reshape_599_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+28409856);
inception3_Convolution_600_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+32391168);
inception3_BatchNormInference_604_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+60801024);
inception3_Relu_606_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+60801024);
inception3_Concat_616_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+89210880);
inception3_AvgPool_623_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+0);
inception3_Reshape_627_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+56819712);
inception3_Convolution_628_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+57409536);
inception3_BatchNormInference_632_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+0);
inception3_Relu_637_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+0);
inception3_Reshape_621_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+14204928);
inception3_Convolution_622_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+14598144);
inception3_BatchNormInference_626_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+24068096);
inception3_Relu_631_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+24068096);
inception3_Reshape_635_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+14204928);
inception3_Convolution_636_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+33538048);
inception3_BatchNormInference_639_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+14204928);
inception3_Relu_641_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+14204928);
inception3_Reshape_644_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+23674880);
inception3_Convolution_645_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+24133632);
inception3_BatchNormInference_647_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+14204928);
inception3_Relu_649_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+14204928);
inception3_Reshape_650_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+23674880);
inception3_Convolution_651_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+24133632);
inception3_BatchNormInference_652_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+14204928);
inception3_Relu_653_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+14204928);
inception3_Reshape_654_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+23674880);
inception3_Convolution_655_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+24363008);
inception3_BatchNormInference_656_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+38567936);
inception3_Relu_657_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+38567936);
inception3_Reshape_619_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+14204928);
inception3_Convolution_620_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+14598144);
inception3_BatchNormInference_625_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+24068096);
inception3_Relu_630_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+24068096);
inception3_Reshape_633_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+14204928);
inception3_Convolution_634_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+52772864);
inception3_BatchNormInference_638_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+14204928);
inception3_Relu_640_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+14204928);
inception3_Reshape_642_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+23674880);
inception3_Convolution_643_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+24363008);
inception3_BatchNormInference_646_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+52772864);
inception3_Relu_648_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+52772864);
inception3_Reshape_617_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+14204928);
inception3_Convolution_618_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+14794752);
inception3_BatchNormInference_624_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+66977792);
inception3_Relu_629_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+66977792);
inception3_Concat_658_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+81182720);
inception3_AvgPool_665_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+0);
inception3_Reshape_669_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+56819712);
inception3_Convolution_670_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+57409536);
inception3_BatchNormInference_674_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+0);
inception3_Relu_679_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+0);
inception3_Reshape_663_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+14204928);
inception3_Convolution_664_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+14696448);
inception3_BatchNormInference_668_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+26533888);
inception3_Relu_673_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+26533888);
inception3_Reshape_677_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+14204928);
inception3_Convolution_678_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+38371328);
inception3_BatchNormInference_681_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+14204928);
inception3_Relu_683_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+14204928);
inception3_Reshape_686_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+26042368);
inception3_Convolution_687_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+26759168);
inception3_BatchNormInference_689_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+14204928);
inception3_Relu_691_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+14204928);
inception3_Reshape_692_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+26042368);
inception3_Convolution_693_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+26759168);
inception3_BatchNormInference_694_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+14204928);
inception3_Relu_695_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+14204928);
inception3_Reshape_696_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+26042368);
inception3_Convolution_697_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+26902528);
inception3_BatchNormInference_698_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+41107456);
inception3_Relu_699_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+41107456);
inception3_Reshape_661_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+14204928);
inception3_Convolution_662_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+14696448);
inception3_BatchNormInference_667_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+26533888);
inception3_Relu_672_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+26533888);
inception3_Reshape_675_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+14204928);
inception3_Convolution_676_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+55312384);
inception3_BatchNormInference_680_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+14204928);
inception3_Relu_682_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+14204928);
inception3_Reshape_684_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+26042368);
inception3_Convolution_685_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+26902528);
inception3_BatchNormInference_688_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+55312384);
inception3_Relu_690_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+55312384);
inception3_Reshape_659_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+14204928);
inception3_Convolution_660_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+14794752);
inception3_BatchNormInference_666_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+69517312);
inception3_Relu_671_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+69517312);
inception3_Concat_700_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+83722240);
inception3_AvgPool_707_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+0);
inception3_Reshape_711_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+56819712);
inception3_Convolution_712_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+57409536);
inception3_BatchNormInference_716_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+0);
inception3_Relu_721_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+0);
inception3_Reshape_705_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+14204928);
inception3_Convolution_706_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+14696448);
inception3_BatchNormInference_710_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+26533888);
inception3_Relu_715_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+26533888);
inception3_Reshape_719_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+14204928);
inception3_Convolution_720_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+38371328);
inception3_BatchNormInference_723_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+14204928);
inception3_Relu_725_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+14204928);
inception3_Reshape_728_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+26042368);
inception3_Convolution_729_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+26759168);
inception3_BatchNormInference_731_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+14204928);
inception3_Relu_733_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+14204928);
inception3_Reshape_734_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+26042368);
inception3_Convolution_735_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+26759168);
inception3_BatchNormInference_736_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+14204928);
inception3_Relu_737_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+14204928);
inception3_Reshape_738_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+26042368);
inception3_Convolution_739_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+26902528);
inception3_BatchNormInference_740_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+41107456);
inception3_Relu_741_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+41107456);
inception3_Reshape_703_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+14204928);
inception3_Convolution_704_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+14696448);
inception3_BatchNormInference_709_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+26533888);
inception3_Relu_714_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+26533888);
inception3_Reshape_717_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+14204928);
inception3_Convolution_718_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+55312384);
inception3_BatchNormInference_722_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+14204928);
inception3_Relu_724_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+14204928);
inception3_Reshape_726_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+26042368);
inception3_Convolution_727_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+26902528);
inception3_BatchNormInference_730_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+55312384);
inception3_Relu_732_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+55312384);
inception3_Reshape_701_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+14204928);
inception3_Convolution_702_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+14794752);
inception3_BatchNormInference_708_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+69517312);
inception3_Relu_713_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+69517312);
inception3_Concat_742_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+83722240);
inception3_AvgPool_749_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+0);
inception3_Reshape_753_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+56819712);
inception3_Convolution_754_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+57409536);
inception3_BatchNormInference_758_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+0);
inception3_Relu_763_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+0);
inception3_Reshape_747_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+14204928);
inception3_Convolution_748_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+14794752);
inception3_BatchNormInference_752_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+28999680);
inception3_Relu_757_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+28999680);
inception3_Reshape_761_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+14204928);
inception3_Convolution_762_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+43204608);
inception3_BatchNormInference_765_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+14204928);
inception3_Relu_767_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+14204928);
inception3_Reshape_770_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+28409856);
inception3_Convolution_771_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+29442048);
inception3_BatchNormInference_773_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+14204928);
inception3_Relu_775_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+14204928);
inception3_Reshape_776_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+28409856);
inception3_Convolution_777_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+29442048);
inception3_BatchNormInference_778_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+14204928);
inception3_Relu_779_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+14204928);
inception3_Reshape_780_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+28409856);
inception3_Convolution_781_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+29442048);
inception3_BatchNormInference_782_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+14204928);
inception3_Relu_783_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+14204928);
inception3_Reshape_745_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+28409856);
inception3_Convolution_746_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+28999680);
inception3_BatchNormInference_751_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+43204608);
inception3_Relu_756_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+43204608);
inception3_Reshape_759_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+28409856);
inception3_Convolution_760_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+57409536);
inception3_BatchNormInference_764_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+28409856);
inception3_Relu_766_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+28409856);
inception3_Reshape_768_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+42614784);
inception3_Convolution_769_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+43646976);
inception3_BatchNormInference_772_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+28409856);
inception3_Relu_774_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+28409856);
inception3_Reshape_743_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+42614784);
inception3_Convolution_744_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+43204608);
inception3_BatchNormInference_750_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+57409536);
inception3_Relu_755_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+57409536);
inception3_Concat_784_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+71614464);
inception3_MaxPool_789_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+0);
inception3_Reshape_787_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+12582912);
inception3_Convolution_788_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+13172736);
inception3_BatchNormInference_791_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+27377664);
inception3_Relu_793_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+27377664);
inception3_Reshape_796_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+12582912);
inception3_Convolution_797_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+41582592);
inception3_BatchNormInference_799_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+12582912);
inception3_Relu_801_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+12582912);
inception3_Reshape_802_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+26787840);
inception3_Convolution_803_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+27820032);
inception3_BatchNormInference_804_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+12582912);
inception3_Relu_805_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+12582912);
inception3_Reshape_806_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+26787840);
inception3_Convolution_807_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+28114944);
inception3_BatchNormInference_808_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+12582912);
inception3_Relu_809_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+12582912);
inception3_Reshape_785_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+15728640);
inception3_Convolution_786_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+16318464);
inception3_BatchNormInference_790_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+30523392);
inception3_Relu_792_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+30523392);
inception3_Reshape_794_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+15728640);
inception3_Convolution_795_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+17940480);
inception3_BatchNormInference_798_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+23183360);
inception3_Relu_800_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+23183360);
inception3_Concat_810_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+28426240);
inception3_AvgPool_817_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+0);
inception3_Reshape_821_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+20971520);
inception3_Convolution_822_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+21954560);
inception3_BatchNormInference_826_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+0);
inception3_Relu_833_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+0);
inception3_Reshape_815_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+3145728);
inception3_Convolution_816_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+5439488);
inception3_BatchNormInference_820_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+12779520);
inception3_Relu_825_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+12779520);
inception3_Reshape_831_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+3145728);
inception3_Convolution_832_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+20119552);
inception3_BatchNormInference_836_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+3145728);
inception3_Relu_839_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+3145728);
inception3_Reshape_842_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+9437184);
inception3_Convolution_843_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+11206656);
inception3_BatchNormInference_845_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+17498112);
inception3_Relu_847_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+17498112);
inception3_Reshape_840_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+9437184);
inception3_Convolution_841_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+11206656);
inception3_BatchNormInference_844_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+3145728);
inception3_Relu_846_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+3145728);
inception3_Reshape_813_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+9437184);
inception3_Convolution_814_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+49397760);
inception3_BatchNormInference_819_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+9437184);
inception3_Relu_824_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+9437184);
inception3_Reshape_829_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+15728640);
inception3_Convolution_830_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+49397760);
inception3_BatchNormInference_835_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+55689216);
inception3_Relu_838_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+55689216);
inception3_Reshape_827_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+15728640);
inception3_Convolution_828_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+49397760);
inception3_BatchNormInference_834_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+9437184);
inception3_Relu_837_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+9437184);
inception3_Reshape_811_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+15728640);
inception3_Convolution_812_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+49397760);
inception3_BatchNormInference_818_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+23789568);
inception3_Relu_823_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+23789568);
inception3_Concat_848_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+61980672);
inception3_MaxPool_855_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+0);
inception3_Reshape_859_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+33554432);
inception3_Convolution_860_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+35127296);
inception3_BatchNormInference_864_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+0);
inception3_Relu_871_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+0);
inception3_Reshape_853_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+3145728);
inception3_Convolution_854_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+6815744);
inception3_BatchNormInference_858_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+14155776);
inception3_Relu_863_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+14155776);
inception3_Reshape_869_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+3145728);
inception3_Convolution_870_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+21495808);
inception3_BatchNormInference_874_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+3145728);
inception3_Relu_877_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+3145728);
inception3_Reshape_880_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+9437184);
inception3_Convolution_881_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+11206656);
inception3_BatchNormInference_883_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+17498112);
inception3_Relu_885_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+17498112);
inception3_Reshape_878_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+9437184);
inception3_Convolution_879_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+11206656);
inception3_BatchNormInference_882_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+3145728);
inception3_Relu_884_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+3145728);
inception3_Reshape_851_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+9437184);
inception3_Convolution_852_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+23789568);
inception3_BatchNormInference_857_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+9437184);
inception3_Relu_862_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+9437184);
inception3_Reshape_867_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+15728640);
inception3_Convolution_868_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+23789568);
inception3_BatchNormInference_873_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+30081024);
inception3_Relu_876_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+30081024);
inception3_Reshape_865_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+15728640);
inception3_Convolution_866_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+23789568);
inception3_BatchNormInference_872_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+9437184);
inception3_Relu_875_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+9437184);
inception3_Reshape_849_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+23789568);
inception3_Convolution_850_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+36372480);
inception3_BatchNormInference_856_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+23789568);
inception3_Relu_861_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+23789568);
inception3_Concat_886_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+36372480);
inception3_AvgPool_887_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+0);
inception3_Reshape_888_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+0);
inception3_Dot_889_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+524288);
inception3_Broadcast_890_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+0);
inception3_Add_891_0 = (float*)(inception3_group_0_CUDA_GPU0_allocator_memory_pool+524288);

CUDA_SAFE_CALL(cudaMalloc((void**)&inception3_group_persist_CUDA_GPU0_allocator_memory_pool,95484224));
CUDA_SAFE_CALL(cudaMemset((void*)inception3_group_persist_CUDA_GPU0_allocator_memory_pool, 0, 95484224));
inception3_Constant_484_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+0);
inception3_Constant_2_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+8200192);
inception3_Constant_6_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+8203648);
inception3_Constant_5_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+8203776);
inception3_Constant_4_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+8203904);
inception3_Constant_3_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+8204032);
inception3_Constant_7_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+8204160);
inception3_Constant_11_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+8241024);
inception3_Constant_10_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+8241152);
inception3_Constant_9_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+8241280);
inception3_Constant_8_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+8241408);
inception3_Constant_12_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+8241536);
inception3_Constant_16_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+8315264);
inception3_Constant_15_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+8315520);
inception3_Constant_14_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+8315776);
inception3_Constant_13_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+8316032);
inception3_Constant_17_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+8316288);
inception3_Constant_21_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+8336768);
inception3_Constant_20_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+8337088);
inception3_Constant_19_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+8337408);
inception3_Constant_18_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+8337728);
inception3_Constant_22_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+8338048);
inception3_Constant_26_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+8891008);
inception3_Constant_25_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+8891776);
inception3_Constant_24_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+8892544);
inception3_Constant_23_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+8893312);
inception3_Constant_32_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+8894080);
inception3_Constant_36_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+8930944);
inception3_Constant_35_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+8931136);
inception3_Constant_34_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+8931328);
inception3_Constant_33_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+8931520);
inception3_Constant_37_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+8931712);
inception3_Constant_41_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+9238912);
inception3_Constant_40_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+9239168);
inception3_Constant_39_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+9239424);
inception3_Constant_38_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+9239680);
inception3_Constant_27_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+9239936);
inception3_Constant_31_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+9289088);
inception3_Constant_30_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+9289344);
inception3_Constant_29_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+9289600);
inception3_Constant_28_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+9289856);
inception3_Constant_57_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+9290112);
inception3_Constant_61_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+9314688);
inception3_Constant_60_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+9314816);
inception3_Constant_59_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+9314944);
inception3_Constant_58_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+9315072);
inception3_Constant_42_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+9315200);
inception3_Constant_46_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+9364352);
inception3_Constant_45_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+9364608);
inception3_Constant_44_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+9364864);
inception3_Constant_43_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+9365120);
inception3_Constant_47_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+9365376);
inception3_Constant_51_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+9586560);
inception3_Constant_50_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+9586944);
inception3_Constant_49_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+9587328);
inception3_Constant_48_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+9587712);
inception3_Constant_52_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+9588096);
inception3_Constant_56_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+9919872);
inception3_Constant_55_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+9920256);
inception3_Constant_54_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+9920640);
inception3_Constant_53_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+9921024);
inception3_Constant_93_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+9921408);
inception3_Constant_94_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+9986944);
inception3_Constant_97_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+9987200);
inception3_Constant_96_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+9987456);
inception3_Constant_95_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+9987712);
inception3_Constant_78_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+9987968);
inception3_Constant_79_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+10053504);
inception3_Constant_82_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+10053760);
inception3_Constant_81_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+10054016);
inception3_Constant_80_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+10054272);
inception3_Constant_83_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+10054528);
inception3_Constant_84_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+10275712);
inception3_Constant_87_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+10276096);
inception3_Constant_86_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+10276480);
inception3_Constant_85_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+10276864);
inception3_Constant_88_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+10277248);
inception3_Constant_89_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+10609024);
inception3_Constant_92_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+10609408);
inception3_Constant_91_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+10609792);
inception3_Constant_90_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+10610176);
inception3_Constant_68_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+10610560);
inception3_Constant_69_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+10659712);
inception3_Constant_72_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+10659904);
inception3_Constant_71_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+10660096);
inception3_Constant_70_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+10660288);
inception3_Constant_73_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+10660480);
inception3_Constant_74_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+10967680);
inception3_Constant_77_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+10967936);
inception3_Constant_76_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+10968192);
inception3_Constant_75_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+10968448);
inception3_Constant_63_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+10968704);
inception3_Constant_64_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+11034240);
inception3_Constant_67_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+11034496);
inception3_Constant_66_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+11034752);
inception3_Constant_65_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+11035008);
inception3_Constant_129_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+11035264);
inception3_Constant_130_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+11108992);
inception3_Constant_133_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+11109248);
inception3_Constant_132_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+11109504);
inception3_Constant_131_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+11109760);
inception3_Constant_114_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+11110016);
inception3_Constant_115_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+11183744);
inception3_Constant_118_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+11184000);
inception3_Constant_117_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+11184256);
inception3_Constant_116_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+11184512);
inception3_Constant_119_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+11184768);
inception3_Constant_120_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+11405952);
inception3_Constant_123_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+11406336);
inception3_Constant_122_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+11406720);
inception3_Constant_121_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+11407104);
inception3_Constant_124_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+11407488);
inception3_Constant_125_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+11739264);
inception3_Constant_128_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+11739648);
inception3_Constant_127_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+11740032);
inception3_Constant_126_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+11740416);
inception3_Constant_104_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+11740800);
inception3_Constant_105_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+11796096);
inception3_Constant_108_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+11796288);
inception3_Constant_107_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+11796480);
inception3_Constant_106_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+11796672);
inception3_Constant_109_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+11796864);
inception3_Constant_110_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+12104064);
inception3_Constant_113_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+12104320);
inception3_Constant_112_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+12104576);
inception3_Constant_111_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+12104832);
inception3_Constant_99_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+12105088);
inception3_Constant_100_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+12178816);
inception3_Constant_103_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+12179072);
inception3_Constant_102_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+12179328);
inception3_Constant_101_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+12179584);
inception3_Constant_140_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+12179840);
inception3_Constant_144_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+12253568);
inception3_Constant_143_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+12253824);
inception3_Constant_142_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+12254080);
inception3_Constant_141_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+12254336);
inception3_Constant_145_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+12254592);
inception3_Constant_149_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+12475776);
inception3_Constant_148_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+12476160);
inception3_Constant_147_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+12476544);
inception3_Constant_146_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+12476928);
inception3_Constant_150_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+12477312);
inception3_Constant_154_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+12809088);
inception3_Constant_153_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+12809472);
inception3_Constant_152_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+12809856);
inception3_Constant_151_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+12810240);
inception3_Constant_135_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+12810624);
inception3_Constant_139_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+16791936);
inception3_Constant_138_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+16793472);
inception3_Constant_137_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+16795008);
inception3_Constant_136_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+16796544);
inception3_Constant_201_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+16798080);
inception3_Constant_205_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+17387904);
inception3_Constant_204_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+17388672);
inception3_Constant_203_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+17389440);
inception3_Constant_202_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+17390208);
inception3_Constant_176_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+17390976);
inception3_Constant_180_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+17784192);
inception3_Constant_179_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+17784704);
inception3_Constant_178_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+17785216);
inception3_Constant_177_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+17785728);
inception3_Constant_181_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+17786240);
inception3_Constant_185_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+18244992);
inception3_Constant_184_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+18245504);
inception3_Constant_183_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+18246016);
inception3_Constant_182_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+18246528);
inception3_Constant_186_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+18247040);
inception3_Constant_190_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+18705792);
inception3_Constant_189_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+18706304);
inception3_Constant_188_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+18706816);
inception3_Constant_187_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+18707328);
inception3_Constant_191_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+18707840);
inception3_Constant_195_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+19166592);
inception3_Constant_194_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+19167104);
inception3_Constant_193_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+19167616);
inception3_Constant_192_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+19168128);
inception3_Constant_196_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+19168640);
inception3_Constant_200_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+19856768);
inception3_Constant_199_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+19857536);
inception3_Constant_198_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+19858304);
inception3_Constant_197_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+19859072);
inception3_Constant_161_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+19859840);
inception3_Constant_165_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+20253056);
inception3_Constant_164_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+20253568);
inception3_Constant_163_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+20254080);
inception3_Constant_162_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+20254592);
inception3_Constant_166_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+20255104);
inception3_Constant_170_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+20713856);
inception3_Constant_169_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+20714368);
inception3_Constant_168_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+20714880);
inception3_Constant_167_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+20715392);
inception3_Constant_171_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+20715904);
inception3_Constant_175_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+21404032);
inception3_Constant_174_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+21404800);
inception3_Constant_173_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+21405568);
inception3_Constant_172_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+21406336);
inception3_Constant_156_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+21407104);
inception3_Constant_160_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+21996928);
inception3_Constant_159_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+21997696);
inception3_Constant_158_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+21998464);
inception3_Constant_157_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+21999232);
inception3_Constant_252_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+22000000);
inception3_Constant_253_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+22589824);
inception3_Constant_256_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+22590592);
inception3_Constant_255_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+22591360);
inception3_Constant_254_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+22592128);
inception3_Constant_227_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+22592896);
inception3_Constant_228_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+23084416);
inception3_Constant_231_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+23085056);
inception3_Constant_230_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+23085696);
inception3_Constant_229_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+23086336);
inception3_Constant_232_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+23086976);
inception3_Constant_233_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+23803776);
inception3_Constant_236_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+23804416);
inception3_Constant_235_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+23805056);
inception3_Constant_234_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+23805696);
inception3_Constant_237_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+23806336);
inception3_Constant_238_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+24523136);
inception3_Constant_241_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+24523776);
inception3_Constant_240_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+24524416);
inception3_Constant_239_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+24525056);
inception3_Constant_242_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+24525696);
inception3_Constant_243_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+25242496);
inception3_Constant_246_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+25243136);
inception3_Constant_245_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+25243776);
inception3_Constant_244_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+25244416);
inception3_Constant_247_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+25245056);
inception3_Constant_248_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+26105216);
inception3_Constant_251_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+26105984);
inception3_Constant_250_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+26106752);
inception3_Constant_249_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+26107520);
inception3_Constant_212_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+26108288);
inception3_Constant_213_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+26599808);
inception3_Constant_216_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+26600448);
inception3_Constant_215_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+26601088);
inception3_Constant_214_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+26601728);
inception3_Constant_217_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+26602368);
inception3_Constant_218_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+27319168);
inception3_Constant_221_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+27319808);
inception3_Constant_220_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+27320448);
inception3_Constant_219_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+27321088);
inception3_Constant_222_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+27321728);
inception3_Constant_223_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+28181888);
inception3_Constant_226_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+28182656);
inception3_Constant_225_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+28183424);
inception3_Constant_224_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+28184192);
inception3_Constant_207_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+28184960);
inception3_Constant_208_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+28774784);
inception3_Constant_211_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+28775552);
inception3_Constant_210_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+28776320);
inception3_Constant_209_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+28777088);
inception3_Constant_303_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+28777856);
inception3_Constant_304_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+29367680);
inception3_Constant_307_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+29368448);
inception3_Constant_306_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+29369216);
inception3_Constant_305_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+29369984);
inception3_Constant_278_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+29370752);
inception3_Constant_279_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+29862272);
inception3_Constant_282_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+29862912);
inception3_Constant_281_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+29863552);
inception3_Constant_280_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+29864192);
inception3_Constant_283_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+29864832);
inception3_Constant_284_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+30581632);
inception3_Constant_287_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+30582272);
inception3_Constant_286_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+30582912);
inception3_Constant_285_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+30583552);
inception3_Constant_288_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+30584192);
inception3_Constant_289_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+31300992);
inception3_Constant_292_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+31301632);
inception3_Constant_291_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+31302272);
inception3_Constant_290_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+31302912);
inception3_Constant_293_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+31303552);
inception3_Constant_294_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+32020352);
inception3_Constant_297_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+32020992);
inception3_Constant_296_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+32021632);
inception3_Constant_295_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+32022272);
inception3_Constant_298_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+32022912);
inception3_Constant_299_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+32883072);
inception3_Constant_302_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+32883840);
inception3_Constant_301_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+32884608);
inception3_Constant_300_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+32885376);
inception3_Constant_263_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+32886144);
inception3_Constant_264_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+33377664);
inception3_Constant_267_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+33378304);
inception3_Constant_266_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+33378944);
inception3_Constant_265_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+33379584);
inception3_Constant_268_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+33380224);
inception3_Constant_269_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+34097024);
inception3_Constant_272_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+34097664);
inception3_Constant_271_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+34098304);
inception3_Constant_270_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+34098944);
inception3_Constant_273_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+34099584);
inception3_Constant_274_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+34959744);
inception3_Constant_277_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+34960512);
inception3_Constant_276_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+34961280);
inception3_Constant_275_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+34962048);
inception3_Constant_258_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+34962816);
inception3_Constant_259_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+35552640);
inception3_Constant_262_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+35553408);
inception3_Constant_261_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+35554176);
inception3_Constant_260_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+35554944);
inception3_Constant_354_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+35555712);
inception3_Constant_355_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+36145536);
inception3_Constant_358_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+36146304);
inception3_Constant_357_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+36147072);
inception3_Constant_356_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+36147840);
inception3_Constant_329_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+36148608);
inception3_Constant_330_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+36738432);
inception3_Constant_333_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+36739200);
inception3_Constant_332_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+36739968);
inception3_Constant_331_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+36740736);
inception3_Constant_334_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+36741504);
inception3_Constant_335_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+37773696);
inception3_Constant_338_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+37774464);
inception3_Constant_337_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+37775232);
inception3_Constant_336_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+37776000);
inception3_Constant_339_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+37776768);
inception3_Constant_340_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+38808960);
inception3_Constant_343_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+38809728);
inception3_Constant_342_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+38810496);
inception3_Constant_341_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+38811264);
inception3_Constant_344_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+38812032);
inception3_Constant_345_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+39844224);
inception3_Constant_348_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+39844992);
inception3_Constant_347_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+39845760);
inception3_Constant_346_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+39846528);
inception3_Constant_349_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+39847296);
inception3_Constant_350_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+40879488);
inception3_Constant_353_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+40880256);
inception3_Constant_352_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+40881024);
inception3_Constant_351_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+40881792);
inception3_Constant_314_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+40882560);
inception3_Constant_315_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+41472384);
inception3_Constant_318_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+41473152);
inception3_Constant_317_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+41473920);
inception3_Constant_316_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+41474688);
inception3_Constant_319_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+41475456);
inception3_Constant_320_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+42507648);
inception3_Constant_323_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+42508416);
inception3_Constant_322_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+42509184);
inception3_Constant_321_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+42509952);
inception3_Constant_324_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+42510720);
inception3_Constant_325_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+43542912);
inception3_Constant_328_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+43543680);
inception3_Constant_327_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+43544448);
inception3_Constant_326_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+43545216);
inception3_Constant_309_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+43545984);
inception3_Constant_310_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+44135808);
inception3_Constant_313_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+44136576);
inception3_Constant_312_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+44137344);
inception3_Constant_311_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+44138112);
inception3_Constant_370_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+44138880);
inception3_Constant_374_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+44728704);
inception3_Constant_373_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+44729472);
inception3_Constant_372_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+44730240);
inception3_Constant_371_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+44731008);
inception3_Constant_375_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+44731776);
inception3_Constant_379_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+45763968);
inception3_Constant_378_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+45764736);
inception3_Constant_377_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+45765504);
inception3_Constant_376_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+45766272);
inception3_Constant_380_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+45767040);
inception3_Constant_384_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+46799232);
inception3_Constant_383_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+46800000);
inception3_Constant_382_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+46800768);
inception3_Constant_381_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+46801536);
inception3_Constant_385_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+46802304);
inception3_Constant_389_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+48129408);
inception3_Constant_388_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+48130176);
inception3_Constant_387_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+48130944);
inception3_Constant_386_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+48131712);
inception3_Constant_360_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+48132480);
inception3_Constant_364_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+48722304);
inception3_Constant_363_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+48723072);
inception3_Constant_362_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+48723840);
inception3_Constant_361_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+48724608);
inception3_Constant_365_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+48725376);
inception3_Constant_369_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+50937216);
inception3_Constant_368_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+50938496);
inception3_Constant_367_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+50939776);
inception3_Constant_366_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+50941056);
inception3_Constant_431_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+50942336);
inception3_Constant_435_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+51925376);
inception3_Constant_434_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+51926144);
inception3_Constant_433_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+51926912);
inception3_Constant_432_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+51927680);
inception3_Constant_411_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+51928448);
inception3_Constant_415_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+54222208);
inception3_Constant_414_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+54224000);
inception3_Constant_413_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+54225792);
inception3_Constant_412_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+54227584);
inception3_Constant_416_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+54229376);
inception3_Constant_420_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+60422528);
inception3_Constant_419_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+60424064);
inception3_Constant_418_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+60425600);
inception3_Constant_417_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+60427136);
inception3_Constant_426_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+60428672);
inception3_Constant_430_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+62198144);
inception3_Constant_429_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+62199680);
inception3_Constant_428_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+62201216);
inception3_Constant_427_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+62202752);
inception3_Constant_421_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+62204288);
inception3_Constant_425_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+63973760);
inception3_Constant_424_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+63975296);
inception3_Constant_423_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+63976832);
inception3_Constant_422_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+63978368);
inception3_Constant_396_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+63979904);
inception3_Constant_400_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+65945984);
inception3_Constant_399_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+65947520);
inception3_Constant_398_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+65949056);
inception3_Constant_397_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+65950592);
inception3_Constant_406_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+65952128);
inception3_Constant_410_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+67721600);
inception3_Constant_409_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+67723136);
inception3_Constant_408_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+67724672);
inception3_Constant_407_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+67726208);
inception3_Constant_401_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+67727744);
inception3_Constant_405_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+69497216);
inception3_Constant_404_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+69498752);
inception3_Constant_403_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+69500288);
inception3_Constant_402_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+69501824);
inception3_Constant_391_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+69503360);
inception3_Constant_395_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+71141760);
inception3_Constant_394_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+71143040);
inception3_Constant_393_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+71144320);
inception3_Constant_392_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+71145600);
inception3_Constant_477_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+71146880);
inception3_Constant_478_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+72719744);
inception3_Constant_481_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+72720512);
inception3_Constant_480_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+72721280);
inception3_Constant_479_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+72722048);
inception3_Constant_457_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+72722816);
inception3_Constant_458_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+76392832);
inception3_Constant_461_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+76394624);
inception3_Constant_460_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+76396416);
inception3_Constant_459_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+76398208);
inception3_Constant_462_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+76400000);
inception3_Constant_463_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+82593152);
inception3_Constant_466_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+82594688);
inception3_Constant_465_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+82596224);
inception3_Constant_464_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+82597760);
inception3_Constant_472_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+82599296);
inception3_Constant_473_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+84368768);
inception3_Constant_476_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+84370304);
inception3_Constant_475_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+84371840);
inception3_Constant_474_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+84373376);
inception3_Constant_467_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+84374912);
inception3_Constant_468_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+86144384);
inception3_Constant_471_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+86145920);
inception3_Constant_470_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+86147456);
inception3_Constant_469_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+86148992);
inception3_Constant_442_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+86150528);
inception3_Constant_443_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+89296256);
inception3_Constant_446_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+89297792);
inception3_Constant_445_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+89299328);
inception3_Constant_444_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+89300864);
inception3_Constant_452_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+89302400);
inception3_Constant_453_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+91071872);
inception3_Constant_456_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+91073408);
inception3_Constant_455_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+91074944);
inception3_Constant_454_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+91076480);
inception3_Constant_447_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+91078016);
inception3_Constant_448_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+92847488);
inception3_Constant_451_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+92849024);
inception3_Constant_450_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+92850560);
inception3_Constant_449_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+92852096);
inception3_Constant_437_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+92853632);
inception3_Constant_438_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+95475072);
inception3_Constant_441_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+95476352);
inception3_Constant_440_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+95477632);
inception3_Constant_439_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+95478912);
inception3_Constant_485_0 = (float*)(inception3_group_persist_CUDA_GPU0_allocator_memory_pool+95480192);
// create streams/handles
CUBLAS_SAFE_CALL(cublasCreate(&inception3_cublas_handle_0));
CUDNN_SAFE_CALL(cudnnCreate(&inception3_cudnn_handle_0));
 // name=cg/affine0/weights
inception3_Constant_float_cuda_Constant_484(0, inception3_Constant_484_0);
 // name=cg/conv0/conv2d/kernel
inception3_Constant_float_cuda_Constant_2(0, inception3_Constant_2_0);
 // name=cg/conv0/batchnorm0/moving_variance
inception3_Constant_float_cuda_Constant_6(0, inception3_Constant_6_0);
 // name=cg/conv0/batchnorm0/moving_mean
inception3_Constant_float_cuda_Constant_5(0, inception3_Constant_5_0);
 // name=cg/conv0/batchnorm0/beta
inception3_Constant_float_cuda_Constant_4(0, inception3_Constant_4_0);
 // name=cg/conv0/batchnorm0/Const
inception3_Constant_float_cuda_Constant_3(0, inception3_Constant_3_0);
 // name=cg/conv1/conv2d/kernel
inception3_Constant_float_cuda_Constant_7(0, inception3_Constant_7_0);
 // name=cg/conv1/batchnorm1/moving_variance
inception3_Constant_float_cuda_Constant_11(0, inception3_Constant_11_0);
 // name=cg/conv1/batchnorm1/moving_mean
inception3_Constant_float_cuda_Constant_10(0, inception3_Constant_10_0);
 // name=cg/conv1/batchnorm1/beta
inception3_Constant_float_cuda_Constant_9(0, inception3_Constant_9_0);
 // name=cg/conv1/batchnorm1/Const
inception3_Constant_float_cuda_Constant_8(0, inception3_Constant_8_0);
 // name=cg/conv2/conv2d/kernel
inception3_Constant_float_cuda_Constant_12(0, inception3_Constant_12_0);
 // name=cg/conv2/batchnorm2/moving_variance
inception3_Constant_float_cuda_Constant_16(0, inception3_Constant_16_0);
 // name=cg/conv2/batchnorm2/moving_mean
inception3_Constant_float_cuda_Constant_15(0, inception3_Constant_15_0);
 // name=cg/conv2/batchnorm2/beta
inception3_Constant_float_cuda_Constant_14(0, inception3_Constant_14_0);
 // name=cg/conv2/batchnorm2/Const
inception3_Constant_float_cuda_Constant_13(0, inception3_Constant_13_0);
 // name=cg/conv3/conv2d/kernel
inception3_Constant_float_cuda_Constant_17(0, inception3_Constant_17_0);
 // name=cg/conv3/batchnorm3/moving_variance
inception3_Constant_float_cuda_Constant_21(0, inception3_Constant_21_0);
 // name=cg/conv3/batchnorm3/moving_mean
inception3_Constant_float_cuda_Constant_20(0, inception3_Constant_20_0);
 // name=cg/conv3/batchnorm3/beta
inception3_Constant_float_cuda_Constant_19(0, inception3_Constant_19_0);
 // name=cg/conv3/batchnorm3/Const
inception3_Constant_float_cuda_Constant_18(0, inception3_Constant_18_0);
 // name=cg/conv4/conv2d/kernel
inception3_Constant_float_cuda_Constant_22(0, inception3_Constant_22_0);
 // name=cg/conv4/batchnorm4/moving_variance
inception3_Constant_float_cuda_Constant_26(0, inception3_Constant_26_0);
 // name=cg/conv4/batchnorm4/moving_mean
inception3_Constant_float_cuda_Constant_25(0, inception3_Constant_25_0);
 // name=cg/conv4/batchnorm4/beta
inception3_Constant_float_cuda_Constant_24(0, inception3_Constant_24_0);
 // name=cg/conv4/batchnorm4/Const
inception3_Constant_float_cuda_Constant_23(0, inception3_Constant_23_0);
 // name=cg/incept_v3_a0/conv6/conv2d/kernel
inception3_Constant_float_cuda_Constant_32(0, inception3_Constant_32_0);
 // name=cg/incept_v3_a0/conv6/batchnorm6/moving_variance
inception3_Constant_float_cuda_Constant_36(0, inception3_Constant_36_0);
 // name=cg/incept_v3_a0/conv6/batchnorm6/moving_mean
inception3_Constant_float_cuda_Constant_35(0, inception3_Constant_35_0);
 // name=cg/incept_v3_a0/conv6/batchnorm6/beta
inception3_Constant_float_cuda_Constant_34(0, inception3_Constant_34_0);
 // name=cg/incept_v3_a0/conv6/batchnorm6/Const
inception3_Constant_float_cuda_Constant_33(0, inception3_Constant_33_0);
 // name=cg/incept_v3_a0/conv7/conv2d/kernel
inception3_Constant_float_cuda_Constant_37(0, inception3_Constant_37_0);
 // name=cg/incept_v3_a0/conv7/batchnorm7/moving_variance
inception3_Constant_float_cuda_Constant_41(0, inception3_Constant_41_0);
 // name=cg/incept_v3_a0/conv7/batchnorm7/moving_mean
inception3_Constant_float_cuda_Constant_40(0, inception3_Constant_40_0);
 // name=cg/incept_v3_a0/conv7/batchnorm7/beta
inception3_Constant_float_cuda_Constant_39(0, inception3_Constant_39_0);
 // name=cg/incept_v3_a0/conv7/batchnorm7/Const
inception3_Constant_float_cuda_Constant_38(0, inception3_Constant_38_0);
 // name=cg/incept_v3_a0/conv5/conv2d/kernel
inception3_Constant_float_cuda_Constant_27(0, inception3_Constant_27_0);
 // name=cg/incept_v3_a0/conv5/batchnorm5/moving_variance
inception3_Constant_float_cuda_Constant_31(0, inception3_Constant_31_0);
 // name=cg/incept_v3_a0/conv5/batchnorm5/moving_mean
inception3_Constant_float_cuda_Constant_30(0, inception3_Constant_30_0);
 // name=cg/incept_v3_a0/conv5/batchnorm5/beta
inception3_Constant_float_cuda_Constant_29(0, inception3_Constant_29_0);
 // name=cg/incept_v3_a0/conv5/batchnorm5/Const
inception3_Constant_float_cuda_Constant_28(0, inception3_Constant_28_0);
 // name=cg/incept_v3_a0/conv11/conv2d/kernel
inception3_Constant_float_cuda_Constant_57(0, inception3_Constant_57_0);
 // name=cg/incept_v3_a0/conv11/batchnorm11/moving_variance
inception3_Constant_float_cuda_Constant_61(0, inception3_Constant_61_0);
 // name=cg/incept_v3_a0/conv11/batchnorm11/moving_mean
inception3_Constant_float_cuda_Constant_60(0, inception3_Constant_60_0);
 // name=cg/incept_v3_a0/conv11/batchnorm11/beta
inception3_Constant_float_cuda_Constant_59(0, inception3_Constant_59_0);
 // name=cg/incept_v3_a0/conv11/batchnorm11/Const
inception3_Constant_float_cuda_Constant_58(0, inception3_Constant_58_0);
 // name=cg/incept_v3_a0/conv8/conv2d/kernel
inception3_Constant_float_cuda_Constant_42(0, inception3_Constant_42_0);
 // name=cg/incept_v3_a0/conv8/batchnorm8/moving_variance
inception3_Constant_float_cuda_Constant_46(0, inception3_Constant_46_0);
 // name=cg/incept_v3_a0/conv8/batchnorm8/moving_mean
inception3_Constant_float_cuda_Constant_45(0, inception3_Constant_45_0);
 // name=cg/incept_v3_a0/conv8/batchnorm8/beta
inception3_Constant_float_cuda_Constant_44(0, inception3_Constant_44_0);
 // name=cg/incept_v3_a0/conv8/batchnorm8/Const
inception3_Constant_float_cuda_Constant_43(0, inception3_Constant_43_0);
 // name=cg/incept_v3_a0/conv9/conv2d/kernel
inception3_Constant_float_cuda_Constant_47(0, inception3_Constant_47_0);
 // name=cg/incept_v3_a0/conv9/batchnorm9/moving_variance
inception3_Constant_float_cuda_Constant_51(0, inception3_Constant_51_0);
 // name=cg/incept_v3_a0/conv9/batchnorm9/moving_mean
inception3_Constant_float_cuda_Constant_50(0, inception3_Constant_50_0);
 // name=cg/incept_v3_a0/conv9/batchnorm9/beta
inception3_Constant_float_cuda_Constant_49(0, inception3_Constant_49_0);
 // name=cg/incept_v3_a0/conv9/batchnorm9/Const
inception3_Constant_float_cuda_Constant_48(0, inception3_Constant_48_0);
 // name=cg/incept_v3_a0/conv10/conv2d/kernel
inception3_Constant_float_cuda_Constant_52(0, inception3_Constant_52_0);
 // name=cg/incept_v3_a0/conv10/batchnorm10/moving_variance
inception3_Constant_float_cuda_Constant_56(0, inception3_Constant_56_0);
 // name=cg/incept_v3_a0/conv10/batchnorm10/moving_mean
inception3_Constant_float_cuda_Constant_55(0, inception3_Constant_55_0);
 // name=cg/incept_v3_a0/conv10/batchnorm10/beta
inception3_Constant_float_cuda_Constant_54(0, inception3_Constant_54_0);
 // name=cg/incept_v3_a0/conv10/batchnorm10/Const
inception3_Constant_float_cuda_Constant_53(0, inception3_Constant_53_0);
 // name=cg/incept_v3_a0/conv18/conv2d/kernel
inception3_Constant_float_cuda_Constant_93(0, inception3_Constant_93_0);
 // name=cg/incept_v3_a0_1/conv18/batchnorm18/Const
inception3_Constant_float_cuda_Constant_94(0, inception3_Constant_94_0);
 // name=cg/incept_v3_a0/conv18/batchnorm18/moving_variance
inception3_Constant_float_cuda_Constant_97(0, inception3_Constant_97_0);
 // name=cg/incept_v3_a0/conv18/batchnorm18/moving_mean
inception3_Constant_float_cuda_Constant_96(0, inception3_Constant_96_0);
 // name=cg/incept_v3_a0/conv18/batchnorm18/beta
inception3_Constant_float_cuda_Constant_95(0, inception3_Constant_95_0);
 // name=cg/incept_v3_a0/conv15/conv2d/kernel
inception3_Constant_float_cuda_Constant_78(0, inception3_Constant_78_0);
 // name=cg/incept_v3_a0_1/conv15/batchnorm15/Const
inception3_Constant_float_cuda_Constant_79(0, inception3_Constant_79_0);
 // name=cg/incept_v3_a0/conv15/batchnorm15/moving_variance
inception3_Constant_float_cuda_Constant_82(0, inception3_Constant_82_0);
 // name=cg/incept_v3_a0/conv15/batchnorm15/moving_mean
inception3_Constant_float_cuda_Constant_81(0, inception3_Constant_81_0);
 // name=cg/incept_v3_a0/conv15/batchnorm15/beta
inception3_Constant_float_cuda_Constant_80(0, inception3_Constant_80_0);
 // name=cg/incept_v3_a0/conv16/conv2d/kernel
inception3_Constant_float_cuda_Constant_83(0, inception3_Constant_83_0);
 // name=cg/incept_v3_a0_1/conv16/batchnorm16/Const
inception3_Constant_float_cuda_Constant_84(0, inception3_Constant_84_0);
 // name=cg/incept_v3_a0/conv16/batchnorm16/moving_variance
inception3_Constant_float_cuda_Constant_87(0, inception3_Constant_87_0);
 // name=cg/incept_v3_a0/conv16/batchnorm16/moving_mean
inception3_Constant_float_cuda_Constant_86(0, inception3_Constant_86_0);
 // name=cg/incept_v3_a0/conv16/batchnorm16/beta
inception3_Constant_float_cuda_Constant_85(0, inception3_Constant_85_0);
 // name=cg/incept_v3_a0/conv17/conv2d/kernel
inception3_Constant_float_cuda_Constant_88(0, inception3_Constant_88_0);
 // name=cg/incept_v3_a0_1/conv17/batchnorm17/Const
inception3_Constant_float_cuda_Constant_89(0, inception3_Constant_89_0);
 // name=cg/incept_v3_a0/conv17/batchnorm17/moving_variance
inception3_Constant_float_cuda_Constant_92(0, inception3_Constant_92_0);
 // name=cg/incept_v3_a0/conv17/batchnorm17/moving_mean
inception3_Constant_float_cuda_Constant_91(0, inception3_Constant_91_0);
 // name=cg/incept_v3_a0/conv17/batchnorm17/beta
inception3_Constant_float_cuda_Constant_90(0, inception3_Constant_90_0);
 // name=cg/incept_v3_a0/conv13/conv2d/kernel
inception3_Constant_float_cuda_Constant_68(0, inception3_Constant_68_0);
 // name=cg/incept_v3_a0_1/conv13/batchnorm13/Const
inception3_Constant_float_cuda_Constant_69(0, inception3_Constant_69_0);
 // name=cg/incept_v3_a0/conv13/batchnorm13/moving_variance
inception3_Constant_float_cuda_Constant_72(0, inception3_Constant_72_0);
 // name=cg/incept_v3_a0/conv13/batchnorm13/moving_mean
inception3_Constant_float_cuda_Constant_71(0, inception3_Constant_71_0);
 // name=cg/incept_v3_a0/conv13/batchnorm13/beta
inception3_Constant_float_cuda_Constant_70(0, inception3_Constant_70_0);
 // name=cg/incept_v3_a0/conv14/conv2d/kernel
inception3_Constant_float_cuda_Constant_73(0, inception3_Constant_73_0);
 // name=cg/incept_v3_a0_1/conv14/batchnorm14/Const
inception3_Constant_float_cuda_Constant_74(0, inception3_Constant_74_0);
 // name=cg/incept_v3_a0/conv14/batchnorm14/moving_variance
inception3_Constant_float_cuda_Constant_77(0, inception3_Constant_77_0);
 // name=cg/incept_v3_a0/conv14/batchnorm14/moving_mean
inception3_Constant_float_cuda_Constant_76(0, inception3_Constant_76_0);
 // name=cg/incept_v3_a0/conv14/batchnorm14/beta
inception3_Constant_float_cuda_Constant_75(0, inception3_Constant_75_0);
 // name=cg/incept_v3_a0/conv12/conv2d/kernel
inception3_Constant_float_cuda_Constant_63(0, inception3_Constant_63_0);
 // name=cg/incept_v3_a0_1/conv12/batchnorm12/Const
inception3_Constant_float_cuda_Constant_64(0, inception3_Constant_64_0);
 // name=cg/incept_v3_a0/conv12/batchnorm12/moving_variance
inception3_Constant_float_cuda_Constant_67(0, inception3_Constant_67_0);
 // name=cg/incept_v3_a0/conv12/batchnorm12/moving_mean
inception3_Constant_float_cuda_Constant_66(0, inception3_Constant_66_0);
 // name=cg/incept_v3_a0/conv12/batchnorm12/beta
inception3_Constant_float_cuda_Constant_65(0, inception3_Constant_65_0);
 // name=cg/incept_v3_a0/conv25/conv2d/kernel
inception3_Constant_float_cuda_Constant_129(0, inception3_Constant_129_0);
 // name=cg/incept_v3_a0_2/conv25/batchnorm25/Const
inception3_Constant_float_cuda_Constant_130(0, inception3_Constant_130_0);
 // name=cg/incept_v3_a0/conv25/batchnorm25/moving_variance
inception3_Constant_float_cuda_Constant_133(0, inception3_Constant_133_0);
 // name=cg/incept_v3_a0/conv25/batchnorm25/moving_mean
inception3_Constant_float_cuda_Constant_132(0, inception3_Constant_132_0);
 // name=cg/incept_v3_a0/conv25/batchnorm25/beta
inception3_Constant_float_cuda_Constant_131(0, inception3_Constant_131_0);
 // name=cg/incept_v3_a0/conv22/conv2d/kernel
inception3_Constant_float_cuda_Constant_114(0, inception3_Constant_114_0);
 // name=cg/incept_v3_a0_2/conv22/batchnorm22/Const
inception3_Constant_float_cuda_Constant_115(0, inception3_Constant_115_0);
 // name=cg/incept_v3_a0/conv22/batchnorm22/moving_variance
inception3_Constant_float_cuda_Constant_118(0, inception3_Constant_118_0);
 // name=cg/incept_v3_a0/conv22/batchnorm22/moving_mean
inception3_Constant_float_cuda_Constant_117(0, inception3_Constant_117_0);
 // name=cg/incept_v3_a0/conv22/batchnorm22/beta
inception3_Constant_float_cuda_Constant_116(0, inception3_Constant_116_0);
 // name=cg/incept_v3_a0/conv23/conv2d/kernel
inception3_Constant_float_cuda_Constant_119(0, inception3_Constant_119_0);
 // name=cg/incept_v3_a0_2/conv23/batchnorm23/Const
inception3_Constant_float_cuda_Constant_120(0, inception3_Constant_120_0);
 // name=cg/incept_v3_a0/conv23/batchnorm23/moving_variance
inception3_Constant_float_cuda_Constant_123(0, inception3_Constant_123_0);
 // name=cg/incept_v3_a0/conv23/batchnorm23/moving_mean
inception3_Constant_float_cuda_Constant_122(0, inception3_Constant_122_0);
 // name=cg/incept_v3_a0/conv23/batchnorm23/beta
inception3_Constant_float_cuda_Constant_121(0, inception3_Constant_121_0);
 // name=cg/incept_v3_a0/conv24/conv2d/kernel
inception3_Constant_float_cuda_Constant_124(0, inception3_Constant_124_0);
 // name=cg/incept_v3_a0_2/conv24/batchnorm24/Const
inception3_Constant_float_cuda_Constant_125(0, inception3_Constant_125_0);
 // name=cg/incept_v3_a0/conv24/batchnorm24/moving_variance
inception3_Constant_float_cuda_Constant_128(0, inception3_Constant_128_0);
 // name=cg/incept_v3_a0/conv24/batchnorm24/moving_mean
inception3_Constant_float_cuda_Constant_127(0, inception3_Constant_127_0);
 // name=cg/incept_v3_a0/conv24/batchnorm24/beta
inception3_Constant_float_cuda_Constant_126(0, inception3_Constant_126_0);
 // name=cg/incept_v3_a0/conv20/conv2d/kernel
inception3_Constant_float_cuda_Constant_104(0, inception3_Constant_104_0);
 // name=cg/incept_v3_a0_2/conv20/batchnorm20/Const
inception3_Constant_float_cuda_Constant_105(0, inception3_Constant_105_0);
 // name=cg/incept_v3_a0/conv20/batchnorm20/moving_variance
inception3_Constant_float_cuda_Constant_108(0, inception3_Constant_108_0);
 // name=cg/incept_v3_a0/conv20/batchnorm20/moving_mean
inception3_Constant_float_cuda_Constant_107(0, inception3_Constant_107_0);
 // name=cg/incept_v3_a0/conv20/batchnorm20/beta
inception3_Constant_float_cuda_Constant_106(0, inception3_Constant_106_0);
 // name=cg/incept_v3_a0/conv21/conv2d/kernel
inception3_Constant_float_cuda_Constant_109(0, inception3_Constant_109_0);
 // name=cg/incept_v3_a0_2/conv21/batchnorm21/Const
inception3_Constant_float_cuda_Constant_110(0, inception3_Constant_110_0);
 // name=cg/incept_v3_a0/conv21/batchnorm21/moving_variance
inception3_Constant_float_cuda_Constant_113(0, inception3_Constant_113_0);
 // name=cg/incept_v3_a0/conv21/batchnorm21/moving_mean
inception3_Constant_float_cuda_Constant_112(0, inception3_Constant_112_0);
 // name=cg/incept_v3_a0/conv21/batchnorm21/beta
inception3_Constant_float_cuda_Constant_111(0, inception3_Constant_111_0);
 // name=cg/incept_v3_a0/conv19/conv2d/kernel
inception3_Constant_float_cuda_Constant_99(0, inception3_Constant_99_0);
 // name=cg/incept_v3_a0_2/conv19/batchnorm19/Const
inception3_Constant_float_cuda_Constant_100(0, inception3_Constant_100_0);
 // name=cg/incept_v3_a0/conv19/batchnorm19/moving_variance
inception3_Constant_float_cuda_Constant_103(0, inception3_Constant_103_0);
 // name=cg/incept_v3_a0/conv19/batchnorm19/moving_mean
inception3_Constant_float_cuda_Constant_102(0, inception3_Constant_102_0);
 // name=cg/incept_v3_a0/conv19/batchnorm19/beta
inception3_Constant_float_cuda_Constant_101(0, inception3_Constant_101_0);
 // name=cg/incept_v3_b0/conv27/conv2d/kernel
inception3_Constant_float_cuda_Constant_140(0, inception3_Constant_140_0);
 // name=cg/incept_v3_b0/conv27/batchnorm27/moving_variance
inception3_Constant_float_cuda_Constant_144(0, inception3_Constant_144_0);
 // name=cg/incept_v3_b0/conv27/batchnorm27/moving_mean
inception3_Constant_float_cuda_Constant_143(0, inception3_Constant_143_0);
 // name=cg/incept_v3_b0/conv27/batchnorm27/beta
inception3_Constant_float_cuda_Constant_142(0, inception3_Constant_142_0);
 // name=cg/incept_v3_b0/conv27/batchnorm27/Const
inception3_Constant_float_cuda_Constant_141(0, inception3_Constant_141_0);
 // name=cg/incept_v3_b0/conv28/conv2d/kernel
inception3_Constant_float_cuda_Constant_145(0, inception3_Constant_145_0);
 // name=cg/incept_v3_b0/conv28/batchnorm28/moving_variance
inception3_Constant_float_cuda_Constant_149(0, inception3_Constant_149_0);
 // name=cg/incept_v3_b0/conv28/batchnorm28/moving_mean
inception3_Constant_float_cuda_Constant_148(0, inception3_Constant_148_0);
 // name=cg/incept_v3_b0/conv28/batchnorm28/beta
inception3_Constant_float_cuda_Constant_147(0, inception3_Constant_147_0);
 // name=cg/incept_v3_b0/conv28/batchnorm28/Const
inception3_Constant_float_cuda_Constant_146(0, inception3_Constant_146_0);
 // name=cg/incept_v3_b0/conv29/conv2d/kernel
inception3_Constant_float_cuda_Constant_150(0, inception3_Constant_150_0);
 // name=cg/incept_v3_b0/conv29/batchnorm29/moving_variance
inception3_Constant_float_cuda_Constant_154(0, inception3_Constant_154_0);
 // name=cg/incept_v3_b0/conv29/batchnorm29/moving_mean
inception3_Constant_float_cuda_Constant_153(0, inception3_Constant_153_0);
 // name=cg/incept_v3_b0/conv29/batchnorm29/beta
inception3_Constant_float_cuda_Constant_152(0, inception3_Constant_152_0);
 // name=cg/incept_v3_b0/conv29/batchnorm29/Const
inception3_Constant_float_cuda_Constant_151(0, inception3_Constant_151_0);
 // name=cg/incept_v3_b0/conv26/conv2d/kernel
inception3_Constant_float_cuda_Constant_135(0, inception3_Constant_135_0);
 // name=cg/incept_v3_b0/conv26/batchnorm26/moving_variance
inception3_Constant_float_cuda_Constant_139(0, inception3_Constant_139_0);
 // name=cg/incept_v3_b0/conv26/batchnorm26/moving_mean
inception3_Constant_float_cuda_Constant_138(0, inception3_Constant_138_0);
 // name=cg/incept_v3_b0/conv26/batchnorm26/beta
inception3_Constant_float_cuda_Constant_137(0, inception3_Constant_137_0);
 // name=cg/incept_v3_b0/conv26/batchnorm26/Const
inception3_Constant_float_cuda_Constant_136(0, inception3_Constant_136_0);
 // name=cg/incept_v3_c0/conv39/conv2d/kernel
inception3_Constant_float_cuda_Constant_201(0, inception3_Constant_201_0);
 // name=cg/incept_v3_c0/conv39/batchnorm39/moving_variance
inception3_Constant_float_cuda_Constant_205(0, inception3_Constant_205_0);
 // name=cg/incept_v3_c0/conv39/batchnorm39/moving_mean
inception3_Constant_float_cuda_Constant_204(0, inception3_Constant_204_0);
 // name=cg/incept_v3_c0/conv39/batchnorm39/beta
inception3_Constant_float_cuda_Constant_203(0, inception3_Constant_203_0);
 // name=cg/incept_v3_c0/conv39/batchnorm39/Const
inception3_Constant_float_cuda_Constant_202(0, inception3_Constant_202_0);
 // name=cg/incept_v3_c0/conv34/conv2d/kernel
inception3_Constant_float_cuda_Constant_176(0, inception3_Constant_176_0);
 // name=cg/incept_v3_c0/conv34/batchnorm34/moving_variance
inception3_Constant_float_cuda_Constant_180(0, inception3_Constant_180_0);
 // name=cg/incept_v3_c0/conv34/batchnorm34/moving_mean
inception3_Constant_float_cuda_Constant_179(0, inception3_Constant_179_0);
 // name=cg/incept_v3_c0/conv34/batchnorm34/beta
inception3_Constant_float_cuda_Constant_178(0, inception3_Constant_178_0);
 // name=cg/incept_v3_c0/conv34/batchnorm34/Const
inception3_Constant_float_cuda_Constant_177(0, inception3_Constant_177_0);
 // name=cg/incept_v3_c0/conv35/conv2d/kernel
inception3_Constant_float_cuda_Constant_181(0, inception3_Constant_181_0);
 // name=cg/incept_v3_c0/conv35/batchnorm35/moving_variance
inception3_Constant_float_cuda_Constant_185(0, inception3_Constant_185_0);
 // name=cg/incept_v3_c0/conv35/batchnorm35/moving_mean
inception3_Constant_float_cuda_Constant_184(0, inception3_Constant_184_0);
 // name=cg/incept_v3_c0/conv35/batchnorm35/beta
inception3_Constant_float_cuda_Constant_183(0, inception3_Constant_183_0);
 // name=cg/incept_v3_c0/conv35/batchnorm35/Const
inception3_Constant_float_cuda_Constant_182(0, inception3_Constant_182_0);
 // name=cg/incept_v3_c0/conv36/conv2d/kernel
inception3_Constant_float_cuda_Constant_186(0, inception3_Constant_186_0);
 // name=cg/incept_v3_c0/conv36/batchnorm36/moving_variance
inception3_Constant_float_cuda_Constant_190(0, inception3_Constant_190_0);
 // name=cg/incept_v3_c0/conv36/batchnorm36/moving_mean
inception3_Constant_float_cuda_Constant_189(0, inception3_Constant_189_0);
 // name=cg/incept_v3_c0/conv36/batchnorm36/beta
inception3_Constant_float_cuda_Constant_188(0, inception3_Constant_188_0);
 // name=cg/incept_v3_c0/conv36/batchnorm36/Const
inception3_Constant_float_cuda_Constant_187(0, inception3_Constant_187_0);
 // name=cg/incept_v3_c0/conv37/conv2d/kernel
inception3_Constant_float_cuda_Constant_191(0, inception3_Constant_191_0);
 // name=cg/incept_v3_c0/conv37/batchnorm37/moving_variance
inception3_Constant_float_cuda_Constant_195(0, inception3_Constant_195_0);
 // name=cg/incept_v3_c0/conv37/batchnorm37/moving_mean
inception3_Constant_float_cuda_Constant_194(0, inception3_Constant_194_0);
 // name=cg/incept_v3_c0/conv37/batchnorm37/beta
inception3_Constant_float_cuda_Constant_193(0, inception3_Constant_193_0);
 // name=cg/incept_v3_c0/conv37/batchnorm37/Const
inception3_Constant_float_cuda_Constant_192(0, inception3_Constant_192_0);
 // name=cg/incept_v3_c0/conv38/conv2d/kernel
inception3_Constant_float_cuda_Constant_196(0, inception3_Constant_196_0);
 // name=cg/incept_v3_c0/conv38/batchnorm38/moving_variance
inception3_Constant_float_cuda_Constant_200(0, inception3_Constant_200_0);
 // name=cg/incept_v3_c0/conv38/batchnorm38/moving_mean
inception3_Constant_float_cuda_Constant_199(0, inception3_Constant_199_0);
 // name=cg/incept_v3_c0/conv38/batchnorm38/beta
inception3_Constant_float_cuda_Constant_198(0, inception3_Constant_198_0);
 // name=cg/incept_v3_c0/conv38/batchnorm38/Const
inception3_Constant_float_cuda_Constant_197(0, inception3_Constant_197_0);
 // name=cg/incept_v3_c0/conv31/conv2d/kernel
inception3_Constant_float_cuda_Constant_161(0, inception3_Constant_161_0);
 // name=cg/incept_v3_c0/conv31/batchnorm31/moving_variance
inception3_Constant_float_cuda_Constant_165(0, inception3_Constant_165_0);
 // name=cg/incept_v3_c0/conv31/batchnorm31/moving_mean
inception3_Constant_float_cuda_Constant_164(0, inception3_Constant_164_0);
 // name=cg/incept_v3_c0/conv31/batchnorm31/beta
inception3_Constant_float_cuda_Constant_163(0, inception3_Constant_163_0);
 // name=cg/incept_v3_c0/conv31/batchnorm31/Const
inception3_Constant_float_cuda_Constant_162(0, inception3_Constant_162_0);
 // name=cg/incept_v3_c0/conv32/conv2d/kernel
inception3_Constant_float_cuda_Constant_166(0, inception3_Constant_166_0);
 // name=cg/incept_v3_c0/conv32/batchnorm32/moving_variance
inception3_Constant_float_cuda_Constant_170(0, inception3_Constant_170_0);
 // name=cg/incept_v3_c0/conv32/batchnorm32/moving_mean
inception3_Constant_float_cuda_Constant_169(0, inception3_Constant_169_0);
 // name=cg/incept_v3_c0/conv32/batchnorm32/beta
inception3_Constant_float_cuda_Constant_168(0, inception3_Constant_168_0);
 // name=cg/incept_v3_c0/conv32/batchnorm32/Const
inception3_Constant_float_cuda_Constant_167(0, inception3_Constant_167_0);
 // name=cg/incept_v3_c0/conv33/conv2d/kernel
inception3_Constant_float_cuda_Constant_171(0, inception3_Constant_171_0);
 // name=cg/incept_v3_c0/conv33/batchnorm33/moving_variance
inception3_Constant_float_cuda_Constant_175(0, inception3_Constant_175_0);
 // name=cg/incept_v3_c0/conv33/batchnorm33/moving_mean
inception3_Constant_float_cuda_Constant_174(0, inception3_Constant_174_0);
 // name=cg/incept_v3_c0/conv33/batchnorm33/beta
inception3_Constant_float_cuda_Constant_173(0, inception3_Constant_173_0);
 // name=cg/incept_v3_c0/conv33/batchnorm33/Const
inception3_Constant_float_cuda_Constant_172(0, inception3_Constant_172_0);
 // name=cg/incept_v3_c0/conv30/conv2d/kernel
inception3_Constant_float_cuda_Constant_156(0, inception3_Constant_156_0);
 // name=cg/incept_v3_c0/conv30/batchnorm30/moving_variance
inception3_Constant_float_cuda_Constant_160(0, inception3_Constant_160_0);
 // name=cg/incept_v3_c0/conv30/batchnorm30/moving_mean
inception3_Constant_float_cuda_Constant_159(0, inception3_Constant_159_0);
 // name=cg/incept_v3_c0/conv30/batchnorm30/beta
inception3_Constant_float_cuda_Constant_158(0, inception3_Constant_158_0);
 // name=cg/incept_v3_c0/conv30/batchnorm30/Const
inception3_Constant_float_cuda_Constant_157(0, inception3_Constant_157_0);
 // name=cg/incept_v3_c0/conv49/conv2d/kernel
inception3_Constant_float_cuda_Constant_252(0, inception3_Constant_252_0);
 // name=cg/incept_v3_c0_1/conv49/batchnorm49/Const
inception3_Constant_float_cuda_Constant_253(0, inception3_Constant_253_0);
 // name=cg/incept_v3_c0/conv49/batchnorm49/moving_variance
inception3_Constant_float_cuda_Constant_256(0, inception3_Constant_256_0);
 // name=cg/incept_v3_c0/conv49/batchnorm49/moving_mean
inception3_Constant_float_cuda_Constant_255(0, inception3_Constant_255_0);
 // name=cg/incept_v3_c0/conv49/batchnorm49/beta
inception3_Constant_float_cuda_Constant_254(0, inception3_Constant_254_0);
 // name=cg/incept_v3_c0/conv44/conv2d/kernel
inception3_Constant_float_cuda_Constant_227(0, inception3_Constant_227_0);
 // name=cg/incept_v3_c0_1/conv44/batchnorm44/Const
inception3_Constant_float_cuda_Constant_228(0, inception3_Constant_228_0);
 // name=cg/incept_v3_c0/conv44/batchnorm44/moving_variance
inception3_Constant_float_cuda_Constant_231(0, inception3_Constant_231_0);
 // name=cg/incept_v3_c0/conv44/batchnorm44/moving_mean
inception3_Constant_float_cuda_Constant_230(0, inception3_Constant_230_0);
 // name=cg/incept_v3_c0/conv44/batchnorm44/beta
inception3_Constant_float_cuda_Constant_229(0, inception3_Constant_229_0);
 // name=cg/incept_v3_c0/conv45/conv2d/kernel
inception3_Constant_float_cuda_Constant_232(0, inception3_Constant_232_0);
 // name=cg/incept_v3_c0_1/conv45/batchnorm45/Const
inception3_Constant_float_cuda_Constant_233(0, inception3_Constant_233_0);
 // name=cg/incept_v3_c0/conv45/batchnorm45/moving_variance
inception3_Constant_float_cuda_Constant_236(0, inception3_Constant_236_0);
 // name=cg/incept_v3_c0/conv45/batchnorm45/moving_mean
inception3_Constant_float_cuda_Constant_235(0, inception3_Constant_235_0);
 // name=cg/incept_v3_c0/conv45/batchnorm45/beta
inception3_Constant_float_cuda_Constant_234(0, inception3_Constant_234_0);
 // name=cg/incept_v3_c0/conv46/conv2d/kernel
inception3_Constant_float_cuda_Constant_237(0, inception3_Constant_237_0);
 // name=cg/incept_v3_c0_1/conv46/batchnorm46/Const
inception3_Constant_float_cuda_Constant_238(0, inception3_Constant_238_0);
 // name=cg/incept_v3_c0/conv46/batchnorm46/moving_variance
inception3_Constant_float_cuda_Constant_241(0, inception3_Constant_241_0);
 // name=cg/incept_v3_c0/conv46/batchnorm46/moving_mean
inception3_Constant_float_cuda_Constant_240(0, inception3_Constant_240_0);
 // name=cg/incept_v3_c0/conv46/batchnorm46/beta
inception3_Constant_float_cuda_Constant_239(0, inception3_Constant_239_0);
 // name=cg/incept_v3_c0/conv47/conv2d/kernel
inception3_Constant_float_cuda_Constant_242(0, inception3_Constant_242_0);
 // name=cg/incept_v3_c0_1/conv47/batchnorm47/Const
inception3_Constant_float_cuda_Constant_243(0, inception3_Constant_243_0);
 // name=cg/incept_v3_c0/conv47/batchnorm47/moving_variance
inception3_Constant_float_cuda_Constant_246(0, inception3_Constant_246_0);
 // name=cg/incept_v3_c0/conv47/batchnorm47/moving_mean
inception3_Constant_float_cuda_Constant_245(0, inception3_Constant_245_0);
 // name=cg/incept_v3_c0/conv47/batchnorm47/beta
inception3_Constant_float_cuda_Constant_244(0, inception3_Constant_244_0);
 // name=cg/incept_v3_c0/conv48/conv2d/kernel
inception3_Constant_float_cuda_Constant_247(0, inception3_Constant_247_0);
 // name=cg/incept_v3_c0_1/conv48/batchnorm48/Const
inception3_Constant_float_cuda_Constant_248(0, inception3_Constant_248_0);
 // name=cg/incept_v3_c0/conv48/batchnorm48/moving_variance
inception3_Constant_float_cuda_Constant_251(0, inception3_Constant_251_0);
 // name=cg/incept_v3_c0/conv48/batchnorm48/moving_mean
inception3_Constant_float_cuda_Constant_250(0, inception3_Constant_250_0);
 // name=cg/incept_v3_c0/conv48/batchnorm48/beta
inception3_Constant_float_cuda_Constant_249(0, inception3_Constant_249_0);
 // name=cg/incept_v3_c0/conv41/conv2d/kernel
inception3_Constant_float_cuda_Constant_212(0, inception3_Constant_212_0);
 // name=cg/incept_v3_c0_1/conv41/batchnorm41/Const
inception3_Constant_float_cuda_Constant_213(0, inception3_Constant_213_0);
 // name=cg/incept_v3_c0/conv41/batchnorm41/moving_variance
inception3_Constant_float_cuda_Constant_216(0, inception3_Constant_216_0);
 // name=cg/incept_v3_c0/conv41/batchnorm41/moving_mean
inception3_Constant_float_cuda_Constant_215(0, inception3_Constant_215_0);
 // name=cg/incept_v3_c0/conv41/batchnorm41/beta
inception3_Constant_float_cuda_Constant_214(0, inception3_Constant_214_0);
 // name=cg/incept_v3_c0/conv42/conv2d/kernel
inception3_Constant_float_cuda_Constant_217(0, inception3_Constant_217_0);
 // name=cg/incept_v3_c0_1/conv42/batchnorm42/Const
inception3_Constant_float_cuda_Constant_218(0, inception3_Constant_218_0);
 // name=cg/incept_v3_c0/conv42/batchnorm42/moving_variance
inception3_Constant_float_cuda_Constant_221(0, inception3_Constant_221_0);
 // name=cg/incept_v3_c0/conv42/batchnorm42/moving_mean
inception3_Constant_float_cuda_Constant_220(0, inception3_Constant_220_0);
 // name=cg/incept_v3_c0/conv42/batchnorm42/beta
inception3_Constant_float_cuda_Constant_219(0, inception3_Constant_219_0);
 // name=cg/incept_v3_c0/conv43/conv2d/kernel
inception3_Constant_float_cuda_Constant_222(0, inception3_Constant_222_0);
 // name=cg/incept_v3_c0_1/conv43/batchnorm43/Const
inception3_Constant_float_cuda_Constant_223(0, inception3_Constant_223_0);
 // name=cg/incept_v3_c0/conv43/batchnorm43/moving_variance
inception3_Constant_float_cuda_Constant_226(0, inception3_Constant_226_0);
 // name=cg/incept_v3_c0/conv43/batchnorm43/moving_mean
inception3_Constant_float_cuda_Constant_225(0, inception3_Constant_225_0);
 // name=cg/incept_v3_c0/conv43/batchnorm43/beta
inception3_Constant_float_cuda_Constant_224(0, inception3_Constant_224_0);
 // name=cg/incept_v3_c0/conv40/conv2d/kernel
inception3_Constant_float_cuda_Constant_207(0, inception3_Constant_207_0);
 // name=cg/incept_v3_c0_1/conv40/batchnorm40/Const
inception3_Constant_float_cuda_Constant_208(0, inception3_Constant_208_0);
 // name=cg/incept_v3_c0/conv40/batchnorm40/moving_variance
inception3_Constant_float_cuda_Constant_211(0, inception3_Constant_211_0);
 // name=cg/incept_v3_c0/conv40/batchnorm40/moving_mean
inception3_Constant_float_cuda_Constant_210(0, inception3_Constant_210_0);
 // name=cg/incept_v3_c0/conv40/batchnorm40/beta
inception3_Constant_float_cuda_Constant_209(0, inception3_Constant_209_0);
 // name=cg/incept_v3_c0/conv59/conv2d/kernel
inception3_Constant_float_cuda_Constant_303(0, inception3_Constant_303_0);
 // name=cg/incept_v3_c0_2/conv59/batchnorm59/Const
inception3_Constant_float_cuda_Constant_304(0, inception3_Constant_304_0);
 // name=cg/incept_v3_c0/conv59/batchnorm59/moving_variance
inception3_Constant_float_cuda_Constant_307(0, inception3_Constant_307_0);
 // name=cg/incept_v3_c0/conv59/batchnorm59/moving_mean
inception3_Constant_float_cuda_Constant_306(0, inception3_Constant_306_0);
 // name=cg/incept_v3_c0/conv59/batchnorm59/beta
inception3_Constant_float_cuda_Constant_305(0, inception3_Constant_305_0);
 // name=cg/incept_v3_c0/conv54/conv2d/kernel
inception3_Constant_float_cuda_Constant_278(0, inception3_Constant_278_0);
 // name=cg/incept_v3_c0_2/conv54/batchnorm54/Const
inception3_Constant_float_cuda_Constant_279(0, inception3_Constant_279_0);
 // name=cg/incept_v3_c0/conv54/batchnorm54/moving_variance
inception3_Constant_float_cuda_Constant_282(0, inception3_Constant_282_0);
 // name=cg/incept_v3_c0/conv54/batchnorm54/moving_mean
inception3_Constant_float_cuda_Constant_281(0, inception3_Constant_281_0);
 // name=cg/incept_v3_c0/conv54/batchnorm54/beta
inception3_Constant_float_cuda_Constant_280(0, inception3_Constant_280_0);
 // name=cg/incept_v3_c0/conv55/conv2d/kernel
inception3_Constant_float_cuda_Constant_283(0, inception3_Constant_283_0);
 // name=cg/incept_v3_c0_2/conv55/batchnorm55/Const
inception3_Constant_float_cuda_Constant_284(0, inception3_Constant_284_0);
 // name=cg/incept_v3_c0/conv55/batchnorm55/moving_variance
inception3_Constant_float_cuda_Constant_287(0, inception3_Constant_287_0);
 // name=cg/incept_v3_c0/conv55/batchnorm55/moving_mean
inception3_Constant_float_cuda_Constant_286(0, inception3_Constant_286_0);
 // name=cg/incept_v3_c0/conv55/batchnorm55/beta
inception3_Constant_float_cuda_Constant_285(0, inception3_Constant_285_0);
 // name=cg/incept_v3_c0/conv56/conv2d/kernel
inception3_Constant_float_cuda_Constant_288(0, inception3_Constant_288_0);
 // name=cg/incept_v3_c0_2/conv56/batchnorm56/Const
inception3_Constant_float_cuda_Constant_289(0, inception3_Constant_289_0);
 // name=cg/incept_v3_c0/conv56/batchnorm56/moving_variance
inception3_Constant_float_cuda_Constant_292(0, inception3_Constant_292_0);
 // name=cg/incept_v3_c0/conv56/batchnorm56/moving_mean
inception3_Constant_float_cuda_Constant_291(0, inception3_Constant_291_0);
 // name=cg/incept_v3_c0/conv56/batchnorm56/beta
inception3_Constant_float_cuda_Constant_290(0, inception3_Constant_290_0);
 // name=cg/incept_v3_c0/conv57/conv2d/kernel
inception3_Constant_float_cuda_Constant_293(0, inception3_Constant_293_0);
 // name=cg/incept_v3_c0_2/conv57/batchnorm57/Const
inception3_Constant_float_cuda_Constant_294(0, inception3_Constant_294_0);
 // name=cg/incept_v3_c0/conv57/batchnorm57/moving_variance
inception3_Constant_float_cuda_Constant_297(0, inception3_Constant_297_0);
 // name=cg/incept_v3_c0/conv57/batchnorm57/moving_mean
inception3_Constant_float_cuda_Constant_296(0, inception3_Constant_296_0);
 // name=cg/incept_v3_c0/conv57/batchnorm57/beta
inception3_Constant_float_cuda_Constant_295(0, inception3_Constant_295_0);
 // name=cg/incept_v3_c0/conv58/conv2d/kernel
inception3_Constant_float_cuda_Constant_298(0, inception3_Constant_298_0);
 // name=cg/incept_v3_c0_2/conv58/batchnorm58/Const
inception3_Constant_float_cuda_Constant_299(0, inception3_Constant_299_0);
 // name=cg/incept_v3_c0/conv58/batchnorm58/moving_variance
inception3_Constant_float_cuda_Constant_302(0, inception3_Constant_302_0);
 // name=cg/incept_v3_c0/conv58/batchnorm58/moving_mean
inception3_Constant_float_cuda_Constant_301(0, inception3_Constant_301_0);
 // name=cg/incept_v3_c0/conv58/batchnorm58/beta
inception3_Constant_float_cuda_Constant_300(0, inception3_Constant_300_0);
 // name=cg/incept_v3_c0/conv51/conv2d/kernel
inception3_Constant_float_cuda_Constant_263(0, inception3_Constant_263_0);
 // name=cg/incept_v3_c0_2/conv51/batchnorm51/Const
inception3_Constant_float_cuda_Constant_264(0, inception3_Constant_264_0);
 // name=cg/incept_v3_c0/conv51/batchnorm51/moving_variance
inception3_Constant_float_cuda_Constant_267(0, inception3_Constant_267_0);
 // name=cg/incept_v3_c0/conv51/batchnorm51/moving_mean
inception3_Constant_float_cuda_Constant_266(0, inception3_Constant_266_0);
 // name=cg/incept_v3_c0/conv51/batchnorm51/beta
inception3_Constant_float_cuda_Constant_265(0, inception3_Constant_265_0);
 // name=cg/incept_v3_c0/conv52/conv2d/kernel
inception3_Constant_float_cuda_Constant_268(0, inception3_Constant_268_0);
 // name=cg/incept_v3_c0_2/conv52/batchnorm52/Const
inception3_Constant_float_cuda_Constant_269(0, inception3_Constant_269_0);
 // name=cg/incept_v3_c0/conv52/batchnorm52/moving_variance
inception3_Constant_float_cuda_Constant_272(0, inception3_Constant_272_0);
 // name=cg/incept_v3_c0/conv52/batchnorm52/moving_mean
inception3_Constant_float_cuda_Constant_271(0, inception3_Constant_271_0);
 // name=cg/incept_v3_c0/conv52/batchnorm52/beta
inception3_Constant_float_cuda_Constant_270(0, inception3_Constant_270_0);
 // name=cg/incept_v3_c0/conv53/conv2d/kernel
inception3_Constant_float_cuda_Constant_273(0, inception3_Constant_273_0);
 // name=cg/incept_v3_c0_2/conv53/batchnorm53/Const
inception3_Constant_float_cuda_Constant_274(0, inception3_Constant_274_0);
 // name=cg/incept_v3_c0/conv53/batchnorm53/moving_variance
inception3_Constant_float_cuda_Constant_277(0, inception3_Constant_277_0);
 // name=cg/incept_v3_c0/conv53/batchnorm53/moving_mean
inception3_Constant_float_cuda_Constant_276(0, inception3_Constant_276_0);
 // name=cg/incept_v3_c0/conv53/batchnorm53/beta
inception3_Constant_float_cuda_Constant_275(0, inception3_Constant_275_0);
 // name=cg/incept_v3_c0/conv50/conv2d/kernel
inception3_Constant_float_cuda_Constant_258(0, inception3_Constant_258_0);
 // name=cg/incept_v3_c0_2/conv50/batchnorm50/Const
inception3_Constant_float_cuda_Constant_259(0, inception3_Constant_259_0);
 // name=cg/incept_v3_c0/conv50/batchnorm50/moving_variance
inception3_Constant_float_cuda_Constant_262(0, inception3_Constant_262_0);
 // name=cg/incept_v3_c0/conv50/batchnorm50/moving_mean
inception3_Constant_float_cuda_Constant_261(0, inception3_Constant_261_0);
 // name=cg/incept_v3_c0/conv50/batchnorm50/beta
inception3_Constant_float_cuda_Constant_260(0, inception3_Constant_260_0);
 // name=cg/incept_v3_c0/conv69/conv2d/kernel
inception3_Constant_float_cuda_Constant_354(0, inception3_Constant_354_0);
 // name=cg/incept_v3_c0_3/conv69/batchnorm69/Const
inception3_Constant_float_cuda_Constant_355(0, inception3_Constant_355_0);
 // name=cg/incept_v3_c0/conv69/batchnorm69/moving_variance
inception3_Constant_float_cuda_Constant_358(0, inception3_Constant_358_0);
 // name=cg/incept_v3_c0/conv69/batchnorm69/moving_mean
inception3_Constant_float_cuda_Constant_357(0, inception3_Constant_357_0);
 // name=cg/incept_v3_c0/conv69/batchnorm69/beta
inception3_Constant_float_cuda_Constant_356(0, inception3_Constant_356_0);
 // name=cg/incept_v3_c0/conv64/conv2d/kernel
inception3_Constant_float_cuda_Constant_329(0, inception3_Constant_329_0);
 // name=cg/incept_v3_c0_3/conv64/batchnorm64/Const
inception3_Constant_float_cuda_Constant_330(0, inception3_Constant_330_0);
 // name=cg/incept_v3_c0/conv64/batchnorm64/moving_variance
inception3_Constant_float_cuda_Constant_333(0, inception3_Constant_333_0);
 // name=cg/incept_v3_c0/conv64/batchnorm64/moving_mean
inception3_Constant_float_cuda_Constant_332(0, inception3_Constant_332_0);
 // name=cg/incept_v3_c0/conv64/batchnorm64/beta
inception3_Constant_float_cuda_Constant_331(0, inception3_Constant_331_0);
 // name=cg/incept_v3_c0/conv65/conv2d/kernel
inception3_Constant_float_cuda_Constant_334(0, inception3_Constant_334_0);
 // name=cg/incept_v3_c0_3/conv65/batchnorm65/Const
inception3_Constant_float_cuda_Constant_335(0, inception3_Constant_335_0);
 // name=cg/incept_v3_c0/conv65/batchnorm65/moving_variance
inception3_Constant_float_cuda_Constant_338(0, inception3_Constant_338_0);
 // name=cg/incept_v3_c0/conv65/batchnorm65/moving_mean
inception3_Constant_float_cuda_Constant_337(0, inception3_Constant_337_0);
 // name=cg/incept_v3_c0/conv65/batchnorm65/beta
inception3_Constant_float_cuda_Constant_336(0, inception3_Constant_336_0);
 // name=cg/incept_v3_c0/conv66/conv2d/kernel
inception3_Constant_float_cuda_Constant_339(0, inception3_Constant_339_0);
 // name=cg/incept_v3_c0_3/conv66/batchnorm66/Const
inception3_Constant_float_cuda_Constant_340(0, inception3_Constant_340_0);
 // name=cg/incept_v3_c0/conv66/batchnorm66/moving_variance
inception3_Constant_float_cuda_Constant_343(0, inception3_Constant_343_0);
 // name=cg/incept_v3_c0/conv66/batchnorm66/moving_mean
inception3_Constant_float_cuda_Constant_342(0, inception3_Constant_342_0);
 // name=cg/incept_v3_c0/conv66/batchnorm66/beta
inception3_Constant_float_cuda_Constant_341(0, inception3_Constant_341_0);
 // name=cg/incept_v3_c0/conv67/conv2d/kernel
inception3_Constant_float_cuda_Constant_344(0, inception3_Constant_344_0);
 // name=cg/incept_v3_c0_3/conv67/batchnorm67/Const
inception3_Constant_float_cuda_Constant_345(0, inception3_Constant_345_0);
 // name=cg/incept_v3_c0/conv67/batchnorm67/moving_variance
inception3_Constant_float_cuda_Constant_348(0, inception3_Constant_348_0);
 // name=cg/incept_v3_c0/conv67/batchnorm67/moving_mean
inception3_Constant_float_cuda_Constant_347(0, inception3_Constant_347_0);
 // name=cg/incept_v3_c0/conv67/batchnorm67/beta
inception3_Constant_float_cuda_Constant_346(0, inception3_Constant_346_0);
 // name=cg/incept_v3_c0/conv68/conv2d/kernel
inception3_Constant_float_cuda_Constant_349(0, inception3_Constant_349_0);
 // name=cg/incept_v3_c0_3/conv68/batchnorm68/Const
inception3_Constant_float_cuda_Constant_350(0, inception3_Constant_350_0);
 // name=cg/incept_v3_c0/conv68/batchnorm68/moving_variance
inception3_Constant_float_cuda_Constant_353(0, inception3_Constant_353_0);
 // name=cg/incept_v3_c0/conv68/batchnorm68/moving_mean
inception3_Constant_float_cuda_Constant_352(0, inception3_Constant_352_0);
 // name=cg/incept_v3_c0/conv68/batchnorm68/beta
inception3_Constant_float_cuda_Constant_351(0, inception3_Constant_351_0);
 // name=cg/incept_v3_c0/conv61/conv2d/kernel
inception3_Constant_float_cuda_Constant_314(0, inception3_Constant_314_0);
 // name=cg/incept_v3_c0_3/conv61/batchnorm61/Const
inception3_Constant_float_cuda_Constant_315(0, inception3_Constant_315_0);
 // name=cg/incept_v3_c0/conv61/batchnorm61/moving_variance
inception3_Constant_float_cuda_Constant_318(0, inception3_Constant_318_0);
 // name=cg/incept_v3_c0/conv61/batchnorm61/moving_mean
inception3_Constant_float_cuda_Constant_317(0, inception3_Constant_317_0);
 // name=cg/incept_v3_c0/conv61/batchnorm61/beta
inception3_Constant_float_cuda_Constant_316(0, inception3_Constant_316_0);
 // name=cg/incept_v3_c0/conv62/conv2d/kernel
inception3_Constant_float_cuda_Constant_319(0, inception3_Constant_319_0);
 // name=cg/incept_v3_c0_3/conv62/batchnorm62/Const
inception3_Constant_float_cuda_Constant_320(0, inception3_Constant_320_0);
 // name=cg/incept_v3_c0/conv62/batchnorm62/moving_variance
inception3_Constant_float_cuda_Constant_323(0, inception3_Constant_323_0);
 // name=cg/incept_v3_c0/conv62/batchnorm62/moving_mean
inception3_Constant_float_cuda_Constant_322(0, inception3_Constant_322_0);
 // name=cg/incept_v3_c0/conv62/batchnorm62/beta
inception3_Constant_float_cuda_Constant_321(0, inception3_Constant_321_0);
 // name=cg/incept_v3_c0/conv63/conv2d/kernel
inception3_Constant_float_cuda_Constant_324(0, inception3_Constant_324_0);
 // name=cg/incept_v3_c0_3/conv63/batchnorm63/Const
inception3_Constant_float_cuda_Constant_325(0, inception3_Constant_325_0);
 // name=cg/incept_v3_c0/conv63/batchnorm63/moving_variance
inception3_Constant_float_cuda_Constant_328(0, inception3_Constant_328_0);
 // name=cg/incept_v3_c0/conv63/batchnorm63/moving_mean
inception3_Constant_float_cuda_Constant_327(0, inception3_Constant_327_0);
 // name=cg/incept_v3_c0/conv63/batchnorm63/beta
inception3_Constant_float_cuda_Constant_326(0, inception3_Constant_326_0);
 // name=cg/incept_v3_c0/conv60/conv2d/kernel
inception3_Constant_float_cuda_Constant_309(0, inception3_Constant_309_0);
 // name=cg/incept_v3_c0_3/conv60/batchnorm60/Const
inception3_Constant_float_cuda_Constant_310(0, inception3_Constant_310_0);
 // name=cg/incept_v3_c0/conv60/batchnorm60/moving_variance
inception3_Constant_float_cuda_Constant_313(0, inception3_Constant_313_0);
 // name=cg/incept_v3_c0/conv60/batchnorm60/moving_mean
inception3_Constant_float_cuda_Constant_312(0, inception3_Constant_312_0);
 // name=cg/incept_v3_c0/conv60/batchnorm60/beta
inception3_Constant_float_cuda_Constant_311(0, inception3_Constant_311_0);
 // name=cg/incept_v3_d0/conv72/conv2d/kernel
inception3_Constant_float_cuda_Constant_370(0, inception3_Constant_370_0);
 // name=cg/incept_v3_d0/conv72/batchnorm72/moving_variance
inception3_Constant_float_cuda_Constant_374(0, inception3_Constant_374_0);
 // name=cg/incept_v3_d0/conv72/batchnorm72/moving_mean
inception3_Constant_float_cuda_Constant_373(0, inception3_Constant_373_0);
 // name=cg/incept_v3_d0/conv72/batchnorm72/beta
inception3_Constant_float_cuda_Constant_372(0, inception3_Constant_372_0);
 // name=cg/incept_v3_d0/conv72/batchnorm72/Const
inception3_Constant_float_cuda_Constant_371(0, inception3_Constant_371_0);
 // name=cg/incept_v3_d0/conv73/conv2d/kernel
inception3_Constant_float_cuda_Constant_375(0, inception3_Constant_375_0);
 // name=cg/incept_v3_d0/conv73/batchnorm73/moving_variance
inception3_Constant_float_cuda_Constant_379(0, inception3_Constant_379_0);
 // name=cg/incept_v3_d0/conv73/batchnorm73/moving_mean
inception3_Constant_float_cuda_Constant_378(0, inception3_Constant_378_0);
 // name=cg/incept_v3_d0/conv73/batchnorm73/beta
inception3_Constant_float_cuda_Constant_377(0, inception3_Constant_377_0);
 // name=cg/incept_v3_d0/conv73/batchnorm73/Const
inception3_Constant_float_cuda_Constant_376(0, inception3_Constant_376_0);
 // name=cg/incept_v3_d0/conv74/conv2d/kernel
inception3_Constant_float_cuda_Constant_380(0, inception3_Constant_380_0);
 // name=cg/incept_v3_d0/conv74/batchnorm74/moving_variance
inception3_Constant_float_cuda_Constant_384(0, inception3_Constant_384_0);
 // name=cg/incept_v3_d0/conv74/batchnorm74/moving_mean
inception3_Constant_float_cuda_Constant_383(0, inception3_Constant_383_0);
 // name=cg/incept_v3_d0/conv74/batchnorm74/beta
inception3_Constant_float_cuda_Constant_382(0, inception3_Constant_382_0);
 // name=cg/incept_v3_d0/conv74/batchnorm74/Const
inception3_Constant_float_cuda_Constant_381(0, inception3_Constant_381_0);
 // name=cg/incept_v3_d0/conv75/conv2d/kernel
inception3_Constant_float_cuda_Constant_385(0, inception3_Constant_385_0);
 // name=cg/incept_v3_d0/conv75/batchnorm75/moving_variance
inception3_Constant_float_cuda_Constant_389(0, inception3_Constant_389_0);
 // name=cg/incept_v3_d0/conv75/batchnorm75/moving_mean
inception3_Constant_float_cuda_Constant_388(0, inception3_Constant_388_0);
 // name=cg/incept_v3_d0/conv75/batchnorm75/beta
inception3_Constant_float_cuda_Constant_387(0, inception3_Constant_387_0);
 // name=cg/incept_v3_d0/conv75/batchnorm75/Const
inception3_Constant_float_cuda_Constant_386(0, inception3_Constant_386_0);
 // name=cg/incept_v3_d0/conv70/conv2d/kernel
inception3_Constant_float_cuda_Constant_360(0, inception3_Constant_360_0);
 // name=cg/incept_v3_d0/conv70/batchnorm70/moving_variance
inception3_Constant_float_cuda_Constant_364(0, inception3_Constant_364_0);
 // name=cg/incept_v3_d0/conv70/batchnorm70/moving_mean
inception3_Constant_float_cuda_Constant_363(0, inception3_Constant_363_0);
 // name=cg/incept_v3_d0/conv70/batchnorm70/beta
inception3_Constant_float_cuda_Constant_362(0, inception3_Constant_362_0);
 // name=cg/incept_v3_d0/conv70/batchnorm70/Const
inception3_Constant_float_cuda_Constant_361(0, inception3_Constant_361_0);
 // name=cg/incept_v3_d0/conv71/conv2d/kernel
inception3_Constant_float_cuda_Constant_365(0, inception3_Constant_365_0);
 // name=cg/incept_v3_d0/conv71/batchnorm71/moving_variance
inception3_Constant_float_cuda_Constant_369(0, inception3_Constant_369_0);
 // name=cg/incept_v3_d0/conv71/batchnorm71/moving_mean
inception3_Constant_float_cuda_Constant_368(0, inception3_Constant_368_0);
 // name=cg/incept_v3_d0/conv71/batchnorm71/beta
inception3_Constant_float_cuda_Constant_367(0, inception3_Constant_367_0);
 // name=cg/incept_v3_d0/conv71/batchnorm71/Const
inception3_Constant_float_cuda_Constant_366(0, inception3_Constant_366_0);
 // name=cg/incept_v3_e0/conv84/conv2d/kernel
inception3_Constant_float_cuda_Constant_431(0, inception3_Constant_431_0);
 // name=cg/incept_v3_e0/conv84/batchnorm84/moving_variance
inception3_Constant_float_cuda_Constant_435(0, inception3_Constant_435_0);
 // name=cg/incept_v3_e0/conv84/batchnorm84/moving_mean
inception3_Constant_float_cuda_Constant_434(0, inception3_Constant_434_0);
 // name=cg/incept_v3_e0/conv84/batchnorm84/beta
inception3_Constant_float_cuda_Constant_433(0, inception3_Constant_433_0);
 // name=cg/incept_v3_e0/conv84/batchnorm84/Const
inception3_Constant_float_cuda_Constant_432(0, inception3_Constant_432_0);
 // name=cg/incept_v3_e0/conv80/conv2d/kernel
inception3_Constant_float_cuda_Constant_411(0, inception3_Constant_411_0);
 // name=cg/incept_v3_e0/conv80/batchnorm80/moving_variance
inception3_Constant_float_cuda_Constant_415(0, inception3_Constant_415_0);
 // name=cg/incept_v3_e0/conv80/batchnorm80/moving_mean
inception3_Constant_float_cuda_Constant_414(0, inception3_Constant_414_0);
 // name=cg/incept_v3_e0/conv80/batchnorm80/beta
inception3_Constant_float_cuda_Constant_413(0, inception3_Constant_413_0);
 // name=cg/incept_v3_e0/conv80/batchnorm80/Const
inception3_Constant_float_cuda_Constant_412(0, inception3_Constant_412_0);
 // name=cg/incept_v3_e0/conv81/conv2d/kernel
inception3_Constant_float_cuda_Constant_416(0, inception3_Constant_416_0);
 // name=cg/incept_v3_e0/conv81/batchnorm81/moving_variance
inception3_Constant_float_cuda_Constant_420(0, inception3_Constant_420_0);
 // name=cg/incept_v3_e0/conv81/batchnorm81/moving_mean
inception3_Constant_float_cuda_Constant_419(0, inception3_Constant_419_0);
 // name=cg/incept_v3_e0/conv81/batchnorm81/beta
inception3_Constant_float_cuda_Constant_418(0, inception3_Constant_418_0);
 // name=cg/incept_v3_e0/conv81/batchnorm81/Const
inception3_Constant_float_cuda_Constant_417(0, inception3_Constant_417_0);
 // name=cg/incept_v3_e0/conv83/conv2d/kernel
inception3_Constant_float_cuda_Constant_426(0, inception3_Constant_426_0);
 // name=cg/incept_v3_e0/conv83/batchnorm83/moving_variance
inception3_Constant_float_cuda_Constant_430(0, inception3_Constant_430_0);
 // name=cg/incept_v3_e0/conv83/batchnorm83/moving_mean
inception3_Constant_float_cuda_Constant_429(0, inception3_Constant_429_0);
 // name=cg/incept_v3_e0/conv83/batchnorm83/beta
inception3_Constant_float_cuda_Constant_428(0, inception3_Constant_428_0);
 // name=cg/incept_v3_e0/conv83/batchnorm83/Const
inception3_Constant_float_cuda_Constant_427(0, inception3_Constant_427_0);
 // name=cg/incept_v3_e0/conv82/conv2d/kernel
inception3_Constant_float_cuda_Constant_421(0, inception3_Constant_421_0);
 // name=cg/incept_v3_e0/conv82/batchnorm82/moving_variance
inception3_Constant_float_cuda_Constant_425(0, inception3_Constant_425_0);
 // name=cg/incept_v3_e0/conv82/batchnorm82/moving_mean
inception3_Constant_float_cuda_Constant_424(0, inception3_Constant_424_0);
 // name=cg/incept_v3_e0/conv82/batchnorm82/beta
inception3_Constant_float_cuda_Constant_423(0, inception3_Constant_423_0);
 // name=cg/incept_v3_e0/conv82/batchnorm82/Const
inception3_Constant_float_cuda_Constant_422(0, inception3_Constant_422_0);
 // name=cg/incept_v3_e0/conv77/conv2d/kernel
inception3_Constant_float_cuda_Constant_396(0, inception3_Constant_396_0);
 // name=cg/incept_v3_e0/conv77/batchnorm77/moving_variance
inception3_Constant_float_cuda_Constant_400(0, inception3_Constant_400_0);
 // name=cg/incept_v3_e0/conv77/batchnorm77/moving_mean
inception3_Constant_float_cuda_Constant_399(0, inception3_Constant_399_0);
 // name=cg/incept_v3_e0/conv77/batchnorm77/beta
inception3_Constant_float_cuda_Constant_398(0, inception3_Constant_398_0);
 // name=cg/incept_v3_e0/conv77/batchnorm77/Const
inception3_Constant_float_cuda_Constant_397(0, inception3_Constant_397_0);
 // name=cg/incept_v3_e0/conv79/conv2d/kernel
inception3_Constant_float_cuda_Constant_406(0, inception3_Constant_406_0);
 // name=cg/incept_v3_e0/conv79/batchnorm79/moving_variance
inception3_Constant_float_cuda_Constant_410(0, inception3_Constant_410_0);
 // name=cg/incept_v3_e0/conv79/batchnorm79/moving_mean
inception3_Constant_float_cuda_Constant_409(0, inception3_Constant_409_0);
 // name=cg/incept_v3_e0/conv79/batchnorm79/beta
inception3_Constant_float_cuda_Constant_408(0, inception3_Constant_408_0);
 // name=cg/incept_v3_e0/conv79/batchnorm79/Const
inception3_Constant_float_cuda_Constant_407(0, inception3_Constant_407_0);
 // name=cg/incept_v3_e0/conv78/conv2d/kernel
inception3_Constant_float_cuda_Constant_401(0, inception3_Constant_401_0);
 // name=cg/incept_v3_e0/conv78/batchnorm78/moving_variance
inception3_Constant_float_cuda_Constant_405(0, inception3_Constant_405_0);
 // name=cg/incept_v3_e0/conv78/batchnorm78/moving_mean
inception3_Constant_float_cuda_Constant_404(0, inception3_Constant_404_0);
 // name=cg/incept_v3_e0/conv78/batchnorm78/beta
inception3_Constant_float_cuda_Constant_403(0, inception3_Constant_403_0);
 // name=cg/incept_v3_e0/conv78/batchnorm78/Const
inception3_Constant_float_cuda_Constant_402(0, inception3_Constant_402_0);
 // name=cg/incept_v3_e0/conv76/conv2d/kernel
inception3_Constant_float_cuda_Constant_391(0, inception3_Constant_391_0);
 // name=cg/incept_v3_e0/conv76/batchnorm76/moving_variance
inception3_Constant_float_cuda_Constant_395(0, inception3_Constant_395_0);
 // name=cg/incept_v3_e0/conv76/batchnorm76/moving_mean
inception3_Constant_float_cuda_Constant_394(0, inception3_Constant_394_0);
 // name=cg/incept_v3_e0/conv76/batchnorm76/beta
inception3_Constant_float_cuda_Constant_393(0, inception3_Constant_393_0);
 // name=cg/incept_v3_e0/conv76/batchnorm76/Const
inception3_Constant_float_cuda_Constant_392(0, inception3_Constant_392_0);
 // name=cg/incept_v3_e0/conv93/conv2d/kernel
inception3_Constant_float_cuda_Constant_477(0, inception3_Constant_477_0);
 // name=cg/incept_v3_e0_1/conv93/batchnorm93/Const
inception3_Constant_float_cuda_Constant_478(0, inception3_Constant_478_0);
 // name=cg/incept_v3_e0/conv93/batchnorm93/moving_variance
inception3_Constant_float_cuda_Constant_481(0, inception3_Constant_481_0);
 // name=cg/incept_v3_e0/conv93/batchnorm93/moving_mean
inception3_Constant_float_cuda_Constant_480(0, inception3_Constant_480_0);
 // name=cg/incept_v3_e0/conv93/batchnorm93/beta
inception3_Constant_float_cuda_Constant_479(0, inception3_Constant_479_0);
 // name=cg/incept_v3_e0/conv89/conv2d/kernel
inception3_Constant_float_cuda_Constant_457(0, inception3_Constant_457_0);
 // name=cg/incept_v3_e0_1/conv89/batchnorm89/Const
inception3_Constant_float_cuda_Constant_458(0, inception3_Constant_458_0);
 // name=cg/incept_v3_e0/conv89/batchnorm89/moving_variance
inception3_Constant_float_cuda_Constant_461(0, inception3_Constant_461_0);
 // name=cg/incept_v3_e0/conv89/batchnorm89/moving_mean
inception3_Constant_float_cuda_Constant_460(0, inception3_Constant_460_0);
 // name=cg/incept_v3_e0/conv89/batchnorm89/beta
inception3_Constant_float_cuda_Constant_459(0, inception3_Constant_459_0);
 // name=cg/incept_v3_e0/conv90/conv2d/kernel
inception3_Constant_float_cuda_Constant_462(0, inception3_Constant_462_0);
 // name=cg/incept_v3_e0_1/conv90/batchnorm90/Const
inception3_Constant_float_cuda_Constant_463(0, inception3_Constant_463_0);
 // name=cg/incept_v3_e0/conv90/batchnorm90/moving_variance
inception3_Constant_float_cuda_Constant_466(0, inception3_Constant_466_0);
 // name=cg/incept_v3_e0/conv90/batchnorm90/moving_mean
inception3_Constant_float_cuda_Constant_465(0, inception3_Constant_465_0);
 // name=cg/incept_v3_e0/conv90/batchnorm90/beta
inception3_Constant_float_cuda_Constant_464(0, inception3_Constant_464_0);
 // name=cg/incept_v3_e0/conv92/conv2d/kernel
inception3_Constant_float_cuda_Constant_472(0, inception3_Constant_472_0);
 // name=cg/incept_v3_e0_1/conv92/batchnorm92/Const
inception3_Constant_float_cuda_Constant_473(0, inception3_Constant_473_0);
 // name=cg/incept_v3_e0/conv92/batchnorm92/moving_variance
inception3_Constant_float_cuda_Constant_476(0, inception3_Constant_476_0);
 // name=cg/incept_v3_e0/conv92/batchnorm92/moving_mean
inception3_Constant_float_cuda_Constant_475(0, inception3_Constant_475_0);
 // name=cg/incept_v3_e0/conv92/batchnorm92/beta
inception3_Constant_float_cuda_Constant_474(0, inception3_Constant_474_0);
 // name=cg/incept_v3_e0/conv91/conv2d/kernel
inception3_Constant_float_cuda_Constant_467(0, inception3_Constant_467_0);
 // name=cg/incept_v3_e0_1/conv91/batchnorm91/Const
inception3_Constant_float_cuda_Constant_468(0, inception3_Constant_468_0);
 // name=cg/incept_v3_e0/conv91/batchnorm91/moving_variance
inception3_Constant_float_cuda_Constant_471(0, inception3_Constant_471_0);
 // name=cg/incept_v3_e0/conv91/batchnorm91/moving_mean
inception3_Constant_float_cuda_Constant_470(0, inception3_Constant_470_0);
 // name=cg/incept_v3_e0/conv91/batchnorm91/beta
inception3_Constant_float_cuda_Constant_469(0, inception3_Constant_469_0);
 // name=cg/incept_v3_e0/conv86/conv2d/kernel
inception3_Constant_float_cuda_Constant_442(0, inception3_Constant_442_0);
 // name=cg/incept_v3_e0_1/conv86/batchnorm86/Const
inception3_Constant_float_cuda_Constant_443(0, inception3_Constant_443_0);
 // name=cg/incept_v3_e0/conv86/batchnorm86/moving_variance
inception3_Constant_float_cuda_Constant_446(0, inception3_Constant_446_0);
 // name=cg/incept_v3_e0/conv86/batchnorm86/moving_mean
inception3_Constant_float_cuda_Constant_445(0, inception3_Constant_445_0);
 // name=cg/incept_v3_e0/conv86/batchnorm86/beta
inception3_Constant_float_cuda_Constant_444(0, inception3_Constant_444_0);
 // name=cg/incept_v3_e0/conv88/conv2d/kernel
inception3_Constant_float_cuda_Constant_452(0, inception3_Constant_452_0);
 // name=cg/incept_v3_e0_1/conv88/batchnorm88/Const
inception3_Constant_float_cuda_Constant_453(0, inception3_Constant_453_0);
 // name=cg/incept_v3_e0/conv88/batchnorm88/moving_variance
inception3_Constant_float_cuda_Constant_456(0, inception3_Constant_456_0);
 // name=cg/incept_v3_e0/conv88/batchnorm88/moving_mean
inception3_Constant_float_cuda_Constant_455(0, inception3_Constant_455_0);
 // name=cg/incept_v3_e0/conv88/batchnorm88/beta
inception3_Constant_float_cuda_Constant_454(0, inception3_Constant_454_0);
 // name=cg/incept_v3_e0/conv87/conv2d/kernel
inception3_Constant_float_cuda_Constant_447(0, inception3_Constant_447_0);
 // name=cg/incept_v3_e0_1/conv87/batchnorm87/Const
inception3_Constant_float_cuda_Constant_448(0, inception3_Constant_448_0);
 // name=cg/incept_v3_e0/conv87/batchnorm87/moving_variance
inception3_Constant_float_cuda_Constant_451(0, inception3_Constant_451_0);
 // name=cg/incept_v3_e0/conv87/batchnorm87/moving_mean
inception3_Constant_float_cuda_Constant_450(0, inception3_Constant_450_0);
 // name=cg/incept_v3_e0/conv87/batchnorm87/beta
inception3_Constant_float_cuda_Constant_449(0, inception3_Constant_449_0);
 // name=cg/incept_v3_e0/conv85/conv2d/kernel
inception3_Constant_float_cuda_Constant_437(0, inception3_Constant_437_0);
 // name=cg/incept_v3_e0_1/conv85/batchnorm85/Const
inception3_Constant_float_cuda_Constant_438(0, inception3_Constant_438_0);
 // name=cg/incept_v3_e0/conv85/batchnorm85/moving_variance
inception3_Constant_float_cuda_Constant_441(0, inception3_Constant_441_0);
 // name=cg/incept_v3_e0/conv85/batchnorm85/moving_mean
inception3_Constant_float_cuda_Constant_440(0, inception3_Constant_440_0);
 // name=cg/incept_v3_e0/conv85/batchnorm85/beta
inception3_Constant_float_cuda_Constant_439(0, inception3_Constant_439_0);
 // name=cg/affine0/biases
inception3_Constant_float_cuda_Constant_485(0, inception3_Constant_485_0);
}

// Node name:	Convolution_812
// Description:	Convolution
// Input:
//	- name: inception3_Concat_810_0	type: float	shape: Shape{64, 1280, 8, 8}
//	- name: inception3_Reshape_811_0	type: float	shape: Shape{320, 1280, 1, 1}
// Output:
//	- name: inception3_Convolution_812_0	type: float	shape: Shape{64, 320, 8, 8}
void Convolution_float_float_float_cuda_lib_Convolution_812(cudnnHandle_t cudnn_handle, float* input0, float* input1, float* output0)
{
    cudnnTensorDescriptor_t tensor_desc_0;
    CUDNN_SAFE_CALL(cudnnCreateTensorDescriptor(&tensor_desc_0));
    CUDNN_SAFE_CALL(cudnnSetTensor4dDescriptor(tensor_desc_0, CUDNN_TENSOR_NCHW, CUDNN_DATA_FLOAT, 64, 1280, 8, 8));
    cudnnTensorDescriptor_t tensor_desc_1;
    CUDNN_SAFE_CALL(cudnnCreateTensorDescriptor(&tensor_desc_1));
    CUDNN_SAFE_CALL(cudnnSetTensor4dDescriptor(tensor_desc_1, CUDNN_TENSOR_NCHW, CUDNN_DATA_FLOAT, 64, 320, 8, 8));
    cudnnFilterDescriptor_t filter_desc;
    CUDNN_SAFE_CALL(cudnnCreateFilterDescriptor(&filter_desc));
    CUDNN_SAFE_CALL(cudnnSetFilter4dDescriptor(filter_desc, CUDNN_DATA_FLOAT, CUDNN_TENSOR_NCHW, 320, 1280, 1, 1));
    cudnnConvolutionDescriptor_t conv_desc;
    CUDNN_SAFE_CALL(cudnnCreateConvolutionDescriptor(&conv_desc));
    CUDNN_SAFE_CALL(cudnnSetConvolution2dDescriptor(conv_desc, 0, 0, 1, 1, 1, 1, CUDNN_CROSS_CORRELATION, CUDNN_DATA_FLOAT));

    static bool selected_algo = true;
    static cudnnConvolutionFwdAlgo_t conv_fwd_algo = CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM;

    if (!selected_algo) {
        int num_algos;
        int max_algos = 0;
        // cudnnGetConvolutionForwardAlgorithm_v7;
        CUDNN_SAFE_CALL(
            cudnnGetConvolutionForwardAlgorithmMaxCount(cudnn_handle, &max_algos));
        std::vector<cudnnConvolutionFwdAlgoPerf_t> results(max_algos);
        CUDNN_SAFE_CALL(cudnnFindConvolutionForwardAlgorithm(cudnn_handle,
                                                tensor_desc_0,
                                                filter_desc,
                                                conv_desc,
                                                tensor_desc_1,
                                                static_cast<int>(results.size()),
                                                &num_algos,
                                                results.data()));
        results.resize(num_algos);
        for (size_t i = 0; i != results.size(); ++i) {
            cudnnConvolutionFwdAlgoPerf_t const& result = results[i];
            if (result.status == CUDNN_STATUS_SUCCESS) {
                conv_fwd_algo = result.algo;
                break;
            }
        }
        selected_algo = true;
    }
    const float alpha = 1.0;
    const float beta = 0.0;
    static void *workspace_ptr_0 = NULL;
    static size_t workspace_size_in_bytes = 0;
    if (!workspace_ptr_0)
    {
        CUDNN_SAFE_CALL(cudnnGetConvolutionForwardWorkspaceSize(cudnn_handle, tensor_desc_0, filter_desc, conv_desc, tensor_desc_1, conv_fwd_algo, &workspace_size_in_bytes));
        CUDA_SAFE_CALL(cudaMalloc(&workspace_ptr_0, workspace_size_in_bytes));
    }
    CUDNN_SAFE_CALL(cudnnConvolutionForward(cudnn_handle, &alpha, tensor_desc_0, input0,filter_desc, input1, conv_desc, conv_fwd_algo, workspace_ptr_0, workspace_size_in_bytes, &beta, tensor_desc_1, output0));
    CUDNN_SAFE_CALL(cudnnDestroyTensorDescriptor(tensor_desc_0));
    CUDNN_SAFE_CALL(cudnnDestroyTensorDescriptor(tensor_desc_1));
    CUDNN_SAFE_CALL(cudnnDestroyFilterDescriptor(filter_desc));
    CUDNN_SAFE_CALL(cudnnDestroyConvolutionDescriptor(conv_desc));

}
// Node name:	MaxPool_855
// Description:	MaxPool
// Input:
//	- name: inception3_Concat_848_0	type: float	shape: Shape{64, 2048, 8, 8}
// Output:
//	- name: inception3_MaxPool_855_0	type: float	shape: Shape{64, 2048, 8, 8}
void MaxPool_float_float_cuda_lib_MaxPool_855(cudnnHandle_t cudnn_handle, float* input0, float* output0)
{
    cudnnTensorDescriptor_t input_desc;
    CUDNN_SAFE_CALL(cudnnCreateTensorDescriptor(&input_desc));
    CUDNN_SAFE_CALL(cudnnSetTensor4dDescriptor(input_desc, CUDNN_TENSOR_NCHW, CUDNN_DATA_FLOAT, 64, 2048, 8, 8));
    cudnnTensorDescriptor_t output_desc;
    CUDNN_SAFE_CALL(cudnnCreateTensorDescriptor(&output_desc));
    CUDNN_SAFE_CALL(cudnnSetTensor4dDescriptor(output_desc, CUDNN_TENSOR_NCHW, CUDNN_DATA_FLOAT, 64, 2048, 8, 8));
    cudnnPoolingDescriptor_t desc;
    cudnnCreatePoolingDescriptor(&desc);
    CUDNN_SAFE_CALL(cudnnSetPooling2dDescriptor(desc, CUDNN_POOLING_MAX, CUDNN_NOT_PROPAGATE_NAN,3, 3, 1, 1, 1, 1));
    const float alpha = 1.0;
    const float beta = 0.0;
    CUDNN_SAFE_CALL(cudnnPoolingForward(cudnn_handle, desc, &alpha, input_desc, input0, &beta, output_desc, output0));
    CUDNN_SAFE_CALL(cudnnDestroyTensorDescriptor(input_desc));
    CUDNN_SAFE_CALL(cudnnDestroyTensorDescriptor(output_desc));
    CUDNN_SAFE_CALL(cudnnDestroyPoolingDescriptor(desc));

}
// Node name:	Convolution_852
// Description:	Convolution
// Input:
//	- name: inception3_Concat_848_0	type: float	shape: Shape{64, 2048, 8, 8}
//	- name: inception3_Reshape_851_0	type: float	shape: Shape{384, 2048, 1, 1}
// Output:
//	- name: inception3_Convolution_852_0	type: float	shape: Shape{64, 384, 8, 8}
void Convolution_float_float_float_cuda_lib_Convolution_852(cudnnHandle_t cudnn_handle, float* input0, float* input1, float* output0)
{
    cudnnTensorDescriptor_t tensor_desc_0;
    CUDNN_SAFE_CALL(cudnnCreateTensorDescriptor(&tensor_desc_0));
    CUDNN_SAFE_CALL(cudnnSetTensor4dDescriptor(tensor_desc_0, CUDNN_TENSOR_NCHW, CUDNN_DATA_FLOAT, 64, 2048, 8, 8));
    cudnnTensorDescriptor_t tensor_desc_1;
    CUDNN_SAFE_CALL(cudnnCreateTensorDescriptor(&tensor_desc_1));
    CUDNN_SAFE_CALL(cudnnSetTensor4dDescriptor(tensor_desc_1, CUDNN_TENSOR_NCHW, CUDNN_DATA_FLOAT, 64, 384, 8, 8));
    cudnnFilterDescriptor_t filter_desc;
    CUDNN_SAFE_CALL(cudnnCreateFilterDescriptor(&filter_desc));
    CUDNN_SAFE_CALL(cudnnSetFilter4dDescriptor(filter_desc, CUDNN_DATA_FLOAT, CUDNN_TENSOR_NCHW, 384, 2048, 1, 1));
    cudnnConvolutionDescriptor_t conv_desc;
    CUDNN_SAFE_CALL(cudnnCreateConvolutionDescriptor(&conv_desc));
    CUDNN_SAFE_CALL(cudnnSetConvolution2dDescriptor(conv_desc, 0, 0, 1, 1, 1, 1, CUDNN_CROSS_CORRELATION, CUDNN_DATA_FLOAT));

    static bool selected_algo = true;
    static cudnnConvolutionFwdAlgo_t conv_fwd_algo = CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM;

    if (!selected_algo) {
        int num_algos;
        int max_algos = 0;
        // cudnnGetConvolutionForwardAlgorithm_v7;
        CUDNN_SAFE_CALL(
            cudnnGetConvolutionForwardAlgorithmMaxCount(cudnn_handle, &max_algos));
        std::vector<cudnnConvolutionFwdAlgoPerf_t> results(max_algos);
        CUDNN_SAFE_CALL(cudnnFindConvolutionForwardAlgorithm(cudnn_handle,
                                                tensor_desc_0,
                                                filter_desc,
                                                conv_desc,
                                                tensor_desc_1,
                                                static_cast<int>(results.size()),
                                                &num_algos,
                                                results.data()));
        results.resize(num_algos);
        for (size_t i = 0; i != results.size(); ++i) {
            cudnnConvolutionFwdAlgoPerf_t const& result = results[i];
            if (result.status == CUDNN_STATUS_SUCCESS) {
                conv_fwd_algo = result.algo;
                break;
            }
        }
        selected_algo = true;
    }
    const float alpha = 1.0;
    const float beta = 0.0;
    static void *workspace_ptr_0 = NULL;
    static size_t workspace_size_in_bytes = 0;
    if (!workspace_ptr_0)
    {
        CUDNN_SAFE_CALL(cudnnGetConvolutionForwardWorkspaceSize(cudnn_handle, tensor_desc_0, filter_desc, conv_desc, tensor_desc_1, conv_fwd_algo, &workspace_size_in_bytes));
        CUDA_SAFE_CALL(cudaMalloc(&workspace_ptr_0, workspace_size_in_bytes));
    }
    CUDNN_SAFE_CALL(cudnnConvolutionForward(cudnn_handle, &alpha, tensor_desc_0, input0,filter_desc, input1, conv_desc, conv_fwd_algo, workspace_ptr_0, workspace_size_in_bytes, &beta, tensor_desc_1, output0));
    CUDNN_SAFE_CALL(cudnnDestroyTensorDescriptor(tensor_desc_0));
    CUDNN_SAFE_CALL(cudnnDestroyTensorDescriptor(tensor_desc_1));
    CUDNN_SAFE_CALL(cudnnDestroyFilterDescriptor(filter_desc));
    CUDNN_SAFE_CALL(cudnnDestroyConvolutionDescriptor(conv_desc));

}
// Node name:	Convolution_841
// Description:	Convolution
// Input:
//	- name: inception3_Relu_839_0	type: float	shape: Shape{64, 384, 8, 8}
//	- name: inception3_Reshape_840_0	type: float	shape: Shape{384, 384, 1, 3}
// Output:
//	- name: inception3_Convolution_841_0	type: float	shape: Shape{64, 384, 8, 8}
void Convolution_float_float_float_cuda_lib_Convolution_841(cudnnHandle_t cudnn_handle, float* input0, float* input1, float* output0)
{
    cudnnTensorDescriptor_t tensor_desc_0;
    CUDNN_SAFE_CALL(cudnnCreateTensorDescriptor(&tensor_desc_0));
    CUDNN_SAFE_CALL(cudnnSetTensor4dDescriptor(tensor_desc_0, CUDNN_TENSOR_NCHW, CUDNN_DATA_FLOAT, 64, 384, 8, 8));
    cudnnTensorDescriptor_t tensor_desc_1;
    CUDNN_SAFE_CALL(cudnnCreateTensorDescriptor(&tensor_desc_1));
    CUDNN_SAFE_CALL(cudnnSetTensor4dDescriptor(tensor_desc_1, CUDNN_TENSOR_NCHW, CUDNN_DATA_FLOAT, 64, 384, 8, 8));
    cudnnFilterDescriptor_t filter_desc;
    CUDNN_SAFE_CALL(cudnnCreateFilterDescriptor(&filter_desc));
    CUDNN_SAFE_CALL(cudnnSetFilter4dDescriptor(filter_desc, CUDNN_DATA_FLOAT, CUDNN_TENSOR_NCHW, 384, 384, 1, 3));
    cudnnConvolutionDescriptor_t conv_desc;
    CUDNN_SAFE_CALL(cudnnCreateConvolutionDescriptor(&conv_desc));
    CUDNN_SAFE_CALL(cudnnSetConvolution2dDescriptor(conv_desc, 0, 1, 1, 1, 1, 1, CUDNN_CROSS_CORRELATION, CUDNN_DATA_FLOAT));

    static bool selected_algo = true;
    static cudnnConvolutionFwdAlgo_t conv_fwd_algo = CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM;

    if (!selected_algo) {
        int num_algos;
        int max_algos = 0;
        // cudnnGetConvolutionForwardAlgorithm_v7;
        CUDNN_SAFE_CALL(
            cudnnGetConvolutionForwardAlgorithmMaxCount(cudnn_handle, &max_algos));
        std::vector<cudnnConvolutionFwdAlgoPerf_t> results(max_algos);
        CUDNN_SAFE_CALL(cudnnFindConvolutionForwardAlgorithm(cudnn_handle,
                                                tensor_desc_0,
                                                filter_desc,
                                                conv_desc,
                                                tensor_desc_1,
                                                static_cast<int>(results.size()),
                                                &num_algos,
                                                results.data()));
        results.resize(num_algos);
        for (size_t i = 0; i != results.size(); ++i) {
            cudnnConvolutionFwdAlgoPerf_t const& result = results[i];
            if (result.status == CUDNN_STATUS_SUCCESS) {
                conv_fwd_algo = result.algo;
                break;
            }
        }
        selected_algo = true;
    }
    const float alpha = 1.0;
    const float beta = 0.0;
    static void *workspace_ptr_0 = NULL;
    static size_t workspace_size_in_bytes = 0;
    if (!workspace_ptr_0)
    {
        CUDNN_SAFE_CALL(cudnnGetConvolutionForwardWorkspaceSize(cudnn_handle, tensor_desc_0, filter_desc, conv_desc, tensor_desc_1, conv_fwd_algo, &workspace_size_in_bytes));
        CUDA_SAFE_CALL(cudaMalloc(&workspace_ptr_0, workspace_size_in_bytes));
    }
    CUDNN_SAFE_CALL(cudnnConvolutionForward(cudnn_handle, &alpha, tensor_desc_0, input0,filter_desc, input1, conv_desc, conv_fwd_algo, workspace_ptr_0, workspace_size_in_bytes, &beta, tensor_desc_1, output0));
    CUDNN_SAFE_CALL(cudnnDestroyTensorDescriptor(tensor_desc_0));
    CUDNN_SAFE_CALL(cudnnDestroyTensorDescriptor(tensor_desc_1));
    CUDNN_SAFE_CALL(cudnnDestroyFilterDescriptor(filter_desc));
    CUDNN_SAFE_CALL(cudnnDestroyConvolutionDescriptor(conv_desc));

}
// Node name:	Concat_848
// Description:	Concat
// Input:
//	- name: inception3_Relu_823_0	type: float	shape: Shape{64, 320, 8, 8}
//	- name: inception3_Relu_837_0	type: float	shape: Shape{64, 384, 8, 8}
//	- name: inception3_Relu_838_0	type: float	shape: Shape{64, 384, 8, 8}
//	- name: inception3_Relu_846_0	type: float	shape: Shape{64, 384, 8, 8}
//	- name: inception3_Relu_847_0	type: float	shape: Shape{64, 384, 8, 8}
//	- name: inception3_Relu_833_0	type: float	shape: Shape{64, 192, 8, 8}
// Output:
//	- name: inception3_Concat_848_0	type: float	shape: Shape{64, 2048, 8, 8}
extern "C" __launch_bounds__(512) __global__ void inception3_Concat_float_float_float_float_float_float_float_cuda_Concat_848(float* input0, float* input1, float* input2, float* input3, float* input4, float* input5, float* output0)
{
    uint32_t inputs_strides[] = {20480, 24576, 24576, 24576, 24576, 12288};
    uint32_t tid = blockIdx.x * blockDim.x + threadIdx.x;
    if(tid < 8388608)
    {
        uint32_t block_id = tid / 131072;
        uint32_t block_idx = tid % 131072;
        uint32_t output_idx = block_id * 131072 + block_idx;
        if(block_idx < inputs_strides[0])
        {
            output0[output_idx] = input0[block_id * inputs_strides[0] + block_idx];
            return;
        }
        block_idx -= inputs_strides[0];
        if(block_idx < inputs_strides[1])
        {
            output0[output_idx] = input1[block_id * inputs_strides[1] + block_idx];
            return;
        }
        block_idx -= inputs_strides[1];
        if(block_idx < inputs_strides[2])
        {
            output0[output_idx] = input2[block_id * inputs_strides[2] + block_idx];
            return;
        }
        block_idx -= inputs_strides[2];
        if(block_idx < inputs_strides[3])
        {
            output0[output_idx] = input3[block_id * inputs_strides[3] + block_idx];
            return;
        }
        block_idx -= inputs_strides[3];
        if(block_idx < inputs_strides[4])
        {
            output0[output_idx] = input4[block_id * inputs_strides[4] + block_idx];
            return;
        }
        block_idx -= inputs_strides[4];
        if(block_idx < inputs_strides[5])
        {
            output0[output_idx] = input5[block_id * inputs_strides[5] + block_idx];
            return;
        }
        block_idx -= inputs_strides[5];
    }

}
extern void inception3_Concat_float_float_float_float_float_float_float_cuda_Concat_848_Call(const dim3 &grids, const dim3 &blocks, unsigned mem, cudaStream_t stream, float* input0, float* input1, float* input2, float* input3, float* input4, float* input5, float* output0) {
    inception3_Concat_float_float_float_float_float_float_float_cuda_Concat_848<<<grids, blocks, mem, stream>>>(input0, input1, input2, input3, input4, input5, output0);
}
// Node name:	Add_891
// Description:	Add
// Input:
//	- name: inception3_Dot_889_0	type: float	shape: Shape{64, 1001}
//	- name: inception3_Broadcast_890_0	type: float	shape: Shape{64, 1001}
// Output:
//	- name: inception3_Add_891_0	type: float	shape: Shape{64, 1001}
extern "C" __launch_bounds__(64) __global__ void inception3_Add_float_float_float_cuda_Add_891(float* input0, float* input1, float* output0)
{
    output0[blockIdx.x * 64 + threadIdx.x] = add(input0[blockIdx.x * 64 + threadIdx.x], input1[blockIdx.x * 64 + threadIdx.x]);

}
extern void inception3_Add_float_float_float_cuda_Add_891_Call(const dim3 &grids, const dim3 &blocks, unsigned mem, cudaStream_t stream, float* input0, float* input1, float* output0) {
    inception3_Add_float_float_float_cuda_Add_891<<<grids, blocks, mem, stream>>>(input0, input1, output0);
}
// Node name:	Reshape_859
// Description:	Reshape
// Input:
//	- name: inception3_Constant_477_0	type: float	shape: Shape{1, 1, 2048, 192}
// Output:
//	- name: inception3_Reshape_859_0	type: float	shape: Shape{192, 2048, 1, 1}
extern "C" __launch_bounds__(256) __global__ void inception3_Reshape_float_float_cuda_Reshape_859(float* input0, float* output0)
{
    uint32_t input_strides0 = 192;
    uint32_t input_strides1 = 1;
    uint32_t trans_strides0 = 1;
    uint32_t trans_strides1 = 2048;
    size_t nx = 192;
    size_t ny = 2048;
    __shared__ float tile[16][17];
    uint32_t base1 = blockIdx.x * blockDim.x;
    uint32_t base0 = blockIdx.y * blockDim.y;
    uint32_t tid1 = threadIdx.x;
    uint32_t tid0 = threadIdx.y;
    uint32_t idx1 = base1 + tid1;
    uint32_t idx0 = base0 + tid0;
    if (idx1 < nx && idx0 < ny)
    {
        uint32_t input_idx = 0;
        input_idx += input_strides0* idx0;
        input_idx += input_strides1* idx1;
        tile[tid0][tid1] = input0[input_idx];
    }
    idx1 = base1 + tid0;
    idx0 = base0 + tid1;
    __syncthreads();
    if (idx1 < nx && idx0 < ny)
    {
        uint32_t output_idx = 0;
        output_idx += trans_strides0* idx0;
        output_idx += trans_strides1* idx1;
        output0[output_idx] = tile[tid1][tid0];
    }

}
extern void inception3_Reshape_float_float_cuda_Reshape_859_Call(const dim3 &grids, const dim3 &blocks, unsigned mem, cudaStream_t stream, float* input0, float* output0) {
    inception3_Reshape_float_float_cuda_Reshape_859<<<grids, blocks, mem, stream>>>(input0, output0);
}
// Node name:	Convolution_860
// Description:	Convolution
// Input:
//	- name: inception3_MaxPool_855_0	type: float	shape: Shape{64, 2048, 8, 8}
//	- name: inception3_Reshape_859_0	type: float	shape: Shape{192, 2048, 1, 1}
// Output:
//	- name: inception3_Convolution_860_0	type: float	shape: Shape{64, 192, 8, 8}
void Convolution_float_float_float_cuda_lib_Convolution_860(cudnnHandle_t cudnn_handle, float* input0, float* input1, float* output0)
{
    cudnnTensorDescriptor_t tensor_desc_0;
    CUDNN_SAFE_CALL(cudnnCreateTensorDescriptor(&tensor_desc_0));
    CUDNN_SAFE_CALL(cudnnSetTensor4dDescriptor(tensor_desc_0, CUDNN_TENSOR_NCHW, CUDNN_DATA_FLOAT, 64, 2048, 8, 8));
    cudnnTensorDescriptor_t tensor_desc_1;
    CUDNN_SAFE_CALL(cudnnCreateTensorDescriptor(&tensor_desc_1));
    CUDNN_SAFE_CALL(cudnnSetTensor4dDescriptor(tensor_desc_1, CUDNN_TENSOR_NCHW, CUDNN_DATA_FLOAT, 64, 192, 8, 8));
    cudnnFilterDescriptor_t filter_desc;
    CUDNN_SAFE_CALL(cudnnCreateFilterDescriptor(&filter_desc));
    CUDNN_SAFE_CALL(cudnnSetFilter4dDescriptor(filter_desc, CUDNN_DATA_FLOAT, CUDNN_TENSOR_NCHW, 192, 2048, 1, 1));
    cudnnConvolutionDescriptor_t conv_desc;
    CUDNN_SAFE_CALL(cudnnCreateConvolutionDescriptor(&conv_desc));
    CUDNN_SAFE_CALL(cudnnSetConvolution2dDescriptor(conv_desc, 0, 0, 1, 1, 1, 1, CUDNN_CROSS_CORRELATION, CUDNN_DATA_FLOAT));

    static bool selected_algo = true;
    static cudnnConvolutionFwdAlgo_t conv_fwd_algo = CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM;

    if (!selected_algo) {
        int num_algos;
        int max_algos = 0;
        // cudnnGetConvolutionForwardAlgorithm_v7;
        CUDNN_SAFE_CALL(
            cudnnGetConvolutionForwardAlgorithmMaxCount(cudnn_handle, &max_algos));
        std::vector<cudnnConvolutionFwdAlgoPerf_t> results(max_algos);
        CUDNN_SAFE_CALL(cudnnFindConvolutionForwardAlgorithm(cudnn_handle,
                                                tensor_desc_0,
                                                filter_desc,
                                                conv_desc,
                                                tensor_desc_1,
                                                static_cast<int>(results.size()),
                                                &num_algos,
                                                results.data()));
        results.resize(num_algos);
        for (size_t i = 0; i != results.size(); ++i) {
            cudnnConvolutionFwdAlgoPerf_t const& result = results[i];
            if (result.status == CUDNN_STATUS_SUCCESS) {
                conv_fwd_algo = result.algo;
                break;
            }
        }
        selected_algo = true;
    }
    const float alpha = 1.0;
    const float beta = 0.0;
    static void *workspace_ptr_0 = NULL;
    static size_t workspace_size_in_bytes = 0;
    if (!workspace_ptr_0)
    {
        CUDNN_SAFE_CALL(cudnnGetConvolutionForwardWorkspaceSize(cudnn_handle, tensor_desc_0, filter_desc, conv_desc, tensor_desc_1, conv_fwd_algo, &workspace_size_in_bytes));
        CUDA_SAFE_CALL(cudaMalloc(&workspace_ptr_0, workspace_size_in_bytes));
    }
    CUDNN_SAFE_CALL(cudnnConvolutionForward(cudnn_handle, &alpha, tensor_desc_0, input0,filter_desc, input1, conv_desc, conv_fwd_algo, workspace_ptr_0, workspace_size_in_bytes, &beta, tensor_desc_1, output0));
    CUDNN_SAFE_CALL(cudnnDestroyTensorDescriptor(tensor_desc_0));
    CUDNN_SAFE_CALL(cudnnDestroyTensorDescriptor(tensor_desc_1));
    CUDNN_SAFE_CALL(cudnnDestroyFilterDescriptor(filter_desc));
    CUDNN_SAFE_CALL(cudnnDestroyConvolutionDescriptor(conv_desc));

}
// Node name:	Convolution_488
// Description:	Convolution
// Input:
//	- name: inception3_Reshape_486_0	type: float	shape: Shape{64, 3, 299, 299}
//	- name: inception3_Reshape_487_0	type: float	shape: Shape{32, 3, 3, 3}
// Output:
//	- name: inception3_Convolution_488_0	type: float	shape: Shape{64, 32, 149, 149}
void Convolution_float_float_float_cuda_lib_Convolution_488(cudnnHandle_t cudnn_handle, float* input0, float* input1, float* output0)
{
    cudnnTensorDescriptor_t tensor_desc_0;
    CUDNN_SAFE_CALL(cudnnCreateTensorDescriptor(&tensor_desc_0));
    CUDNN_SAFE_CALL(cudnnSetTensor4dDescriptor(tensor_desc_0, CUDNN_TENSOR_NCHW, CUDNN_DATA_FLOAT, 64, 3, 299, 299));
    cudnnTensorDescriptor_t tensor_desc_1;
    CUDNN_SAFE_CALL(cudnnCreateTensorDescriptor(&tensor_desc_1));
    CUDNN_SAFE_CALL(cudnnSetTensor4dDescriptor(tensor_desc_1, CUDNN_TENSOR_NCHW, CUDNN_DATA_FLOAT, 64, 32, 149, 149));
    cudnnFilterDescriptor_t filter_desc;
    CUDNN_SAFE_CALL(cudnnCreateFilterDescriptor(&filter_desc));
    CUDNN_SAFE_CALL(cudnnSetFilter4dDescriptor(filter_desc, CUDNN_DATA_FLOAT, CUDNN_TENSOR_NCHW, 32, 3, 3, 3));
    cudnnConvolutionDescriptor_t conv_desc;
    CUDNN_SAFE_CALL(cudnnCreateConvolutionDescriptor(&conv_desc));
    CUDNN_SAFE_CALL(cudnnSetConvolution2dDescriptor(conv_desc, 0, 0, 2, 2, 1, 1, CUDNN_CROSS_CORRELATION, CUDNN_DATA_FLOAT));

    static bool selected_algo = true;
    static cudnnConvolutionFwdAlgo_t conv_fwd_algo = CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM;

    if (!selected_algo) {
        int num_algos;
        int max_algos = 0;
        // cudnnGetConvolutionForwardAlgorithm_v7;
        CUDNN_SAFE_CALL(
            cudnnGetConvolutionForwardAlgorithmMaxCount(cudnn_handle, &max_algos));
        std::vector<cudnnConvolutionFwdAlgoPerf_t> results(max_algos);
        CUDNN_SAFE_CALL(cudnnFindConvolutionForwardAlgorithm(cudnn_handle,
                                                tensor_desc_0,
                                                filter_desc,
                                                conv_desc,
                                                tensor_desc_1,
                                                static_cast<int>(results.size()),
                                                &num_algos,
                                                results.data()));
        results.resize(num_algos);
        for (size_t i = 0; i != results.size(); ++i) {
            cudnnConvolutionFwdAlgoPerf_t const& result = results[i];
            if (result.status == CUDNN_STATUS_SUCCESS) {
                conv_fwd_algo = result.algo;
                break;
            }
        }
        selected_algo = true;
    }
    const float alpha = 1.0;
    const float beta = 0.0;
    static void *workspace_ptr_0 = NULL;
    static size_t workspace_size_in_bytes = 0;
    if (!workspace_ptr_0)
    {
        CUDNN_SAFE_CALL(cudnnGetConvolutionForwardWorkspaceSize(cudnn_handle, tensor_desc_0, filter_desc, conv_desc, tensor_desc_1, conv_fwd_algo, &workspace_size_in_bytes));
        CUDA_SAFE_CALL(cudaMalloc(&workspace_ptr_0, workspace_size_in_bytes));
    }
    CUDNN_SAFE_CALL(cudnnConvolutionForward(cudnn_handle, &alpha, tensor_desc_0, input0,filter_desc, input1, conv_desc, conv_fwd_algo, workspace_ptr_0, workspace_size_in_bytes, &beta, tensor_desc_1, output0));
    CUDNN_SAFE_CALL(cudnnDestroyTensorDescriptor(tensor_desc_0));
    CUDNN_SAFE_CALL(cudnnDestroyTensorDescriptor(tensor_desc_1));
    CUDNN_SAFE_CALL(cudnnDestroyFilterDescriptor(filter_desc));
    CUDNN_SAFE_CALL(cudnnDestroyConvolutionDescriptor(conv_desc));

}
// Node name:	Convolution_843
// Description:	Convolution
// Input:
//	- name: inception3_Relu_839_0	type: float	shape: Shape{64, 384, 8, 8}
//	- name: inception3_Reshape_842_0	type: float	shape: Shape{384, 384, 3, 1}
// Output:
//	- name: inception3_Convolution_843_0	type: float	shape: Shape{64, 384, 8, 8}
void Convolution_float_float_float_cuda_lib_Convolution_843(cudnnHandle_t cudnn_handle, float* input0, float* input1, float* output0)
{
    cudnnTensorDescriptor_t tensor_desc_0;
    CUDNN_SAFE_CALL(cudnnCreateTensorDescriptor(&tensor_desc_0));
    CUDNN_SAFE_CALL(cudnnSetTensor4dDescriptor(tensor_desc_0, CUDNN_TENSOR_NCHW, CUDNN_DATA_FLOAT, 64, 384, 8, 8));
    cudnnTensorDescriptor_t tensor_desc_1;
    CUDNN_SAFE_CALL(cudnnCreateTensorDescriptor(&tensor_desc_1));
    CUDNN_SAFE_CALL(cudnnSetTensor4dDescriptor(tensor_desc_1, CUDNN_TENSOR_NCHW, CUDNN_DATA_FLOAT, 64, 384, 8, 8));
    cudnnFilterDescriptor_t filter_desc;
    CUDNN_SAFE_CALL(cudnnCreateFilterDescriptor(&filter_desc));
    CUDNN_SAFE_CALL(cudnnSetFilter4dDescriptor(filter_desc, CUDNN_DATA_FLOAT, CUDNN_TENSOR_NCHW, 384, 384, 3, 1));
    cudnnConvolutionDescriptor_t conv_desc;
    CUDNN_SAFE_CALL(cudnnCreateConvolutionDescriptor(&conv_desc));
    CUDNN_SAFE_CALL(cudnnSetConvolution2dDescriptor(conv_desc, 1, 0, 1, 1, 1, 1, CUDNN_CROSS_CORRELATION, CUDNN_DATA_FLOAT));

    static bool selected_algo = true;
    static cudnnConvolutionFwdAlgo_t conv_fwd_algo = CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM;

    if (!selected_algo) {
        int num_algos;
        int max_algos = 0;
        // cudnnGetConvolutionForwardAlgorithm_v7;
        CUDNN_SAFE_CALL(
            cudnnGetConvolutionForwardAlgorithmMaxCount(cudnn_handle, &max_algos));
        std::vector<cudnnConvolutionFwdAlgoPerf_t> results(max_algos);
        CUDNN_SAFE_CALL(cudnnFindConvolutionForwardAlgorithm(cudnn_handle,
                                                tensor_desc_0,
                                                filter_desc,
                                                conv_desc,
                                                tensor_desc_1,
                                                static_cast<int>(results.size()),
                                                &num_algos,
                                                results.data()));
        results.resize(num_algos);
        for (size_t i = 0; i != results.size(); ++i) {
            cudnnConvolutionFwdAlgoPerf_t const& result = results[i];
            if (result.status == CUDNN_STATUS_SUCCESS) {
                conv_fwd_algo = result.algo;
                break;
            }
        }
        selected_algo = true;
    }
    const float alpha = 1.0;
    const float beta = 0.0;
    static void *workspace_ptr_0 = NULL;
    static size_t workspace_size_in_bytes = 0;
    if (!workspace_ptr_0)
    {
        CUDNN_SAFE_CALL(cudnnGetConvolutionForwardWorkspaceSize(cudnn_handle, tensor_desc_0, filter_desc, conv_desc, tensor_desc_1, conv_fwd_algo, &workspace_size_in_bytes));
        CUDA_SAFE_CALL(cudaMalloc(&workspace_ptr_0, workspace_size_in_bytes));
    }
    CUDNN_SAFE_CALL(cudnnConvolutionForward(cudnn_handle, &alpha, tensor_desc_0, input0,filter_desc, input1, conv_desc, conv_fwd_algo, workspace_ptr_0, workspace_size_in_bytes, &beta, tensor_desc_1, output0));
    CUDNN_SAFE_CALL(cudnnDestroyTensorDescriptor(tensor_desc_0));
    CUDNN_SAFE_CALL(cudnnDestroyTensorDescriptor(tensor_desc_1));
    CUDNN_SAFE_CALL(cudnnDestroyFilterDescriptor(filter_desc));
    CUDNN_SAFE_CALL(cudnnDestroyConvolutionDescriptor(conv_desc));

}
// Node name:	Reshape_851
// Description:	Reshape
// Input:
//	- name: inception3_Constant_442_0	type: float	shape: Shape{1, 1, 2048, 384}
// Output:
//	- name: inception3_Reshape_851_0	type: float	shape: Shape{384, 2048, 1, 1}
extern "C" __launch_bounds__(256) __global__ void inception3_Reshape_float_float_cuda_Reshape_851(float* input0, float* output0)
{
    uint32_t input_strides0 = 384;
    uint32_t input_strides1 = 1;
    uint32_t trans_strides0 = 1;
    uint32_t trans_strides1 = 2048;
    size_t nx = 384;
    size_t ny = 2048;
    __shared__ float tile[16][17];
    uint32_t base1 = blockIdx.x * blockDim.x;
    uint32_t base0 = blockIdx.y * blockDim.y;
    uint32_t tid1 = threadIdx.x;
    uint32_t tid0 = threadIdx.y;
    uint32_t idx1 = base1 + tid1;
    uint32_t idx0 = base0 + tid0;
    if (idx1 < nx && idx0 < ny)
    {
        uint32_t input_idx = 0;
        input_idx += input_strides0* idx0;
        input_idx += input_strides1* idx1;
        tile[tid0][tid1] = input0[input_idx];
    }
    idx1 = base1 + tid0;
    idx0 = base0 + tid1;
    __syncthreads();
    if (idx1 < nx && idx0 < ny)
    {
        uint32_t output_idx = 0;
        output_idx += trans_strides0* idx0;
        output_idx += trans_strides1* idx1;
        output0[output_idx] = tile[tid1][tid0];
    }

}
extern void inception3_Reshape_float_float_cuda_Reshape_851_Call(const dim3 &grids, const dim3 &blocks, unsigned mem, cudaStream_t stream, float* input0, float* output0) {
    inception3_Reshape_float_float_cuda_Reshape_851<<<grids, blocks, mem, stream>>>(input0, output0);
}
// Node name:	Dot_889
// Description:	Dot
// Input:
//	- name: inception3_Reshape_888_0	type: float	shape: Shape{64, 2048}
//	- name: inception3_Constant_484_0	type: float	shape: Shape{2048, 1001}
// Output:
//	- name: inception3_Dot_889_0	type: float	shape: Shape{64, 1001}
void Dot_float_float_float_cuda_lib_Dot_889(cublasHandle_t cublas_handle, float* input0, float* input1, float* output0)
{
    const float alpha = 1.0;
    const float beta = 0;
    CUBLAS_SAFE_CALL(cublasSgemm(cublas_handle, CUBLAS_OP_N, CUBLAS_OP_N, 1001, 64, 2048, &alpha, static_cast<const float*>(input1), 1001, static_cast<const float*>(input0), 2048, &beta, static_cast<float*>(output0), 1001));

}
// Node name:	Convolution_795
// Description:	Convolution
// Input:
//	- name: inception3_Relu_792_0	type: float	shape: Shape{64, 192, 17, 17}
//	- name: inception3_Reshape_794_0	type: float	shape: Shape{320, 192, 3, 3}
// Output:
//	- name: inception3_Convolution_795_0	type: float	shape: Shape{64, 320, 8, 8}
void Convolution_float_float_float_cuda_lib_Convolution_795(cudnnHandle_t cudnn_handle, float* input0, float* input1, float* output0)
{
    cudnnTensorDescriptor_t tensor_desc_0;
    CUDNN_SAFE_CALL(cudnnCreateTensorDescriptor(&tensor_desc_0));
    CUDNN_SAFE_CALL(cudnnSetTensor4dDescriptor(tensor_desc_0, CUDNN_TENSOR_NCHW, CUDNN_DATA_FLOAT, 64, 192, 17, 17));
    cudnnTensorDescriptor_t tensor_desc_1;
    CUDNN_SAFE_CALL(cudnnCreateTensorDescriptor(&tensor_desc_1));
    CUDNN_SAFE_CALL(cudnnSetTensor4dDescriptor(tensor_desc_1, CUDNN_TENSOR_NCHW, CUDNN_DATA_FLOAT, 64, 320, 8, 8));
    cudnnFilterDescriptor_t filter_desc;
    CUDNN_SAFE_CALL(cudnnCreateFilterDescriptor(&filter_desc));
    CUDNN_SAFE_CALL(cudnnSetFilter4dDescriptor(filter_desc, CUDNN_DATA_FLOAT, CUDNN_TENSOR_NCHW, 320, 192, 3, 3));
    cudnnConvolutionDescriptor_t conv_desc;
    CUDNN_SAFE_CALL(cudnnCreateConvolutionDescriptor(&conv_desc));
    CUDNN_SAFE_CALL(cudnnSetConvolution2dDescriptor(conv_desc, 0, 0, 2, 2, 1, 1, CUDNN_CROSS_CORRELATION, CUDNN_DATA_FLOAT));

    static bool selected_algo = true;
    static cudnnConvolutionFwdAlgo_t conv_fwd_algo = CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM;

    if (!selected_algo) {
        int num_algos;
        int max_algos = 0;
        // cudnnGetConvolutionForwardAlgorithm_v7;
        CUDNN_SAFE_CALL(
            cudnnGetConvolutionForwardAlgorithmMaxCount(cudnn_handle, &max_algos));
        std::vector<cudnnConvolutionFwdAlgoPerf_t> results(max_algos);
        CUDNN_SAFE_CALL(cudnnFindConvolutionForwardAlgorithm(cudnn_handle,
                                                tensor_desc_0,
                                                filter_desc,
                                                conv_desc,
                                                tensor_desc_1,
                                                static_cast<int>(results.size()),
                                                &num_algos,
                                                results.data()));
        results.resize(num_algos);
        for (size_t i = 0; i != results.size(); ++i) {
            cudnnConvolutionFwdAlgoPerf_t const& result = results[i];
            if (result.status == CUDNN_STATUS_SUCCESS) {
                conv_fwd_algo = result.algo;
                break;
            }
        }
        selected_algo = true;
    }
    const float alpha = 1.0;
    const float beta = 0.0;
    static void *workspace_ptr_0 = NULL;
    static size_t workspace_size_in_bytes = 0;
    if (!workspace_ptr_0)
    {
        CUDNN_SAFE_CALL(cudnnGetConvolutionForwardWorkspaceSize(cudnn_handle, tensor_desc_0, filter_desc, conv_desc, tensor_desc_1, conv_fwd_algo, &workspace_size_in_bytes));
        CUDA_SAFE_CALL(cudaMalloc(&workspace_ptr_0, workspace_size_in_bytes));
    }
    CUDNN_SAFE_CALL(cudnnConvolutionForward(cudnn_handle, &alpha, tensor_desc_0, input0,filter_desc, input1, conv_desc, conv_fwd_algo, workspace_ptr_0, workspace_size_in_bytes, &beta, tensor_desc_1, output0));
    CUDNN_SAFE_CALL(cudnnDestroyTensorDescriptor(tensor_desc_0));
    CUDNN_SAFE_CALL(cudnnDestroyTensorDescriptor(tensor_desc_1));
    CUDNN_SAFE_CALL(cudnnDestroyFilterDescriptor(filter_desc));
    CUDNN_SAFE_CALL(cudnnDestroyConvolutionDescriptor(conv_desc));

}
// Node name:	BatchNormInference_517
// Description:	BatchNormInference
// Input:
//	- name: inception3_Constant_33_0	type: float	shape: Shape{48}
//	- name: inception3_Constant_34_0	type: float	shape: Shape{48}
//	- name: inception3_Convolution_512_0	type: float	shape: Shape{64, 48, 35, 35}
//	- name: inception3_Constant_35_0	type: float	shape: Shape{48}
//	- name: inception3_Constant_36_0	type: float	shape: Shape{48}
// Output:
//	- name: inception3_BatchNormInference_517_0	type: float	shape: Shape{64, 48, 35, 35}
extern "C" __launch_bounds__(512) __global__ void inception3_BatchNormInference_float_float_float_float_float_float_cuda_BatchNormInference_517(float* input0, float* input1, float* input2, float* input3, float* input4, float* output0)
{
    const int st = blockIdx.x * 35 * 35;
    const int c_id = blockIdx.x % 48;
    #pragma unroll 1
    for (int i = threadIdx.x; i < 35 * 35; i += blockDim.x)
    {
        output0[st + i] = (input1[c_id] + (input0[c_id] * (input2[st + i] - input3[c_id]) / sqrtf(0.001 + input4[c_id])));
    }

}
extern void inception3_BatchNormInference_float_float_float_float_float_float_cuda_BatchNormInference_517_Call(const dim3 &grids, const dim3 &blocks, unsigned mem, cudaStream_t stream, float* input0, float* input1, float* input2, float* input3, float* input4, float* output0) {
    inception3_BatchNormInference_float_float_float_float_float_float_cuda_BatchNormInference_517<<<grids, blocks, mem, stream>>>(input0, input1, input2, input3, input4, output0);
}
// Node name:	BatchNormInference_820
// Description:	BatchNormInference
// Input:
//	- name: inception3_Constant_412_0	type: float	shape: Shape{448}
//	- name: inception3_Constant_413_0	type: float	shape: Shape{448}
//	- name: inception3_Convolution_816_0	type: float	shape: Shape{64, 448, 8, 8}
//	- name: inception3_Constant_414_0	type: float	shape: Shape{448}
//	- name: inception3_Constant_415_0	type: float	shape: Shape{448}
// Output:
//	- name: inception3_BatchNormInference_820_0	type: float	shape: Shape{64, 448, 8, 8}
extern "C" __launch_bounds__(64) __global__ void inception3_BatchNormInference_float_float_float_float_float_float_cuda_BatchNormInference_820(float* input0, float* input1, float* input2, float* input3, float* input4, float* output0)
{
    const int st = blockIdx.x * 8 * 8;
    const int c_id = blockIdx.x % 448;
    #pragma unroll 1
    for (int i = threadIdx.x; i < 8 * 8; i += blockDim.x)
    {
        output0[st + i] = (input1[c_id] + (input0[c_id] * (input2[st + i] - input3[c_id]) / sqrtf(0.001 + input4[c_id])));
    }

}
extern void inception3_BatchNormInference_float_float_float_float_float_float_cuda_BatchNormInference_820_Call(const dim3 &grids, const dim3 &blocks, unsigned mem, cudaStream_t stream, float* input0, float* input1, float* input2, float* input3, float* input4, float* output0) {
    inception3_BatchNormInference_float_float_float_float_float_float_cuda_BatchNormInference_820<<<grids, blocks, mem, stream>>>(input0, input1, input2, input3, input4, output0);
}
// Node name:	Convolution_822
// Description:	Convolution
// Input:
//	- name: inception3_AvgPool_817_0	type: float	shape: Shape{64, 1280, 8, 8}
//	- name: inception3_Reshape_821_0	type: float	shape: Shape{192, 1280, 1, 1}
// Output:
//	- name: inception3_Convolution_822_0	type: float	shape: Shape{64, 192, 8, 8}
void Convolution_float_float_float_cuda_lib_Convolution_822(cudnnHandle_t cudnn_handle, float* input0, float* input1, float* output0)
{
    cudnnTensorDescriptor_t tensor_desc_0;
    CUDNN_SAFE_CALL(cudnnCreateTensorDescriptor(&tensor_desc_0));
    CUDNN_SAFE_CALL(cudnnSetTensor4dDescriptor(tensor_desc_0, CUDNN_TENSOR_NCHW, CUDNN_DATA_FLOAT, 64, 1280, 8, 8));
    cudnnTensorDescriptor_t tensor_desc_1;
    CUDNN_SAFE_CALL(cudnnCreateTensorDescriptor(&tensor_desc_1));
    CUDNN_SAFE_CALL(cudnnSetTensor4dDescriptor(tensor_desc_1, CUDNN_TENSOR_NCHW, CUDNN_DATA_FLOAT, 64, 192, 8, 8));
    cudnnFilterDescriptor_t filter_desc;
    CUDNN_SAFE_CALL(cudnnCreateFilterDescriptor(&filter_desc));
    CUDNN_SAFE_CALL(cudnnSetFilter4dDescriptor(filter_desc, CUDNN_DATA_FLOAT, CUDNN_TENSOR_NCHW, 192, 1280, 1, 1));
    cudnnConvolutionDescriptor_t conv_desc;
    CUDNN_SAFE_CALL(cudnnCreateConvolutionDescriptor(&conv_desc));
    CUDNN_SAFE_CALL(cudnnSetConvolution2dDescriptor(conv_desc, 0, 0, 1, 1, 1, 1, CUDNN_CROSS_CORRELATION, CUDNN_DATA_FLOAT));

    static bool selected_algo = true;
    static cudnnConvolutionFwdAlgo_t conv_fwd_algo = CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM;

    if (!selected_algo) {
        int num_algos;
        int max_algos = 0;
        // cudnnGetConvolutionForwardAlgorithm_v7;
        CUDNN_SAFE_CALL(
            cudnnGetConvolutionForwardAlgorithmMaxCount(cudnn_handle, &max_algos));
        std::vector<cudnnConvolutionFwdAlgoPerf_t> results(max_algos);
        CUDNN_SAFE_CALL(cudnnFindConvolutionForwardAlgorithm(cudnn_handle,
                                                tensor_desc_0,
                                                filter_desc,
                                                conv_desc,
                                                tensor_desc_1,
                                                static_cast<int>(results.size()),
                                                &num_algos,
                                                results.data()));
        results.resize(num_algos);
        for (size_t i = 0; i != results.size(); ++i) {
            cudnnConvolutionFwdAlgoPerf_t const& result = results[i];
            if (result.status == CUDNN_STATUS_SUCCESS) {
                conv_fwd_algo = result.algo;
                break;
            }
        }
        selected_algo = true;
    }
    const float alpha = 1.0;
    const float beta = 0.0;
    static void *workspace_ptr_0 = NULL;
    static size_t workspace_size_in_bytes = 0;
    if (!workspace_ptr_0)
    {
        CUDNN_SAFE_CALL(cudnnGetConvolutionForwardWorkspaceSize(cudnn_handle, tensor_desc_0, filter_desc, conv_desc, tensor_desc_1, conv_fwd_algo, &workspace_size_in_bytes));
        CUDA_SAFE_CALL(cudaMalloc(&workspace_ptr_0, workspace_size_in_bytes));
    }
    CUDNN_SAFE_CALL(cudnnConvolutionForward(cudnn_handle, &alpha, tensor_desc_0, input0,filter_desc, input1, conv_desc, conv_fwd_algo, workspace_ptr_0, workspace_size_in_bytes, &beta, tensor_desc_1, output0));
    CUDNN_SAFE_CALL(cudnnDestroyTensorDescriptor(tensor_desc_0));
    CUDNN_SAFE_CALL(cudnnDestroyTensorDescriptor(tensor_desc_1));
    CUDNN_SAFE_CALL(cudnnDestroyFilterDescriptor(filter_desc));
    CUDNN_SAFE_CALL(cudnnDestroyConvolutionDescriptor(conv_desc));

}
// Node name:	Result_892
// Description:	Result
// Input:
//	- name: inception3_Add_891_0	type: float	shape: Shape{64, 1001}
// Output:
//	- name: Result_892_0	type: float	shape: Shape{64, 1001}
void Result_float_float_cuda_lib_Result_892(float* input0, float** output0)
{
    *output0 = input0;
}
// Node name:	Reshape_849
// Description:	Reshape
// Input:
//	- name: inception3_Constant_437_0	type: float	shape: Shape{1, 1, 2048, 320}
// Output:
//	- name: inception3_Reshape_849_0	type: float	shape: Shape{320, 2048, 1, 1}
extern "C" __launch_bounds__(256) __global__ void inception3_Reshape_float_float_cuda_Reshape_849(float* input0, float* output0)
{
    uint32_t input_strides0 = 320;
    uint32_t input_strides1 = 1;
    uint32_t trans_strides0 = 1;
    uint32_t trans_strides1 = 2048;
    size_t nx = 320;
    size_t ny = 2048;
    __shared__ float tile[16][17];
    uint32_t base1 = blockIdx.x * blockDim.x;
    uint32_t base0 = blockIdx.y * blockDim.y;
    uint32_t tid1 = threadIdx.x;
    uint32_t tid0 = threadIdx.y;
    uint32_t idx1 = base1 + tid1;
    uint32_t idx0 = base0 + tid0;
    if (idx1 < nx && idx0 < ny)
    {
        uint32_t input_idx = 0;
        input_idx += input_strides0* idx0;
        input_idx += input_strides1* idx1;
        tile[tid0][tid1] = input0[input_idx];
    }
    idx1 = base1 + tid0;
    idx0 = base0 + tid1;
    __syncthreads();
    if (idx1 < nx && idx0 < ny)
    {
        uint32_t output_idx = 0;
        output_idx += trans_strides0* idx0;
        output_idx += trans_strides1* idx1;
        output0[output_idx] = tile[tid1][tid0];
    }

}
extern void inception3_Reshape_float_float_cuda_Reshape_849_Call(const dim3 &grids, const dim3 &blocks, unsigned mem, cudaStream_t stream, float* input0, float* output0) {
    inception3_Reshape_float_float_cuda_Reshape_849<<<grids, blocks, mem, stream>>>(input0, output0);
}
// Node name:	Convolution_816
// Description:	Convolution
// Input:
//	- name: inception3_Concat_810_0	type: float	shape: Shape{64, 1280, 8, 8}
//	- name: inception3_Reshape_815_0	type: float	shape: Shape{448, 1280, 1, 1}
// Output:
//	- name: inception3_Convolution_816_0	type: float	shape: Shape{64, 448, 8, 8}
void Convolution_float_float_float_cuda_lib_Convolution_816(cudnnHandle_t cudnn_handle, float* input0, float* input1, float* output0)
{
    cudnnTensorDescriptor_t tensor_desc_0;
    CUDNN_SAFE_CALL(cudnnCreateTensorDescriptor(&tensor_desc_0));
    CUDNN_SAFE_CALL(cudnnSetTensor4dDescriptor(tensor_desc_0, CUDNN_TENSOR_NCHW, CUDNN_DATA_FLOAT, 64, 1280, 8, 8));
    cudnnTensorDescriptor_t tensor_desc_1;
    CUDNN_SAFE_CALL(cudnnCreateTensorDescriptor(&tensor_desc_1));
    CUDNN_SAFE_CALL(cudnnSetTensor4dDescriptor(tensor_desc_1, CUDNN_TENSOR_NCHW, CUDNN_DATA_FLOAT, 64, 448, 8, 8));
    cudnnFilterDescriptor_t filter_desc;
    CUDNN_SAFE_CALL(cudnnCreateFilterDescriptor(&filter_desc));
    CUDNN_SAFE_CALL(cudnnSetFilter4dDescriptor(filter_desc, CUDNN_DATA_FLOAT, CUDNN_TENSOR_NCHW, 448, 1280, 1, 1));
    cudnnConvolutionDescriptor_t conv_desc;
    CUDNN_SAFE_CALL(cudnnCreateConvolutionDescriptor(&conv_desc));
    CUDNN_SAFE_CALL(cudnnSetConvolution2dDescriptor(conv_desc, 0, 0, 1, 1, 1, 1, CUDNN_CROSS_CORRELATION, CUDNN_DATA_FLOAT));

    static bool selected_algo = true;
    static cudnnConvolutionFwdAlgo_t conv_fwd_algo = CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM;

    if (!selected_algo) {
        int num_algos;
        int max_algos = 0;
        // cudnnGetConvolutionForwardAlgorithm_v7;
        CUDNN_SAFE_CALL(
            cudnnGetConvolutionForwardAlgorithmMaxCount(cudnn_handle, &max_algos));
        std::vector<cudnnConvolutionFwdAlgoPerf_t> results(max_algos);
        CUDNN_SAFE_CALL(cudnnFindConvolutionForwardAlgorithm(cudnn_handle,
                                                tensor_desc_0,
                                                filter_desc,
                                                conv_desc,
                                                tensor_desc_1,
                                                static_cast<int>(results.size()),
                                                &num_algos,
                                                results.data()));
        results.resize(num_algos);
        for (size_t i = 0; i != results.size(); ++i) {
            cudnnConvolutionFwdAlgoPerf_t const& result = results[i];
            if (result.status == CUDNN_STATUS_SUCCESS) {
                conv_fwd_algo = result.algo;
                break;
            }
        }
        selected_algo = true;
    }
    const float alpha = 1.0;
    const float beta = 0.0;
    static void *workspace_ptr_0 = NULL;
    static size_t workspace_size_in_bytes = 0;
    if (!workspace_ptr_0)
    {
        CUDNN_SAFE_CALL(cudnnGetConvolutionForwardWorkspaceSize(cudnn_handle, tensor_desc_0, filter_desc, conv_desc, tensor_desc_1, conv_fwd_algo, &workspace_size_in_bytes));
        CUDA_SAFE_CALL(cudaMalloc(&workspace_ptr_0, workspace_size_in_bytes));
    }
    CUDNN_SAFE_CALL(cudnnConvolutionForward(cudnn_handle, &alpha, tensor_desc_0, input0,filter_desc, input1, conv_desc, conv_fwd_algo, workspace_ptr_0, workspace_size_in_bytes, &beta, tensor_desc_1, output0));
    CUDNN_SAFE_CALL(cudnnDestroyTensorDescriptor(tensor_desc_0));
    CUDNN_SAFE_CALL(cudnnDestroyTensorDescriptor(tensor_desc_1));
    CUDNN_SAFE_CALL(cudnnDestroyFilterDescriptor(filter_desc));
    CUDNN_SAFE_CALL(cudnnDestroyConvolutionDescriptor(conv_desc));

}
// Node name:	Reshape_815
// Description:	Reshape
// Input:
//	- name: inception3_Constant_411_0	type: float	shape: Shape{1, 1, 1280, 448}
// Output:
//	- name: inception3_Reshape_815_0	type: float	shape: Shape{448, 1280, 1, 1}
extern "C" __launch_bounds__(256) __global__ void inception3_Reshape_float_float_cuda_Reshape_815(float* input0, float* output0)
{
    uint32_t input_strides0 = 448;
    uint32_t input_strides1 = 1;
    uint32_t trans_strides0 = 1;
    uint32_t trans_strides1 = 1280;
    size_t nx = 448;
    size_t ny = 1280;
    __shared__ float tile[16][17];
    uint32_t base1 = blockIdx.x * blockDim.x;
    uint32_t base0 = blockIdx.y * blockDim.y;
    uint32_t tid1 = threadIdx.x;
    uint32_t tid0 = threadIdx.y;
    uint32_t idx1 = base1 + tid1;
    uint32_t idx0 = base0 + tid0;
    if (idx1 < nx && idx0 < ny)
    {
        uint32_t input_idx = 0;
        input_idx += input_strides0* idx0;
        input_idx += input_strides1* idx1;
        tile[tid0][tid1] = input0[input_idx];
    }
    idx1 = base1 + tid0;
    idx0 = base0 + tid1;
    __syncthreads();
    if (idx1 < nx && idx0 < ny)
    {
        uint32_t output_idx = 0;
        output_idx += trans_strides0* idx0;
        output_idx += trans_strides1* idx1;
        output0[output_idx] = tile[tid1][tid0];
    }

}
extern void inception3_Reshape_float_float_cuda_Reshape_815_Call(const dim3 &grids, const dim3 &blocks, unsigned mem, cudaStream_t stream, float* input0, float* output0) {
    inception3_Reshape_float_float_cuda_Reshape_815<<<grids, blocks, mem, stream>>>(input0, output0);
}
// Node name:	MaxPool_789
// Description:	MaxPool
// Input:
//	- name: inception3_Concat_784_0	type: float	shape: Shape{64, 768, 17, 17}
// Output:
//	- name: inception3_MaxPool_789_0	type: float	shape: Shape{64, 768, 8, 8}
void MaxPool_float_float_cuda_lib_MaxPool_789(cudnnHandle_t cudnn_handle, float* input0, float* output0)
{
    cudnnTensorDescriptor_t input_desc;
    CUDNN_SAFE_CALL(cudnnCreateTensorDescriptor(&input_desc));
    CUDNN_SAFE_CALL(cudnnSetTensor4dDescriptor(input_desc, CUDNN_TENSOR_NCHW, CUDNN_DATA_FLOAT, 64, 768, 17, 17));
    cudnnTensorDescriptor_t output_desc;
    CUDNN_SAFE_CALL(cudnnCreateTensorDescriptor(&output_desc));
    CUDNN_SAFE_CALL(cudnnSetTensor4dDescriptor(output_desc, CUDNN_TENSOR_NCHW, CUDNN_DATA_FLOAT, 64, 768, 8, 8));
    cudnnPoolingDescriptor_t desc;
    cudnnCreatePoolingDescriptor(&desc);
    CUDNN_SAFE_CALL(cudnnSetPooling2dDescriptor(desc, CUDNN_POOLING_MAX, CUDNN_NOT_PROPAGATE_NAN,3, 3, 0, 0, 2, 2));
    const float alpha = 1.0;
    const float beta = 0.0;
    CUDNN_SAFE_CALL(cudnnPoolingForward(cudnn_handle, desc, &alpha, input_desc, input0, &beta, output_desc, output0));
    CUDNN_SAFE_CALL(cudnnDestroyTensorDescriptor(input_desc));
    CUDNN_SAFE_CALL(cudnnDestroyTensorDescriptor(output_desc));
    CUDNN_SAFE_CALL(cudnnDestroyPoolingDescriptor(desc));

}
// Node name:	BatchNormInference_502
// Description:	BatchNormInference
// Input:
//	- name: inception3_Constant_18_0	type: float	shape: Shape{80}
//	- name: inception3_Constant_19_0	type: float	shape: Shape{80}
//	- name: inception3_Convolution_501_0	type: float	shape: Shape{64, 80, 73, 73}
//	- name: inception3_Constant_20_0	type: float	shape: Shape{80}
//	- name: inception3_Constant_21_0	type: float	shape: Shape{80}
// Output:
//	- name: inception3_BatchNormInference_502_0	type: float	shape: Shape{64, 80, 73, 73}
extern "C" __launch_bounds__(512) __global__ void inception3_BatchNormInference_float_float_float_float_float_float_cuda_BatchNormInference_502(float* input0, float* input1, float* input2, float* input3, float* input4, float* output0)
{
    const int st = blockIdx.x * 73 * 73;
    const int c_id = blockIdx.x % 80;
    #pragma unroll 1
    for (int i = threadIdx.x; i < 73 * 73; i += blockDim.x)
    {
        output0[st + i] = (input1[c_id] + (input0[c_id] * (input2[st + i] - input3[c_id]) / sqrtf(0.001 + input4[c_id])));
    }

}
extern void inception3_BatchNormInference_float_float_float_float_float_float_cuda_BatchNormInference_502_Call(const dim3 &grids, const dim3 &blocks, unsigned mem, cudaStream_t stream, float* input0, float* input1, float* input2, float* input3, float* input4, float* output0) {
    inception3_BatchNormInference_float_float_float_float_float_float_cuda_BatchNormInference_502<<<grids, blocks, mem, stream>>>(input0, input1, input2, input3, input4, output0);
}
// Node name:	AvgPool_817
// Description:	AvgPool
// Input:
//	- name: inception3_Concat_810_0	type: float	shape: Shape{64, 1280, 8, 8}
// Output:
//	- name: inception3_AvgPool_817_0	type: float	shape: Shape{64, 1280, 8, 8}
void AvgPool_float_float_cuda_lib_AvgPool_817(cudnnHandle_t cudnn_handle, float* input0, float* output0)
{
    cudnnTensorDescriptor_t input_desc;
    CUDNN_SAFE_CALL(cudnnCreateTensorDescriptor(&input_desc));
    CUDNN_SAFE_CALL(cudnnSetTensor4dDescriptor(input_desc, CUDNN_TENSOR_NCHW, CUDNN_DATA_FLOAT, 64, 1280, 8, 8));
    cudnnTensorDescriptor_t output_desc;
    CUDNN_SAFE_CALL(cudnnCreateTensorDescriptor(&output_desc));
    CUDNN_SAFE_CALL(cudnnSetTensor4dDescriptor(output_desc, CUDNN_TENSOR_NCHW, CUDNN_DATA_FLOAT, 64, 1280, 8, 8));
    cudnnPoolingDescriptor_t desc;
    cudnnCreatePoolingDescriptor(&desc);
    CUDNN_SAFE_CALL(cudnnSetPooling2dDescriptor(desc, CUDNN_POOLING_AVERAGE_COUNT_EXCLUDE_PADDING, CUDNN_NOT_PROPAGATE_NAN,3, 3, 1, 1, 1, 1));
    const float alpha = 1.0;
    const float beta = 0.0;
    CUDNN_SAFE_CALL(cudnnPoolingForward(cudnn_handle, desc, &alpha, input_desc, input0, &beta, output_desc, output0));
    CUDNN_SAFE_CALL(cudnnDestroyTensorDescriptor(input_desc));
    CUDNN_SAFE_CALL(cudnnDestroyTensorDescriptor(output_desc));
    CUDNN_SAFE_CALL(cudnnDestroyPoolingDescriptor(desc));

}
// Node name:	Reshape_794
// Description:	Reshape
// Input:
//	- name: inception3_Constant_365_0	type: float	shape: Shape{3, 3, 192, 320}
// Output:
//	- name: inception3_Reshape_794_0	type: float	shape: Shape{320, 192, 3, 3}
extern "C" __launch_bounds__(256) __global__ void inception3_Reshape_float_float_cuda_Reshape_794(float* input0, float* output0)
{
    uint32_t input_strides0 = 61440;
    uint32_t input_strides1 = 320;
    uint32_t input_strides2 = 1;
    uint32_t trans_strides0 = 1;
    uint32_t trans_strides1 = 9;
    uint32_t trans_strides2 = 1728;
    size_t nx = 320;
    size_t ny = 192;
    size_t nz = 9;
    __shared__ float tile[16][1][17];
    uint32_t base2 = blockIdx.x * blockDim.x;
    uint32_t base1 = blockIdx.y * blockDim.y;
    uint32_t base0 = blockIdx.z * blockDim.z;
    uint32_t tid2 = threadIdx.x;
    uint32_t tid1 = threadIdx.y;
    uint32_t tid0 = threadIdx.z;
    uint32_t otid2 = tid2;
    uint32_t otid1 = tid1;
    uint32_t otid0 = tid0;
    uint32_t idx2 = base2 + tid2;
    uint32_t idx1 = base1 + tid1;
    uint32_t idx0 = base0 + tid0;
    if (idx2 < nx && idx1 < ny && idx0 < nz)
    {
        uint32_t input_idx = 0;
        input_idx += input_strides0* idx0;
        input_idx += input_strides1* idx1;
        input_idx += input_strides2* idx2;
        tile[tid0][tid1][tid2] = input0[input_idx];
    }
    otid2 = tid0;
    otid0 = tid2;
    idx2 = base2 + otid2;
    idx1 = base1 + otid1;
    idx0 = base0 + otid0;
    __syncthreads();
    if (idx2 < nx && idx1 < ny && idx0 < nz)
    {
        uint32_t output_idx = 0;
        output_idx += trans_strides0* idx0;
        output_idx += trans_strides1* idx1;
        output_idx += trans_strides2* idx2;
        output0[output_idx] = tile[otid0][otid1][otid2];
    }

}
extern void inception3_Reshape_float_float_cuda_Reshape_794_Call(const dim3 &grids, const dim3 &blocks, unsigned mem, cudaStream_t stream, float* input0, float* output0) {
    inception3_Reshape_float_float_cuda_Reshape_794<<<grids, blocks, mem, stream>>>(input0, output0);
}
// Node name:	BatchNormInference_808
// Description:	BatchNormInference
// Input:
//	- name: inception3_Constant_386_0	type: float	shape: Shape{192}
//	- name: inception3_Constant_387_0	type: float	shape: Shape{192}
//	- name: inception3_Convolution_807_0	type: float	shape: Shape{64, 192, 8, 8}
//	- name: inception3_Constant_388_0	type: float	shape: Shape{192}
//	- name: inception3_Constant_389_0	type: float	shape: Shape{192}
// Output:
//	- name: inception3_BatchNormInference_808_0	type: float	shape: Shape{64, 192, 8, 8}
extern "C" __launch_bounds__(64) __global__ void inception3_BatchNormInference_float_float_float_float_float_float_cuda_BatchNormInference_808(float* input0, float* input1, float* input2, float* input3, float* input4, float* output0)
{
    const int st = blockIdx.x * 8 * 8;
    const int c_id = blockIdx.x % 192;
    #pragma unroll 1
    for (int i = threadIdx.x; i < 8 * 8; i += blockDim.x)
    {
        output0[st + i] = (input1[c_id] + (input0[c_id] * (input2[st + i] - input3[c_id]) / sqrtf(0.001 + input4[c_id])));
    }

}
extern void inception3_BatchNormInference_float_float_float_float_float_float_cuda_BatchNormInference_808_Call(const dim3 &grids, const dim3 &blocks, unsigned mem, cudaStream_t stream, float* input0, float* input1, float* input2, float* input3, float* input4, float* output0) {
    inception3_BatchNormInference_float_float_float_float_float_float_cuda_BatchNormInference_808<<<grids, blocks, mem, stream>>>(input0, input1, input2, input3, input4, output0);
}
// Node name:	Concat_810
// Description:	Concat
// Input:
//	- name: inception3_Relu_800_0	type: float	shape: Shape{64, 320, 8, 8}
//	- name: inception3_Relu_809_0	type: float	shape: Shape{64, 192, 8, 8}
//	- name: inception3_MaxPool_789_0	type: float	shape: Shape{64, 768, 8, 8}
// Output:
//	- name: inception3_Concat_810_0	type: float	shape: Shape{64, 1280, 8, 8}
extern "C" __launch_bounds__(512) __global__ void inception3_Concat_float_float_float_float_cuda_Concat_810(float* input0, float* input1, float* input2, float* output0)
{
    uint32_t inputs_strides[] = {20480, 12288, 49152};
    uint32_t tid = blockIdx.x * blockDim.x + threadIdx.x;
    if(tid < 5242880)
    {
        uint32_t block_id = tid / 81920;
        uint32_t block_idx = tid % 81920;
        uint32_t output_idx = block_id * 81920 + block_idx;
        if(block_idx < inputs_strides[0])
        {
            output0[output_idx] = input0[block_id * inputs_strides[0] + block_idx];
            return;
        }
        block_idx -= inputs_strides[0];
        if(block_idx < inputs_strides[1])
        {
            output0[output_idx] = input1[block_id * inputs_strides[1] + block_idx];
            return;
        }
        block_idx -= inputs_strides[1];
        if(block_idx < inputs_strides[2])
        {
            output0[output_idx] = input2[block_id * inputs_strides[2] + block_idx];
            return;
        }
        block_idx -= inputs_strides[2];
    }

}
extern void inception3_Concat_float_float_float_float_cuda_Concat_810_Call(const dim3 &grids, const dim3 &blocks, unsigned mem, cudaStream_t stream, float* input0, float* input1, float* input2, float* output0) {
    inception3_Concat_float_float_float_float_cuda_Concat_810<<<grids, blocks, mem, stream>>>(input0, input1, input2, output0);
}
// Node name:	Convolution_678
// Description:	Convolution
// Input:
//	- name: inception3_Relu_673_0	type: float	shape: Shape{64, 160, 17, 17}
//	- name: inception3_Reshape_677_0	type: float	shape: Shape{160, 160, 7, 1}
// Output:
//	- name: inception3_Convolution_678_0	type: float	shape: Shape{64, 160, 17, 17}
void Convolution_float_float_float_cuda_lib_Convolution_678(cudnnHandle_t cudnn_handle, float* input0, float* input1, float* output0)
{
    cudnnTensorDescriptor_t tensor_desc_0;
    CUDNN_SAFE_CALL(cudnnCreateTensorDescriptor(&tensor_desc_0));
    CUDNN_SAFE_CALL(cudnnSetTensor4dDescriptor(tensor_desc_0, CUDNN_TENSOR_NCHW, CUDNN_DATA_FLOAT, 64, 160, 17, 17));
    cudnnTensorDescriptor_t tensor_desc_1;
    CUDNN_SAFE_CALL(cudnnCreateTensorDescriptor(&tensor_desc_1));
    CUDNN_SAFE_CALL(cudnnSetTensor4dDescriptor(tensor_desc_1, CUDNN_TENSOR_NCHW, CUDNN_DATA_FLOAT, 64, 160, 17, 17));
    cudnnFilterDescriptor_t filter_desc;
    CUDNN_SAFE_CALL(cudnnCreateFilterDescriptor(&filter_desc));
    CUDNN_SAFE_CALL(cudnnSetFilter4dDescriptor(filter_desc, CUDNN_DATA_FLOAT, CUDNN_TENSOR_NCHW, 160, 160, 7, 1));
    cudnnConvolutionDescriptor_t conv_desc;
    CUDNN_SAFE_CALL(cudnnCreateConvolutionDescriptor(&conv_desc));
    CUDNN_SAFE_CALL(cudnnSetConvolution2dDescriptor(conv_desc, 3, 0, 1, 1, 1, 1, CUDNN_CROSS_CORRELATION, CUDNN_DATA_FLOAT));

    static bool selected_algo = true;
    static cudnnConvolutionFwdAlgo_t conv_fwd_algo = CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM;

    if (!selected_algo) {
        int num_algos;
        int max_algos = 0;
        // cudnnGetConvolutionForwardAlgorithm_v7;
        CUDNN_SAFE_CALL(
            cudnnGetConvolutionForwardAlgorithmMaxCount(cudnn_handle, &max_algos));
        std::vector<cudnnConvolutionFwdAlgoPerf_t> results(max_algos);
        CUDNN_SAFE_CALL(cudnnFindConvolutionForwardAlgorithm(cudnn_handle,
                                                tensor_desc_0,
                                                filter_desc,
                                                conv_desc,
                                                tensor_desc_1,
                                                static_cast<int>(results.size()),
                                                &num_algos,
                                                results.data()));
        results.resize(num_algos);
        for (size_t i = 0; i != results.size(); ++i) {
            cudnnConvolutionFwdAlgoPerf_t const& result = results[i];
            if (result.status == CUDNN_STATUS_SUCCESS) {
                conv_fwd_algo = result.algo;
                break;
            }
        }
        selected_algo = true;
    }
    const float alpha = 1.0;
    const float beta = 0.0;
    static void *workspace_ptr_0 = NULL;
    static size_t workspace_size_in_bytes = 0;
    if (!workspace_ptr_0)
    {
        CUDNN_SAFE_CALL(cudnnGetConvolutionForwardWorkspaceSize(cudnn_handle, tensor_desc_0, filter_desc, conv_desc, tensor_desc_1, conv_fwd_algo, &workspace_size_in_bytes));
        CUDA_SAFE_CALL(cudaMalloc(&workspace_ptr_0, workspace_size_in_bytes));
    }
    CUDNN_SAFE_CALL(cudnnConvolutionForward(cudnn_handle, &alpha, tensor_desc_0, input0,filter_desc, input1, conv_desc, conv_fwd_algo, workspace_ptr_0, workspace_size_in_bytes, &beta, tensor_desc_1, output0));
    CUDNN_SAFE_CALL(cudnnDestroyTensorDescriptor(tensor_desc_0));
    CUDNN_SAFE_CALL(cudnnDestroyTensorDescriptor(tensor_desc_1));
    CUDNN_SAFE_CALL(cudnnDestroyFilterDescriptor(filter_desc));
    CUDNN_SAFE_CALL(cudnnDestroyConvolutionDescriptor(conv_desc));

}
// Node name:	Convolution_628
// Description:	Convolution
// Input:
//	- name: inception3_AvgPool_623_0	type: float	shape: Shape{64, 768, 17, 17}
//	- name: inception3_Reshape_627_0	type: float	shape: Shape{192, 768, 1, 1}
// Output:
//	- name: inception3_Convolution_628_0	type: float	shape: Shape{64, 192, 17, 17}
void Convolution_float_float_float_cuda_lib_Convolution_628(cudnnHandle_t cudnn_handle, float* input0, float* input1, float* output0)
{
    cudnnTensorDescriptor_t tensor_desc_0;
    CUDNN_SAFE_CALL(cudnnCreateTensorDescriptor(&tensor_desc_0));
    CUDNN_SAFE_CALL(cudnnSetTensor4dDescriptor(tensor_desc_0, CUDNN_TENSOR_NCHW, CUDNN_DATA_FLOAT, 64, 768, 17, 17));
    cudnnTensorDescriptor_t tensor_desc_1;
    CUDNN_SAFE_CALL(cudnnCreateTensorDescriptor(&tensor_desc_1));
    CUDNN_SAFE_CALL(cudnnSetTensor4dDescriptor(tensor_desc_1, CUDNN_TENSOR_NCHW, CUDNN_DATA_FLOAT, 64, 192, 17, 17));
    cudnnFilterDescriptor_t filter_desc;
    CUDNN_SAFE_CALL(cudnnCreateFilterDescriptor(&filter_desc));
    CUDNN_SAFE_CALL(cudnnSetFilter4dDescriptor(filter_desc, CUDNN_DATA_FLOAT, CUDNN_TENSOR_NCHW, 192, 768, 1, 1));
    cudnnConvolutionDescriptor_t conv_desc;
    CUDNN_SAFE_CALL(cudnnCreateConvolutionDescriptor(&conv_desc));
    CUDNN_SAFE_CALL(cudnnSetConvolution2dDescriptor(conv_desc, 0, 0, 1, 1, 1, 1, CUDNN_CROSS_CORRELATION, CUDNN_DATA_FLOAT));

    static bool selected_algo = true;
    static cudnnConvolutionFwdAlgo_t conv_fwd_algo = CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM;

    if (!selected_algo) {
        int num_algos;
        int max_algos = 0;
        // cudnnGetConvolutionForwardAlgorithm_v7;
        CUDNN_SAFE_CALL(
            cudnnGetConvolutionForwardAlgorithmMaxCount(cudnn_handle, &max_algos));
        std::vector<cudnnConvolutionFwdAlgoPerf_t> results(max_algos);
        CUDNN_SAFE_CALL(cudnnFindConvolutionForwardAlgorithm(cudnn_handle,
                                                tensor_desc_0,
                                                filter_desc,
                                                conv_desc,
                                                tensor_desc_1,
                                                static_cast<int>(results.size()),
                                                &num_algos,
                                                results.data()));
        results.resize(num_algos);
        for (size_t i = 0; i != results.size(); ++i) {
            cudnnConvolutionFwdAlgoPerf_t const& result = results[i];
            if (result.status == CUDNN_STATUS_SUCCESS) {
                conv_fwd_algo = result.algo;
                break;
            }
        }
        selected_algo = true;
    }
    const float alpha = 1.0;
    const float beta = 0.0;
    static void *workspace_ptr_0 = NULL;
    static size_t workspace_size_in_bytes = 0;
    if (!workspace_ptr_0)
    {
        CUDNN_SAFE_CALL(cudnnGetConvolutionForwardWorkspaceSize(cudnn_handle, tensor_desc_0, filter_desc, conv_desc, tensor_desc_1, conv_fwd_algo, &workspace_size_in_bytes));
        CUDA_SAFE_CALL(cudaMalloc(&workspace_ptr_0, workspace_size_in_bytes));
    }
    CUDNN_SAFE_CALL(cudnnConvolutionForward(cudnn_handle, &alpha, tensor_desc_0, input0,filter_desc, input1, conv_desc, conv_fwd_algo, workspace_ptr_0, workspace_size_in_bytes, &beta, tensor_desc_1, output0));
    CUDNN_SAFE_CALL(cudnnDestroyTensorDescriptor(tensor_desc_0));
    CUDNN_SAFE_CALL(cudnnDestroyTensorDescriptor(tensor_desc_1));
    CUDNN_SAFE_CALL(cudnnDestroyFilterDescriptor(filter_desc));
    CUDNN_SAFE_CALL(cudnnDestroyConvolutionDescriptor(conv_desc));

}
// Node name:	Reshape_519
// Description:	Reshape
// Input:
//	- name: inception3_Constant_57_0	type: float	shape: Shape{1, 1, 192, 32}
// Output:
//	- name: inception3_Reshape_519_0	type: float	shape: Shape{32, 192, 1, 1}
extern "C" __launch_bounds__(256) __global__ void inception3_Reshape_float_float_cuda_Reshape_519(float* input0, float* output0)
{
    uint32_t input_strides0 = 32;
    uint32_t input_strides1 = 1;
    uint32_t trans_strides0 = 1;
    uint32_t trans_strides1 = 192;
    size_t nx = 32;
    size_t ny = 192;
    __shared__ float tile[16][17];
    uint32_t base1 = blockIdx.x * blockDim.x;
    uint32_t base0 = blockIdx.y * blockDim.y;
    uint32_t tid1 = threadIdx.x;
    uint32_t tid0 = threadIdx.y;
    uint32_t idx1 = base1 + tid1;
    uint32_t idx0 = base0 + tid0;
    if (idx1 < nx && idx0 < ny)
    {
        uint32_t input_idx = 0;
        input_idx += input_strides0* idx0;
        input_idx += input_strides1* idx1;
        tile[tid0][tid1] = input0[input_idx];
    }
    idx1 = base1 + tid0;
    idx0 = base0 + tid1;
    __syncthreads();
    if (idx1 < nx && idx0 < ny)
    {
        uint32_t output_idx = 0;
        output_idx += trans_strides0* idx0;
        output_idx += trans_strides1* idx1;
        output0[output_idx] = tile[tid1][tid0];
    }

}
extern void inception3_Reshape_float_float_cuda_Reshape_519_Call(const dim3 &grids, const dim3 &blocks, unsigned mem, cudaStream_t stream, float* input0, float* output0) {
    inception3_Reshape_float_float_cuda_Reshape_519<<<grids, blocks, mem, stream>>>(input0, output0);
}
// Node name:	Reshape_806
// Description:	Reshape
// Input:
//	- name: inception3_Constant_385_0	type: float	shape: Shape{3, 3, 192, 192}
// Output:
//	- name: inception3_Reshape_806_0	type: float	shape: Shape{192, 192, 3, 3}
extern "C" __launch_bounds__(256) __global__ void inception3_Reshape_float_float_cuda_Reshape_806(float* input0, float* output0)
{
    uint32_t input_strides0 = 36864;
    uint32_t input_strides1 = 192;
    uint32_t input_strides2 = 1;
    uint32_t trans_strides0 = 1;
    uint32_t trans_strides1 = 9;
    uint32_t trans_strides2 = 1728;
    size_t nx = 192;
    size_t ny = 192;
    size_t nz = 9;
    __shared__ float tile[16][1][17];
    uint32_t base2 = blockIdx.x * blockDim.x;
    uint32_t base1 = blockIdx.y * blockDim.y;
    uint32_t base0 = blockIdx.z * blockDim.z;
    uint32_t tid2 = threadIdx.x;
    uint32_t tid1 = threadIdx.y;
    uint32_t tid0 = threadIdx.z;
    uint32_t otid2 = tid2;
    uint32_t otid1 = tid1;
    uint32_t otid0 = tid0;
    uint32_t idx2 = base2 + tid2;
    uint32_t idx1 = base1 + tid1;
    uint32_t idx0 = base0 + tid0;
    if (idx2 < nx && idx1 < ny && idx0 < nz)
    {
        uint32_t input_idx = 0;
        input_idx += input_strides0* idx0;
        input_idx += input_strides1* idx1;
        input_idx += input_strides2* idx2;
        tile[tid0][tid1][tid2] = input0[input_idx];
    }
    otid2 = tid0;
    otid0 = tid2;
    idx2 = base2 + otid2;
    idx1 = base1 + otid1;
    idx0 = base0 + otid0;
    __syncthreads();
    if (idx2 < nx && idx1 < ny && idx0 < nz)
    {
        uint32_t output_idx = 0;
        output_idx += trans_strides0* idx0;
        output_idx += trans_strides1* idx1;
        output_idx += trans_strides2* idx2;
        output0[output_idx] = tile[otid0][otid1][otid2];
    }

}
extern void inception3_Reshape_float_float_cuda_Reshape_806_Call(const dim3 &grids, const dim3 &blocks, unsigned mem, cudaStream_t stream, float* input0, float* output0) {
    inception3_Reshape_float_float_cuda_Reshape_806<<<grids, blocks, mem, stream>>>(input0, output0);
}
// Node name:	Convolution_854
// Description:	Convolution
// Input:
//	- name: inception3_Concat_848_0	type: float	shape: Shape{64, 2048, 8, 8}
//	- name: inception3_Reshape_853_0	type: float	shape: Shape{448, 2048, 1, 1}
// Output:
//	- name: inception3_Convolution_854_0	type: float	shape: Shape{64, 448, 8, 8}
void Convolution_float_float_float_cuda_lib_Convolution_854(cudnnHandle_t cudnn_handle, float* input0, float* input1, float* output0)
{
    cudnnTensorDescriptor_t tensor_desc_0;
    CUDNN_SAFE_CALL(cudnnCreateTensorDescriptor(&tensor_desc_0));
    CUDNN_SAFE_CALL(cudnnSetTensor4dDescriptor(tensor_desc_0, CUDNN_TENSOR_NCHW, CUDNN_DATA_FLOAT, 64, 2048, 8, 8));
    cudnnTensorDescriptor_t tensor_desc_1;
    CUDNN_SAFE_CALL(cudnnCreateTensorDescriptor(&tensor_desc_1));
    CUDNN_SAFE_CALL(cudnnSetTensor4dDescriptor(tensor_desc_1, CUDNN_TENSOR_NCHW, CUDNN_DATA_FLOAT, 64, 448, 8, 8));
    cudnnFilterDescriptor_t filter_desc;
    CUDNN_SAFE_CALL(cudnnCreateFilterDescriptor(&filter_desc));
    CUDNN_SAFE_CALL(cudnnSetFilter4dDescriptor(filter_desc, CUDNN_DATA_FLOAT, CUDNN_TENSOR_NCHW, 448, 2048, 1, 1));
    cudnnConvolutionDescriptor_t conv_desc;
    CUDNN_SAFE_CALL(cudnnCreateConvolutionDescriptor(&conv_desc));
    CUDNN_SAFE_CALL(cudnnSetConvolution2dDescriptor(conv_desc, 0, 0, 1, 1, 1, 1, CUDNN_CROSS_CORRELATION, CUDNN_DATA_FLOAT));

    static bool selected_algo = true;
    static cudnnConvolutionFwdAlgo_t conv_fwd_algo = CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM;

    if (!selected_algo) {
        int num_algos;
        int max_algos = 0;
        // cudnnGetConvolutionForwardAlgorithm_v7;
        CUDNN_SAFE_CALL(
            cudnnGetConvolutionForwardAlgorithmMaxCount(cudnn_handle, &max_algos));
        std::vector<cudnnConvolutionFwdAlgoPerf_t> results(max_algos);
        CUDNN_SAFE_CALL(cudnnFindConvolutionForwardAlgorithm(cudnn_handle,
                                                tensor_desc_0,
                                                filter_desc,
                                                conv_desc,
                                                tensor_desc_1,
                                                static_cast<int>(results.size()),
                                                &num_algos,
                                                results.data()));
        results.resize(num_algos);
        for (size_t i = 0; i != results.size(); ++i) {
            cudnnConvolutionFwdAlgoPerf_t const& result = results[i];
            if (result.status == CUDNN_STATUS_SUCCESS) {
                conv_fwd_algo = result.algo;
                break;
            }
        }
        selected_algo = true;
    }
    const float alpha = 1.0;
    const float beta = 0.0;
    static void *workspace_ptr_0 = NULL;
    static size_t workspace_size_in_bytes = 0;
    if (!workspace_ptr_0)
    {
        CUDNN_SAFE_CALL(cudnnGetConvolutionForwardWorkspaceSize(cudnn_handle, tensor_desc_0, filter_desc, conv_desc, tensor_desc_1, conv_fwd_algo, &workspace_size_in_bytes));
        CUDA_SAFE_CALL(cudaMalloc(&workspace_ptr_0, workspace_size_in_bytes));
    }
    CUDNN_SAFE_CALL(cudnnConvolutionForward(cudnn_handle, &alpha, tensor_desc_0, input0,filter_desc, input1, conv_desc, conv_fwd_algo, workspace_ptr_0, workspace_size_in_bytes, &beta, tensor_desc_1, output0));
    CUDNN_SAFE_CALL(cudnnDestroyTensorDescriptor(tensor_desc_0));
    CUDNN_SAFE_CALL(cudnnDestroyTensorDescriptor(tensor_desc_1));
    CUDNN_SAFE_CALL(cudnnDestroyFilterDescriptor(filter_desc));
    CUDNN_SAFE_CALL(cudnnDestroyConvolutionDescriptor(conv_desc));

}
// Node name:	Reshape_504
// Description:	Reshape
// Input:
//	- name: inception3_Constant_22_0	type: float	shape: Shape{3, 3, 80, 192}
// Output:
//	- name: inception3_Reshape_504_0	type: float	shape: Shape{192, 80, 3, 3}
extern "C" __launch_bounds__(256) __global__ void inception3_Reshape_float_float_cuda_Reshape_504(float* input0, float* output0)
{
    uint32_t input_strides0 = 15360;
    uint32_t input_strides1 = 192;
    uint32_t input_strides2 = 1;
    uint32_t trans_strides0 = 1;
    uint32_t trans_strides1 = 9;
    uint32_t trans_strides2 = 720;
    size_t nx = 192;
    size_t ny = 80;
    size_t nz = 9;
    __shared__ float tile[16][1][17];
    uint32_t base2 = blockIdx.x * blockDim.x;
    uint32_t base1 = blockIdx.y * blockDim.y;
    uint32_t base0 = blockIdx.z * blockDim.z;
    uint32_t tid2 = threadIdx.x;
    uint32_t tid1 = threadIdx.y;
    uint32_t tid0 = threadIdx.z;
    uint32_t otid2 = tid2;
    uint32_t otid1 = tid1;
    uint32_t otid0 = tid0;
    uint32_t idx2 = base2 + tid2;
    uint32_t idx1 = base1 + tid1;
    uint32_t idx0 = base0 + tid0;
    if (idx2 < nx && idx1 < ny && idx0 < nz)
    {
        uint32_t input_idx = 0;
        input_idx += input_strides0* idx0;
        input_idx += input_strides1* idx1;
        input_idx += input_strides2* idx2;
        tile[tid0][tid1][tid2] = input0[input_idx];
    }
    otid2 = tid0;
    otid0 = tid2;
    idx2 = base2 + otid2;
    idx1 = base1 + otid1;
    idx0 = base0 + otid0;
    __syncthreads();
    if (idx2 < nx && idx1 < ny && idx0 < nz)
    {
        uint32_t output_idx = 0;
        output_idx += trans_strides0* idx0;
        output_idx += trans_strides1* idx1;
        output_idx += trans_strides2* idx2;
        output0[output_idx] = tile[otid0][otid1][otid2];
    }

}
extern void inception3_Reshape_float_float_cuda_Reshape_504_Call(const dim3 &grids, const dim3 &blocks, unsigned mem, cudaStream_t stream, float* input0, float* output0) {
    inception3_Reshape_float_float_cuda_Reshape_504<<<grids, blocks, mem, stream>>>(input0, output0);
}
// Node name:	Convolution_512
// Description:	Convolution
// Input:
//	- name: inception3_MaxPool_508_0	type: float	shape: Shape{64, 192, 35, 35}
//	- name: inception3_Reshape_511_0	type: float	shape: Shape{48, 192, 1, 1}
// Output:
//	- name: inception3_Convolution_512_0	type: float	shape: Shape{64, 48, 35, 35}
void Convolution_float_float_float_cuda_lib_Convolution_512(cudnnHandle_t cudnn_handle, float* input0, float* input1, float* output0)
{
    cudnnTensorDescriptor_t tensor_desc_0;
    CUDNN_SAFE_CALL(cudnnCreateTensorDescriptor(&tensor_desc_0));
    CUDNN_SAFE_CALL(cudnnSetTensor4dDescriptor(tensor_desc_0, CUDNN_TENSOR_NCHW, CUDNN_DATA_FLOAT, 64, 192, 35, 35));
    cudnnTensorDescriptor_t tensor_desc_1;
    CUDNN_SAFE_CALL(cudnnCreateTensorDescriptor(&tensor_desc_1));
    CUDNN_SAFE_CALL(cudnnSetTensor4dDescriptor(tensor_desc_1, CUDNN_TENSOR_NCHW, CUDNN_DATA_FLOAT, 64, 48, 35, 35));
    cudnnFilterDescriptor_t filter_desc;
    CUDNN_SAFE_CALL(cudnnCreateFilterDescriptor(&filter_desc));
    CUDNN_SAFE_CALL(cudnnSetFilter4dDescriptor(filter_desc, CUDNN_DATA_FLOAT, CUDNN_TENSOR_NCHW, 48, 192, 1, 1));
    cudnnConvolutionDescriptor_t conv_desc;
    CUDNN_SAFE_CALL(cudnnCreateConvolutionDescriptor(&conv_desc));
    CUDNN_SAFE_CALL(cudnnSetConvolution2dDescriptor(conv_desc, 0, 0, 1, 1, 1, 1, CUDNN_CROSS_CORRELATION, CUDNN_DATA_FLOAT));

    static bool selected_algo = true;
    static cudnnConvolutionFwdAlgo_t conv_fwd_algo = CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM;

    if (!selected_algo) {
        int num_algos;
        int max_algos = 0;
        // cudnnGetConvolutionForwardAlgorithm_v7;
        CUDNN_SAFE_CALL(
            cudnnGetConvolutionForwardAlgorithmMaxCount(cudnn_handle, &max_algos));
        std::vector<cudnnConvolutionFwdAlgoPerf_t> results(max_algos);
        CUDNN_SAFE_CALL(cudnnFindConvolutionForwardAlgorithm(cudnn_handle,
                                                tensor_desc_0,
                                                filter_desc,
                                                conv_desc,
                                                tensor_desc_1,
                                                static_cast<int>(results.size()),
                                                &num_algos,
                                                results.data()));
        results.resize(num_algos);
        for (size_t i = 0; i != results.size(); ++i) {
            cudnnConvolutionFwdAlgoPerf_t const& result = results[i];
            if (result.status == CUDNN_STATUS_SUCCESS) {
                conv_fwd_algo = result.algo;
                break;
            }
        }
        selected_algo = true;
    }
    const float alpha = 1.0;
    const float beta = 0.0;
    static void *workspace_ptr_0 = NULL;
    static size_t workspace_size_in_bytes = 0;
    if (!workspace_ptr_0)
    {
        CUDNN_SAFE_CALL(cudnnGetConvolutionForwardWorkspaceSize(cudnn_handle, tensor_desc_0, filter_desc, conv_desc, tensor_desc_1, conv_fwd_algo, &workspace_size_in_bytes));
        CUDA_SAFE_CALL(cudaMalloc(&workspace_ptr_0, workspace_size_in_bytes));
    }
    CUDNN_SAFE_CALL(cudnnConvolutionForward(cudnn_handle, &alpha, tensor_desc_0, input0,filter_desc, input1, conv_desc, conv_fwd_algo, workspace_ptr_0, workspace_size_in_bytes, &beta, tensor_desc_1, output0));
    CUDNN_SAFE_CALL(cudnnDestroyTensorDescriptor(tensor_desc_0));
    CUDNN_SAFE_CALL(cudnnDestroyTensorDescriptor(tensor_desc_1));
    CUDNN_SAFE_CALL(cudnnDestroyFilterDescriptor(filter_desc));
    CUDNN_SAFE_CALL(cudnnDestroyConvolutionDescriptor(conv_desc));

}
// Node name:	Convolution_520
// Description:	Convolution
// Input:
//	- name: inception3_AvgPool_515_0	type: float	shape: Shape{64, 192, 35, 35}
//	- name: inception3_Reshape_519_0	type: float	shape: Shape{32, 192, 1, 1}
// Output:
//	- name: inception3_Convolution_520_0	type: float	shape: Shape{64, 32, 35, 35}
void Convolution_float_float_float_cuda_lib_Convolution_520(cudnnHandle_t cudnn_handle, float* input0, float* input1, float* output0)
{
    cudnnTensorDescriptor_t tensor_desc_0;
    CUDNN_SAFE_CALL(cudnnCreateTensorDescriptor(&tensor_desc_0));
    CUDNN_SAFE_CALL(cudnnSetTensor4dDescriptor(tensor_desc_0, CUDNN_TENSOR_NCHW, CUDNN_DATA_FLOAT, 64, 192, 35, 35));
    cudnnTensorDescriptor_t tensor_desc_1;
    CUDNN_SAFE_CALL(cudnnCreateTensorDescriptor(&tensor_desc_1));
    CUDNN_SAFE_CALL(cudnnSetTensor4dDescriptor(tensor_desc_1, CUDNN_TENSOR_NCHW, CUDNN_DATA_FLOAT, 64, 32, 35, 35));
    cudnnFilterDescriptor_t filter_desc;
    CUDNN_SAFE_CALL(cudnnCreateFilterDescriptor(&filter_desc));
    CUDNN_SAFE_CALL(cudnnSetFilter4dDescriptor(filter_desc, CUDNN_DATA_FLOAT, CUDNN_TENSOR_NCHW, 32, 192, 1, 1));
    cudnnConvolutionDescriptor_t conv_desc;
    CUDNN_SAFE_CALL(cudnnCreateConvolutionDescriptor(&conv_desc));
    CUDNN_SAFE_CALL(cudnnSetConvolution2dDescriptor(conv_desc, 0, 0, 1, 1, 1, 1, CUDNN_CROSS_CORRELATION, CUDNN_DATA_FLOAT));

    static bool selected_algo = true;
    static cudnnConvolutionFwdAlgo_t conv_fwd_algo = CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM;

    if (!selected_algo) {
        int num_algos;
        int max_algos = 0;
        // cudnnGetConvolutionForwardAlgorithm_v7;
        CUDNN_SAFE_CALL(
            cudnnGetConvolutionForwardAlgorithmMaxCount(cudnn_handle, &max_algos));
        std::vector<cudnnConvolutionFwdAlgoPerf_t> results(max_algos);
        CUDNN_SAFE_CALL(cudnnFindConvolutionForwardAlgorithm(cudnn_handle,
                                                tensor_desc_0,
                                                filter_desc,
                                                conv_desc,
                                                tensor_desc_1,
                                                static_cast<int>(results.size()),
                                                &num_algos,
                                                results.data()));
        results.resize(num_algos);
        for (size_t i = 0; i != results.size(); ++i) {
            cudnnConvolutionFwdAlgoPerf_t const& result = results[i];
            if (result.status == CUDNN_STATUS_SUCCESS) {
                conv_fwd_algo = result.algo;
                break;
            }
        }
        selected_algo = true;
    }
    const float alpha = 1.0;
    const float beta = 0.0;
    static void *workspace_ptr_0 = NULL;
    static size_t workspace_size_in_bytes = 0;
    if (!workspace_ptr_0)
    {
        CUDNN_SAFE_CALL(cudnnGetConvolutionForwardWorkspaceSize(cudnn_handle, tensor_desc_0, filter_desc, conv_desc, tensor_desc_1, conv_fwd_algo, &workspace_size_in_bytes));
        CUDA_SAFE_CALL(cudaMalloc(&workspace_ptr_0, workspace_size_in_bytes));
    }
    CUDNN_SAFE_CALL(cudnnConvolutionForward(cudnn_handle, &alpha, tensor_desc_0, input0,filter_desc, input1, conv_desc, conv_fwd_algo, workspace_ptr_0, workspace_size_in_bytes, &beta, tensor_desc_1, output0));
    CUDNN_SAFE_CALL(cudnnDestroyTensorDescriptor(tensor_desc_0));
    CUDNN_SAFE_CALL(cudnnDestroyTensorDescriptor(tensor_desc_1));
    CUDNN_SAFE_CALL(cudnnDestroyFilterDescriptor(filter_desc));
    CUDNN_SAFE_CALL(cudnnDestroyConvolutionDescriptor(conv_desc));

}
// Node name:	Convolution_771
// Description:	Convolution
// Input:
//	- name: inception3_Relu_767_0	type: float	shape: Shape{64, 192, 17, 17}
//	- name: inception3_Reshape_770_0	type: float	shape: Shape{192, 192, 1, 7}
// Output:
//	- name: inception3_Convolution_771_0	type: float	shape: Shape{64, 192, 17, 17}
void Convolution_float_float_float_cuda_lib_Convolution_771(cudnnHandle_t cudnn_handle, float* input0, float* input1, float* output0)
{
    cudnnTensorDescriptor_t tensor_desc_0;
    CUDNN_SAFE_CALL(cudnnCreateTensorDescriptor(&tensor_desc_0));
    CUDNN_SAFE_CALL(cudnnSetTensor4dDescriptor(tensor_desc_0, CUDNN_TENSOR_NCHW, CUDNN_DATA_FLOAT, 64, 192, 17, 17));
    cudnnTensorDescriptor_t tensor_desc_1;
    CUDNN_SAFE_CALL(cudnnCreateTensorDescriptor(&tensor_desc_1));
    CUDNN_SAFE_CALL(cudnnSetTensor4dDescriptor(tensor_desc_1, CUDNN_TENSOR_NCHW, CUDNN_DATA_FLOAT, 64, 192, 17, 17));
    cudnnFilterDescriptor_t filter_desc;
    CUDNN_SAFE_CALL(cudnnCreateFilterDescriptor(&filter_desc));
    CUDNN_SAFE_CALL(cudnnSetFilter4dDescriptor(filter_desc, CUDNN_DATA_FLOAT, CUDNN_TENSOR_NCHW, 192, 192, 1, 7));
    cudnnConvolutionDescriptor_t conv_desc;
    CUDNN_SAFE_CALL(cudnnCreateConvolutionDescriptor(&conv_desc));
    CUDNN_SAFE_CALL(cudnnSetConvolution2dDescriptor(conv_desc, 0, 3, 1, 1, 1, 1, CUDNN_CROSS_CORRELATION, CUDNN_DATA_FLOAT));

    static bool selected_algo = true;
    static cudnnConvolutionFwdAlgo_t conv_fwd_algo = CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM;

    if (!selected_algo) {
        int num_algos;
        int max_algos = 0;
        // cudnnGetConvolutionForwardAlgorithm_v7;
        CUDNN_SAFE_CALL(
            cudnnGetConvolutionForwardAlgorithmMaxCount(cudnn_handle, &max_algos));
        std::vector<cudnnConvolutionFwdAlgoPerf_t> results(max_algos);
        CUDNN_SAFE_CALL(cudnnFindConvolutionForwardAlgorithm(cudnn_handle,
                                                tensor_desc_0,
                                                filter_desc,
                                                conv_desc,
                                                tensor_desc_1,
                                                static_cast<int>(results.size()),
                                                &num_algos,
                                                results.data()));
        results.resize(num_algos);
        for (size_t i = 0; i != results.size(); ++i) {
            cudnnConvolutionFwdAlgoPerf_t const& result = results[i];
            if (result.status == CUDNN_STATUS_SUCCESS) {
                conv_fwd_algo = result.algo;
                break;
            }
        }
        selected_algo = true;
    }
    const float alpha = 1.0;
    const float beta = 0.0;
    static void *workspace_ptr_0 = NULL;
    static size_t workspace_size_in_bytes = 0;
    if (!workspace_ptr_0)
    {
        CUDNN_SAFE_CALL(cudnnGetConvolutionForwardWorkspaceSize(cudnn_handle, tensor_desc_0, filter_desc, conv_desc, tensor_desc_1, conv_fwd_algo, &workspace_size_in_bytes));
        CUDA_SAFE_CALL(cudaMalloc(&workspace_ptr_0, workspace_size_in_bytes));
    }
    CUDNN_SAFE_CALL(cudnnConvolutionForward(cudnn_handle, &alpha, tensor_desc_0, input0,filter_desc, input1, conv_desc, conv_fwd_algo, workspace_ptr_0, workspace_size_in_bytes, &beta, tensor_desc_1, output0));
    CUDNN_SAFE_CALL(cudnnDestroyTensorDescriptor(tensor_desc_0));
    CUDNN_SAFE_CALL(cudnnDestroyTensorDescriptor(tensor_desc_1));
    CUDNN_SAFE_CALL(cudnnDestroyFilterDescriptor(filter_desc));
    CUDNN_SAFE_CALL(cudnnDestroyConvolutionDescriptor(conv_desc));

}
// Node name:	AvgPool_887
// Description:	AvgPool
// Input:
//	- name: inception3_Concat_886_0	type: float	shape: Shape{64, 2048, 8, 8}
// Output:
//	- name: inception3_AvgPool_887_0	type: float	shape: Shape{64, 2048, 1, 1}
void AvgPool_float_float_cuda_lib_AvgPool_887(cudnnHandle_t cudnn_handle, float* input0, float* output0)
{
    cudnnTensorDescriptor_t input_desc;
    CUDNN_SAFE_CALL(cudnnCreateTensorDescriptor(&input_desc));
    CUDNN_SAFE_CALL(cudnnSetTensor4dDescriptor(input_desc, CUDNN_TENSOR_NCHW, CUDNN_DATA_FLOAT, 64, 2048, 8, 8));
    cudnnTensorDescriptor_t output_desc;
    CUDNN_SAFE_CALL(cudnnCreateTensorDescriptor(&output_desc));
    CUDNN_SAFE_CALL(cudnnSetTensor4dDescriptor(output_desc, CUDNN_TENSOR_NCHW, CUDNN_DATA_FLOAT, 64, 2048, 1, 1));
    cudnnPoolingDescriptor_t desc;
    cudnnCreatePoolingDescriptor(&desc);
    CUDNN_SAFE_CALL(cudnnSetPooling2dDescriptor(desc, CUDNN_POOLING_AVERAGE_COUNT_EXCLUDE_PADDING, CUDNN_NOT_PROPAGATE_NAN,8, 8, 0, 0, 1, 1));
    const float alpha = 1.0;
    const float beta = 0.0;
    CUDNN_SAFE_CALL(cudnnPoolingForward(cudnn_handle, desc, &alpha, input_desc, input0, &beta, output_desc, output0));
    CUDNN_SAFE_CALL(cudnnDestroyTensorDescriptor(input_desc));
    CUDNN_SAFE_CALL(cudnnDestroyTensorDescriptor(output_desc));
    CUDNN_SAFE_CALL(cudnnDestroyPoolingDescriptor(desc));

}
// Node name:	Convolution_762
// Description:	Convolution
// Input:
//	- name: inception3_Relu_757_0	type: float	shape: Shape{64, 192, 17, 17}
//	- name: inception3_Reshape_761_0	type: float	shape: Shape{192, 192, 7, 1}
// Output:
//	- name: inception3_Convolution_762_0	type: float	shape: Shape{64, 192, 17, 17}
void Convolution_float_float_float_cuda_lib_Convolution_762(cudnnHandle_t cudnn_handle, float* input0, float* input1, float* output0)
{
    cudnnTensorDescriptor_t tensor_desc_0;
    CUDNN_SAFE_CALL(cudnnCreateTensorDescriptor(&tensor_desc_0));
    CUDNN_SAFE_CALL(cudnnSetTensor4dDescriptor(tensor_desc_0, CUDNN_TENSOR_NCHW, CUDNN_DATA_FLOAT, 64, 192, 17, 17));
    cudnnTensorDescriptor_t tensor_desc_1;
    CUDNN_SAFE_CALL(cudnnCreateTensorDescriptor(&tensor_desc_1));
    CUDNN_SAFE_CALL(cudnnSetTensor4dDescriptor(tensor_desc_1, CUDNN_TENSOR_NCHW, CUDNN_DATA_FLOAT, 64, 192, 17, 17));
    cudnnFilterDescriptor_t filter_desc;
    CUDNN_SAFE_CALL(cudnnCreateFilterDescriptor(&filter_desc));
    CUDNN_SAFE_CALL(cudnnSetFilter4dDescriptor(filter_desc, CUDNN_DATA_FLOAT, CUDNN_TENSOR_NCHW, 192, 192, 7, 1));
    cudnnConvolutionDescriptor_t conv_desc;
    CUDNN_SAFE_CALL(cudnnCreateConvolutionDescriptor(&conv_desc));
    CUDNN_SAFE_CALL(cudnnSetConvolution2dDescriptor(conv_desc, 3, 0, 1, 1, 1, 1, CUDNN_CROSS_CORRELATION, CUDNN_DATA_FLOAT));

    static bool selected_algo = true;
    static cudnnConvolutionFwdAlgo_t conv_fwd_algo = CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM;

    if (!selected_algo) {
        int num_algos;
        int max_algos = 0;
        // cudnnGetConvolutionForwardAlgorithm_v7;
        CUDNN_SAFE_CALL(
            cudnnGetConvolutionForwardAlgorithmMaxCount(cudnn_handle, &max_algos));
        std::vector<cudnnConvolutionFwdAlgoPerf_t> results(max_algos);
        CUDNN_SAFE_CALL(cudnnFindConvolutionForwardAlgorithm(cudnn_handle,
                                                tensor_desc_0,
                                                filter_desc,
                                                conv_desc,
                                                tensor_desc_1,
                                                static_cast<int>(results.size()),
                                                &num_algos,
                                                results.data()));
        results.resize(num_algos);
        for (size_t i = 0; i != results.size(); ++i) {
            cudnnConvolutionFwdAlgoPerf_t const& result = results[i];
            if (result.status == CUDNN_STATUS_SUCCESS) {
                conv_fwd_algo = result.algo;
                break;
            }
        }
        selected_algo = true;
    }
    const float alpha = 1.0;
    const float beta = 0.0;
    static void *workspace_ptr_0 = NULL;
    static size_t workspace_size_in_bytes = 0;
    if (!workspace_ptr_0)
    {
        CUDNN_SAFE_CALL(cudnnGetConvolutionForwardWorkspaceSize(cudnn_handle, tensor_desc_0, filter_desc, conv_desc, tensor_desc_1, conv_fwd_algo, &workspace_size_in_bytes));
        CUDA_SAFE_CALL(cudaMalloc(&workspace_ptr_0, workspace_size_in_bytes));
    }
    CUDNN_SAFE_CALL(cudnnConvolutionForward(cudnn_handle, &alpha, tensor_desc_0, input0,filter_desc, input1, conv_desc, conv_fwd_algo, workspace_ptr_0, workspace_size_in_bytes, &beta, tensor_desc_1, output0));
    CUDNN_SAFE_CALL(cudnnDestroyTensorDescriptor(tensor_desc_0));
    CUDNN_SAFE_CALL(cudnnDestroyTensorDescriptor(tensor_desc_1));
    CUDNN_SAFE_CALL(cudnnDestroyFilterDescriptor(filter_desc));
    CUDNN_SAFE_CALL(cudnnDestroyConvolutionDescriptor(conv_desc));

}
// Node name:	Convolution_832
// Description:	Convolution
// Input:
//	- name: inception3_Relu_825_0	type: float	shape: Shape{64, 448, 8, 8}
//	- name: inception3_Reshape_831_0	type: float	shape: Shape{384, 448, 3, 3}
// Output:
//	- name: inception3_Convolution_832_0	type: float	shape: Shape{64, 384, 8, 8}
void Convolution_float_float_float_cuda_lib_Convolution_832(cudnnHandle_t cudnn_handle, float* input0, float* input1, float* output0)
{
    cudnnTensorDescriptor_t tensor_desc_0;
    CUDNN_SAFE_CALL(cudnnCreateTensorDescriptor(&tensor_desc_0));
    CUDNN_SAFE_CALL(cudnnSetTensor4dDescriptor(tensor_desc_0, CUDNN_TENSOR_NCHW, CUDNN_DATA_FLOAT, 64, 448, 8, 8));
    cudnnTensorDescriptor_t tensor_desc_1;
    CUDNN_SAFE_CALL(cudnnCreateTensorDescriptor(&tensor_desc_1));
    CUDNN_SAFE_CALL(cudnnSetTensor4dDescriptor(tensor_desc_1, CUDNN_TENSOR_NCHW, CUDNN_DATA_FLOAT, 64, 384, 8, 8));
    cudnnFilterDescriptor_t filter_desc;
    CUDNN_SAFE_CALL(cudnnCreateFilterDescriptor(&filter_desc));
    CUDNN_SAFE_CALL(cudnnSetFilter4dDescriptor(filter_desc, CUDNN_DATA_FLOAT, CUDNN_TENSOR_NCHW, 384, 448, 3, 3));
    cudnnConvolutionDescriptor_t conv_desc;
    CUDNN_SAFE_CALL(cudnnCreateConvolutionDescriptor(&conv_desc));
    CUDNN_SAFE_CALL(cudnnSetConvolution2dDescriptor(conv_desc, 1, 1, 1, 1, 1, 1, CUDNN_CROSS_CORRELATION, CUDNN_DATA_FLOAT));

    static bool selected_algo = true;
    static cudnnConvolutionFwdAlgo_t conv_fwd_algo = CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM;

    if (!selected_algo) {
        int num_algos;
        int max_algos = 0;
        // cudnnGetConvolutionForwardAlgorithm_v7;
        CUDNN_SAFE_CALL(
            cudnnGetConvolutionForwardAlgorithmMaxCount(cudnn_handle, &max_algos));
        std::vector<cudnnConvolutionFwdAlgoPerf_t> results(max_algos);
        CUDNN_SAFE_CALL(cudnnFindConvolutionForwardAlgorithm(cudnn_handle,
                                                tensor_desc_0,
                                                filter_desc,
                                                conv_desc,
                                                tensor_desc_1,
                                                static_cast<int>(results.size()),
                                                &num_algos,
                                                results.data()));
        results.resize(num_algos);
        for (size_t i = 0; i != results.size(); ++i) {
            cudnnConvolutionFwdAlgoPerf_t const& result = results[i];
            if (result.status == CUDNN_STATUS_SUCCESS) {
                conv_fwd_algo = result.algo;
                break;
            }
        }
        selected_algo = true;
    }
    const float alpha = 1.0;
    const float beta = 0.0;
    static void *workspace_ptr_0 = NULL;
    static size_t workspace_size_in_bytes = 0;
    if (!workspace_ptr_0)
    {
        CUDNN_SAFE_CALL(cudnnGetConvolutionForwardWorkspaceSize(cudnn_handle, tensor_desc_0, filter_desc, conv_desc, tensor_desc_1, conv_fwd_algo, &workspace_size_in_bytes));
        CUDA_SAFE_CALL(cudaMalloc(&workspace_ptr_0, workspace_size_in_bytes));
    }
    CUDNN_SAFE_CALL(cudnnConvolutionForward(cudnn_handle, &alpha, tensor_desc_0, input0,filter_desc, input1, conv_desc, conv_fwd_algo, workspace_ptr_0, workspace_size_in_bytes, &beta, tensor_desc_1, output0));
    CUDNN_SAFE_CALL(cudnnDestroyTensorDescriptor(tensor_desc_0));
    CUDNN_SAFE_CALL(cudnnDestroyTensorDescriptor(tensor_desc_1));
    CUDNN_SAFE_CALL(cudnnDestroyFilterDescriptor(filter_desc));
    CUDNN_SAFE_CALL(cudnnDestroyConvolutionDescriptor(conv_desc));

}
// Node name:	Convolution_528
// Description:	Convolution
// Input:
//	- name: inception3_Relu_523_0	type: float	shape: Shape{64, 64, 35, 35}
//	- name: inception3_Reshape_527_0	type: float	shape: Shape{96, 64, 3, 3}
// Output:
//	- name: inception3_Convolution_528_0	type: float	shape: Shape{64, 96, 35, 35}
void Convolution_float_float_float_cuda_lib_Convolution_528(cudnnHandle_t cudnn_handle, float* input0, float* input1, float* output0)
{
    cudnnTensorDescriptor_t tensor_desc_0;
    CUDNN_SAFE_CALL(cudnnCreateTensorDescriptor(&tensor_desc_0));
    CUDNN_SAFE_CALL(cudnnSetTensor4dDescriptor(tensor_desc_0, CUDNN_TENSOR_NCHW, CUDNN_DATA_FLOAT, 64, 64, 35, 35));
    cudnnTensorDescriptor_t tensor_desc_1;
    CUDNN_SAFE_CALL(cudnnCreateTensorDescriptor(&tensor_desc_1));
    CUDNN_SAFE_CALL(cudnnSetTensor4dDescriptor(tensor_desc_1, CUDNN_TENSOR_NCHW, CUDNN_DATA_FLOAT, 64, 96, 35, 35));
    cudnnFilterDescriptor_t filter_desc;
    CUDNN_SAFE_CALL(cudnnCreateFilterDescriptor(&filter_desc));
    CUDNN_SAFE_CALL(cudnnSetFilter4dDescriptor(filter_desc, CUDNN_DATA_FLOAT, CUDNN_TENSOR_NCHW, 96, 64, 3, 3));
    cudnnConvolutionDescriptor_t conv_desc;
    CUDNN_SAFE_CALL(cudnnCreateConvolutionDescriptor(&conv_desc));
    CUDNN_SAFE_CALL(cudnnSetConvolution2dDescriptor(conv_desc, 1, 1, 1, 1, 1, 1, CUDNN_CROSS_CORRELATION, CUDNN_DATA_FLOAT));

    static bool selected_algo = true;
    static cudnnConvolutionFwdAlgo_t conv_fwd_algo = CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM;

    if (!selected_algo) {
        int num_algos;
        int max_algos = 0;
        // cudnnGetConvolutionForwardAlgorithm_v7;
        CUDNN_SAFE_CALL(
            cudnnGetConvolutionForwardAlgorithmMaxCount(cudnn_handle, &max_algos));
        std::vector<cudnnConvolutionFwdAlgoPerf_t> results(max_algos);
        CUDNN_SAFE_CALL(cudnnFindConvolutionForwardAlgorithm(cudnn_handle,
                                                tensor_desc_0,
                                                filter_desc,
                                                conv_desc,
                                                tensor_desc_1,
                                                static_cast<int>(results.size()),
                                                &num_algos,
                                                results.data()));
        results.resize(num_algos);
        for (size_t i = 0; i != results.size(); ++i) {
            cudnnConvolutionFwdAlgoPerf_t const& result = results[i];
            if (result.status == CUDNN_STATUS_SUCCESS) {
                conv_fwd_algo = result.algo;
                break;
            }
        }
        selected_algo = true;
    }
    const float alpha = 1.0;
    const float beta = 0.0;
    static void *workspace_ptr_0 = NULL;
    static size_t workspace_size_in_bytes = 0;
    if (!workspace_ptr_0)
    {
        CUDNN_SAFE_CALL(cudnnGetConvolutionForwardWorkspaceSize(cudnn_handle, tensor_desc_0, filter_desc, conv_desc, tensor_desc_1, conv_fwd_algo, &workspace_size_in_bytes));
        CUDA_SAFE_CALL(cudaMalloc(&workspace_ptr_0, workspace_size_in_bytes));
    }
    CUDNN_SAFE_CALL(cudnnConvolutionForward(cudnn_handle, &alpha, tensor_desc_0, input0,filter_desc, input1, conv_desc, conv_fwd_algo, workspace_ptr_0, workspace_size_in_bytes, &beta, tensor_desc_1, output0));
    CUDNN_SAFE_CALL(cudnnDestroyTensorDescriptor(tensor_desc_0));
    CUDNN_SAFE_CALL(cudnnDestroyTensorDescriptor(tensor_desc_1));
    CUDNN_SAFE_CALL(cudnnDestroyFilterDescriptor(filter_desc));
    CUDNN_SAFE_CALL(cudnnDestroyConvolutionDescriptor(conv_desc));

}
// Node name:	BatchNormInference_798
// Description:	BatchNormInference
// Input:
//	- name: inception3_Constant_366_0	type: float	shape: Shape{320}
//	- name: inception3_Constant_367_0	type: float	shape: Shape{320}
//	- name: inception3_Convolution_795_0	type: float	shape: Shape{64, 320, 8, 8}
//	- name: inception3_Constant_368_0	type: float	shape: Shape{320}
//	- name: inception3_Constant_369_0	type: float	shape: Shape{320}
// Output:
//	- name: inception3_BatchNormInference_798_0	type: float	shape: Shape{64, 320, 8, 8}
extern "C" __launch_bounds__(64) __global__ void inception3_BatchNormInference_float_float_float_float_float_float_cuda_BatchNormInference_798(float* input0, float* input1, float* input2, float* input3, float* input4, float* output0)
{
    const int st = blockIdx.x * 8 * 8;
    const int c_id = blockIdx.x % 320;
    #pragma unroll 1
    for (int i = threadIdx.x; i < 8 * 8; i += blockDim.x)
    {
        output0[st + i] = (input1[c_id] + (input0[c_id] * (input2[st + i] - input3[c_id]) / sqrtf(0.001 + input4[c_id])));
    }

}
extern void inception3_BatchNormInference_float_float_float_float_float_float_cuda_BatchNormInference_798_Call(const dim3 &grids, const dim3 &blocks, unsigned mem, cudaStream_t stream, float* input0, float* input1, float* input2, float* input3, float* input4, float* output0) {
    inception3_BatchNormInference_float_float_float_float_float_float_cuda_BatchNormInference_798<<<grids, blocks, mem, stream>>>(input0, input1, input2, input3, input4, output0);
}
// Node name:	Concat_616
// Description:	Concat
// Input:
//	- name: inception3_Relu_606_0	type: float	shape: Shape{64, 384, 17, 17}
//	- name: inception3_Relu_615_0	type: float	shape: Shape{64, 96, 17, 17}
//	- name: inception3_MaxPool_603_0	type: float	shape: Shape{64, 288, 17, 17}
// Output:
//	- name: inception3_Concat_616_0	type: float	shape: Shape{64, 768, 17, 17}
extern "C" __launch_bounds__(512) __global__ void inception3_Concat_float_float_float_float_cuda_Concat_616(float* input0, float* input1, float* input2, float* output0)
{
    uint32_t inputs_strides[] = {110976, 27744, 83232};
    uint32_t tid = blockIdx.x * blockDim.x + threadIdx.x;
    if(tid < 14204928)
    {
        uint32_t block_id = tid / 221952;
        uint32_t block_idx = tid % 221952;
        uint32_t output_idx = block_id * 221952 + block_idx;
        if(block_idx < inputs_strides[0])
        {
            output0[output_idx] = input0[block_id * inputs_strides[0] + block_idx];
            return;
        }
        block_idx -= inputs_strides[0];
        if(block_idx < inputs_strides[1])
        {
            output0[output_idx] = input1[block_id * inputs_strides[1] + block_idx];
            return;
        }
        block_idx -= inputs_strides[1];
        if(block_idx < inputs_strides[2])
        {
            output0[output_idx] = input2[block_id * inputs_strides[2] + block_idx];
            return;
        }
        block_idx -= inputs_strides[2];
    }

}
extern void inception3_Concat_float_float_float_float_cuda_Concat_616_Call(const dim3 &grids, const dim3 &blocks, unsigned mem, cudaStream_t stream, float* input0, float* input1, float* input2, float* output0) {
    inception3_Concat_float_float_float_float_cuda_Concat_616<<<grids, blocks, mem, stream>>>(input0, input1, input2, output0);
}
// Node name:	Convolution_496
// Description:	Convolution
// Input:
//	- name: inception3_Relu_494_0	type: float	shape: Shape{64, 32, 147, 147}
//	- name: inception3_Reshape_495_0	type: float	shape: Shape{64, 32, 3, 3}
// Output:
//	- name: inception3_Convolution_496_0	type: float	shape: Shape{64, 64, 147, 147}
void Convolution_float_float_float_cuda_lib_Convolution_496(cudnnHandle_t cudnn_handle, float* input0, float* input1, float* output0)
{
    cudnnTensorDescriptor_t tensor_desc_0;
    CUDNN_SAFE_CALL(cudnnCreateTensorDescriptor(&tensor_desc_0));
    CUDNN_SAFE_CALL(cudnnSetTensor4dDescriptor(tensor_desc_0, CUDNN_TENSOR_NCHW, CUDNN_DATA_FLOAT, 64, 32, 147, 147));
    cudnnTensorDescriptor_t tensor_desc_1;
    CUDNN_SAFE_CALL(cudnnCreateTensorDescriptor(&tensor_desc_1));
    CUDNN_SAFE_CALL(cudnnSetTensor4dDescriptor(tensor_desc_1, CUDNN_TENSOR_NCHW, CUDNN_DATA_FLOAT, 64, 64, 147, 147));
    cudnnFilterDescriptor_t filter_desc;
    CUDNN_SAFE_CALL(cudnnCreateFilterDescriptor(&filter_desc));
    CUDNN_SAFE_CALL(cudnnSetFilter4dDescriptor(filter_desc, CUDNN_DATA_FLOAT, CUDNN_TENSOR_NCHW, 64, 32, 3, 3));
    cudnnConvolutionDescriptor_t conv_desc;
    CUDNN_SAFE_CALL(cudnnCreateConvolutionDescriptor(&conv_desc));
    CUDNN_SAFE_CALL(cudnnSetConvolution2dDescriptor(conv_desc, 1, 1, 1, 1, 1, 1, CUDNN_CROSS_CORRELATION, CUDNN_DATA_FLOAT));

    static bool selected_algo = true;
    static cudnnConvolutionFwdAlgo_t conv_fwd_algo = CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM;

    if (!selected_algo) {
        int num_algos;
        int max_algos = 0;
        // cudnnGetConvolutionForwardAlgorithm_v7;
        CUDNN_SAFE_CALL(
            cudnnGetConvolutionForwardAlgorithmMaxCount(cudnn_handle, &max_algos));
        std::vector<cudnnConvolutionFwdAlgoPerf_t> results(max_algos);
        CUDNN_SAFE_CALL(cudnnFindConvolutionForwardAlgorithm(cudnn_handle,
                                                tensor_desc_0,
                                                filter_desc,
                                                conv_desc,
                                                tensor_desc_1,
                                                static_cast<int>(results.size()),
                                                &num_algos,
                                                results.data()));
        results.resize(num_algos);
        for (size_t i = 0; i != results.size(); ++i) {
            cudnnConvolutionFwdAlgoPerf_t const& result = results[i];
            if (result.status == CUDNN_STATUS_SUCCESS) {
                conv_fwd_algo = result.algo;
                break;
            }
        }
        selected_algo = true;
    }
    const float alpha = 1.0;
    const float beta = 0.0;
    static void *workspace_ptr_0 = NULL;
    static size_t workspace_size_in_bytes = 0;
    if (!workspace_ptr_0)
    {
        CUDNN_SAFE_CALL(cudnnGetConvolutionForwardWorkspaceSize(cudnn_handle, tensor_desc_0, filter_desc, conv_desc, tensor_desc_1, conv_fwd_algo, &workspace_size_in_bytes));
        CUDA_SAFE_CALL(cudaMalloc(&workspace_ptr_0, workspace_size_in_bytes));
    }
    CUDNN_SAFE_CALL(cudnnConvolutionForward(cudnn_handle, &alpha, tensor_desc_0, input0,filter_desc, input1, conv_desc, conv_fwd_algo, workspace_ptr_0, workspace_size_in_bytes, &beta, tensor_desc_1, output0));
    CUDNN_SAFE_CALL(cudnnDestroyTensorDescriptor(tensor_desc_0));
    CUDNN_SAFE_CALL(cudnnDestroyTensorDescriptor(tensor_desc_1));
    CUDNN_SAFE_CALL(cudnnDestroyFilterDescriptor(filter_desc));
    CUDNN_SAFE_CALL(cudnnDestroyConvolutionDescriptor(conv_desc));

}
// Node name:	Reshape_549
// Description:	Reshape
// Input:
//	- name: inception3_Constant_93_0	type: float	shape: Shape{1, 1, 256, 64}
// Output:
//	- name: inception3_Reshape_549_0	type: float	shape: Shape{64, 256, 1, 1}
extern "C" __launch_bounds__(256) __global__ void inception3_Reshape_float_float_cuda_Reshape_549(float* input0, float* output0)
{
    uint32_t input_strides0 = 64;
    uint32_t input_strides1 = 1;
    uint32_t trans_strides0 = 1;
    uint32_t trans_strides1 = 256;
    size_t nx = 64;
    size_t ny = 256;
    __shared__ float tile[16][17];
    uint32_t base1 = blockIdx.x * blockDim.x;
    uint32_t base0 = blockIdx.y * blockDim.y;
    uint32_t tid1 = threadIdx.x;
    uint32_t tid0 = threadIdx.y;
    uint32_t idx1 = base1 + tid1;
    uint32_t idx0 = base0 + tid0;
    if (idx1 < nx && idx0 < ny)
    {
        uint32_t input_idx = 0;
        input_idx += input_strides0* idx0;
        input_idx += input_strides1* idx1;
        tile[tid0][tid1] = input0[input_idx];
    }
    idx1 = base1 + tid0;
    idx0 = base0 + tid1;
    __syncthreads();
    if (idx1 < nx && idx0 < ny)
    {
        uint32_t output_idx = 0;
        output_idx += trans_strides0* idx0;
        output_idx += trans_strides1* idx1;
        output0[output_idx] = tile[tid1][tid0];
    }

}
extern void inception3_Reshape_float_float_cuda_Reshape_549_Call(const dim3 &grids, const dim3 &blocks, unsigned mem, cudaStream_t stream, float* input0, float* output0) {
    inception3_Reshape_float_float_cuda_Reshape_549<<<grids, blocks, mem, stream>>>(input0, output0);
}
// Node name:	BatchNormInference_524
// Description:	BatchNormInference
// Input:
//	- name: inception3_Constant_58_0	type: float	shape: Shape{32}
//	- name: inception3_Constant_59_0	type: float	shape: Shape{32}
//	- name: inception3_Convolution_520_0	type: float	shape: Shape{64, 32, 35, 35}
//	- name: inception3_Constant_60_0	type: float	shape: Shape{32}
//	- name: inception3_Constant_61_0	type: float	shape: Shape{32}
// Output:
//	- name: inception3_BatchNormInference_524_0	type: float	shape: Shape{64, 32, 35, 35}
extern "C" __launch_bounds__(512) __global__ void inception3_BatchNormInference_float_float_float_float_float_float_cuda_BatchNormInference_524(float* input0, float* input1, float* input2, float* input3, float* input4, float* output0)
{
    const int st = blockIdx.x * 35 * 35;
    const int c_id = blockIdx.x % 32;
    #pragma unroll 1
    for (int i = threadIdx.x; i < 35 * 35; i += blockDim.x)
    {
        output0[st + i] = (input1[c_id] + (input0[c_id] * (input2[st + i] - input3[c_id]) / sqrtf(0.001 + input4[c_id])));
    }

}
extern void inception3_BatchNormInference_float_float_float_float_float_float_cuda_BatchNormInference_524_Call(const dim3 &grids, const dim3 &blocks, unsigned mem, cudaStream_t stream, float* input0, float* input1, float* input2, float* input3, float* input4, float* output0) {
    inception3_BatchNormInference_float_float_float_float_float_float_cuda_BatchNormInference_524<<<grids, blocks, mem, stream>>>(input0, input1, input2, input3, input4, output0);
}
// Node name:	Convolution_550
// Description:	Convolution
// Input:
//	- name: inception3_AvgPool_545_0	type: float	shape: Shape{64, 256, 35, 35}
//	- name: inception3_Reshape_549_0	type: float	shape: Shape{64, 256, 1, 1}
// Output:
//	- name: inception3_Convolution_550_0	type: float	shape: Shape{64, 64, 35, 35}
void Convolution_float_float_float_cuda_lib_Convolution_550(cudnnHandle_t cudnn_handle, float* input0, float* input1, float* output0)
{
    cudnnTensorDescriptor_t tensor_desc_0;
    CUDNN_SAFE_CALL(cudnnCreateTensorDescriptor(&tensor_desc_0));
    CUDNN_SAFE_CALL(cudnnSetTensor4dDescriptor(tensor_desc_0, CUDNN_TENSOR_NCHW, CUDNN_DATA_FLOAT, 64, 256, 35, 35));
    cudnnTensorDescriptor_t tensor_desc_1;
    CUDNN_SAFE_CALL(cudnnCreateTensorDescriptor(&tensor_desc_1));
    CUDNN_SAFE_CALL(cudnnSetTensor4dDescriptor(tensor_desc_1, CUDNN_TENSOR_NCHW, CUDNN_DATA_FLOAT, 64, 64, 35, 35));
    cudnnFilterDescriptor_t filter_desc;
    CUDNN_SAFE_CALL(cudnnCreateFilterDescriptor(&filter_desc));
    CUDNN_SAFE_CALL(cudnnSetFilter4dDescriptor(filter_desc, CUDNN_DATA_FLOAT, CUDNN_TENSOR_NCHW, 64, 256, 1, 1));
    cudnnConvolutionDescriptor_t conv_desc;
    CUDNN_SAFE_CALL(cudnnCreateConvolutionDescriptor(&conv_desc));
    CUDNN_SAFE_CALL(cudnnSetConvolution2dDescriptor(conv_desc, 0, 0, 1, 1, 1, 1, CUDNN_CROSS_CORRELATION, CUDNN_DATA_FLOAT));

    static bool selected_algo = true;
    static cudnnConvolutionFwdAlgo_t conv_fwd_algo = CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM;

    if (!selected_algo) {
        int num_algos;
        int max_algos = 0;
        // cudnnGetConvolutionForwardAlgorithm_v7;
        CUDNN_SAFE_CALL(
            cudnnGetConvolutionForwardAlgorithmMaxCount(cudnn_handle, &max_algos));
        std::vector<cudnnConvolutionFwdAlgoPerf_t> results(max_algos);
        CUDNN_SAFE_CALL(cudnnFindConvolutionForwardAlgorithm(cudnn_handle,
                                                tensor_desc_0,
                                                filter_desc,
                                                conv_desc,
                                                tensor_desc_1,
                                                static_cast<int>(results.size()),
                                                &num_algos,
                                                results.data()));
        results.resize(num_algos);
        for (size_t i = 0; i != results.size(); ++i) {
            cudnnConvolutionFwdAlgoPerf_t const& result = results[i];
            if (result.status == CUDNN_STATUS_SUCCESS) {
                conv_fwd_algo = result.algo;
                break;
            }
        }
        selected_algo = true;
    }
    const float alpha = 1.0;
    const float beta = 0.0;
    static void *workspace_ptr_0 = NULL;
    static size_t workspace_size_in_bytes = 0;
    if (!workspace_ptr_0)
    {
        CUDNN_SAFE_CALL(cudnnGetConvolutionForwardWorkspaceSize(cudnn_handle, tensor_desc_0, filter_desc, conv_desc, tensor_desc_1, conv_fwd_algo, &workspace_size_in_bytes));
        CUDA_SAFE_CALL(cudaMalloc(&workspace_ptr_0, workspace_size_in_bytes));
    }
    CUDNN_SAFE_CALL(cudnnConvolutionForward(cudnn_handle, &alpha, tensor_desc_0, input0,filter_desc, input1, conv_desc, conv_fwd_algo, workspace_ptr_0, workspace_size_in_bytes, &beta, tensor_desc_1, output0));
    CUDNN_SAFE_CALL(cudnnDestroyTensorDescriptor(tensor_desc_0));
    CUDNN_SAFE_CALL(cudnnDestroyTensorDescriptor(tensor_desc_1));
    CUDNN_SAFE_CALL(cudnnDestroyFilterDescriptor(filter_desc));
    CUDNN_SAFE_CALL(cudnnDestroyConvolutionDescriptor(conv_desc));

}
// Node name:	Reshape_541
// Description:	Reshape
// Input:
//	- name: inception3_Constant_68_0	type: float	shape: Shape{1, 1, 256, 48}
// Output:
//	- name: inception3_Reshape_541_0	type: float	shape: Shape{48, 256, 1, 1}
extern "C" __launch_bounds__(256) __global__ void inception3_Reshape_float_float_cuda_Reshape_541(float* input0, float* output0)
{
    uint32_t input_strides0 = 48;
    uint32_t input_strides1 = 1;
    uint32_t trans_strides0 = 1;
    uint32_t trans_strides1 = 256;
    size_t nx = 48;
    size_t ny = 256;
    __shared__ float tile[16][17];
    uint32_t base1 = blockIdx.x * blockDim.x;
    uint32_t base0 = blockIdx.y * blockDim.y;
    uint32_t tid1 = threadIdx.x;
    uint32_t tid0 = threadIdx.y;
    uint32_t idx1 = base1 + tid1;
    uint32_t idx0 = base0 + tid0;
    if (idx1 < nx && idx0 < ny)
    {
        uint32_t input_idx = 0;
        input_idx += input_strides0* idx0;
        input_idx += input_strides1* idx1;
        tile[tid0][tid1] = input0[input_idx];
    }
    idx1 = base1 + tid0;
    idx0 = base0 + tid1;
    __syncthreads();
    if (idx1 < nx && idx0 < ny)
    {
        uint32_t output_idx = 0;
        output_idx += trans_strides0* idx0;
        output_idx += trans_strides1* idx1;
        output0[output_idx] = tile[tid1][tid0];
    }

}
extern void inception3_Reshape_float_float_cuda_Reshape_541_Call(const dim3 &grids, const dim3 &blocks, unsigned mem, cudaStream_t stream, float* input0, float* output0) {
    inception3_Reshape_float_float_cuda_Reshape_541<<<grids, blocks, mem, stream>>>(input0, output0);
}
// Node name:	Convolution_542
// Description:	Convolution
// Input:
//	- name: inception3_Concat_538_0	type: float	shape: Shape{64, 256, 35, 35}
//	- name: inception3_Reshape_541_0	type: float	shape: Shape{48, 256, 1, 1}
// Output:
//	- name: inception3_Convolution_542_0	type: float	shape: Shape{64, 48, 35, 35}
void Convolution_float_float_float_cuda_lib_Convolution_542(cudnnHandle_t cudnn_handle, float* input0, float* input1, float* output0)
{
    cudnnTensorDescriptor_t tensor_desc_0;
    CUDNN_SAFE_CALL(cudnnCreateTensorDescriptor(&tensor_desc_0));
    CUDNN_SAFE_CALL(cudnnSetTensor4dDescriptor(tensor_desc_0, CUDNN_TENSOR_NCHW, CUDNN_DATA_FLOAT, 64, 256, 35, 35));
    cudnnTensorDescriptor_t tensor_desc_1;
    CUDNN_SAFE_CALL(cudnnCreateTensorDescriptor(&tensor_desc_1));
    CUDNN_SAFE_CALL(cudnnSetTensor4dDescriptor(tensor_desc_1, CUDNN_TENSOR_NCHW, CUDNN_DATA_FLOAT, 64, 48, 35, 35));
    cudnnFilterDescriptor_t filter_desc;
    CUDNN_SAFE_CALL(cudnnCreateFilterDescriptor(&filter_desc));
    CUDNN_SAFE_CALL(cudnnSetFilter4dDescriptor(filter_desc, CUDNN_DATA_FLOAT, CUDNN_TENSOR_NCHW, 48, 256, 1, 1));
    cudnnConvolutionDescriptor_t conv_desc;
    CUDNN_SAFE_CALL(cudnnCreateConvolutionDescriptor(&conv_desc));
    CUDNN_SAFE_CALL(cudnnSetConvolution2dDescriptor(conv_desc, 0, 0, 1, 1, 1, 1, CUDNN_CROSS_CORRELATION, CUDNN_DATA_FLOAT));

    static bool selected_algo = true;
    static cudnnConvolutionFwdAlgo_t conv_fwd_algo = CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM;

    if (!selected_algo) {
        int num_algos;
        int max_algos = 0;
        // cudnnGetConvolutionForwardAlgorithm_v7;
        CUDNN_SAFE_CALL(
            cudnnGetConvolutionForwardAlgorithmMaxCount(cudnn_handle, &max_algos));
        std::vector<cudnnConvolutionFwdAlgoPerf_t> results(max_algos);
        CUDNN_SAFE_CALL(cudnnFindConvolutionForwardAlgorithm(cudnn_handle,
                                                tensor_desc_0,
                                                filter_desc,
                                                conv_desc,
                                                tensor_desc_1,
                                                static_cast<int>(results.size()),
                                                &num_algos,
                                                results.data()));
        results.resize(num_algos);
        for (size_t i = 0; i != results.size(); ++i) {
            cudnnConvolutionFwdAlgoPerf_t const& result = results[i];
            if (result.status == CUDNN_STATUS_SUCCESS) {
                conv_fwd_algo = result.algo;
                break;
            }
        }
        selected_algo = true;
    }
    const float alpha = 1.0;
    const float beta = 0.0;
    static void *workspace_ptr_0 = NULL;
    static size_t workspace_size_in_bytes = 0;
    if (!workspace_ptr_0)
    {
        CUDNN_SAFE_CALL(cudnnGetConvolutionForwardWorkspaceSize(cudnn_handle, tensor_desc_0, filter_desc, conv_desc, tensor_desc_1, conv_fwd_algo, &workspace_size_in_bytes));
        CUDA_SAFE_CALL(cudaMalloc(&workspace_ptr_0, workspace_size_in_bytes));
    }
    CUDNN_SAFE_CALL(cudnnConvolutionForward(cudnn_handle, &alpha, tensor_desc_0, input0,filter_desc, input1, conv_desc, conv_fwd_algo, workspace_ptr_0, workspace_size_in_bytes, &beta, tensor_desc_1, output0));
    CUDNN_SAFE_CALL(cudnnDestroyTensorDescriptor(tensor_desc_0));
    CUDNN_SAFE_CALL(cudnnDestroyTensorDescriptor(tensor_desc_1));
    CUDNN_SAFE_CALL(cudnnDestroyFilterDescriptor(filter_desc));
    CUDNN_SAFE_CALL(cudnnDestroyConvolutionDescriptor(conv_desc));

}
// Node name:	Reshape_821
// Description:	Reshape
// Input:
//	- name: inception3_Constant_431_0	type: float	shape: Shape{1, 1, 1280, 192}
// Output:
//	- name: inception3_Reshape_821_0	type: float	shape: Shape{192, 1280, 1, 1}
extern "C" __launch_bounds__(256) __global__ void inception3_Reshape_float_float_cuda_Reshape_821(float* input0, float* output0)
{
    uint32_t input_strides0 = 192;
    uint32_t input_strides1 = 1;
    uint32_t trans_strides0 = 1;
    uint32_t trans_strides1 = 1280;
    size_t nx = 192;
    size_t ny = 1280;
    __shared__ float tile[16][17];
    uint32_t base1 = blockIdx.x * blockDim.x;
    uint32_t base0 = blockIdx.y * blockDim.y;
    uint32_t tid1 = threadIdx.x;
    uint32_t tid0 = threadIdx.y;
    uint32_t idx1 = base1 + tid1;
    uint32_t idx0 = base0 + tid0;
    if (idx1 < nx && idx0 < ny)
    {
        uint32_t input_idx = 0;
        input_idx += input_strides0* idx0;
        input_idx += input_strides1* idx1;
        tile[tid0][tid1] = input0[input_idx];
    }
    idx1 = base1 + tid0;
    idx0 = base0 + tid1;
    __syncthreads();
    if (idx1 < nx && idx0 < ny)
    {
        uint32_t output_idx = 0;
        output_idx += trans_strides0* idx0;
        output_idx += trans_strides1* idx1;
        output0[output_idx] = tile[tid1][tid0];
    }

}
extern void inception3_Reshape_float_float_cuda_Reshape_821_Call(const dim3 &grids, const dim3 &blocks, unsigned mem, cudaStream_t stream, float* input0, float* output0) {
    inception3_Reshape_float_float_cuda_Reshape_821<<<grids, blocks, mem, stream>>>(input0, output0);
}
// Node name:	Convolution_501
// Description:	Convolution
// Input:
//	- name: inception3_MaxPool_499_0	type: float	shape: Shape{64, 64, 73, 73}
//	- name: inception3_Reshape_500_0	type: float	shape: Shape{80, 64, 1, 1}
// Output:
//	- name: inception3_Convolution_501_0	type: float	shape: Shape{64, 80, 73, 73}
void Convolution_float_float_float_cuda_lib_Convolution_501(cudnnHandle_t cudnn_handle, float* input0, float* input1, float* output0)
{
    cudnnTensorDescriptor_t tensor_desc_0;
    CUDNN_SAFE_CALL(cudnnCreateTensorDescriptor(&tensor_desc_0));
    CUDNN_SAFE_CALL(cudnnSetTensor4dDescriptor(tensor_desc_0, CUDNN_TENSOR_NCHW, CUDNN_DATA_FLOAT, 64, 64, 73, 73));
    cudnnTensorDescriptor_t tensor_desc_1;
    CUDNN_SAFE_CALL(cudnnCreateTensorDescriptor(&tensor_desc_1));
    CUDNN_SAFE_CALL(cudnnSetTensor4dDescriptor(tensor_desc_1, CUDNN_TENSOR_NCHW, CUDNN_DATA_FLOAT, 64, 80, 73, 73));
    cudnnFilterDescriptor_t filter_desc;
    CUDNN_SAFE_CALL(cudnnCreateFilterDescriptor(&filter_desc));
    CUDNN_SAFE_CALL(cudnnSetFilter4dDescriptor(filter_desc, CUDNN_DATA_FLOAT, CUDNN_TENSOR_NCHW, 80, 64, 1, 1));
    cudnnConvolutionDescriptor_t conv_desc;
    CUDNN_SAFE_CALL(cudnnCreateConvolutionDescriptor(&conv_desc));
    CUDNN_SAFE_CALL(cudnnSetConvolution2dDescriptor(conv_desc, 0, 0, 1, 1, 1, 1, CUDNN_CROSS_CORRELATION, CUDNN_DATA_FLOAT));

    static bool selected_algo = true;
    static cudnnConvolutionFwdAlgo_t conv_fwd_algo = CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM;

    if (!selected_algo) {
        int num_algos;
        int max_algos = 0;
        // cudnnGetConvolutionForwardAlgorithm_v7;
        CUDNN_SAFE_CALL(
            cudnnGetConvolutionForwardAlgorithmMaxCount(cudnn_handle, &max_algos));
        std::vector<cudnnConvolutionFwdAlgoPerf_t> results(max_algos);
        CUDNN_SAFE_CALL(cudnnFindConvolutionForwardAlgorithm(cudnn_handle,
                                                tensor_desc_0,
                                                filter_desc,
                                                conv_desc,
                                                tensor_desc_1,
                                                static_cast<int>(results.size()),
                                                &num_algos,
                                                results.data()));
        results.resize(num_algos);
        for (size_t i = 0; i != results.size(); ++i) {
            cudnnConvolutionFwdAlgoPerf_t const& result = results[i];
            if (result.status == CUDNN_STATUS_SUCCESS) {
                conv_fwd_algo = result.algo;
                break;
            }
        }
        selected_algo = true;
    }
    const float alpha = 1.0;
    const float beta = 0.0;
    static void *workspace_ptr_0 = NULL;
    static size_t workspace_size_in_bytes = 0;
    if (!workspace_ptr_0)
    {
        CUDNN_SAFE_CALL(cudnnGetConvolutionForwardWorkspaceSize(cudnn_handle, tensor_desc_0, filter_desc, conv_desc, tensor_desc_1, conv_fwd_algo, &workspace_size_in_bytes));
        CUDA_SAFE_CALL(cudaMalloc(&workspace_ptr_0, workspace_size_in_bytes));
    }
    CUDNN_SAFE_CALL(cudnnConvolutionForward(cudnn_handle, &alpha, tensor_desc_0, input0,filter_desc, input1, conv_desc, conv_fwd_algo, workspace_ptr_0, workspace_size_in_bytes, &beta, tensor_desc_1, output0));
    CUDNN_SAFE_CALL(cudnnDestroyTensorDescriptor(tensor_desc_0));
    CUDNN_SAFE_CALL(cudnnDestroyTensorDescriptor(tensor_desc_1));
    CUDNN_SAFE_CALL(cudnnDestroyFilterDescriptor(filter_desc));
    CUDNN_SAFE_CALL(cudnnDestroyConvolutionDescriptor(conv_desc));

}
// Node name:	Convolution_535
// Description:	Convolution
// Input:
//	- name: inception3_Relu_533_0	type: float	shape: Shape{64, 96, 35, 35}
//	- name: inception3_Reshape_534_0	type: float	shape: Shape{96, 96, 3, 3}
// Output:
//	- name: inception3_Convolution_535_0	type: float	shape: Shape{64, 96, 35, 35}
void Convolution_float_float_float_cuda_lib_Convolution_535(cudnnHandle_t cudnn_handle, float* input0, float* input1, float* output0)
{
    cudnnTensorDescriptor_t tensor_desc_0;
    CUDNN_SAFE_CALL(cudnnCreateTensorDescriptor(&tensor_desc_0));
    CUDNN_SAFE_CALL(cudnnSetTensor4dDescriptor(tensor_desc_0, CUDNN_TENSOR_NCHW, CUDNN_DATA_FLOAT, 64, 96, 35, 35));
    cudnnTensorDescriptor_t tensor_desc_1;
    CUDNN_SAFE_CALL(cudnnCreateTensorDescriptor(&tensor_desc_1));
    CUDNN_SAFE_CALL(cudnnSetTensor4dDescriptor(tensor_desc_1, CUDNN_TENSOR_NCHW, CUDNN_DATA_FLOAT, 64, 96, 35, 35));
    cudnnFilterDescriptor_t filter_desc;
    CUDNN_SAFE_CALL(cudnnCreateFilterDescriptor(&filter_desc));
    CUDNN_SAFE_CALL(cudnnSetFilter4dDescriptor(filter_desc, CUDNN_DATA_FLOAT, CUDNN_TENSOR_NCHW, 96, 96, 3, 3));
    cudnnConvolutionDescriptor_t conv_desc;
    CUDNN_SAFE_CALL(cudnnCreateConvolutionDescriptor(&conv_desc));
    CUDNN_SAFE_CALL(cudnnSetConvolution2dDescriptor(conv_desc, 1, 1, 1, 1, 1, 1, CUDNN_CROSS_CORRELATION, CUDNN_DATA_FLOAT));

    static bool selected_algo = true;
    static cudnnConvolutionFwdAlgo_t conv_fwd_algo = CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM;

    if (!selected_algo) {
        int num_algos;
        int max_algos = 0;
        // cudnnGetConvolutionForwardAlgorithm_v7;
        CUDNN_SAFE_CALL(
            cudnnGetConvolutionForwardAlgorithmMaxCount(cudnn_handle, &max_algos));
        std::vector<cudnnConvolutionFwdAlgoPerf_t> results(max_algos);
        CUDNN_SAFE_CALL(cudnnFindConvolutionForwardAlgorithm(cudnn_handle,
                                                tensor_desc_0,
                                                filter_desc,
                                                conv_desc,
                                                tensor_desc_1,
                                                static_cast<int>(results.size()),
                                                &num_algos,
                                                results.data()));
        results.resize(num_algos);
        for (size_t i = 0; i != results.size(); ++i) {
            cudnnConvolutionFwdAlgoPerf_t const& result = results[i];
            if (result.status == CUDNN_STATUS_SUCCESS) {
                conv_fwd_algo = result.algo;
                break;
            }
        }
        selected_algo = true;
    }
    const float alpha = 1.0;
    const float beta = 0.0;
    static void *workspace_ptr_0 = NULL;
    static size_t workspace_size_in_bytes = 0;
    if (!workspace_ptr_0)
    {
        CUDNN_SAFE_CALL(cudnnGetConvolutionForwardWorkspaceSize(cudnn_handle, tensor_desc_0, filter_desc, conv_desc, tensor_desc_1, conv_fwd_algo, &workspace_size_in_bytes));
        CUDA_SAFE_CALL(cudaMalloc(&workspace_ptr_0, workspace_size_in_bytes));
    }
    CUDNN_SAFE_CALL(cudnnConvolutionForward(cudnn_handle, &alpha, tensor_desc_0, input0,filter_desc, input1, conv_desc, conv_fwd_algo, workspace_ptr_0, workspace_size_in_bytes, &beta, tensor_desc_1, output0));
    CUDNN_SAFE_CALL(cudnnDestroyTensorDescriptor(tensor_desc_0));
    CUDNN_SAFE_CALL(cudnnDestroyTensorDescriptor(tensor_desc_1));
    CUDNN_SAFE_CALL(cudnnDestroyFilterDescriptor(filter_desc));
    CUDNN_SAFE_CALL(cudnnDestroyConvolutionDescriptor(conv_desc));

}
// Node name:	Reshape_579
// Description:	Reshape
// Input:
//	- name: inception3_Constant_129_0	type: float	shape: Shape{1, 1, 288, 64}
// Output:
//	- name: inception3_Reshape_579_0	type: float	shape: Shape{64, 288, 1, 1}
extern "C" __launch_bounds__(256) __global__ void inception3_Reshape_float_float_cuda_Reshape_579(float* input0, float* output0)
{
    uint32_t input_strides0 = 64;
    uint32_t input_strides1 = 1;
    uint32_t trans_strides0 = 1;
    uint32_t trans_strides1 = 288;
    size_t nx = 64;
    size_t ny = 288;
    __shared__ float tile[16][17];
    uint32_t base1 = blockIdx.x * blockDim.x;
    uint32_t base0 = blockIdx.y * blockDim.y;
    uint32_t tid1 = threadIdx.x;
    uint32_t tid0 = threadIdx.y;
    uint32_t idx1 = base1 + tid1;
    uint32_t idx0 = base0 + tid0;
    if (idx1 < nx && idx0 < ny)
    {
        uint32_t input_idx = 0;
        input_idx += input_strides0* idx0;
        input_idx += input_strides1* idx1;
        tile[tid0][tid1] = input0[input_idx];
    }
    idx1 = base1 + tid0;
    idx0 = base0 + tid1;
    __syncthreads();
    if (idx1 < nx && idx0 < ny)
    {
        uint32_t output_idx = 0;
        output_idx += trans_strides0* idx0;
        output_idx += trans_strides1* idx1;
        output0[output_idx] = tile[tid1][tid0];
    }

}
extern void inception3_Reshape_float_float_cuda_Reshape_579_Call(const dim3 &grids, const dim3 &blocks, unsigned mem, cudaStream_t stream, float* input0, float* output0) {
    inception3_Reshape_float_float_cuda_Reshape_579<<<grids, blocks, mem, stream>>>(input0, output0);
}
// Node name:	Convolution_572
// Description:	Convolution
// Input:
//	- name: inception3_Concat_568_0	type: float	shape: Shape{64, 288, 35, 35}
//	- name: inception3_Reshape_571_0	type: float	shape: Shape{48, 288, 1, 1}
// Output:
//	- name: inception3_Convolution_572_0	type: float	shape: Shape{64, 48, 35, 35}
void Convolution_float_float_float_cuda_lib_Convolution_572(cudnnHandle_t cudnn_handle, float* input0, float* input1, float* output0)
{
    cudnnTensorDescriptor_t tensor_desc_0;
    CUDNN_SAFE_CALL(cudnnCreateTensorDescriptor(&tensor_desc_0));
    CUDNN_SAFE_CALL(cudnnSetTensor4dDescriptor(tensor_desc_0, CUDNN_TENSOR_NCHW, CUDNN_DATA_FLOAT, 64, 288, 35, 35));
    cudnnTensorDescriptor_t tensor_desc_1;
    CUDNN_SAFE_CALL(cudnnCreateTensorDescriptor(&tensor_desc_1));
    CUDNN_SAFE_CALL(cudnnSetTensor4dDescriptor(tensor_desc_1, CUDNN_TENSOR_NCHW, CUDNN_DATA_FLOAT, 64, 48, 35, 35));
    cudnnFilterDescriptor_t filter_desc;
    CUDNN_SAFE_CALL(cudnnCreateFilterDescriptor(&filter_desc));
    CUDNN_SAFE_CALL(cudnnSetFilter4dDescriptor(filter_desc, CUDNN_DATA_FLOAT, CUDNN_TENSOR_NCHW, 48, 288, 1, 1));
    cudnnConvolutionDescriptor_t conv_desc;
    CUDNN_SAFE_CALL(cudnnCreateConvolutionDescriptor(&conv_desc));
    CUDNN_SAFE_CALL(cudnnSetConvolution2dDescriptor(conv_desc, 0, 0, 1, 1, 1, 1, CUDNN_CROSS_CORRELATION, CUDNN_DATA_FLOAT));

    static bool selected_algo = true;
    static cudnnConvolutionFwdAlgo_t conv_fwd_algo = CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM;

    if (!selected_algo) {
        int num_algos;
        int max_algos = 0;
        // cudnnGetConvolutionForwardAlgorithm_v7;
        CUDNN_SAFE_CALL(
            cudnnGetConvolutionForwardAlgorithmMaxCount(cudnn_handle, &max_algos));
        std::vector<cudnnConvolutionFwdAlgoPerf_t> results(max_algos);
        CUDNN_SAFE_CALL(cudnnFindConvolutionForwardAlgorithm(cudnn_handle,
                                                tensor_desc_0,
                                                filter_desc,
                                                conv_desc,
                                                tensor_desc_1,
                                                static_cast<int>(results.size()),
                                                &num_algos,
                                                results.data()));
        results.resize(num_algos);
        for (size_t i = 0; i != results.size(); ++i) {
            cudnnConvolutionFwdAlgoPerf_t const& result = results[i];
            if (result.status == CUDNN_STATUS_SUCCESS) {
                conv_fwd_algo = result.algo;
                break;
            }
        }
        selected_algo = true;
    }
    const float alpha = 1.0;
    const float beta = 0.0;
    static void *workspace_ptr_0 = NULL;
    static size_t workspace_size_in_bytes = 0;
    if (!workspace_ptr_0)
    {
        CUDNN_SAFE_CALL(cudnnGetConvolutionForwardWorkspaceSize(cudnn_handle, tensor_desc_0, filter_desc, conv_desc, tensor_desc_1, conv_fwd_algo, &workspace_size_in_bytes));
        CUDA_SAFE_CALL(cudaMalloc(&workspace_ptr_0, workspace_size_in_bytes));
    }
    CUDNN_SAFE_CALL(cudnnConvolutionForward(cudnn_handle, &alpha, tensor_desc_0, input0,filter_desc, input1, conv_desc, conv_fwd_algo, workspace_ptr_0, workspace_size_in_bytes, &beta, tensor_desc_1, output0));
    CUDNN_SAFE_CALL(cudnnDestroyTensorDescriptor(tensor_desc_0));
    CUDNN_SAFE_CALL(cudnnDestroyTensorDescriptor(tensor_desc_1));
    CUDNN_SAFE_CALL(cudnnDestroyFilterDescriptor(filter_desc));
    CUDNN_SAFE_CALL(cudnnDestroyConvolutionDescriptor(conv_desc));

}
// Node name:	BatchNormInference_614
// Description:	BatchNormInference
// Input:
//	- name: inception3_Constant_151_0	type: float	shape: Shape{96}
//	- name: inception3_Constant_152_0	type: float	shape: Shape{96}
//	- name: inception3_Convolution_613_0	type: float	shape: Shape{64, 96, 17, 17}
//	- name: inception3_Constant_153_0	type: float	shape: Shape{96}
//	- name: inception3_Constant_154_0	type: float	shape: Shape{96}
// Output:
//	- name: inception3_BatchNormInference_614_0	type: float	shape: Shape{64, 96, 17, 17}
extern "C" __launch_bounds__(289) __global__ void inception3_BatchNormInference_float_float_float_float_float_float_cuda_BatchNormInference_614(float* input0, float* input1, float* input2, float* input3, float* input4, float* output0)
{
    const int st = blockIdx.x * 17 * 17;
    const int c_id = blockIdx.x % 96;
    #pragma unroll 1
    for (int i = threadIdx.x; i < 17 * 17; i += blockDim.x)
    {
        output0[st + i] = (input1[c_id] + (input0[c_id] * (input2[st + i] - input3[c_id]) / sqrtf(0.001 + input4[c_id])));
    }

}
extern void inception3_BatchNormInference_float_float_float_float_float_float_cuda_BatchNormInference_614_Call(const dim3 &grids, const dim3 &blocks, unsigned mem, cudaStream_t stream, float* input0, float* input1, float* input2, float* input3, float* input4, float* output0) {
    inception3_BatchNormInference_float_float_float_float_float_float_cuda_BatchNormInference_614<<<grids, blocks, mem, stream>>>(input0, input1, input2, input3, input4, output0);
}
// Node name:	Reshape_599
// Description:	Reshape
// Input:
//	- name: inception3_Constant_135_0	type: float	shape: Shape{3, 3, 288, 384}
// Output:
//	- name: inception3_Reshape_599_0	type: float	shape: Shape{384, 288, 3, 3}
extern "C" __launch_bounds__(256) __global__ void inception3_Reshape_float_float_cuda_Reshape_599(float* input0, float* output0)
{
    uint32_t input_strides0 = 110592;
    uint32_t input_strides1 = 384;
    uint32_t input_strides2 = 1;
    uint32_t trans_strides0 = 1;
    uint32_t trans_strides1 = 9;
    uint32_t trans_strides2 = 2592;
    size_t nx = 384;
    size_t ny = 288;
    size_t nz = 9;
    __shared__ float tile[16][1][17];
    uint32_t base2 = blockIdx.x * blockDim.x;
    uint32_t base1 = blockIdx.y * blockDim.y;
    uint32_t base0 = blockIdx.z * blockDim.z;
    uint32_t tid2 = threadIdx.x;
    uint32_t tid1 = threadIdx.y;
    uint32_t tid0 = threadIdx.z;
    uint32_t otid2 = tid2;
    uint32_t otid1 = tid1;
    uint32_t otid0 = tid0;
    uint32_t idx2 = base2 + tid2;
    uint32_t idx1 = base1 + tid1;
    uint32_t idx0 = base0 + tid0;
    if (idx2 < nx && idx1 < ny && idx0 < nz)
    {
        uint32_t input_idx = 0;
        input_idx += input_strides0* idx0;
        input_idx += input_strides1* idx1;
        input_idx += input_strides2* idx2;
        tile[tid0][tid1][tid2] = input0[input_idx];
    }
    otid2 = tid0;
    otid0 = tid2;
    idx2 = base2 + otid2;
    idx1 = base1 + otid1;
    idx0 = base0 + otid0;
    __syncthreads();
    if (idx2 < nx && idx1 < ny && idx0 < nz)
    {
        uint32_t output_idx = 0;
        output_idx += trans_strides0* idx0;
        output_idx += trans_strides1* idx1;
        output_idx += trans_strides2* idx2;
        output0[output_idx] = tile[otid0][otid1][otid2];
    }

}
extern void inception3_Reshape_float_float_cuda_Reshape_599_Call(const dim3 &grids, const dim3 &blocks, unsigned mem, cudaStream_t stream, float* input0, float* output0) {
    inception3_Reshape_float_float_cuda_Reshape_599<<<grids, blocks, mem, stream>>>(input0, output0);
}
// Node name:	Reshape_761
// Description:	Reshape
// Input:
//	- name: inception3_Constant_334_0	type: float	shape: Shape{7, 1, 192, 192}
// Output:
//	- name: inception3_Reshape_761_0	type: float	shape: Shape{192, 192, 7, 1}
extern "C" __launch_bounds__(256) __global__ void inception3_Reshape_float_float_cuda_Reshape_761(float* input0, float* output0)
{
    uint32_t input_strides0 = 36864;
    uint32_t input_strides1 = 192;
    uint32_t input_strides2 = 1;
    uint32_t trans_strides0 = 1;
    uint32_t trans_strides1 = 7;
    uint32_t trans_strides2 = 1344;
    size_t nx = 192;
    size_t ny = 192;
    size_t nz = 7;
    __shared__ float tile[16][1][17];
    uint32_t base2 = blockIdx.x * blockDim.x;
    uint32_t base1 = blockIdx.y * blockDim.y;
    uint32_t base0 = blockIdx.z * blockDim.z;
    uint32_t tid2 = threadIdx.x;
    uint32_t tid1 = threadIdx.y;
    uint32_t tid0 = threadIdx.z;
    uint32_t otid2 = tid2;
    uint32_t otid1 = tid1;
    uint32_t otid0 = tid0;
    uint32_t idx2 = base2 + tid2;
    uint32_t idx1 = base1 + tid1;
    uint32_t idx0 = base0 + tid0;
    if (idx2 < nx && idx1 < ny && idx0 < nz)
    {
        uint32_t input_idx = 0;
        input_idx += input_strides0* idx0;
        input_idx += input_strides1* idx1;
        input_idx += input_strides2* idx2;
        tile[tid0][tid1][tid2] = input0[input_idx];
    }
    otid2 = tid0;
    otid0 = tid2;
    idx2 = base2 + otid2;
    idx1 = base1 + otid1;
    idx0 = base0 + otid0;
    __syncthreads();
    if (idx2 < nx && idx1 < ny && idx0 < nz)
    {
        uint32_t output_idx = 0;
        output_idx += trans_strides0* idx0;
        output_idx += trans_strides1* idx1;
        output_idx += trans_strides2* idx2;
        output0[output_idx] = tile[otid0][otid1][otid2];
    }

}
extern void inception3_Reshape_float_float_cuda_Reshape_761_Call(const dim3 &grids, const dim3 &blocks, unsigned mem, cudaStream_t stream, float* input0, float* output0) {
    inception3_Reshape_float_float_cuda_Reshape_761<<<grids, blocks, mem, stream>>>(input0, output0);
}
// Node name:	Reshape_813
// Description:	Reshape
// Input:
//	- name: inception3_Constant_396_0	type: float	shape: Shape{1, 1, 1280, 384}
// Output:
//	- name: inception3_Reshape_813_0	type: float	shape: Shape{384, 1280, 1, 1}
extern "C" __launch_bounds__(256) __global__ void inception3_Reshape_float_float_cuda_Reshape_813(float* input0, float* output0)
{
    uint32_t input_strides0 = 384;
    uint32_t input_strides1 = 1;
    uint32_t trans_strides0 = 1;
    uint32_t trans_strides1 = 1280;
    size_t nx = 384;
    size_t ny = 1280;
    __shared__ float tile[16][17];
    uint32_t base1 = blockIdx.x * blockDim.x;
    uint32_t base0 = blockIdx.y * blockDim.y;
    uint32_t tid1 = threadIdx.x;
    uint32_t tid0 = threadIdx.y;
    uint32_t idx1 = base1 + tid1;
    uint32_t idx0 = base0 + tid0;
    if (idx1 < nx && idx0 < ny)
    {
        uint32_t input_idx = 0;
        input_idx += input_strides0* idx0;
        input_idx += input_strides1* idx1;
        tile[tid0][tid1] = input0[input_idx];
    }
    idx1 = base1 + tid0;
    idx0 = base0 + tid1;
    __syncthreads();
    if (idx1 < nx && idx0 < ny)
    {
        uint32_t output_idx = 0;
        output_idx += trans_strides0* idx0;
        output_idx += trans_strides1* idx1;
        output0[output_idx] = tile[tid1][tid0];
    }

}
extern void inception3_Reshape_float_float_cuda_Reshape_813_Call(const dim3 &grids, const dim3 &blocks, unsigned mem, cudaStream_t stream, float* input0, float* output0) {
    inception3_Reshape_float_float_cuda_Reshape_813<<<grids, blocks, mem, stream>>>(input0, output0);
}
// Node name:	Convolution_613
// Description:	Convolution
// Input:
//	- name: inception3_Relu_611_0	type: float	shape: Shape{64, 96, 35, 35}
//	- name: inception3_Reshape_612_0	type: float	shape: Shape{96, 96, 3, 3}
// Output:
//	- name: inception3_Convolution_613_0	type: float	shape: Shape{64, 96, 17, 17}
void Convolution_float_float_float_cuda_lib_Convolution_613(cudnnHandle_t cudnn_handle, float* input0, float* input1, float* output0)
{
    cudnnTensorDescriptor_t tensor_desc_0;
    CUDNN_SAFE_CALL(cudnnCreateTensorDescriptor(&tensor_desc_0));
    CUDNN_SAFE_CALL(cudnnSetTensor4dDescriptor(tensor_desc_0, CUDNN_TENSOR_NCHW, CUDNN_DATA_FLOAT, 64, 96, 35, 35));
    cudnnTensorDescriptor_t tensor_desc_1;
    CUDNN_SAFE_CALL(cudnnCreateTensorDescriptor(&tensor_desc_1));
    CUDNN_SAFE_CALL(cudnnSetTensor4dDescriptor(tensor_desc_1, CUDNN_TENSOR_NCHW, CUDNN_DATA_FLOAT, 64, 96, 17, 17));
    cudnnFilterDescriptor_t filter_desc;
    CUDNN_SAFE_CALL(cudnnCreateFilterDescriptor(&filter_desc));
    CUDNN_SAFE_CALL(cudnnSetFilter4dDescriptor(filter_desc, CUDNN_DATA_FLOAT, CUDNN_TENSOR_NCHW, 96, 96, 3, 3));
    cudnnConvolutionDescriptor_t conv_desc;
    CUDNN_SAFE_CALL(cudnnCreateConvolutionDescriptor(&conv_desc));
    CUDNN_SAFE_CALL(cudnnSetConvolution2dDescriptor(conv_desc, 0, 0, 2, 2, 1, 1, CUDNN_CROSS_CORRELATION, CUDNN_DATA_FLOAT));

    static bool selected_algo = true;
    static cudnnConvolutionFwdAlgo_t conv_fwd_algo = CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM;

    if (!selected_algo) {
        int num_algos;
        int max_algos = 0;
        // cudnnGetConvolutionForwardAlgorithm_v7;
        CUDNN_SAFE_CALL(
            cudnnGetConvolutionForwardAlgorithmMaxCount(cudnn_handle, &max_algos));
        std::vector<cudnnConvolutionFwdAlgoPerf_t> results(max_algos);
        CUDNN_SAFE_CALL(cudnnFindConvolutionForwardAlgorithm(cudnn_handle,
                                                tensor_desc_0,
                                                filter_desc,
                                                conv_desc,
                                                tensor_desc_1,
                                                static_cast<int>(results.size()),
                                                &num_algos,
                                                results.data()));
        results.resize(num_algos);
        for (size_t i = 0; i != results.size(); ++i) {
            cudnnConvolutionFwdAlgoPerf_t const& result = results[i];
            if (result.status == CUDNN_STATUS_SUCCESS) {
                conv_fwd_algo = result.algo;
                break;
            }
        }
        selected_algo = true;
    }
    const float alpha = 1.0;
    const float beta = 0.0;
    static void *workspace_ptr_0 = NULL;
    static size_t workspace_size_in_bytes = 0;
    if (!workspace_ptr_0)
    {
        CUDNN_SAFE_CALL(cudnnGetConvolutionForwardWorkspaceSize(cudnn_handle, tensor_desc_0, filter_desc, conv_desc, tensor_desc_1, conv_fwd_algo, &workspace_size_in_bytes));
        CUDA_SAFE_CALL(cudaMalloc(&workspace_ptr_0, workspace_size_in_bytes));
    }
    CUDNN_SAFE_CALL(cudnnConvolutionForward(cudnn_handle, &alpha, tensor_desc_0, input0,filter_desc, input1, conv_desc, conv_fwd_algo, workspace_ptr_0, workspace_size_in_bytes, &beta, tensor_desc_1, output0));
    CUDNN_SAFE_CALL(cudnnDestroyTensorDescriptor(tensor_desc_0));
    CUDNN_SAFE_CALL(cudnnDestroyTensorDescriptor(tensor_desc_1));
    CUDNN_SAFE_CALL(cudnnDestroyFilterDescriptor(filter_desc));
    CUDNN_SAFE_CALL(cudnnDestroyConvolutionDescriptor(conv_desc));

}
// Node name:	BatchNormInference_836
// Description:	BatchNormInference
// Input:
//	- name: inception3_Constant_417_0	type: float	shape: Shape{384}
//	- name: inception3_Constant_418_0	type: float	shape: Shape{384}
//	- name: inception3_Convolution_832_0	type: float	shape: Shape{64, 384, 8, 8}
//	- name: inception3_Constant_419_0	type: float	shape: Shape{384}
//	- name: inception3_Constant_420_0	type: float	shape: Shape{384}
// Output:
//	- name: inception3_BatchNormInference_836_0	type: float	shape: Shape{64, 384, 8, 8}
extern "C" __launch_bounds__(64) __global__ void inception3_BatchNormInference_float_float_float_float_float_float_cuda_BatchNormInference_836(float* input0, float* input1, float* input2, float* input3, float* input4, float* output0)
{
    const int st = blockIdx.x * 8 * 8;
    const int c_id = blockIdx.x % 384;
    #pragma unroll 1
    for (int i = threadIdx.x; i < 8 * 8; i += blockDim.x)
    {
        output0[st + i] = (input1[c_id] + (input0[c_id] * (input2[st + i] - input3[c_id]) / sqrtf(0.001 + input4[c_id])));
    }

}
extern void inception3_BatchNormInference_float_float_float_float_float_float_cuda_BatchNormInference_836_Call(const dim3 &grids, const dim3 &blocks, unsigned mem, cudaStream_t stream, float* input0, float* input1, float* input2, float* input3, float* input4, float* output0) {
    inception3_BatchNormInference_float_float_float_float_float_float_cuda_BatchNormInference_836<<<grids, blocks, mem, stream>>>(input0, input1, input2, input3, input4, output0);
}
// Node name:	AvgPool_623
// Description:	AvgPool
// Input:
//	- name: inception3_Concat_616_0	type: float	shape: Shape{64, 768, 17, 17}
// Output:
//	- name: inception3_AvgPool_623_0	type: float	shape: Shape{64, 768, 17, 17}
void AvgPool_float_float_cuda_lib_AvgPool_623(cudnnHandle_t cudnn_handle, float* input0, float* output0)
{
    cudnnTensorDescriptor_t input_desc;
    CUDNN_SAFE_CALL(cudnnCreateTensorDescriptor(&input_desc));
    CUDNN_SAFE_CALL(cudnnSetTensor4dDescriptor(input_desc, CUDNN_TENSOR_NCHW, CUDNN_DATA_FLOAT, 64, 768, 17, 17));
    cudnnTensorDescriptor_t output_desc;
    CUDNN_SAFE_CALL(cudnnCreateTensorDescriptor(&output_desc));
    CUDNN_SAFE_CALL(cudnnSetTensor4dDescriptor(output_desc, CUDNN_TENSOR_NCHW, CUDNN_DATA_FLOAT, 64, 768, 17, 17));
    cudnnPoolingDescriptor_t desc;
    cudnnCreatePoolingDescriptor(&desc);
    CUDNN_SAFE_CALL(cudnnSetPooling2dDescriptor(desc, CUDNN_POOLING_AVERAGE_COUNT_EXCLUDE_PADDING, CUDNN_NOT_PROPAGATE_NAN,3, 3, 1, 1, 1, 1));
    const float alpha = 1.0;
    const float beta = 0.0;
    CUDNN_SAFE_CALL(cudnnPoolingForward(cudnn_handle, desc, &alpha, input_desc, input0, &beta, output_desc, output0));
    CUDNN_SAFE_CALL(cudnnDestroyTensorDescriptor(input_desc));
    CUDNN_SAFE_CALL(cudnnDestroyTensorDescriptor(output_desc));
    CUDNN_SAFE_CALL(cudnnDestroyPoolingDescriptor(desc));

}
// Node name:	Broadcast_890
// Description:	Broadcast
// Input:
//	- name: inception3_Constant_485_0	type: float	shape: Shape{1001}
// Output:
//	- name: inception3_Broadcast_890_0	type: float	shape: Shape{64, 1001}
extern "C" __launch_bounds__(64) __global__ void inception3_Broadcast_float_float_cuda_Broadcast_890(float* input0, float* output0)
{
    size_t nthreads = 64064;uint32_t strides0 = 1001;
    uint32_t strides1 = 1;
    int stride_magic0 = 1098413215;
    int stride_magic1 = 1;
    int stride_shift0 = 8;
    int stride_shift1 = 0;
    uint32_t reduced_strides0 = 0;
    uint32_t reduced_strides1 = 1;
    const int tid = blockDim.x*blockIdx.x + threadIdx.x;
    if (tid < nthreads)
    {
        int coordinate_product = tid;
        int coordinate0 = division_by_invariant_multiplication(coordinate_product, stride_magic0, stride_shift0);
        coordinate_product -= (coordinate0 * strides0);
        int coordinate1 = division_by_invariant_multiplication(coordinate_product, stride_magic1, stride_shift1);
        uint32_t reduced_idx = 0;
        reduced_idx += coordinate0 * reduced_strides0;
        reduced_idx += coordinate1 * reduced_strides1;
        output0[tid] = load(input0, reduced_idx);
    }

}
extern void inception3_Broadcast_float_float_cuda_Broadcast_890_Call(const dim3 &grids, const dim3 &blocks, unsigned mem, cudaStream_t stream, float* input0, float* output0) {
    inception3_Broadcast_float_float_cuda_Broadcast_890<<<grids, blocks, mem, stream>>>(input0, output0);
}
// Node name:	Reshape_627
// Description:	Reshape
// Input:
//	- name: inception3_Constant_201_0	type: float	shape: Shape{1, 1, 768, 192}
// Output:
//	- name: inception3_Reshape_627_0	type: float	shape: Shape{192, 768, 1, 1}
extern "C" __launch_bounds__(256) __global__ void inception3_Reshape_float_float_cuda_Reshape_627(float* input0, float* output0)
{
    uint32_t input_strides0 = 192;
    uint32_t input_strides1 = 1;
    uint32_t trans_strides0 = 1;
    uint32_t trans_strides1 = 768;
    size_t nx = 192;
    size_t ny = 768;
    __shared__ float tile[16][17];
    uint32_t base1 = blockIdx.x * blockDim.x;
    uint32_t base0 = blockIdx.y * blockDim.y;
    uint32_t tid1 = threadIdx.x;
    uint32_t tid0 = threadIdx.y;
    uint32_t idx1 = base1 + tid1;
    uint32_t idx0 = base0 + tid0;
    if (idx1 < nx && idx0 < ny)
    {
        uint32_t input_idx = 0;
        input_idx += input_strides0* idx0;
        input_idx += input_strides1* idx1;
        tile[tid0][tid1] = input0[input_idx];
    }
    idx1 = base1 + tid0;
    idx0 = base0 + tid1;
    __syncthreads();
    if (idx1 < nx && idx0 < ny)
    {
        uint32_t output_idx = 0;
        output_idx += trans_strides0* idx0;
        output_idx += trans_strides1* idx1;
        output0[output_idx] = tile[tid1][tid0];
    }

}
extern void inception3_Reshape_float_float_cuda_Reshape_627_Call(const dim3 &grids, const dim3 &blocks, unsigned mem, cudaStream_t stream, float* input0, float* output0) {
    inception3_Reshape_float_float_cuda_Reshape_627<<<grids, blocks, mem, stream>>>(input0, output0);
}
// Node name:	BatchNormInference_632
// Description:	BatchNormInference
// Input:
//	- name: inception3_Constant_202_0	type: float	shape: Shape{192}
//	- name: inception3_Constant_203_0	type: float	shape: Shape{192}
//	- name: inception3_Convolution_628_0	type: float	shape: Shape{64, 192, 17, 17}
//	- name: inception3_Constant_204_0	type: float	shape: Shape{192}
//	- name: inception3_Constant_205_0	type: float	shape: Shape{192}
// Output:
//	- name: inception3_BatchNormInference_632_0	type: float	shape: Shape{64, 192, 17, 17}
extern "C" __launch_bounds__(289) __global__ void inception3_BatchNormInference_float_float_float_float_float_float_cuda_BatchNormInference_632(float* input0, float* input1, float* input2, float* input3, float* input4, float* output0)
{
    const int st = blockIdx.x * 17 * 17;
    const int c_id = blockIdx.x % 192;
    #pragma unroll 1
    for (int i = threadIdx.x; i < 17 * 17; i += blockDim.x)
    {
        output0[st + i] = (input1[c_id] + (input0[c_id] * (input2[st + i] - input3[c_id]) / sqrtf(0.001 + input4[c_id])));
    }

}
extern void inception3_BatchNormInference_float_float_float_float_float_float_cuda_BatchNormInference_632_Call(const dim3 &grids, const dim3 &blocks, unsigned mem, cudaStream_t stream, float* input0, float* input1, float* input2, float* input3, float* input4, float* output0) {
    inception3_BatchNormInference_float_float_float_float_float_float_cuda_BatchNormInference_632<<<grids, blocks, mem, stream>>>(input0, input1, input2, input3, input4, output0);
}
// Node name:	Reshape_842
// Description:	Reshape
// Input:
//	- name: inception3_Constant_426_0	type: float	shape: Shape{3, 1, 384, 384}
// Output:
//	- name: inception3_Reshape_842_0	type: float	shape: Shape{384, 384, 3, 1}
extern "C" __launch_bounds__(256) __global__ void inception3_Reshape_float_float_cuda_Reshape_842(float* input0, float* output0)
{
    uint32_t input_strides0 = 147456;
    uint32_t input_strides1 = 384;
    uint32_t input_strides2 = 1;
    uint32_t trans_strides0 = 1;
    uint32_t trans_strides1 = 3;
    uint32_t trans_strides2 = 1152;
    size_t nx = 384;
    size_t ny = 384;
    size_t nz = 3;
    __shared__ float tile[16][1][17];
    uint32_t base2 = blockIdx.x * blockDim.x;
    uint32_t base1 = blockIdx.y * blockDim.y;
    uint32_t base0 = blockIdx.z * blockDim.z;
    uint32_t tid2 = threadIdx.x;
    uint32_t tid1 = threadIdx.y;
    uint32_t tid0 = threadIdx.z;
    uint32_t otid2 = tid2;
    uint32_t otid1 = tid1;
    uint32_t otid0 = tid0;
    uint32_t idx2 = base2 + tid2;
    uint32_t idx1 = base1 + tid1;
    uint32_t idx0 = base0 + tid0;
    if (idx2 < nx && idx1 < ny && idx0 < nz)
    {
        uint32_t input_idx = 0;
        input_idx += input_strides0* idx0;
        input_idx += input_strides1* idx1;
        input_idx += input_strides2* idx2;
        tile[tid0][tid1][tid2] = input0[input_idx];
    }
    otid2 = tid0;
    otid0 = tid2;
    idx2 = base2 + otid2;
    idx1 = base1 + otid1;
    idx0 = base0 + otid0;
    __syncthreads();
    if (idx2 < nx && idx1 < ny && idx0 < nz)
    {
        uint32_t output_idx = 0;
        output_idx += trans_strides0* idx0;
        output_idx += trans_strides1* idx1;
        output_idx += trans_strides2* idx2;
        output0[output_idx] = tile[otid0][otid1][otid2];
    }

}
extern void inception3_Reshape_float_float_cuda_Reshape_842_Call(const dim3 &grids, const dim3 &blocks, unsigned mem, cudaStream_t stream, float* input0, float* output0) {
    inception3_Reshape_float_float_cuda_Reshape_842<<<grids, blocks, mem, stream>>>(input0, output0);
}
// Node name:	Reshape_571
// Description:	Reshape
// Input:
//	- name: inception3_Constant_104_0	type: float	shape: Shape{1, 1, 288, 48}
// Output:
//	- name: inception3_Reshape_571_0	type: float	shape: Shape{48, 288, 1, 1}
extern "C" __launch_bounds__(256) __global__ void inception3_Reshape_float_float_cuda_Reshape_571(float* input0, float* output0)
{
    uint32_t input_strides0 = 48;
    uint32_t input_strides1 = 1;
    uint32_t trans_strides0 = 1;
    uint32_t trans_strides1 = 288;
    size_t nx = 48;
    size_t ny = 288;
    __shared__ float tile[16][17];
    uint32_t base1 = blockIdx.x * blockDim.x;
    uint32_t base0 = blockIdx.y * blockDim.y;
    uint32_t tid1 = threadIdx.x;
    uint32_t tid0 = threadIdx.y;
    uint32_t idx1 = base1 + tid1;
    uint32_t idx0 = base0 + tid0;
    if (idx1 < nx && idx0 < ny)
    {
        uint32_t input_idx = 0;
        input_idx += input_strides0* idx0;
        input_idx += input_strides1* idx1;
        tile[tid0][tid1] = input0[input_idx];
    }
    idx1 = base1 + tid0;
    idx0 = base0 + tid1;
    __syncthreads();
    if (idx1 < nx && idx0 < ny)
    {
        uint32_t output_idx = 0;
        output_idx += trans_strides0* idx0;
        output_idx += trans_strides1* idx1;
        output0[output_idx] = tile[tid1][tid0];
    }

}
extern void inception3_Reshape_float_float_cuda_Reshape_571_Call(const dim3 &grids, const dim3 &blocks, unsigned mem, cudaStream_t stream, float* input0, float* output0) {
    inception3_Reshape_float_float_cuda_Reshape_571<<<grids, blocks, mem, stream>>>(input0, output0);
}
// Node name:	Reshape_663
// Description:	Reshape
// Input:
//	- name: inception3_Constant_227_0	type: float	shape: Shape{1, 1, 768, 160}
// Output:
//	- name: inception3_Reshape_663_0	type: float	shape: Shape{160, 768, 1, 1}
extern "C" __launch_bounds__(256) __global__ void inception3_Reshape_float_float_cuda_Reshape_663(float* input0, float* output0)
{
    uint32_t input_strides0 = 160;
    uint32_t input_strides1 = 1;
    uint32_t trans_strides0 = 1;
    uint32_t trans_strides1 = 768;
    size_t nx = 160;
    size_t ny = 768;
    __shared__ float tile[16][17];
    uint32_t base1 = blockIdx.x * blockDim.x;
    uint32_t base0 = blockIdx.y * blockDim.y;
    uint32_t tid1 = threadIdx.x;
    uint32_t tid0 = threadIdx.y;
    uint32_t idx1 = base1 + tid1;
    uint32_t idx0 = base0 + tid0;
    if (idx1 < nx && idx0 < ny)
    {
        uint32_t input_idx = 0;
        input_idx += input_strides0* idx0;
        input_idx += input_strides1* idx1;
        tile[tid0][tid1] = input0[input_idx];
    }
    idx1 = base1 + tid0;
    idx0 = base0 + tid1;
    __syncthreads();
    if (idx1 < nx && idx0 < ny)
    {
        uint32_t output_idx = 0;
        output_idx += trans_strides0* idx0;
        output_idx += trans_strides1* idx1;
        output0[output_idx] = tile[tid1][tid0];
    }

}
extern void inception3_Reshape_float_float_cuda_Reshape_663_Call(const dim3 &grids, const dim3 &blocks, unsigned mem, cudaStream_t stream, float* input0, float* output0) {
    inception3_Reshape_float_float_cuda_Reshape_663<<<grids, blocks, mem, stream>>>(input0, output0);
}
// Node name:	Reshape_487
// Description:	Reshape
// Input:
//	- name: inception3_Constant_2_0	type: float	shape: Shape{3, 3, 3, 32}
// Output:
//	- name: inception3_Reshape_487_0	type: float	shape: Shape{32, 3, 3, 3}
extern "C" __launch_bounds__(256) __global__ void inception3_Reshape_float_float_cuda_Reshape_487(float* input0, float* output0)
{
    uint32_t input_strides0 = 96;
    uint32_t input_strides1 = 32;
    uint32_t input_strides2 = 1;
    uint32_t trans_strides0 = 1;
    uint32_t trans_strides1 = 9;
    uint32_t trans_strides2 = 27;
    size_t nx = 32;
    size_t ny = 3;
    size_t nz = 9;
    __shared__ float tile[16][1][17];
    uint32_t base2 = blockIdx.x * blockDim.x;
    uint32_t base1 = blockIdx.y * blockDim.y;
    uint32_t base0 = blockIdx.z * blockDim.z;
    uint32_t tid2 = threadIdx.x;
    uint32_t tid1 = threadIdx.y;
    uint32_t tid0 = threadIdx.z;
    uint32_t otid2 = tid2;
    uint32_t otid1 = tid1;
    uint32_t otid0 = tid0;
    uint32_t idx2 = base2 + tid2;
    uint32_t idx1 = base1 + tid1;
    uint32_t idx0 = base0 + tid0;
    if (idx2 < nx && idx1 < ny && idx0 < nz)
    {
        uint32_t input_idx = 0;
        input_idx += input_strides0* idx0;
        input_idx += input_strides1* idx1;
        input_idx += input_strides2* idx2;
        tile[tid0][tid1][tid2] = input0[input_idx];
    }
    otid2 = tid0;
    otid0 = tid2;
    idx2 = base2 + otid2;
    idx1 = base1 + otid1;
    idx0 = base0 + otid0;
    __syncthreads();
    if (idx2 < nx && idx1 < ny && idx0 < nz)
    {
        uint32_t output_idx = 0;
        output_idx += trans_strides0* idx0;
        output_idx += trans_strides1* idx1;
        output_idx += trans_strides2* idx2;
        output0[output_idx] = tile[otid0][otid1][otid2];
    }

}
extern void inception3_Reshape_float_float_cuda_Reshape_487_Call(const dim3 &grids, const dim3 &blocks, unsigned mem, cudaStream_t stream, float* input0, float* output0) {
    inception3_Reshape_float_float_cuda_Reshape_487<<<grids, blocks, mem, stream>>>(input0, output0);
}
// Node name:	Reshape_621
// Description:	Reshape
// Input:
//	- name: inception3_Constant_176_0	type: float	shape: Shape{1, 1, 768, 128}
// Output:
//	- name: inception3_Reshape_621_0	type: float	shape: Shape{128, 768, 1, 1}
extern "C" __launch_bounds__(256) __global__ void inception3_Reshape_float_float_cuda_Reshape_621(float* input0, float* output0)
{
    uint32_t input_strides0 = 128;
    uint32_t input_strides1 = 1;
    uint32_t trans_strides0 = 1;
    uint32_t trans_strides1 = 768;
    size_t nx = 128;
    size_t ny = 768;
    __shared__ float tile[16][17];
    uint32_t base1 = blockIdx.x * blockDim.x;
    uint32_t base0 = blockIdx.y * blockDim.y;
    uint32_t tid1 = threadIdx.x;
    uint32_t tid0 = threadIdx.y;
    uint32_t idx1 = base1 + tid1;
    uint32_t idx0 = base0 + tid0;
    if (idx1 < nx && idx0 < ny)
    {
        uint32_t input_idx = 0;
        input_idx += input_strides0* idx0;
        input_idx += input_strides1* idx1;
        tile[tid0][tid1] = input0[input_idx];
    }
    idx1 = base1 + tid0;
    idx0 = base0 + tid1;
    __syncthreads();
    if (idx1 < nx && idx0 < ny)
    {
        uint32_t output_idx = 0;
        output_idx += trans_strides0* idx0;
        output_idx += trans_strides1* idx1;
        output0[output_idx] = tile[tid1][tid0];
    }

}
extern void inception3_Reshape_float_float_cuda_Reshape_621_Call(const dim3 &grids, const dim3 &blocks, unsigned mem, cudaStream_t stream, float* input0, float* output0) {
    inception3_Reshape_float_float_cuda_Reshape_621<<<grids, blocks, mem, stream>>>(input0, output0);
}
// Node name:	Convolution_622
// Description:	Convolution
// Input:
//	- name: inception3_Concat_616_0	type: float	shape: Shape{64, 768, 17, 17}
//	- name: inception3_Reshape_621_0	type: float	shape: Shape{128, 768, 1, 1}
// Output:
//	- name: inception3_Convolution_622_0	type: float	shape: Shape{64, 128, 17, 17}
void Convolution_float_float_float_cuda_lib_Convolution_622(cudnnHandle_t cudnn_handle, float* input0, float* input1, float* output0)
{
    cudnnTensorDescriptor_t tensor_desc_0;
    CUDNN_SAFE_CALL(cudnnCreateTensorDescriptor(&tensor_desc_0));
    CUDNN_SAFE_CALL(cudnnSetTensor4dDescriptor(tensor_desc_0, CUDNN_TENSOR_NCHW, CUDNN_DATA_FLOAT, 64, 768, 17, 17));
    cudnnTensorDescriptor_t tensor_desc_1;
    CUDNN_SAFE_CALL(cudnnCreateTensorDescriptor(&tensor_desc_1));
    CUDNN_SAFE_CALL(cudnnSetTensor4dDescriptor(tensor_desc_1, CUDNN_TENSOR_NCHW, CUDNN_DATA_FLOAT, 64, 128, 17, 17));
    cudnnFilterDescriptor_t filter_desc;
    CUDNN_SAFE_CALL(cudnnCreateFilterDescriptor(&filter_desc));
    CUDNN_SAFE_CALL(cudnnSetFilter4dDescriptor(filter_desc, CUDNN_DATA_FLOAT, CUDNN_TENSOR_NCHW, 128, 768, 1, 1));
    cudnnConvolutionDescriptor_t conv_desc;
    CUDNN_SAFE_CALL(cudnnCreateConvolutionDescriptor(&conv_desc));
    CUDNN_SAFE_CALL(cudnnSetConvolution2dDescriptor(conv_desc, 0, 0, 1, 1, 1, 1, CUDNN_CROSS_CORRELATION, CUDNN_DATA_FLOAT));

    static bool selected_algo = true;
    static cudnnConvolutionFwdAlgo_t conv_fwd_algo = CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM;

    if (!selected_algo) {
        int num_algos;
        int max_algos = 0;
        // cudnnGetConvolutionForwardAlgorithm_v7;
        CUDNN_SAFE_CALL(
            cudnnGetConvolutionForwardAlgorithmMaxCount(cudnn_handle, &max_algos));
        std::vector<cudnnConvolutionFwdAlgoPerf_t> results(max_algos);
        CUDNN_SAFE_CALL(cudnnFindConvolutionForwardAlgorithm(cudnn_handle,
                                                tensor_desc_0,
                                                filter_desc,
                                                conv_desc,
                                                tensor_desc_1,
                                                static_cast<int>(results.size()),
                                                &num_algos,
                                                results.data()));
        results.resize(num_algos);
        for (size_t i = 0; i != results.size(); ++i) {
            cudnnConvolutionFwdAlgoPerf_t const& result = results[i];
            if (result.status == CUDNN_STATUS_SUCCESS) {
                conv_fwd_algo = result.algo;
                break;
            }
        }
        selected_algo = true;
    }
    const float alpha = 1.0;
    const float beta = 0.0;
    static void *workspace_ptr_0 = NULL;
    static size_t workspace_size_in_bytes = 0;
    if (!workspace_ptr_0)
    {
        CUDNN_SAFE_CALL(cudnnGetConvolutionForwardWorkspaceSize(cudnn_handle, tensor_desc_0, filter_desc, conv_desc, tensor_desc_1, conv_fwd_algo, &workspace_size_in_bytes));
        CUDA_SAFE_CALL(cudaMalloc(&workspace_ptr_0, workspace_size_in_bytes));
    }
    CUDNN_SAFE_CALL(cudnnConvolutionForward(cudnn_handle, &alpha, tensor_desc_0, input0,filter_desc, input1, conv_desc, conv_fwd_algo, workspace_ptr_0, workspace_size_in_bytes, &beta, tensor_desc_1, output0));
    CUDNN_SAFE_CALL(cudnnDestroyTensorDescriptor(tensor_desc_0));
    CUDNN_SAFE_CALL(cudnnDestroyTensorDescriptor(tensor_desc_1));
    CUDNN_SAFE_CALL(cudnnDestroyFilterDescriptor(filter_desc));
    CUDNN_SAFE_CALL(cudnnDestroyConvolutionDescriptor(conv_desc));

}
// Node name:	Reshape_635
// Description:	Reshape
// Input:
//	- name: inception3_Constant_181_0	type: float	shape: Shape{7, 1, 128, 128}
// Output:
//	- name: inception3_Reshape_635_0	type: float	shape: Shape{128, 128, 7, 1}
extern "C" __launch_bounds__(256) __global__ void inception3_Reshape_float_float_cuda_Reshape_635(float* input0, float* output0)
{
    uint32_t input_strides0 = 16384;
    uint32_t input_strides1 = 128;
    uint32_t input_strides2 = 1;
    uint32_t trans_strides0 = 1;
    uint32_t trans_strides1 = 7;
    uint32_t trans_strides2 = 896;
    size_t nx = 128;
    size_t ny = 128;
    size_t nz = 7;
    __shared__ float tile[16][1][17];
    uint32_t base2 = blockIdx.x * blockDim.x;
    uint32_t base1 = blockIdx.y * blockDim.y;
    uint32_t base0 = blockIdx.z * blockDim.z;
    uint32_t tid2 = threadIdx.x;
    uint32_t tid1 = threadIdx.y;
    uint32_t tid0 = threadIdx.z;
    uint32_t otid2 = tid2;
    uint32_t otid1 = tid1;
    uint32_t otid0 = tid0;
    uint32_t idx2 = base2 + tid2;
    uint32_t idx1 = base1 + tid1;
    uint32_t idx0 = base0 + tid0;
    if (idx2 < nx && idx1 < ny && idx0 < nz)
    {
        uint32_t input_idx = 0;
        input_idx += input_strides0* idx0;
        input_idx += input_strides1* idx1;
        input_idx += input_strides2* idx2;
        tile[tid0][tid1][tid2] = input0[input_idx];
    }
    otid2 = tid0;
    otid0 = tid2;
    idx2 = base2 + otid2;
    idx1 = base1 + otid1;
    idx0 = base0 + otid0;
    __syncthreads();
    if (idx2 < nx && idx1 < ny && idx0 < nz)
    {
        uint32_t output_idx = 0;
        output_idx += trans_strides0* idx0;
        output_idx += trans_strides1* idx1;
        output_idx += trans_strides2* idx2;
        output0[output_idx] = tile[otid0][otid1][otid2];
    }

}
extern void inception3_Reshape_float_float_cuda_Reshape_635_Call(const dim3 &grids, const dim3 &blocks, unsigned mem, cudaStream_t stream, float* input0, float* output0) {
    inception3_Reshape_float_float_cuda_Reshape_635<<<grids, blocks, mem, stream>>>(input0, output0);
}
// Node name:	Convolution_636
// Description:	Convolution
// Input:
//	- name: inception3_Relu_631_0	type: float	shape: Shape{64, 128, 17, 17}
//	- name: inception3_Reshape_635_0	type: float	shape: Shape{128, 128, 7, 1}
// Output:
//	- name: inception3_Convolution_636_0	type: float	shape: Shape{64, 128, 17, 17}
void Convolution_float_float_float_cuda_lib_Convolution_636(cudnnHandle_t cudnn_handle, float* input0, float* input1, float* output0)
{
    cudnnTensorDescriptor_t tensor_desc_0;
    CUDNN_SAFE_CALL(cudnnCreateTensorDescriptor(&tensor_desc_0));
    CUDNN_SAFE_CALL(cudnnSetTensor4dDescriptor(tensor_desc_0, CUDNN_TENSOR_NCHW, CUDNN_DATA_FLOAT, 64, 128, 17, 17));
    cudnnTensorDescriptor_t tensor_desc_1;
    CUDNN_SAFE_CALL(cudnnCreateTensorDescriptor(&tensor_desc_1));
    CUDNN_SAFE_CALL(cudnnSetTensor4dDescriptor(tensor_desc_1, CUDNN_TENSOR_NCHW, CUDNN_DATA_FLOAT, 64, 128, 17, 17));
    cudnnFilterDescriptor_t filter_desc;
    CUDNN_SAFE_CALL(cudnnCreateFilterDescriptor(&filter_desc));
    CUDNN_SAFE_CALL(cudnnSetFilter4dDescriptor(filter_desc, CUDNN_DATA_FLOAT, CUDNN_TENSOR_NCHW, 128, 128, 7, 1));
    cudnnConvolutionDescriptor_t conv_desc;
    CUDNN_SAFE_CALL(cudnnCreateConvolutionDescriptor(&conv_desc));
    CUDNN_SAFE_CALL(cudnnSetConvolution2dDescriptor(conv_desc, 3, 0, 1, 1, 1, 1, CUDNN_CROSS_CORRELATION, CUDNN_DATA_FLOAT));

    static bool selected_algo = true;
    static cudnnConvolutionFwdAlgo_t conv_fwd_algo = CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM;

    if (!selected_algo) {
        int num_algos;
        int max_algos = 0;
        // cudnnGetConvolutionForwardAlgorithm_v7;
        CUDNN_SAFE_CALL(
            cudnnGetConvolutionForwardAlgorithmMaxCount(cudnn_handle, &max_algos));
        std::vector<cudnnConvolutionFwdAlgoPerf_t> results(max_algos);
        CUDNN_SAFE_CALL(cudnnFindConvolutionForwardAlgorithm(cudnn_handle,
                                                tensor_desc_0,
                                                filter_desc,
                                                conv_desc,
                                                tensor_desc_1,
                                                static_cast<int>(results.size()),
                                                &num_algos,
                                                results.data()));
        results.resize(num_algos);
        for (size_t i = 0; i != results.size(); ++i) {
            cudnnConvolutionFwdAlgoPerf_t const& result = results[i];
            if (result.status == CUDNN_STATUS_SUCCESS) {
                conv_fwd_algo = result.algo;
                break;
            }
        }
        selected_algo = true;
    }
    const float alpha = 1.0;
    const float beta = 0.0;
    static void *workspace_ptr_0 = NULL;
    static size_t workspace_size_in_bytes = 0;
    if (!workspace_ptr_0)
    {
        CUDNN_SAFE_CALL(cudnnGetConvolutionForwardWorkspaceSize(cudnn_handle, tensor_desc_0, filter_desc, conv_desc, tensor_desc_1, conv_fwd_algo, &workspace_size_in_bytes));
        CUDA_SAFE_CALL(cudaMalloc(&workspace_ptr_0, workspace_size_in_bytes));
    }
    CUDNN_SAFE_CALL(cudnnConvolutionForward(cudnn_handle, &alpha, tensor_desc_0, input0,filter_desc, input1, conv_desc, conv_fwd_algo, workspace_ptr_0, workspace_size_in_bytes, &beta, tensor_desc_1, output0));
    CUDNN_SAFE_CALL(cudnnDestroyTensorDescriptor(tensor_desc_0));
    CUDNN_SAFE_CALL(cudnnDestroyTensorDescriptor(tensor_desc_1));
    CUDNN_SAFE_CALL(cudnnDestroyFilterDescriptor(filter_desc));
    CUDNN_SAFE_CALL(cudnnDestroyConvolutionDescriptor(conv_desc));

}
// Node name:	Convolution_655
// Description:	Convolution
// Input:
//	- name: inception3_Relu_653_0	type: float	shape: Shape{64, 128, 17, 17}
//	- name: inception3_Reshape_654_0	type: float	shape: Shape{192, 128, 1, 7}
// Output:
//	- name: inception3_Convolution_655_0	type: float	shape: Shape{64, 192, 17, 17}
void Convolution_float_float_float_cuda_lib_Convolution_655(cudnnHandle_t cudnn_handle, float* input0, float* input1, float* output0)
{
    cudnnTensorDescriptor_t tensor_desc_0;
    CUDNN_SAFE_CALL(cudnnCreateTensorDescriptor(&tensor_desc_0));
    CUDNN_SAFE_CALL(cudnnSetTensor4dDescriptor(tensor_desc_0, CUDNN_TENSOR_NCHW, CUDNN_DATA_FLOAT, 64, 128, 17, 17));
    cudnnTensorDescriptor_t tensor_desc_1;
    CUDNN_SAFE_CALL(cudnnCreateTensorDescriptor(&tensor_desc_1));
    CUDNN_SAFE_CALL(cudnnSetTensor4dDescriptor(tensor_desc_1, CUDNN_TENSOR_NCHW, CUDNN_DATA_FLOAT, 64, 192, 17, 17));
    cudnnFilterDescriptor_t filter_desc;
    CUDNN_SAFE_CALL(cudnnCreateFilterDescriptor(&filter_desc));
    CUDNN_SAFE_CALL(cudnnSetFilter4dDescriptor(filter_desc, CUDNN_DATA_FLOAT, CUDNN_TENSOR_NCHW, 192, 128, 1, 7));
    cudnnConvolutionDescriptor_t conv_desc;
    CUDNN_SAFE_CALL(cudnnCreateConvolutionDescriptor(&conv_desc));
    CUDNN_SAFE_CALL(cudnnSetConvolution2dDescriptor(conv_desc, 0, 3, 1, 1, 1, 1, CUDNN_CROSS_CORRELATION, CUDNN_DATA_FLOAT));

    static bool selected_algo = true;
    static cudnnConvolutionFwdAlgo_t conv_fwd_algo = CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM;

    if (!selected_algo) {
        int num_algos;
        int max_algos = 0;
        // cudnnGetConvolutionForwardAlgorithm_v7;
        CUDNN_SAFE_CALL(
            cudnnGetConvolutionForwardAlgorithmMaxCount(cudnn_handle, &max_algos));
        std::vector<cudnnConvolutionFwdAlgoPerf_t> results(max_algos);
        CUDNN_SAFE_CALL(cudnnFindConvolutionForwardAlgorithm(cudnn_handle,
                                                tensor_desc_0,
                                                filter_desc,
                                                conv_desc,
                                                tensor_desc_1,
                                                static_cast<int>(results.size()),
                                                &num_algos,
                                                results.data()));
        results.resize(num_algos);
        for (size_t i = 0; i != results.size(); ++i) {
            cudnnConvolutionFwdAlgoPerf_t const& result = results[i];
            if (result.status == CUDNN_STATUS_SUCCESS) {
                conv_fwd_algo = result.algo;
                break;
            }
        }
        selected_algo = true;
    }
    const float alpha = 1.0;
    const float beta = 0.0;
    static void *workspace_ptr_0 = NULL;
    static size_t workspace_size_in_bytes = 0;
    if (!workspace_ptr_0)
    {
        CUDNN_SAFE_CALL(cudnnGetConvolutionForwardWorkspaceSize(cudnn_handle, tensor_desc_0, filter_desc, conv_desc, tensor_desc_1, conv_fwd_algo, &workspace_size_in_bytes));
        CUDA_SAFE_CALL(cudaMalloc(&workspace_ptr_0, workspace_size_in_bytes));
    }
    CUDNN_SAFE_CALL(cudnnConvolutionForward(cudnn_handle, &alpha, tensor_desc_0, input0,filter_desc, input1, conv_desc, conv_fwd_algo, workspace_ptr_0, workspace_size_in_bytes, &beta, tensor_desc_1, output0));
    CUDNN_SAFE_CALL(cudnnDestroyTensorDescriptor(tensor_desc_0));
    CUDNN_SAFE_CALL(cudnnDestroyTensorDescriptor(tensor_desc_1));
    CUDNN_SAFE_CALL(cudnnDestroyFilterDescriptor(filter_desc));
    CUDNN_SAFE_CALL(cudnnDestroyConvolutionDescriptor(conv_desc));

}
// Node name:	Convolution_645
// Description:	Convolution
// Input:
//	- name: inception3_Relu_641_0	type: float	shape: Shape{64, 128, 17, 17}
//	- name: inception3_Reshape_644_0	type: float	shape: Shape{128, 128, 1, 7}
// Output:
//	- name: inception3_Convolution_645_0	type: float	shape: Shape{64, 128, 17, 17}
void Convolution_float_float_float_cuda_lib_Convolution_645(cudnnHandle_t cudnn_handle, float* input0, float* input1, float* output0)
{
    cudnnTensorDescriptor_t tensor_desc_0;
    CUDNN_SAFE_CALL(cudnnCreateTensorDescriptor(&tensor_desc_0));
    CUDNN_SAFE_CALL(cudnnSetTensor4dDescriptor(tensor_desc_0, CUDNN_TENSOR_NCHW, CUDNN_DATA_FLOAT, 64, 128, 17, 17));
    cudnnTensorDescriptor_t tensor_desc_1;
    CUDNN_SAFE_CALL(cudnnCreateTensorDescriptor(&tensor_desc_1));
    CUDNN_SAFE_CALL(cudnnSetTensor4dDescriptor(tensor_desc_1, CUDNN_TENSOR_NCHW, CUDNN_DATA_FLOAT, 64, 128, 17, 17));
    cudnnFilterDescriptor_t filter_desc;
    CUDNN_SAFE_CALL(cudnnCreateFilterDescriptor(&filter_desc));
    CUDNN_SAFE_CALL(cudnnSetFilter4dDescriptor(filter_desc, CUDNN_DATA_FLOAT, CUDNN_TENSOR_NCHW, 128, 128, 1, 7));
    cudnnConvolutionDescriptor_t conv_desc;
    CUDNN_SAFE_CALL(cudnnCreateConvolutionDescriptor(&conv_desc));
    CUDNN_SAFE_CALL(cudnnSetConvolution2dDescriptor(conv_desc, 0, 3, 1, 1, 1, 1, CUDNN_CROSS_CORRELATION, CUDNN_DATA_FLOAT));

    static bool selected_algo = true;
    static cudnnConvolutionFwdAlgo_t conv_fwd_algo = CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM;

    if (!selected_algo) {
        int num_algos;
        int max_algos = 0;
        // cudnnGetConvolutionForwardAlgorithm_v7;
        CUDNN_SAFE_CALL(
            cudnnGetConvolutionForwardAlgorithmMaxCount(cudnn_handle, &max_algos));
        std::vector<cudnnConvolutionFwdAlgoPerf_t> results(max_algos);
        CUDNN_SAFE_CALL(cudnnFindConvolutionForwardAlgorithm(cudnn_handle,
                                                tensor_desc_0,
                                                filter_desc,
                                                conv_desc,
                                                tensor_desc_1,
                                                static_cast<int>(results.size()),
                                                &num_algos,
                                                results.data()));
        results.resize(num_algos);
        for (size_t i = 0; i != results.size(); ++i) {
            cudnnConvolutionFwdAlgoPerf_t const& result = results[i];
            if (result.status == CUDNN_STATUS_SUCCESS) {
                conv_fwd_algo = result.algo;
                break;
            }
        }
        selected_algo = true;
    }
    const float alpha = 1.0;
    const float beta = 0.0;
    static void *workspace_ptr_0 = NULL;
    static size_t workspace_size_in_bytes = 0;
    if (!workspace_ptr_0)
    {
        CUDNN_SAFE_CALL(cudnnGetConvolutionForwardWorkspaceSize(cudnn_handle, tensor_desc_0, filter_desc, conv_desc, tensor_desc_1, conv_fwd_algo, &workspace_size_in_bytes));
        CUDA_SAFE_CALL(cudaMalloc(&workspace_ptr_0, workspace_size_in_bytes));
    }
    CUDNN_SAFE_CALL(cudnnConvolutionForward(cudnn_handle, &alpha, tensor_desc_0, input0,filter_desc, input1, conv_desc, conv_fwd_algo, workspace_ptr_0, workspace_size_in_bytes, &beta, tensor_desc_1, output0));
    CUDNN_SAFE_CALL(cudnnDestroyTensorDescriptor(tensor_desc_0));
    CUDNN_SAFE_CALL(cudnnDestroyTensorDescriptor(tensor_desc_1));
    CUDNN_SAFE_CALL(cudnnDestroyFilterDescriptor(filter_desc));
    CUDNN_SAFE_CALL(cudnnDestroyConvolutionDescriptor(conv_desc));

}
// Node name:	BatchNormInference_489
// Description:	BatchNormInference
// Input:
//	- name: inception3_Constant_3_0	type: float	shape: Shape{32}
//	- name: inception3_Constant_4_0	type: float	shape: Shape{32}
//	- name: inception3_Convolution_488_0	type: float	shape: Shape{64, 32, 149, 149}
//	- name: inception3_Constant_5_0	type: float	shape: Shape{32}
//	- name: inception3_Constant_6_0	type: float	shape: Shape{32}
// Output:
//	- name: inception3_BatchNormInference_489_0	type: float	shape: Shape{64, 32, 149, 149}
extern "C" __launch_bounds__(512) __global__ void inception3_BatchNormInference_float_float_float_float_float_float_cuda_BatchNormInference_489(float* input0, float* input1, float* input2, float* input3, float* input4, float* output0)
{
    const int st = blockIdx.x * 149 * 149;
    const int c_id = blockIdx.x % 32;
    #pragma unroll 1
    for (int i = threadIdx.x; i < 149 * 149; i += blockDim.x)
    {
        output0[st + i] = (input1[c_id] + (input0[c_id] * (input2[st + i] - input3[c_id]) / sqrtf(0.001 + input4[c_id])));
    }

}
extern void inception3_BatchNormInference_float_float_float_float_float_float_cuda_BatchNormInference_489_Call(const dim3 &grids, const dim3 &blocks, unsigned mem, cudaStream_t stream, float* input0, float* input1, float* input2, float* input3, float* input4, float* output0) {
    inception3_BatchNormInference_float_float_float_float_float_float_cuda_BatchNormInference_489<<<grids, blocks, mem, stream>>>(input0, input1, input2, input3, input4, output0);
}
// Node name:	Relu_490
// Description:	Relu
// Input:
//	- name: inception3_BatchNormInference_489_0	type: float	shape: Shape{64, 32, 149, 149}
// Output:
//	- name: inception3_Relu_490_0	type: float	shape: Shape{64, 32, 149, 149}
extern "C" __launch_bounds__(512) __global__ void inception3_Relu_float_float_cuda_Relu_490(float* input0, float* output0)
{
    output0[blockIdx.x * 512 + threadIdx.x] = relu(input0[blockIdx.x * 512 + threadIdx.x]);

}
extern void inception3_Relu_float_float_cuda_Relu_490_Call(const dim3 &grids, const dim3 &blocks, unsigned mem, cudaStream_t stream, float* input0, float* output0) {
    inception3_Relu_float_float_cuda_Relu_490<<<grids, blocks, mem, stream>>>(input0, output0);
}
// Node name:	Reshape_509
// Description:	Reshape
// Input:
//	- name: inception3_Constant_27_0	type: float	shape: Shape{1, 1, 192, 64}
// Output:
//	- name: inception3_Reshape_509_0	type: float	shape: Shape{64, 192, 1, 1}
extern "C" __launch_bounds__(256) __global__ void inception3_Reshape_float_float_cuda_Reshape_509(float* input0, float* output0)
{
    uint32_t input_strides0 = 64;
    uint32_t input_strides1 = 1;
    uint32_t trans_strides0 = 1;
    uint32_t trans_strides1 = 192;
    size_t nx = 64;
    size_t ny = 192;
    __shared__ float tile[16][17];
    uint32_t base1 = blockIdx.x * blockDim.x;
    uint32_t base0 = blockIdx.y * blockDim.y;
    uint32_t tid1 = threadIdx.x;
    uint32_t tid0 = threadIdx.y;
    uint32_t idx1 = base1 + tid1;
    uint32_t idx0 = base0 + tid0;
    if (idx1 < nx && idx0 < ny)
    {
        uint32_t input_idx = 0;
        input_idx += input_strides0* idx0;
        input_idx += input_strides1* idx1;
        tile[tid0][tid1] = input0[input_idx];
    }
    idx1 = base1 + tid0;
    idx0 = base0 + tid1;
    __syncthreads();
    if (idx1 < nx && idx0 < ny)
    {
        uint32_t output_idx = 0;
        output_idx += trans_strides0* idx0;
        output_idx += trans_strides1* idx1;
        output0[output_idx] = tile[tid1][tid0];
    }

}
extern void inception3_Reshape_float_float_cuda_Reshape_509_Call(const dim3 &grids, const dim3 &blocks, unsigned mem, cudaStream_t stream, float* input0, float* output0) {
    inception3_Reshape_float_float_cuda_Reshape_509<<<grids, blocks, mem, stream>>>(input0, output0);
}
// Node name:	BatchNormInference_668
// Description:	BatchNormInference
// Input:
//	- name: inception3_Constant_228_0	type: float	shape: Shape{160}
//	- name: inception3_Constant_229_0	type: float	shape: Shape{160}
//	- name: inception3_Convolution_664_0	type: float	shape: Shape{64, 160, 17, 17}
//	- name: inception3_Constant_230_0	type: float	shape: Shape{160}
//	- name: inception3_Constant_231_0	type: float	shape: Shape{160}
// Output:
//	- name: inception3_BatchNormInference_668_0	type: float	shape: Shape{64, 160, 17, 17}
extern "C" __launch_bounds__(289) __global__ void inception3_BatchNormInference_float_float_float_float_float_float_cuda_BatchNormInference_668(float* input0, float* input1, float* input2, float* input3, float* input4, float* output0)
{
    const int st = blockIdx.x * 17 * 17;
    const int c_id = blockIdx.x % 160;
    #pragma unroll 1
    for (int i = threadIdx.x; i < 17 * 17; i += blockDim.x)
    {
        output0[st + i] = (input1[c_id] + (input0[c_id] * (input2[st + i] - input3[c_id]) / sqrtf(0.001 + input4[c_id])));
    }

}
extern void inception3_BatchNormInference_float_float_float_float_float_float_cuda_BatchNormInference_668_Call(const dim3 &grids, const dim3 &blocks, unsigned mem, cudaStream_t stream, float* input0, float* input1, float* input2, float* input3, float* input4, float* output0) {
    inception3_BatchNormInference_float_float_float_float_float_float_cuda_BatchNormInference_668<<<grids, blocks, mem, stream>>>(input0, input1, input2, input3, input4, output0);
}
// Node name:	Reshape_677
// Description:	Reshape
// Input:
//	- name: inception3_Constant_232_0	type: float	shape: Shape{7, 1, 160, 160}
// Output:
//	- name: inception3_Reshape_677_0	type: float	shape: Shape{160, 160, 7, 1}
extern "C" __launch_bounds__(256) __global__ void inception3_Reshape_float_float_cuda_Reshape_677(float* input0, float* output0)
{
    uint32_t input_strides0 = 25600;
    uint32_t input_strides1 = 160;
    uint32_t input_strides2 = 1;
    uint32_t trans_strides0 = 1;
    uint32_t trans_strides1 = 7;
    uint32_t trans_strides2 = 1120;
    size_t nx = 160;
    size_t ny = 160;
    size_t nz = 7;
    __shared__ float tile[16][1][17];
    uint32_t base2 = blockIdx.x * blockDim.x;
    uint32_t base1 = blockIdx.y * blockDim.y;
    uint32_t base0 = blockIdx.z * blockDim.z;
    uint32_t tid2 = threadIdx.x;
    uint32_t tid1 = threadIdx.y;
    uint32_t tid0 = threadIdx.z;
    uint32_t otid2 = tid2;
    uint32_t otid1 = tid1;
    uint32_t otid0 = tid0;
    uint32_t idx2 = base2 + tid2;
    uint32_t idx1 = base1 + tid1;
    uint32_t idx0 = base0 + tid0;
    if (idx2 < nx && idx1 < ny && idx0 < nz)
    {
        uint32_t input_idx = 0;
        input_idx += input_strides0* idx0;
        input_idx += input_strides1* idx1;
        input_idx += input_strides2* idx2;
        tile[tid0][tid1][tid2] = input0[input_idx];
    }
    otid2 = tid0;
    otid0 = tid2;
    idx2 = base2 + otid2;
    idx1 = base1 + otid1;
    idx0 = base0 + otid0;
    __syncthreads();
    if (idx2 < nx && idx1 < ny && idx0 < nz)
    {
        uint32_t output_idx = 0;
        output_idx += trans_strides0* idx0;
        output_idx += trans_strides1* idx1;
        output_idx += trans_strides2* idx2;
        output0[output_idx] = tile[otid0][otid1][otid2];
    }

}
extern void inception3_Reshape_float_float_cuda_Reshape_677_Call(const dim3 &grids, const dim3 &blocks, unsigned mem, cudaStream_t stream, float* input0, float* output0) {
    inception3_Reshape_float_float_cuda_Reshape_677<<<grids, blocks, mem, stream>>>(input0, output0);
}
// Node name:	Convolution_687
// Description:	Convolution
// Input:
//	- name: inception3_Relu_683_0	type: float	shape: Shape{64, 160, 17, 17}
//	- name: inception3_Reshape_686_0	type: float	shape: Shape{160, 160, 1, 7}
// Output:
//	- name: inception3_Convolution_687_0	type: float	shape: Shape{64, 160, 17, 17}
void Convolution_float_float_float_cuda_lib_Convolution_687(cudnnHandle_t cudnn_handle, float* input0, float* input1, float* output0)
{
    cudnnTensorDescriptor_t tensor_desc_0;
    CUDNN_SAFE_CALL(cudnnCreateTensorDescriptor(&tensor_desc_0));
    CUDNN_SAFE_CALL(cudnnSetTensor4dDescriptor(tensor_desc_0, CUDNN_TENSOR_NCHW, CUDNN_DATA_FLOAT, 64, 160, 17, 17));
    cudnnTensorDescriptor_t tensor_desc_1;
    CUDNN_SAFE_CALL(cudnnCreateTensorDescriptor(&tensor_desc_1));
    CUDNN_SAFE_CALL(cudnnSetTensor4dDescriptor(tensor_desc_1, CUDNN_TENSOR_NCHW, CUDNN_DATA_FLOAT, 64, 160, 17, 17));
    cudnnFilterDescriptor_t filter_desc;
    CUDNN_SAFE_CALL(cudnnCreateFilterDescriptor(&filter_desc));
    CUDNN_SAFE_CALL(cudnnSetFilter4dDescriptor(filter_desc, CUDNN_DATA_FLOAT, CUDNN_TENSOR_NCHW, 160, 160, 1, 7));
    cudnnConvolutionDescriptor_t conv_desc;
    CUDNN_SAFE_CALL(cudnnCreateConvolutionDescriptor(&conv_desc));
    CUDNN_SAFE_CALL(cudnnSetConvolution2dDescriptor(conv_desc, 0, 3, 1, 1, 1, 1, CUDNN_CROSS_CORRELATION, CUDNN_DATA_FLOAT));

    static bool selected_algo = true;
    static cudnnConvolutionFwdAlgo_t conv_fwd_algo = CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM;

    if (!selected_algo) {
        int num_algos;
        int max_algos = 0;
        // cudnnGetConvolutionForwardAlgorithm_v7;
        CUDNN_SAFE_CALL(
            cudnnGetConvolutionForwardAlgorithmMaxCount(cudnn_handle, &max_algos));
        std::vector<cudnnConvolutionFwdAlgoPerf_t> results(max_algos);
        CUDNN_SAFE_CALL(cudnnFindConvolutionForwardAlgorithm(cudnn_handle,
                                                tensor_desc_0,
                                                filter_desc,
                                                conv_desc,
                                                tensor_desc_1,
                                                static_cast<int>(results.size()),
                                                &num_algos,
                                                results.data()));
        results.resize(num_algos);
        for (size_t i = 0; i != results.size(); ++i) {
            cudnnConvolutionFwdAlgoPerf_t const& result = results[i];
            if (result.status == CUDNN_STATUS_SUCCESS) {
                conv_fwd_algo = result.algo;
                break;
            }
        }
        selected_algo = true;
    }
    const float alpha = 1.0;
    const float beta = 0.0;
    static void *workspace_ptr_0 = NULL;
    static size_t workspace_size_in_bytes = 0;
    if (!workspace_ptr_0)
    {
        CUDNN_SAFE_CALL(cudnnGetConvolutionForwardWorkspaceSize(cudnn_handle, tensor_desc_0, filter_desc, conv_desc, tensor_desc_1, conv_fwd_algo, &workspace_size_in_bytes));
        CUDA_SAFE_CALL(cudaMalloc(&workspace_ptr_0, workspace_size_in_bytes));
    }
    CUDNN_SAFE_CALL(cudnnConvolutionForward(cudnn_handle, &alpha, tensor_desc_0, input0,filter_desc, input1, conv_desc, conv_fwd_algo, workspace_ptr_0, workspace_size_in_bytes, &beta, tensor_desc_1, output0));
    CUDNN_SAFE_CALL(cudnnDestroyTensorDescriptor(tensor_desc_0));
    CUDNN_SAFE_CALL(cudnnDestroyTensorDescriptor(tensor_desc_1));
    CUDNN_SAFE_CALL(cudnnDestroyFilterDescriptor(filter_desc));
    CUDNN_SAFE_CALL(cudnnDestroyConvolutionDescriptor(conv_desc));

}
// Node name:	Convolution_664
// Description:	Convolution
// Input:
//	- name: inception3_Concat_658_0	type: float	shape: Shape{64, 768, 17, 17}
//	- name: inception3_Reshape_663_0	type: float	shape: Shape{160, 768, 1, 1}
// Output:
//	- name: inception3_Convolution_664_0	type: float	shape: Shape{64, 160, 17, 17}
void Convolution_float_float_float_cuda_lib_Convolution_664(cudnnHandle_t cudnn_handle, float* input0, float* input1, float* output0)
{
    cudnnTensorDescriptor_t tensor_desc_0;
    CUDNN_SAFE_CALL(cudnnCreateTensorDescriptor(&tensor_desc_0));
    CUDNN_SAFE_CALL(cudnnSetTensor4dDescriptor(tensor_desc_0, CUDNN_TENSOR_NCHW, CUDNN_DATA_FLOAT, 64, 768, 17, 17));
    cudnnTensorDescriptor_t tensor_desc_1;
    CUDNN_SAFE_CALL(cudnnCreateTensorDescriptor(&tensor_desc_1));
    CUDNN_SAFE_CALL(cudnnSetTensor4dDescriptor(tensor_desc_1, CUDNN_TENSOR_NCHW, CUDNN_DATA_FLOAT, 64, 160, 17, 17));
    cudnnFilterDescriptor_t filter_desc;
    CUDNN_SAFE_CALL(cudnnCreateFilterDescriptor(&filter_desc));
    CUDNN_SAFE_CALL(cudnnSetFilter4dDescriptor(filter_desc, CUDNN_DATA_FLOAT, CUDNN_TENSOR_NCHW, 160, 768, 1, 1));
    cudnnConvolutionDescriptor_t conv_desc;
    CUDNN_SAFE_CALL(cudnnCreateConvolutionDescriptor(&conv_desc));
    CUDNN_SAFE_CALL(cudnnSetConvolution2dDescriptor(conv_desc, 0, 0, 1, 1, 1, 1, CUDNN_CROSS_CORRELATION, CUDNN_DATA_FLOAT));

    static bool selected_algo = true;
    static cudnnConvolutionFwdAlgo_t conv_fwd_algo = CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM;

    if (!selected_algo) {
        int num_algos;
        int max_algos = 0;
        // cudnnGetConvolutionForwardAlgorithm_v7;
        CUDNN_SAFE_CALL(
            cudnnGetConvolutionForwardAlgorithmMaxCount(cudnn_handle, &max_algos));
        std::vector<cudnnConvolutionFwdAlgoPerf_t> results(max_algos);
        CUDNN_SAFE_CALL(cudnnFindConvolutionForwardAlgorithm(cudnn_handle,
                                                tensor_desc_0,
                                                filter_desc,
                                                conv_desc,
                                                tensor_desc_1,
                                                static_cast<int>(results.size()),
                                                &num_algos,
                                                results.data()));
        results.resize(num_algos);
        for (size_t i = 0; i != results.size(); ++i) {
            cudnnConvolutionFwdAlgoPerf_t const& result = results[i];
            if (result.status == CUDNN_STATUS_SUCCESS) {
                conv_fwd_algo = result.algo;
                break;
            }
        }
        selected_algo = true;
    }
    const float alpha = 1.0;
    const float beta = 0.0;
    static void *workspace_ptr_0 = NULL;
    static size_t workspace_size_in_bytes = 0;
    if (!workspace_ptr_0)
    {
        CUDNN_SAFE_CALL(cudnnGetConvolutionForwardWorkspaceSize(cudnn_handle, tensor_desc_0, filter_desc, conv_desc, tensor_desc_1, conv_fwd_algo, &workspace_size_in_bytes));
        CUDA_SAFE_CALL(cudaMalloc(&workspace_ptr_0, workspace_size_in_bytes));
    }
    CUDNN_SAFE_CALL(cudnnConvolutionForward(cudnn_handle, &alpha, tensor_desc_0, input0,filter_desc, input1, conv_desc, conv_fwd_algo, workspace_ptr_0, workspace_size_in_bytes, &beta, tensor_desc_1, output0));
    CUDNN_SAFE_CALL(cudnnDestroyTensorDescriptor(tensor_desc_0));
    CUDNN_SAFE_CALL(cudnnDestroyTensorDescriptor(tensor_desc_1));
    CUDNN_SAFE_CALL(cudnnDestroyFilterDescriptor(filter_desc));
    CUDNN_SAFE_CALL(cudnnDestroyConvolutionDescriptor(conv_desc));

}

#ifndef __NNFUSION_GRAPH_CONFIG__
#define __NNFUSION_GRAPH_CONFIG__
#define NNFUSION_GRAPH_INPUT_NUM 1
#define NNFUSION_GRAPH_OUTPUT_NUM 1
#define NNFUSION_GRAPH_INPUT_DTYPE_0 float
#define NNFUSION_GRAPH_INPUT_SHAPE_0 {64, 299, 299, 3}
#define NNFUSION_GRAPH_OUTPUT_DTYPE_0 float
#define NNFUSION_GRAPH_OUTPUT_SHAPE_0 {64, 1001}
#endif




extern "C" void inception3_cuda_free()
{

CUDA_SAFE_CALL(cudaFree(inception3_group_0_CUDA_GPU0_allocator_memory_pool));

CUDA_SAFE_CALL(cudaFree(inception3_group_persist_CUDA_GPU0_allocator_memory_pool));
CUBLAS_SAFE_CALL(cublasDestroy(inception3_cublas_handle_0));
CUDNN_SAFE_CALL(cudnnDestroy(inception3_cudnn_handle_0));
}

#include "./include/dnn.h"

class inception3_Reshape_float_float_cuda_Reshape_486_CallKernel : public Kernel {
public:
    inception3_Reshape_float_float_cuda_Reshape_486_CallKernel(const dim3 & grids, const dim3 & blocks, unsigned  mem, cudaStream_t  stream, float*  input0, float*  output0, float*  Parameter_0_0, float**  Result_892_0) {
        this->grids = grids, this->blocks = blocks, this->mem = mem, this->stream = stream, this->input0 = input0, this->output0 = output0, this->Parameter_0_0 = Parameter_0_0, this->Result_892_0 = Result_892_0;
        this->kernelName = "inception3_Reshape_float_float_cuda_Reshape_486_Call";
        this->Id = 0;
        this->mixable = 0;
    }

    void initParams() override {
        // empty implementation
    }

    void loadKernel() override {
        // Empty implementation
    }

        dim3  grids; dim3  blocks; unsigned  mem; cudaStream_t  stream; float*  input0; float*  output0;
    float*  Parameter_0_0; float**  Result_892_0;
private:

    
std::vector<int> getArgs() override {
    return std::vector<int>();
}

     void Reshape_float_float_cuda_Reshape_486_Call(const dim3 &grids, const dim3 &blocks, unsigned mem, cudaStream_t stream, float* input0, float* output0) {
    inception3_Reshape_float_float_cuda_Reshape_486<<<grids, blocks, mem, stream>>>(input0, output0);
}

    void executeImpl(cudaStream_t stream) {
        this->Reshape_float_float_cuda_Reshape_486_Call(grids, blocks, mem, stream, input0, output0);
    }
};


class inception3_Reshape_float_float_cuda_Reshape_487_CallKernel : public Kernel {
public:
    inception3_Reshape_float_float_cuda_Reshape_487_CallKernel(const dim3 & grids, const dim3 & blocks, unsigned  mem, cudaStream_t  stream, float*  input0, float*  output0, float*  Parameter_0_0, float**  Result_892_0) {
        this->grids = grids, this->blocks = blocks, this->mem = mem, this->stream = stream, this->input0 = input0, this->output0 = output0, this->Parameter_0_0 = Parameter_0_0, this->Result_892_0 = Result_892_0;
        this->kernelName = "inception3_Reshape_float_float_cuda_Reshape_487_Call";
        this->Id = 0;
        this->mixable = 0;
    }

    void initParams() override {
        // empty implementation
    }

    void loadKernel() override {
        // Empty implementation
    }

        dim3  grids; dim3  blocks; unsigned  mem; cudaStream_t  stream; float*  input0; float*  output0;
    float*  Parameter_0_0; float**  Result_892_0;
private:

    
std::vector<int> getArgs() override {
    return std::vector<int>();
}

     void Reshape_float_float_cuda_Reshape_487_Call(const dim3 &grids, const dim3 &blocks, unsigned mem, cudaStream_t stream, float* input0, float* output0) {
    inception3_Reshape_float_float_cuda_Reshape_487<<<grids, blocks, mem, stream>>>(input0, output0);
}

    void executeImpl(cudaStream_t stream) {
        this->Reshape_float_float_cuda_Reshape_487_Call(grids, blocks, mem, stream, input0, output0);
    }
};


class inception3_Convolution_float_float_float_cuda_lib_Convolution_488Kernel : public Kernel {
public:
    inception3_Convolution_float_float_float_cuda_lib_Convolution_488Kernel(cudnnHandle_t  cudnn_handle, float*  input0, float*  input1, float*  output0, float*  Parameter_0_0, float**  Result_892_0) {
        this->cudnn_handle = cudnn_handle, this->input0 = input0, this->input1 = input1, this->output0 = output0, this->Parameter_0_0 = Parameter_0_0, this->Result_892_0 = Result_892_0;
        this->kernelName = "inception3_Convolution_float_float_float_cuda_lib_Convolution_488";
        this->Id = 0;
        this->mixable = 2;
    }

    void initParams() override {
        // empty implementation
    }

    void loadKernel() override {
        // Empty implementation
    }

        cudnnHandle_t  cudnn_handle; float*  input0; float*  input1; float*  output0;
    float*  Parameter_0_0; float**  Result_892_0;
private:

    
std::vector<int> getArgs() override {
    return std::vector<int>({64, 3, 299, 299, 32, 3, 3, 3, 0, 0, 2, 2, 1, 1});
}

    void Convolution_float_float_float_cuda_lib_Convolution_488(cudnnHandle_t cudnn_handle, float* input0, float* input1, float* output0)
{
    cudnnTensorDescriptor_t tensor_desc_0;
    CUDNN_SAFE_CALL(cudnnCreateTensorDescriptor(&tensor_desc_0));
    CUDNN_SAFE_CALL(cudnnSetTensor4dDescriptor(tensor_desc_0, CUDNN_TENSOR_NCHW, CUDNN_DATA_FLOAT, 64, 3, 299, 299));
    cudnnTensorDescriptor_t tensor_desc_1;
    CUDNN_SAFE_CALL(cudnnCreateTensorDescriptor(&tensor_desc_1));
    CUDNN_SAFE_CALL(cudnnSetTensor4dDescriptor(tensor_desc_1, CUDNN_TENSOR_NCHW, CUDNN_DATA_FLOAT, 64, 32, 149, 149));
    cudnnFilterDescriptor_t filter_desc;
    CUDNN_SAFE_CALL(cudnnCreateFilterDescriptor(&filter_desc));
    CUDNN_SAFE_CALL(cudnnSetFilter4dDescriptor(filter_desc, CUDNN_DATA_FLOAT, CUDNN_TENSOR_NCHW, 32, 3, 3, 3));
    cudnnConvolutionDescriptor_t conv_desc;
    CUDNN_SAFE_CALL(cudnnCreateConvolutionDescriptor(&conv_desc));
    CUDNN_SAFE_CALL(cudnnSetConvolution2dDescriptor(conv_desc, 0, 0, 2, 2, 1, 1, CUDNN_CROSS_CORRELATION, CUDNN_DATA_FLOAT));

    static bool selected_algo = true;
    static cudnnConvolutionFwdAlgo_t conv_fwd_algo = CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM;

    if (!selected_algo) {
        int num_algos;
        int max_algos = 0;
        // cudnnGetConvolutionForwardAlgorithm_v7;
        CUDNN_SAFE_CALL(
            cudnnGetConvolutionForwardAlgorithmMaxCount(cudnn_handle, &max_algos));
        std::vector<cudnnConvolutionFwdAlgoPerf_t> results(max_algos);
        CUDNN_SAFE_CALL(cudnnFindConvolutionForwardAlgorithm(cudnn_handle,
                                                tensor_desc_0,
                                                filter_desc,
                                                conv_desc,
                                                tensor_desc_1,
                                                static_cast<int>(results.size()),
                                                &num_algos,
                                                results.data()));
        results.resize(num_algos);
        for (size_t i = 0; i != results.size(); ++i) {
            cudnnConvolutionFwdAlgoPerf_t const& result = results[i];
            if (result.status == CUDNN_STATUS_SUCCESS) {
                conv_fwd_algo = result.algo;
                break;
            }
        }
        selected_algo = true;
    }
    const float alpha = 1.0;
    const float beta = 0.0;
    static void *workspace_ptr_0 = NULL;
    static size_t workspace_size_in_bytes = 0;
    if (!workspace_ptr_0)
    {
        CUDNN_SAFE_CALL(cudnnGetConvolutionForwardWorkspaceSize(cudnn_handle, tensor_desc_0, filter_desc, conv_desc, tensor_desc_1, conv_fwd_algo, &workspace_size_in_bytes));
        CUDA_SAFE_CALL(cudaMalloc(&workspace_ptr_0, workspace_size_in_bytes));
    }
    CUDNN_SAFE_CALL(mycudnnConvolutionForward(cudnn_handle, &alpha, tensor_desc_0, input0,filter_desc, input1, conv_desc, conv_fwd_algo, workspace_ptr_0, workspace_size_in_bytes, &beta, tensor_desc_1, output0));
    CUDNN_SAFE_CALL(cudnnDestroyTensorDescriptor(tensor_desc_0));
    CUDNN_SAFE_CALL(cudnnDestroyTensorDescriptor(tensor_desc_1));
    CUDNN_SAFE_CALL(cudnnDestroyFilterDescriptor(filter_desc));
    CUDNN_SAFE_CALL(cudnnDestroyConvolutionDescriptor(conv_desc));

}

    void executeImpl(cudaStream_t stream) {
        this->Convolution_float_float_float_cuda_lib_Convolution_488(cudnn_handle, input0, input1, output0);
    }
};


class inception3_BatchNormInference_float_float_float_float_float_float_cuda_BatchNormInference_489_CallKernel : public Kernel {
public:
    inception3_BatchNormInference_float_float_float_float_float_float_cuda_BatchNormInference_489_CallKernel(const dim3 & grids, const dim3 & blocks, unsigned  mem, cudaStream_t  stream, float*  input0, float*  input1, float*  input2, float*  input3, float*  input4, float*  output0, float*  Parameter_0_0, float**  Result_892_0) {
        this->grids = grids, this->blocks = blocks, this->mem = mem, this->stream = stream, this->input0 = input0, this->input1 = input1, this->input2 = input2, this->input3 = input3, this->input4 = input4, this->output0 = output0, this->Parameter_0_0 = Parameter_0_0, this->Result_892_0 = Result_892_0;
        this->kernelName = "inception3_BatchNormInference_float_float_float_float_float_float_cuda_BatchNormInference_489_Call";
        this->Id = 0;
        this->mixable = 0;
    }

    void initParams() override {
        // empty implementation
    }

    void loadKernel() override {
        // Empty implementation
    }

        dim3  grids; dim3  blocks; unsigned  mem; cudaStream_t  stream; float*  input0; float*  input1; float*  input2; float*  input3; float*  input4; float*  output0;
    float*  Parameter_0_0; float**  Result_892_0;
private:

    
std::vector<int> getArgs() override {
    return std::vector<int>();
}

     void BatchNormInference_float_float_float_float_float_float_cuda_BatchNormInference_489_Call(const dim3 &grids, const dim3 &blocks, unsigned mem, cudaStream_t stream, float* input0, float* input1, float* input2, float* input3, float* input4, float* output0) {
    inception3_BatchNormInference_float_float_float_float_float_float_cuda_BatchNormInference_489<<<grids, blocks, mem, stream>>>(input0, input1, input2, input3, input4, output0);
}

    void executeImpl(cudaStream_t stream) {
        this->BatchNormInference_float_float_float_float_float_float_cuda_BatchNormInference_489_Call(grids, blocks, mem, stream, input0, input1, input2, input3, input4, output0);
    }
};


class inception3_Relu_float_float_cuda_Relu_490_CallKernel : public Kernel {
public:
    inception3_Relu_float_float_cuda_Relu_490_CallKernel(const dim3 & grids, const dim3 & blocks, unsigned  mem, cudaStream_t  stream, float*  input0, float*  output0, float*  Parameter_0_0, float**  Result_892_0) {
        this->grids = grids, this->blocks = blocks, this->mem = mem, this->stream = stream, this->input0 = input0, this->output0 = output0, this->Parameter_0_0 = Parameter_0_0, this->Result_892_0 = Result_892_0;
        this->kernelName = "inception3_Relu_float_float_cuda_Relu_490_Call";
        this->Id = 0;
        this->mixable = 0;
    }

    void initParams() override {
        // empty implementation
    }

    void loadKernel() override {
        // Empty implementation
    }

        dim3  grids; dim3  blocks; unsigned  mem; cudaStream_t  stream; float*  input0; float*  output0;
    float*  Parameter_0_0; float**  Result_892_0;
private:

    
std::vector<int> getArgs() override {
    return std::vector<int>();
}

     void Relu_float_float_cuda_Relu_490_Call(const dim3 &grids, const dim3 &blocks, unsigned mem, cudaStream_t stream, float* input0, float* output0) {
    inception3_Relu_float_float_cuda_Relu_490<<<grids, blocks, mem, stream>>>(input0, output0);
}

    void executeImpl(cudaStream_t stream) {
        this->Relu_float_float_cuda_Relu_490_Call(grids, blocks, mem, stream, input0, output0);
    }
};


class inception3_Reshape_float_float_cuda_Reshape_491_CallKernel : public Kernel {
public:
    inception3_Reshape_float_float_cuda_Reshape_491_CallKernel(const dim3 & grids, const dim3 & blocks, unsigned  mem, cudaStream_t  stream, float*  input0, float*  output0, float*  Parameter_0_0, float**  Result_892_0) {
        this->grids = grids, this->blocks = blocks, this->mem = mem, this->stream = stream, this->input0 = input0, this->output0 = output0, this->Parameter_0_0 = Parameter_0_0, this->Result_892_0 = Result_892_0;
        this->kernelName = "inception3_Reshape_float_float_cuda_Reshape_491_Call";
        this->Id = 0;
        this->mixable = 0;
    }

    void initParams() override {
        // empty implementation
    }

    void loadKernel() override {
        // Empty implementation
    }

        dim3  grids; dim3  blocks; unsigned  mem; cudaStream_t  stream; float*  input0; float*  output0;
    float*  Parameter_0_0; float**  Result_892_0;
private:

    
std::vector<int> getArgs() override {
    return std::vector<int>();
}

     void Reshape_float_float_cuda_Reshape_491_Call(const dim3 &grids, const dim3 &blocks, unsigned mem, cudaStream_t stream, float* input0, float* output0) {
    inception3_Reshape_float_float_cuda_Reshape_491<<<grids, blocks, mem, stream>>>(input0, output0);
}

    void executeImpl(cudaStream_t stream) {
        this->Reshape_float_float_cuda_Reshape_491_Call(grids, blocks, mem, stream, input0, output0);
    }
};


class inception3_Convolution_float_float_float_cuda_lib_Convolution_492Kernel : public Kernel {
public:
    inception3_Convolution_float_float_float_cuda_lib_Convolution_492Kernel(cudnnHandle_t  cudnn_handle, float*  input0, float*  input1, float*  output0, float*  Parameter_0_0, float**  Result_892_0) {
        this->cudnn_handle = cudnn_handle, this->input0 = input0, this->input1 = input1, this->output0 = output0, this->Parameter_0_0 = Parameter_0_0, this->Result_892_0 = Result_892_0;
        this->kernelName = "inception3_Convolution_float_float_float_cuda_lib_Convolution_492";
        this->Id = 0;
        this->mixable = 2;
    }

    void initParams() override {
        // empty implementation
    }

    void loadKernel() override {
        // Empty implementation
    }

        cudnnHandle_t  cudnn_handle; float*  input0; float*  input1; float*  output0;
    float*  Parameter_0_0; float**  Result_892_0;
private:

    
std::vector<int> getArgs() override {
    return std::vector<int>({64, 32, 149, 149, 32, 32, 3, 3, 0, 0, 1, 1, 1, 1});
}

    void Convolution_float_float_float_cuda_lib_Convolution_492(cudnnHandle_t cudnn_handle, float* input0, float* input1, float* output0)
{
    cudnnTensorDescriptor_t tensor_desc_0;
    CUDNN_SAFE_CALL(cudnnCreateTensorDescriptor(&tensor_desc_0));
    CUDNN_SAFE_CALL(cudnnSetTensor4dDescriptor(tensor_desc_0, CUDNN_TENSOR_NCHW, CUDNN_DATA_FLOAT, 64, 32, 149, 149));
    cudnnTensorDescriptor_t tensor_desc_1;
    CUDNN_SAFE_CALL(cudnnCreateTensorDescriptor(&tensor_desc_1));
    CUDNN_SAFE_CALL(cudnnSetTensor4dDescriptor(tensor_desc_1, CUDNN_TENSOR_NCHW, CUDNN_DATA_FLOAT, 64, 32, 147, 147));
    cudnnFilterDescriptor_t filter_desc;
    CUDNN_SAFE_CALL(cudnnCreateFilterDescriptor(&filter_desc));
    CUDNN_SAFE_CALL(cudnnSetFilter4dDescriptor(filter_desc, CUDNN_DATA_FLOAT, CUDNN_TENSOR_NCHW, 32, 32, 3, 3));
    cudnnConvolutionDescriptor_t conv_desc;
    CUDNN_SAFE_CALL(cudnnCreateConvolutionDescriptor(&conv_desc));
    CUDNN_SAFE_CALL(cudnnSetConvolution2dDescriptor(conv_desc, 0, 0, 1, 1, 1, 1, CUDNN_CROSS_CORRELATION, CUDNN_DATA_FLOAT));

    static bool selected_algo = true;
    static cudnnConvolutionFwdAlgo_t conv_fwd_algo = CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM;

    if (!selected_algo) {
        int num_algos;
        int max_algos = 0;
        // cudnnGetConvolutionForwardAlgorithm_v7;
        CUDNN_SAFE_CALL(
            cudnnGetConvolutionForwardAlgorithmMaxCount(cudnn_handle, &max_algos));
        std::vector<cudnnConvolutionFwdAlgoPerf_t> results(max_algos);
        CUDNN_SAFE_CALL(cudnnFindConvolutionForwardAlgorithm(cudnn_handle,
                                                tensor_desc_0,
                                                filter_desc,
                                                conv_desc,
                                                tensor_desc_1,
                                                static_cast<int>(results.size()),
                                                &num_algos,
                                                results.data()));
        results.resize(num_algos);
        for (size_t i = 0; i != results.size(); ++i) {
            cudnnConvolutionFwdAlgoPerf_t const& result = results[i];
            if (result.status == CUDNN_STATUS_SUCCESS) {
                conv_fwd_algo = result.algo;
                break;
            }
        }
        selected_algo = true;
    }
    const float alpha = 1.0;
    const float beta = 0.0;
    static void *workspace_ptr_0 = NULL;
    static size_t workspace_size_in_bytes = 0;
    if (!workspace_ptr_0)
    {
        CUDNN_SAFE_CALL(cudnnGetConvolutionForwardWorkspaceSize(cudnn_handle, tensor_desc_0, filter_desc, conv_desc, tensor_desc_1, conv_fwd_algo, &workspace_size_in_bytes));
        CUDA_SAFE_CALL(cudaMalloc(&workspace_ptr_0, workspace_size_in_bytes));
    }
    CUDNN_SAFE_CALL(mycudnnConvolutionForward(cudnn_handle, &alpha, tensor_desc_0, input0,filter_desc, input1, conv_desc, conv_fwd_algo, workspace_ptr_0, workspace_size_in_bytes, &beta, tensor_desc_1, output0));
    CUDNN_SAFE_CALL(cudnnDestroyTensorDescriptor(tensor_desc_0));
    CUDNN_SAFE_CALL(cudnnDestroyTensorDescriptor(tensor_desc_1));
    CUDNN_SAFE_CALL(cudnnDestroyFilterDescriptor(filter_desc));
    CUDNN_SAFE_CALL(cudnnDestroyConvolutionDescriptor(conv_desc));

}

    void executeImpl(cudaStream_t stream) {
        this->Convolution_float_float_float_cuda_lib_Convolution_492(cudnn_handle, input0, input1, output0);
    }
};


class inception3_BatchNormInference_float_float_float_float_float_float_cuda_BatchNormInference_493_CallKernel : public Kernel {
public:
    inception3_BatchNormInference_float_float_float_float_float_float_cuda_BatchNormInference_493_CallKernel(const dim3 & grids, const dim3 & blocks, unsigned  mem, cudaStream_t  stream, float*  input0, float*  input1, float*  input2, float*  input3, float*  input4, float*  output0, float*  Parameter_0_0, float**  Result_892_0) {
        this->grids = grids, this->blocks = blocks, this->mem = mem, this->stream = stream, this->input0 = input0, this->input1 = input1, this->input2 = input2, this->input3 = input3, this->input4 = input4, this->output0 = output0, this->Parameter_0_0 = Parameter_0_0, this->Result_892_0 = Result_892_0;
        this->kernelName = "inception3_BatchNormInference_float_float_float_float_float_float_cuda_BatchNormInference_493_Call";
        this->Id = 0;
        this->mixable = 0;
    }

    void initParams() override {
        // empty implementation
    }

    void loadKernel() override {
        // Empty implementation
    }

        dim3  grids; dim3  blocks; unsigned  mem; cudaStream_t  stream; float*  input0; float*  input1; float*  input2; float*  input3; float*  input4; float*  output0;
    float*  Parameter_0_0; float**  Result_892_0;
private:

    
std::vector<int> getArgs() override {
    return std::vector<int>();
}

     void BatchNormInference_float_float_float_float_float_float_cuda_BatchNormInference_493_Call(const dim3 &grids, const dim3 &blocks, unsigned mem, cudaStream_t stream, float* input0, float* input1, float* input2, float* input3, float* input4, float* output0) {
    inception3_BatchNormInference_float_float_float_float_float_float_cuda_BatchNormInference_493<<<grids, blocks, mem, stream>>>(input0, input1, input2, input3, input4, output0);
}

    void executeImpl(cudaStream_t stream) {
        this->BatchNormInference_float_float_float_float_float_float_cuda_BatchNormInference_493_Call(grids, blocks, mem, stream, input0, input1, input2, input3, input4, output0);
    }
};


class inception3_Reshape_float_float_cuda_Reshape_495_CallKernel : public Kernel {
public:
    inception3_Reshape_float_float_cuda_Reshape_495_CallKernel(const dim3 & grids, const dim3 & blocks, unsigned  mem, cudaStream_t  stream, float*  input0, float*  output0, float*  Parameter_0_0, float**  Result_892_0) {
        this->grids = grids, this->blocks = blocks, this->mem = mem, this->stream = stream, this->input0 = input0, this->output0 = output0, this->Parameter_0_0 = Parameter_0_0, this->Result_892_0 = Result_892_0;
        this->kernelName = "inception3_Reshape_float_float_cuda_Reshape_495_Call";
        this->Id = 0;
        this->mixable = 0;
    }

    void initParams() override {
        // empty implementation
    }

    void loadKernel() override {
        // Empty implementation
    }

        dim3  grids; dim3  blocks; unsigned  mem; cudaStream_t  stream; float*  input0; float*  output0;
    float*  Parameter_0_0; float**  Result_892_0;
private:

    
std::vector<int> getArgs() override {
    return std::vector<int>();
}

     void Reshape_float_float_cuda_Reshape_495_Call(const dim3 &grids, const dim3 &blocks, unsigned mem, cudaStream_t stream, float* input0, float* output0) {
    inception3_Reshape_float_float_cuda_Reshape_495<<<grids, blocks, mem, stream>>>(input0, output0);
}

    void executeImpl(cudaStream_t stream) {
        this->Reshape_float_float_cuda_Reshape_495_Call(grids, blocks, mem, stream, input0, output0);
    }
};


class inception3_Convolution_float_float_float_cuda_lib_Convolution_496Kernel : public Kernel {
public:
    inception3_Convolution_float_float_float_cuda_lib_Convolution_496Kernel(cudnnHandle_t  cudnn_handle, float*  input0, float*  input1, float*  output0, float*  Parameter_0_0, float**  Result_892_0) {
        this->cudnn_handle = cudnn_handle, this->input0 = input0, this->input1 = input1, this->output0 = output0, this->Parameter_0_0 = Parameter_0_0, this->Result_892_0 = Result_892_0;
        this->kernelName = "inception3_Convolution_float_float_float_cuda_lib_Convolution_496";
        this->Id = 0;
        this->mixable = 2;
    }

    void initParams() override {
        // empty implementation
    }

    void loadKernel() override {
        // Empty implementation
    }

        cudnnHandle_t  cudnn_handle; float*  input0; float*  input1; float*  output0;
    float*  Parameter_0_0; float**  Result_892_0;
private:

    
std::vector<int> getArgs() override {
    return std::vector<int>({64, 32, 147, 147, 64, 32, 3, 3, 1, 1, 1, 1, 1, 1});
}

    void Convolution_float_float_float_cuda_lib_Convolution_496(cudnnHandle_t cudnn_handle, float* input0, float* input1, float* output0)
{
    cudnnTensorDescriptor_t tensor_desc_0;
    CUDNN_SAFE_CALL(cudnnCreateTensorDescriptor(&tensor_desc_0));
    CUDNN_SAFE_CALL(cudnnSetTensor4dDescriptor(tensor_desc_0, CUDNN_TENSOR_NCHW, CUDNN_DATA_FLOAT, 64, 32, 147, 147));
    cudnnTensorDescriptor_t tensor_desc_1;
    CUDNN_SAFE_CALL(cudnnCreateTensorDescriptor(&tensor_desc_1));
    CUDNN_SAFE_CALL(cudnnSetTensor4dDescriptor(tensor_desc_1, CUDNN_TENSOR_NCHW, CUDNN_DATA_FLOAT, 64, 64, 147, 147));
    cudnnFilterDescriptor_t filter_desc;
    CUDNN_SAFE_CALL(cudnnCreateFilterDescriptor(&filter_desc));
    CUDNN_SAFE_CALL(cudnnSetFilter4dDescriptor(filter_desc, CUDNN_DATA_FLOAT, CUDNN_TENSOR_NCHW, 64, 32, 3, 3));
    cudnnConvolutionDescriptor_t conv_desc;
    CUDNN_SAFE_CALL(cudnnCreateConvolutionDescriptor(&conv_desc));
    CUDNN_SAFE_CALL(cudnnSetConvolution2dDescriptor(conv_desc, 1, 1, 1, 1, 1, 1, CUDNN_CROSS_CORRELATION, CUDNN_DATA_FLOAT));

    static bool selected_algo = true;
    static cudnnConvolutionFwdAlgo_t conv_fwd_algo = CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM;

    if (!selected_algo) {
        int num_algos;
        int max_algos = 0;
        // cudnnGetConvolutionForwardAlgorithm_v7;
        CUDNN_SAFE_CALL(
            cudnnGetConvolutionForwardAlgorithmMaxCount(cudnn_handle, &max_algos));
        std::vector<cudnnConvolutionFwdAlgoPerf_t> results(max_algos);
        CUDNN_SAFE_CALL(cudnnFindConvolutionForwardAlgorithm(cudnn_handle,
                                                tensor_desc_0,
                                                filter_desc,
                                                conv_desc,
                                                tensor_desc_1,
                                                static_cast<int>(results.size()),
                                                &num_algos,
                                                results.data()));
        results.resize(num_algos);
        for (size_t i = 0; i != results.size(); ++i) {
            cudnnConvolutionFwdAlgoPerf_t const& result = results[i];
            if (result.status == CUDNN_STATUS_SUCCESS) {
                conv_fwd_algo = result.algo;
                break;
            }
        }
        selected_algo = true;
    }
    const float alpha = 1.0;
    const float beta = 0.0;
    static void *workspace_ptr_0 = NULL;
    static size_t workspace_size_in_bytes = 0;
    if (!workspace_ptr_0)
    {
        CUDNN_SAFE_CALL(cudnnGetConvolutionForwardWorkspaceSize(cudnn_handle, tensor_desc_0, filter_desc, conv_desc, tensor_desc_1, conv_fwd_algo, &workspace_size_in_bytes));
        CUDA_SAFE_CALL(cudaMalloc(&workspace_ptr_0, workspace_size_in_bytes));
    }
    CUDNN_SAFE_CALL(mycudnnConvolutionForward(cudnn_handle, &alpha, tensor_desc_0, input0,filter_desc, input1, conv_desc, conv_fwd_algo, workspace_ptr_0, workspace_size_in_bytes, &beta, tensor_desc_1, output0));
    CUDNN_SAFE_CALL(cudnnDestroyTensorDescriptor(tensor_desc_0));
    CUDNN_SAFE_CALL(cudnnDestroyTensorDescriptor(tensor_desc_1));
    CUDNN_SAFE_CALL(cudnnDestroyFilterDescriptor(filter_desc));
    CUDNN_SAFE_CALL(cudnnDestroyConvolutionDescriptor(conv_desc));

}

    void executeImpl(cudaStream_t stream) {
        this->Convolution_float_float_float_cuda_lib_Convolution_496(cudnn_handle, input0, input1, output0);
    }
};


class inception3_BatchNormInference_float_float_float_float_float_float_cuda_BatchNormInference_497_CallKernel : public Kernel {
public:
    inception3_BatchNormInference_float_float_float_float_float_float_cuda_BatchNormInference_497_CallKernel(const dim3 & grids, const dim3 & blocks, unsigned  mem, cudaStream_t  stream, float*  input0, float*  input1, float*  input2, float*  input3, float*  input4, float*  output0, float*  Parameter_0_0, float**  Result_892_0) {
        this->grids = grids, this->blocks = blocks, this->mem = mem, this->stream = stream, this->input0 = input0, this->input1 = input1, this->input2 = input2, this->input3 = input3, this->input4 = input4, this->output0 = output0, this->Parameter_0_0 = Parameter_0_0, this->Result_892_0 = Result_892_0;
        this->kernelName = "inception3_BatchNormInference_float_float_float_float_float_float_cuda_BatchNormInference_497_Call";
        this->Id = 0;
        this->mixable = 0;
    }

    void initParams() override {
        // empty implementation
    }

    void loadKernel() override {
        // Empty implementation
    }

        dim3  grids; dim3  blocks; unsigned  mem; cudaStream_t  stream; float*  input0; float*  input1; float*  input2; float*  input3; float*  input4; float*  output0;
    float*  Parameter_0_0; float**  Result_892_0;
private:

    
std::vector<int> getArgs() override {
    return std::vector<int>();
}

     void BatchNormInference_float_float_float_float_float_float_cuda_BatchNormInference_497_Call(const dim3 &grids, const dim3 &blocks, unsigned mem, cudaStream_t stream, float* input0, float* input1, float* input2, float* input3, float* input4, float* output0) {
    inception3_BatchNormInference_float_float_float_float_float_float_cuda_BatchNormInference_497<<<grids, blocks, mem, stream>>>(input0, input1, input2, input3, input4, output0);
}

    void executeImpl(cudaStream_t stream) {
        this->BatchNormInference_float_float_float_float_float_float_cuda_BatchNormInference_497_Call(grids, blocks, mem, stream, input0, input1, input2, input3, input4, output0);
    }
};


class inception3_MaxPool_float_float_cuda_lib_MaxPool_499Kernel : public Kernel {
public:
    inception3_MaxPool_float_float_cuda_lib_MaxPool_499Kernel(cudnnHandle_t  cudnn_handle, float*  input0, float*  output0, float*  Parameter_0_0, float**  Result_892_0) {
        this->cudnn_handle = cudnn_handle, this->input0 = input0, this->output0 = output0, this->Parameter_0_0 = Parameter_0_0, this->Result_892_0 = Result_892_0;
        this->kernelName = "inception3_MaxPool_float_float_cuda_lib_MaxPool_499";
        this->Id = 0;
        this->mixable = 0;
    }

    void initParams() override {
        // empty implementation
    }

    void loadKernel() override {
        // Empty implementation
    }

        cudnnHandle_t  cudnn_handle; float*  input0; float*  output0;
    float*  Parameter_0_0; float**  Result_892_0;
private:

    
std::vector<int> getArgs() override {
    return std::vector<int>();
}

    void MaxPool_float_float_cuda_lib_MaxPool_499(cudnnHandle_t cudnn_handle, float* input0, float* output0)
{
    cudnnTensorDescriptor_t input_desc;
    CUDNN_SAFE_CALL(cudnnCreateTensorDescriptor(&input_desc));
    CUDNN_SAFE_CALL(cudnnSetTensor4dDescriptor(input_desc, CUDNN_TENSOR_NCHW, CUDNN_DATA_FLOAT, 64, 64, 147, 147));
    cudnnTensorDescriptor_t output_desc;
    CUDNN_SAFE_CALL(cudnnCreateTensorDescriptor(&output_desc));
    CUDNN_SAFE_CALL(cudnnSetTensor4dDescriptor(output_desc, CUDNN_TENSOR_NCHW, CUDNN_DATA_FLOAT, 64, 64, 73, 73));
    cudnnPoolingDescriptor_t desc;
    cudnnCreatePoolingDescriptor(&desc);
    CUDNN_SAFE_CALL(cudnnSetPooling2dDescriptor(desc, CUDNN_POOLING_MAX, CUDNN_NOT_PROPAGATE_NAN,3, 3, 0, 0, 2, 2));
    const float alpha = 1.0;
    const float beta = 0.0;
    CUDNN_SAFE_CALL(cudnnPoolingForward(cudnn_handle, desc, &alpha, input_desc, input0, &beta, output_desc, output0));
    CUDNN_SAFE_CALL(cudnnDestroyTensorDescriptor(input_desc));
    CUDNN_SAFE_CALL(cudnnDestroyTensorDescriptor(output_desc));
    CUDNN_SAFE_CALL(cudnnDestroyPoolingDescriptor(desc));

}

    void executeImpl(cudaStream_t stream) {
        this->MaxPool_float_float_cuda_lib_MaxPool_499(cudnn_handle, input0, output0);
    }
};


class inception3_Reshape_float_float_cuda_Reshape_500_CallKernel : public Kernel {
public:
    inception3_Reshape_float_float_cuda_Reshape_500_CallKernel(const dim3 & grids, const dim3 & blocks, unsigned  mem, cudaStream_t  stream, float*  input0, float*  output0, float*  Parameter_0_0, float**  Result_892_0) {
        this->grids = grids, this->blocks = blocks, this->mem = mem, this->stream = stream, this->input0 = input0, this->output0 = output0, this->Parameter_0_0 = Parameter_0_0, this->Result_892_0 = Result_892_0;
        this->kernelName = "inception3_Reshape_float_float_cuda_Reshape_500_Call";
        this->Id = 0;
        this->mixable = 0;
    }

    void initParams() override {
        // empty implementation
    }

    void loadKernel() override {
        // Empty implementation
    }

        dim3  grids; dim3  blocks; unsigned  mem; cudaStream_t  stream; float*  input0; float*  output0;
    float*  Parameter_0_0; float**  Result_892_0;
private:

    
std::vector<int> getArgs() override {
    return std::vector<int>();
}

     void Reshape_float_float_cuda_Reshape_500_Call(const dim3 &grids, const dim3 &blocks, unsigned mem, cudaStream_t stream, float* input0, float* output0) {
    inception3_Reshape_float_float_cuda_Reshape_500<<<grids, blocks, mem, stream>>>(input0, output0);
}

    void executeImpl(cudaStream_t stream) {
        this->Reshape_float_float_cuda_Reshape_500_Call(grids, blocks, mem, stream, input0, output0);
    }
};


class inception3_Convolution_float_float_float_cuda_lib_Convolution_501Kernel : public Kernel {
public:
    inception3_Convolution_float_float_float_cuda_lib_Convolution_501Kernel(cudnnHandle_t  cudnn_handle, float*  input0, float*  input1, float*  output0, float*  Parameter_0_0, float**  Result_892_0) {
        this->cudnn_handle = cudnn_handle, this->input0 = input0, this->input1 = input1, this->output0 = output0, this->Parameter_0_0 = Parameter_0_0, this->Result_892_0 = Result_892_0;
        this->kernelName = "inception3_Convolution_float_float_float_cuda_lib_Convolution_501";
        this->Id = 0;
        this->mixable = 2;
    }

    void initParams() override {
        // empty implementation
    }

    void loadKernel() override {
        // Empty implementation
    }

        cudnnHandle_t  cudnn_handle; float*  input0; float*  input1; float*  output0;
    float*  Parameter_0_0; float**  Result_892_0;
private:

    
std::vector<int> getArgs() override {
    return std::vector<int>({64, 64, 73, 73, 80, 64, 1, 1, 0, 0, 1, 1, 1, 1});
}

    void Convolution_float_float_float_cuda_lib_Convolution_501(cudnnHandle_t cudnn_handle, float* input0, float* input1, float* output0)
{
    cudnnTensorDescriptor_t tensor_desc_0;
    CUDNN_SAFE_CALL(cudnnCreateTensorDescriptor(&tensor_desc_0));
    CUDNN_SAFE_CALL(cudnnSetTensor4dDescriptor(tensor_desc_0, CUDNN_TENSOR_NCHW, CUDNN_DATA_FLOAT, 64, 64, 73, 73));
    cudnnTensorDescriptor_t tensor_desc_1;
    CUDNN_SAFE_CALL(cudnnCreateTensorDescriptor(&tensor_desc_1));
    CUDNN_SAFE_CALL(cudnnSetTensor4dDescriptor(tensor_desc_1, CUDNN_TENSOR_NCHW, CUDNN_DATA_FLOAT, 64, 80, 73, 73));
    cudnnFilterDescriptor_t filter_desc;
    CUDNN_SAFE_CALL(cudnnCreateFilterDescriptor(&filter_desc));
    CUDNN_SAFE_CALL(cudnnSetFilter4dDescriptor(filter_desc, CUDNN_DATA_FLOAT, CUDNN_TENSOR_NCHW, 80, 64, 1, 1));
    cudnnConvolutionDescriptor_t conv_desc;
    CUDNN_SAFE_CALL(cudnnCreateConvolutionDescriptor(&conv_desc));
    CUDNN_SAFE_CALL(cudnnSetConvolution2dDescriptor(conv_desc, 0, 0, 1, 1, 1, 1, CUDNN_CROSS_CORRELATION, CUDNN_DATA_FLOAT));

    static bool selected_algo = true;
    static cudnnConvolutionFwdAlgo_t conv_fwd_algo = CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM;

    if (!selected_algo) {
        int num_algos;
        int max_algos = 0;
        // cudnnGetConvolutionForwardAlgorithm_v7;
        CUDNN_SAFE_CALL(
            cudnnGetConvolutionForwardAlgorithmMaxCount(cudnn_handle, &max_algos));
        std::vector<cudnnConvolutionFwdAlgoPerf_t> results(max_algos);
        CUDNN_SAFE_CALL(cudnnFindConvolutionForwardAlgorithm(cudnn_handle,
                                                tensor_desc_0,
                                                filter_desc,
                                                conv_desc,
                                                tensor_desc_1,
                                                static_cast<int>(results.size()),
                                                &num_algos,
                                                results.data()));
        results.resize(num_algos);
        for (size_t i = 0; i != results.size(); ++i) {
            cudnnConvolutionFwdAlgoPerf_t const& result = results[i];
            if (result.status == CUDNN_STATUS_SUCCESS) {
                conv_fwd_algo = result.algo;
                break;
            }
        }
        selected_algo = true;
    }
    const float alpha = 1.0;
    const float beta = 0.0;
    static void *workspace_ptr_0 = NULL;
    static size_t workspace_size_in_bytes = 0;
    if (!workspace_ptr_0)
    {
        CUDNN_SAFE_CALL(cudnnGetConvolutionForwardWorkspaceSize(cudnn_handle, tensor_desc_0, filter_desc, conv_desc, tensor_desc_1, conv_fwd_algo, &workspace_size_in_bytes));
        CUDA_SAFE_CALL(cudaMalloc(&workspace_ptr_0, workspace_size_in_bytes));
    }
    CUDNN_SAFE_CALL(mycudnnConvolutionForward(cudnn_handle, &alpha, tensor_desc_0, input0,filter_desc, input1, conv_desc, conv_fwd_algo, workspace_ptr_0, workspace_size_in_bytes, &beta, tensor_desc_1, output0));
    CUDNN_SAFE_CALL(cudnnDestroyTensorDescriptor(tensor_desc_0));
    CUDNN_SAFE_CALL(cudnnDestroyTensorDescriptor(tensor_desc_1));
    CUDNN_SAFE_CALL(cudnnDestroyFilterDescriptor(filter_desc));
    CUDNN_SAFE_CALL(cudnnDestroyConvolutionDescriptor(conv_desc));

}

    void executeImpl(cudaStream_t stream) {
        this->Convolution_float_float_float_cuda_lib_Convolution_501(cudnn_handle, input0, input1, output0);
    }
};


class inception3_BatchNormInference_float_float_float_float_float_float_cuda_BatchNormInference_502_CallKernel : public Kernel {
public:
    inception3_BatchNormInference_float_float_float_float_float_float_cuda_BatchNormInference_502_CallKernel(const dim3 & grids, const dim3 & blocks, unsigned  mem, cudaStream_t  stream, float*  input0, float*  input1, float*  input2, float*  input3, float*  input4, float*  output0, float*  Parameter_0_0, float**  Result_892_0) {
        this->grids = grids, this->blocks = blocks, this->mem = mem, this->stream = stream, this->input0 = input0, this->input1 = input1, this->input2 = input2, this->input3 = input3, this->input4 = input4, this->output0 = output0, this->Parameter_0_0 = Parameter_0_0, this->Result_892_0 = Result_892_0;
        this->kernelName = "inception3_BatchNormInference_float_float_float_float_float_float_cuda_BatchNormInference_502_Call";
        this->Id = 0;
        this->mixable = 0;
    }

    void initParams() override {
        // empty implementation
    }

    void loadKernel() override {
        // Empty implementation
    }

        dim3  grids; dim3  blocks; unsigned  mem; cudaStream_t  stream; float*  input0; float*  input1; float*  input2; float*  input3; float*  input4; float*  output0;
    float*  Parameter_0_0; float**  Result_892_0;
private:

    
std::vector<int> getArgs() override {
    return std::vector<int>();
}

     void BatchNormInference_float_float_float_float_float_float_cuda_BatchNormInference_502_Call(const dim3 &grids, const dim3 &blocks, unsigned mem, cudaStream_t stream, float* input0, float* input1, float* input2, float* input3, float* input4, float* output0) {
    inception3_BatchNormInference_float_float_float_float_float_float_cuda_BatchNormInference_502<<<grids, blocks, mem, stream>>>(input0, input1, input2, input3, input4, output0);
}

    void executeImpl(cudaStream_t stream) {
        this->BatchNormInference_float_float_float_float_float_float_cuda_BatchNormInference_502_Call(grids, blocks, mem, stream, input0, input1, input2, input3, input4, output0);
    }
};


class inception3_Reshape_float_float_cuda_Reshape_504_CallKernel : public Kernel {
public:
    inception3_Reshape_float_float_cuda_Reshape_504_CallKernel(const dim3 & grids, const dim3 & blocks, unsigned  mem, cudaStream_t  stream, float*  input0, float*  output0, float*  Parameter_0_0, float**  Result_892_0) {
        this->grids = grids, this->blocks = blocks, this->mem = mem, this->stream = stream, this->input0 = input0, this->output0 = output0, this->Parameter_0_0 = Parameter_0_0, this->Result_892_0 = Result_892_0;
        this->kernelName = "inception3_Reshape_float_float_cuda_Reshape_504_Call";
        this->Id = 0;
        this->mixable = 0;
    }

    void initParams() override {
        // empty implementation
    }

    void loadKernel() override {
        // Empty implementation
    }

        dim3  grids; dim3  blocks; unsigned  mem; cudaStream_t  stream; float*  input0; float*  output0;
    float*  Parameter_0_0; float**  Result_892_0;
private:

    
std::vector<int> getArgs() override {
    return std::vector<int>();
}

     void Reshape_float_float_cuda_Reshape_504_Call(const dim3 &grids, const dim3 &blocks, unsigned mem, cudaStream_t stream, float* input0, float* output0) {
    inception3_Reshape_float_float_cuda_Reshape_504<<<grids, blocks, mem, stream>>>(input0, output0);
}

    void executeImpl(cudaStream_t stream) {
        this->Reshape_float_float_cuda_Reshape_504_Call(grids, blocks, mem, stream, input0, output0);
    }
};


class inception3_Convolution_float_float_float_cuda_lib_Convolution_505Kernel : public Kernel {
public:
    inception3_Convolution_float_float_float_cuda_lib_Convolution_505Kernel(cudnnHandle_t  cudnn_handle, float*  input0, float*  input1, float*  output0, float*  Parameter_0_0, float**  Result_892_0) {
        this->cudnn_handle = cudnn_handle, this->input0 = input0, this->input1 = input1, this->output0 = output0, this->Parameter_0_0 = Parameter_0_0, this->Result_892_0 = Result_892_0;
        this->kernelName = "inception3_Convolution_float_float_float_cuda_lib_Convolution_505";
        this->Id = 0;
        this->mixable = 2;
    }

    void initParams() override {
        // empty implementation
    }

    void loadKernel() override {
        // Empty implementation
    }

        cudnnHandle_t  cudnn_handle; float*  input0; float*  input1; float*  output0;
    float*  Parameter_0_0; float**  Result_892_0;
private:

    
std::vector<int> getArgs() override {
    return std::vector<int>({64, 80, 73, 73, 192, 80, 3, 3, 0, 0, 1, 1, 1, 1});
}

    void Convolution_float_float_float_cuda_lib_Convolution_505(cudnnHandle_t cudnn_handle, float* input0, float* input1, float* output0)
{
    cudnnTensorDescriptor_t tensor_desc_0;
    CUDNN_SAFE_CALL(cudnnCreateTensorDescriptor(&tensor_desc_0));
    CUDNN_SAFE_CALL(cudnnSetTensor4dDescriptor(tensor_desc_0, CUDNN_TENSOR_NCHW, CUDNN_DATA_FLOAT, 64, 80, 73, 73));
    cudnnTensorDescriptor_t tensor_desc_1;
    CUDNN_SAFE_CALL(cudnnCreateTensorDescriptor(&tensor_desc_1));
    CUDNN_SAFE_CALL(cudnnSetTensor4dDescriptor(tensor_desc_1, CUDNN_TENSOR_NCHW, CUDNN_DATA_FLOAT, 64, 192, 71, 71));
    cudnnFilterDescriptor_t filter_desc;
    CUDNN_SAFE_CALL(cudnnCreateFilterDescriptor(&filter_desc));
    CUDNN_SAFE_CALL(cudnnSetFilter4dDescriptor(filter_desc, CUDNN_DATA_FLOAT, CUDNN_TENSOR_NCHW, 192, 80, 3, 3));
    cudnnConvolutionDescriptor_t conv_desc;
    CUDNN_SAFE_CALL(cudnnCreateConvolutionDescriptor(&conv_desc));
    CUDNN_SAFE_CALL(cudnnSetConvolution2dDescriptor(conv_desc, 0, 0, 1, 1, 1, 1, CUDNN_CROSS_CORRELATION, CUDNN_DATA_FLOAT));

    static bool selected_algo = true;
    static cudnnConvolutionFwdAlgo_t conv_fwd_algo = CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM;

    if (!selected_algo) {
        int num_algos;
        int max_algos = 0;
        // cudnnGetConvolutionForwardAlgorithm_v7;
        CUDNN_SAFE_CALL(
            cudnnGetConvolutionForwardAlgorithmMaxCount(cudnn_handle, &max_algos));
        std::vector<cudnnConvolutionFwdAlgoPerf_t> results(max_algos);
        CUDNN_SAFE_CALL(cudnnFindConvolutionForwardAlgorithm(cudnn_handle,
                                                tensor_desc_0,
                                                filter_desc,
                                                conv_desc,
                                                tensor_desc_1,
                                                static_cast<int>(results.size()),
                                                &num_algos,
                                                results.data()));
        results.resize(num_algos);
        for (size_t i = 0; i != results.size(); ++i) {
            cudnnConvolutionFwdAlgoPerf_t const& result = results[i];
            if (result.status == CUDNN_STATUS_SUCCESS) {
                conv_fwd_algo = result.algo;
                break;
            }
        }
        selected_algo = true;
    }
    const float alpha = 1.0;
    const float beta = 0.0;
    static void *workspace_ptr_0 = NULL;
    static size_t workspace_size_in_bytes = 0;
    if (!workspace_ptr_0)
    {
        CUDNN_SAFE_CALL(cudnnGetConvolutionForwardWorkspaceSize(cudnn_handle, tensor_desc_0, filter_desc, conv_desc, tensor_desc_1, conv_fwd_algo, &workspace_size_in_bytes));
        CUDA_SAFE_CALL(cudaMalloc(&workspace_ptr_0, workspace_size_in_bytes));
    }
    CUDNN_SAFE_CALL(mycudnnConvolutionForward(cudnn_handle, &alpha, tensor_desc_0, input0,filter_desc, input1, conv_desc, conv_fwd_algo, workspace_ptr_0, workspace_size_in_bytes, &beta, tensor_desc_1, output0));
    CUDNN_SAFE_CALL(cudnnDestroyTensorDescriptor(tensor_desc_0));
    CUDNN_SAFE_CALL(cudnnDestroyTensorDescriptor(tensor_desc_1));
    CUDNN_SAFE_CALL(cudnnDestroyFilterDescriptor(filter_desc));
    CUDNN_SAFE_CALL(cudnnDestroyConvolutionDescriptor(conv_desc));

}

    void executeImpl(cudaStream_t stream) {
        this->Convolution_float_float_float_cuda_lib_Convolution_505(cudnn_handle, input0, input1, output0);
    }
};


class inception3_BatchNormInference_float_float_float_float_float_float_cuda_BatchNormInference_506_CallKernel : public Kernel {
public:
    inception3_BatchNormInference_float_float_float_float_float_float_cuda_BatchNormInference_506_CallKernel(const dim3 & grids, const dim3 & blocks, unsigned  mem, cudaStream_t  stream, float*  input0, float*  input1, float*  input2, float*  input3, float*  input4, float*  output0, float*  Parameter_0_0, float**  Result_892_0) {
        this->grids = grids, this->blocks = blocks, this->mem = mem, this->stream = stream, this->input0 = input0, this->input1 = input1, this->input2 = input2, this->input3 = input3, this->input4 = input4, this->output0 = output0, this->Parameter_0_0 = Parameter_0_0, this->Result_892_0 = Result_892_0;
        this->kernelName = "inception3_BatchNormInference_float_float_float_float_float_float_cuda_BatchNormInference_506_Call";
        this->Id = 0;
        this->mixable = 0;
    }

    void initParams() override {
        // empty implementation
    }

    void loadKernel() override {
        // Empty implementation
    }

        dim3  grids; dim3  blocks; unsigned  mem; cudaStream_t  stream; float*  input0; float*  input1; float*  input2; float*  input3; float*  input4; float*  output0;
    float*  Parameter_0_0; float**  Result_892_0;
private:

    
std::vector<int> getArgs() override {
    return std::vector<int>();
}

     void BatchNormInference_float_float_float_float_float_float_cuda_BatchNormInference_506_Call(const dim3 &grids, const dim3 &blocks, unsigned mem, cudaStream_t stream, float* input0, float* input1, float* input2, float* input3, float* input4, float* output0) {
    inception3_BatchNormInference_float_float_float_float_float_float_cuda_BatchNormInference_506<<<grids, blocks, mem, stream>>>(input0, input1, input2, input3, input4, output0);
}

    void executeImpl(cudaStream_t stream) {
        this->BatchNormInference_float_float_float_float_float_float_cuda_BatchNormInference_506_Call(grids, blocks, mem, stream, input0, input1, input2, input3, input4, output0);
    }
};


class inception3_MaxPool_float_float_cuda_lib_MaxPool_508Kernel : public Kernel {
public:
    inception3_MaxPool_float_float_cuda_lib_MaxPool_508Kernel(cudnnHandle_t  cudnn_handle, float*  input0, float*  output0, float*  Parameter_0_0, float**  Result_892_0) {
        this->cudnn_handle = cudnn_handle, this->input0 = input0, this->output0 = output0, this->Parameter_0_0 = Parameter_0_0, this->Result_892_0 = Result_892_0;
        this->kernelName = "inception3_MaxPool_float_float_cuda_lib_MaxPool_508";
        this->Id = 0;
        this->mixable = 0;
    }

    void initParams() override {
        // empty implementation
    }

    void loadKernel() override {
        // Empty implementation
    }

        cudnnHandle_t  cudnn_handle; float*  input0; float*  output0;
    float*  Parameter_0_0; float**  Result_892_0;
private:

    
std::vector<int> getArgs() override {
    return std::vector<int>();
}

    void MaxPool_float_float_cuda_lib_MaxPool_508(cudnnHandle_t cudnn_handle, float* input0, float* output0)
{
    cudnnTensorDescriptor_t input_desc;
    CUDNN_SAFE_CALL(cudnnCreateTensorDescriptor(&input_desc));
    CUDNN_SAFE_CALL(cudnnSetTensor4dDescriptor(input_desc, CUDNN_TENSOR_NCHW, CUDNN_DATA_FLOAT, 64, 192, 71, 71));
    cudnnTensorDescriptor_t output_desc;
    CUDNN_SAFE_CALL(cudnnCreateTensorDescriptor(&output_desc));
    CUDNN_SAFE_CALL(cudnnSetTensor4dDescriptor(output_desc, CUDNN_TENSOR_NCHW, CUDNN_DATA_FLOAT, 64, 192, 35, 35));
    cudnnPoolingDescriptor_t desc;
    cudnnCreatePoolingDescriptor(&desc);
    CUDNN_SAFE_CALL(cudnnSetPooling2dDescriptor(desc, CUDNN_POOLING_MAX, CUDNN_NOT_PROPAGATE_NAN,3, 3, 0, 0, 2, 2));
    const float alpha = 1.0;
    const float beta = 0.0;
    CUDNN_SAFE_CALL(cudnnPoolingForward(cudnn_handle, desc, &alpha, input_desc, input0, &beta, output_desc, output0));
    CUDNN_SAFE_CALL(cudnnDestroyTensorDescriptor(input_desc));
    CUDNN_SAFE_CALL(cudnnDestroyTensorDescriptor(output_desc));
    CUDNN_SAFE_CALL(cudnnDestroyPoolingDescriptor(desc));

}

    void executeImpl(cudaStream_t stream) {
        this->MaxPool_float_float_cuda_lib_MaxPool_508(cudnn_handle, input0, output0);
    }
};


class inception3_Reshape_float_float_cuda_Reshape_511_CallKernel : public Kernel {
public:
    inception3_Reshape_float_float_cuda_Reshape_511_CallKernel(const dim3 & grids, const dim3 & blocks, unsigned  mem, cudaStream_t  stream, float*  input0, float*  output0, float*  Parameter_0_0, float**  Result_892_0) {
        this->grids = grids, this->blocks = blocks, this->mem = mem, this->stream = stream, this->input0 = input0, this->output0 = output0, this->Parameter_0_0 = Parameter_0_0, this->Result_892_0 = Result_892_0;
        this->kernelName = "inception3_Reshape_float_float_cuda_Reshape_511_Call";
        this->Id = 0;
        this->mixable = 0;
    }

    void initParams() override {
        // empty implementation
    }

    void loadKernel() override {
        // Empty implementation
    }

        dim3  grids; dim3  blocks; unsigned  mem; cudaStream_t  stream; float*  input0; float*  output0;
    float*  Parameter_0_0; float**  Result_892_0;
private:

    
std::vector<int> getArgs() override {
    return std::vector<int>();
}

     void Reshape_float_float_cuda_Reshape_511_Call(const dim3 &grids, const dim3 &blocks, unsigned mem, cudaStream_t stream, float* input0, float* output0) {
    inception3_Reshape_float_float_cuda_Reshape_511<<<grids, blocks, mem, stream>>>(input0, output0);
}

    void executeImpl(cudaStream_t stream) {
        this->Reshape_float_float_cuda_Reshape_511_Call(grids, blocks, mem, stream, input0, output0);
    }
};


class inception3_Convolution_float_float_float_cuda_lib_Convolution_512Kernel : public Kernel {
public:
    inception3_Convolution_float_float_float_cuda_lib_Convolution_512Kernel(cudnnHandle_t  cudnn_handle, float*  input0, float*  input1, float*  output0, float*  Parameter_0_0, float**  Result_892_0) {
        this->cudnn_handle = cudnn_handle, this->input0 = input0, this->input1 = input1, this->output0 = output0, this->Parameter_0_0 = Parameter_0_0, this->Result_892_0 = Result_892_0;
        this->kernelName = "inception3_Convolution_float_float_float_cuda_lib_Convolution_512";
        this->Id = 0;
        this->mixable = 2;
    }

    void initParams() override {
        // empty implementation
    }

    void loadKernel() override {
        // Empty implementation
    }

        cudnnHandle_t  cudnn_handle; float*  input0; float*  input1; float*  output0;
    float*  Parameter_0_0; float**  Result_892_0;
private:

    
std::vector<int> getArgs() override {
    return std::vector<int>({64, 192, 35, 35, 48, 192, 1, 1, 0, 0, 1, 1, 1, 1});
}

    void Convolution_float_float_float_cuda_lib_Convolution_512(cudnnHandle_t cudnn_handle, float* input0, float* input1, float* output0)
{
    cudnnTensorDescriptor_t tensor_desc_0;
    CUDNN_SAFE_CALL(cudnnCreateTensorDescriptor(&tensor_desc_0));
    CUDNN_SAFE_CALL(cudnnSetTensor4dDescriptor(tensor_desc_0, CUDNN_TENSOR_NCHW, CUDNN_DATA_FLOAT, 64, 192, 35, 35));
    cudnnTensorDescriptor_t tensor_desc_1;
    CUDNN_SAFE_CALL(cudnnCreateTensorDescriptor(&tensor_desc_1));
    CUDNN_SAFE_CALL(cudnnSetTensor4dDescriptor(tensor_desc_1, CUDNN_TENSOR_NCHW, CUDNN_DATA_FLOAT, 64, 48, 35, 35));
    cudnnFilterDescriptor_t filter_desc;
    CUDNN_SAFE_CALL(cudnnCreateFilterDescriptor(&filter_desc));
    CUDNN_SAFE_CALL(cudnnSetFilter4dDescriptor(filter_desc, CUDNN_DATA_FLOAT, CUDNN_TENSOR_NCHW, 48, 192, 1, 1));
    cudnnConvolutionDescriptor_t conv_desc;
    CUDNN_SAFE_CALL(cudnnCreateConvolutionDescriptor(&conv_desc));
    CUDNN_SAFE_CALL(cudnnSetConvolution2dDescriptor(conv_desc, 0, 0, 1, 1, 1, 1, CUDNN_CROSS_CORRELATION, CUDNN_DATA_FLOAT));

    static bool selected_algo = true;
    static cudnnConvolutionFwdAlgo_t conv_fwd_algo = CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM;

    if (!selected_algo) {
        int num_algos;
        int max_algos = 0;
        // cudnnGetConvolutionForwardAlgorithm_v7;
        CUDNN_SAFE_CALL(
            cudnnGetConvolutionForwardAlgorithmMaxCount(cudnn_handle, &max_algos));
        std::vector<cudnnConvolutionFwdAlgoPerf_t> results(max_algos);
        CUDNN_SAFE_CALL(cudnnFindConvolutionForwardAlgorithm(cudnn_handle,
                                                tensor_desc_0,
                                                filter_desc,
                                                conv_desc,
                                                tensor_desc_1,
                                                static_cast<int>(results.size()),
                                                &num_algos,
                                                results.data()));
        results.resize(num_algos);
        for (size_t i = 0; i != results.size(); ++i) {
            cudnnConvolutionFwdAlgoPerf_t const& result = results[i];
            if (result.status == CUDNN_STATUS_SUCCESS) {
                conv_fwd_algo = result.algo;
                break;
            }
        }
        selected_algo = true;
    }
    const float alpha = 1.0;
    const float beta = 0.0;
    static void *workspace_ptr_0 = NULL;
    static size_t workspace_size_in_bytes = 0;
    if (!workspace_ptr_0)
    {
        CUDNN_SAFE_CALL(cudnnGetConvolutionForwardWorkspaceSize(cudnn_handle, tensor_desc_0, filter_desc, conv_desc, tensor_desc_1, conv_fwd_algo, &workspace_size_in_bytes));
        CUDA_SAFE_CALL(cudaMalloc(&workspace_ptr_0, workspace_size_in_bytes));
    }
    CUDNN_SAFE_CALL(mycudnnConvolutionForward(cudnn_handle, &alpha, tensor_desc_0, input0,filter_desc, input1, conv_desc, conv_fwd_algo, workspace_ptr_0, workspace_size_in_bytes, &beta, tensor_desc_1, output0));
    CUDNN_SAFE_CALL(cudnnDestroyTensorDescriptor(tensor_desc_0));
    CUDNN_SAFE_CALL(cudnnDestroyTensorDescriptor(tensor_desc_1));
    CUDNN_SAFE_CALL(cudnnDestroyFilterDescriptor(filter_desc));
    CUDNN_SAFE_CALL(cudnnDestroyConvolutionDescriptor(conv_desc));

}

    void executeImpl(cudaStream_t stream) {
        this->Convolution_float_float_float_cuda_lib_Convolution_512(cudnn_handle, input0, input1, output0);
    }
};


class inception3_BatchNormInference_float_float_float_float_float_float_cuda_BatchNormInference_517_CallKernel : public Kernel {
public:
    inception3_BatchNormInference_float_float_float_float_float_float_cuda_BatchNormInference_517_CallKernel(const dim3 & grids, const dim3 & blocks, unsigned  mem, cudaStream_t  stream, float*  input0, float*  input1, float*  input2, float*  input3, float*  input4, float*  output0, float*  Parameter_0_0, float**  Result_892_0) {
        this->grids = grids, this->blocks = blocks, this->mem = mem, this->stream = stream, this->input0 = input0, this->input1 = input1, this->input2 = input2, this->input3 = input3, this->input4 = input4, this->output0 = output0, this->Parameter_0_0 = Parameter_0_0, this->Result_892_0 = Result_892_0;
        this->kernelName = "inception3_BatchNormInference_float_float_float_float_float_float_cuda_BatchNormInference_517_Call";
        this->Id = 0;
        this->mixable = 0;
    }

    void initParams() override {
        // empty implementation
    }

    void loadKernel() override {
        // Empty implementation
    }

        dim3  grids; dim3  blocks; unsigned  mem; cudaStream_t  stream; float*  input0; float*  input1; float*  input2; float*  input3; float*  input4; float*  output0;
    float*  Parameter_0_0; float**  Result_892_0;
private:

    
std::vector<int> getArgs() override {
    return std::vector<int>();
}

     void BatchNormInference_float_float_float_float_float_float_cuda_BatchNormInference_517_Call(const dim3 &grids, const dim3 &blocks, unsigned mem, cudaStream_t stream, float* input0, float* input1, float* input2, float* input3, float* input4, float* output0) {
    inception3_BatchNormInference_float_float_float_float_float_float_cuda_BatchNormInference_517<<<grids, blocks, mem, stream>>>(input0, input1, input2, input3, input4, output0);
}

    void executeImpl(cudaStream_t stream) {
        this->BatchNormInference_float_float_float_float_float_float_cuda_BatchNormInference_517_Call(grids, blocks, mem, stream, input0, input1, input2, input3, input4, output0);
    }
};


class inception3_Reshape_float_float_cuda_Reshape_525_CallKernel : public Kernel {
public:
    inception3_Reshape_float_float_cuda_Reshape_525_CallKernel(const dim3 & grids, const dim3 & blocks, unsigned  mem, cudaStream_t  stream, float*  input0, float*  output0, float*  Parameter_0_0, float**  Result_892_0) {
        this->grids = grids, this->blocks = blocks, this->mem = mem, this->stream = stream, this->input0 = input0, this->output0 = output0, this->Parameter_0_0 = Parameter_0_0, this->Result_892_0 = Result_892_0;
        this->kernelName = "inception3_Reshape_float_float_cuda_Reshape_525_Call";
        this->Id = 0;
        this->mixable = 0;
    }

    void initParams() override {
        // empty implementation
    }

    void loadKernel() override {
        // Empty implementation
    }

        dim3  grids; dim3  blocks; unsigned  mem; cudaStream_t  stream; float*  input0; float*  output0;
    float*  Parameter_0_0; float**  Result_892_0;
private:

    
std::vector<int> getArgs() override {
    return std::vector<int>();
}

     void Reshape_float_float_cuda_Reshape_525_Call(const dim3 &grids, const dim3 &blocks, unsigned mem, cudaStream_t stream, float* input0, float* output0) {
    inception3_Reshape_float_float_cuda_Reshape_525<<<grids, blocks, mem, stream>>>(input0, output0);
}

    void executeImpl(cudaStream_t stream) {
        this->Reshape_float_float_cuda_Reshape_525_Call(grids, blocks, mem, stream, input0, output0);
    }
};


class inception3_Convolution_float_float_float_cuda_lib_Convolution_526Kernel : public Kernel {
public:
    inception3_Convolution_float_float_float_cuda_lib_Convolution_526Kernel(cudnnHandle_t  cudnn_handle, float*  input0, float*  input1, float*  output0, float*  Parameter_0_0, float**  Result_892_0) {
        this->cudnn_handle = cudnn_handle, this->input0 = input0, this->input1 = input1, this->output0 = output0, this->Parameter_0_0 = Parameter_0_0, this->Result_892_0 = Result_892_0;
        this->kernelName = "inception3_Convolution_float_float_float_cuda_lib_Convolution_526";
        this->Id = 0;
        this->mixable = 2;
    }

    void initParams() override {
        // empty implementation
    }

    void loadKernel() override {
        // Empty implementation
    }

        cudnnHandle_t  cudnn_handle; float*  input0; float*  input1; float*  output0;
    float*  Parameter_0_0; float**  Result_892_0;
private:

    
std::vector<int> getArgs() override {
    return std::vector<int>({64, 48, 35, 35, 64, 48, 5, 5, 2, 2, 1, 1, 1, 1});
}

    void Convolution_float_float_float_cuda_lib_Convolution_526(cudnnHandle_t cudnn_handle, float* input0, float* input1, float* output0)
{
    cudnnTensorDescriptor_t tensor_desc_0;
    CUDNN_SAFE_CALL(cudnnCreateTensorDescriptor(&tensor_desc_0));
    CUDNN_SAFE_CALL(cudnnSetTensor4dDescriptor(tensor_desc_0, CUDNN_TENSOR_NCHW, CUDNN_DATA_FLOAT, 64, 48, 35, 35));
    cudnnTensorDescriptor_t tensor_desc_1;
    CUDNN_SAFE_CALL(cudnnCreateTensorDescriptor(&tensor_desc_1));
    CUDNN_SAFE_CALL(cudnnSetTensor4dDescriptor(tensor_desc_1, CUDNN_TENSOR_NCHW, CUDNN_DATA_FLOAT, 64, 64, 35, 35));
    cudnnFilterDescriptor_t filter_desc;
    CUDNN_SAFE_CALL(cudnnCreateFilterDescriptor(&filter_desc));
    CUDNN_SAFE_CALL(cudnnSetFilter4dDescriptor(filter_desc, CUDNN_DATA_FLOAT, CUDNN_TENSOR_NCHW, 64, 48, 5, 5));
    cudnnConvolutionDescriptor_t conv_desc;
    CUDNN_SAFE_CALL(cudnnCreateConvolutionDescriptor(&conv_desc));
    CUDNN_SAFE_CALL(cudnnSetConvolution2dDescriptor(conv_desc, 2, 2, 1, 1, 1, 1, CUDNN_CROSS_CORRELATION, CUDNN_DATA_FLOAT));

    static bool selected_algo = true;
    static cudnnConvolutionFwdAlgo_t conv_fwd_algo = CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM;

    if (!selected_algo) {
        int num_algos;
        int max_algos = 0;
        // cudnnGetConvolutionForwardAlgorithm_v7;
        CUDNN_SAFE_CALL(
            cudnnGetConvolutionForwardAlgorithmMaxCount(cudnn_handle, &max_algos));
        std::vector<cudnnConvolutionFwdAlgoPerf_t> results(max_algos);
        CUDNN_SAFE_CALL(cudnnFindConvolutionForwardAlgorithm(cudnn_handle,
                                                tensor_desc_0,
                                                filter_desc,
                                                conv_desc,
                                                tensor_desc_1,
                                                static_cast<int>(results.size()),
                                                &num_algos,
                                                results.data()));
        results.resize(num_algos);
        for (size_t i = 0; i != results.size(); ++i) {
            cudnnConvolutionFwdAlgoPerf_t const& result = results[i];
            if (result.status == CUDNN_STATUS_SUCCESS) {
                conv_fwd_algo = result.algo;
                break;
            }
        }
        selected_algo = true;
    }
    const float alpha = 1.0;
    const float beta = 0.0;
    static void *workspace_ptr_0 = NULL;
    static size_t workspace_size_in_bytes = 0;
    if (!workspace_ptr_0)
    {
        CUDNN_SAFE_CALL(cudnnGetConvolutionForwardWorkspaceSize(cudnn_handle, tensor_desc_0, filter_desc, conv_desc, tensor_desc_1, conv_fwd_algo, &workspace_size_in_bytes));
        CUDA_SAFE_CALL(cudaMalloc(&workspace_ptr_0, workspace_size_in_bytes));
    }
    CUDNN_SAFE_CALL(mycudnnConvolutionForward(cudnn_handle, &alpha, tensor_desc_0, input0,filter_desc, input1, conv_desc, conv_fwd_algo, workspace_ptr_0, workspace_size_in_bytes, &beta, tensor_desc_1, output0));
    CUDNN_SAFE_CALL(cudnnDestroyTensorDescriptor(tensor_desc_0));
    CUDNN_SAFE_CALL(cudnnDestroyTensorDescriptor(tensor_desc_1));
    CUDNN_SAFE_CALL(cudnnDestroyFilterDescriptor(filter_desc));
    CUDNN_SAFE_CALL(cudnnDestroyConvolutionDescriptor(conv_desc));

}

    void executeImpl(cudaStream_t stream) {
        this->Convolution_float_float_float_cuda_lib_Convolution_526(cudnn_handle, input0, input1, output0);
    }
};


class inception3_BatchNormInference_float_float_float_float_float_float_cuda_BatchNormInference_530_CallKernel : public Kernel {
public:
    inception3_BatchNormInference_float_float_float_float_float_float_cuda_BatchNormInference_530_CallKernel(const dim3 & grids, const dim3 & blocks, unsigned  mem, cudaStream_t  stream, float*  input0, float*  input1, float*  input2, float*  input3, float*  input4, float*  output0, float*  Parameter_0_0, float**  Result_892_0) {
        this->grids = grids, this->blocks = blocks, this->mem = mem, this->stream = stream, this->input0 = input0, this->input1 = input1, this->input2 = input2, this->input3 = input3, this->input4 = input4, this->output0 = output0, this->Parameter_0_0 = Parameter_0_0, this->Result_892_0 = Result_892_0;
        this->kernelName = "inception3_BatchNormInference_float_float_float_float_float_float_cuda_BatchNormInference_530_Call";
        this->Id = 0;
        this->mixable = 0;
    }

    void initParams() override {
        // empty implementation
    }

    void loadKernel() override {
        // Empty implementation
    }

        dim3  grids; dim3  blocks; unsigned  mem; cudaStream_t  stream; float*  input0; float*  input1; float*  input2; float*  input3; float*  input4; float*  output0;
    float*  Parameter_0_0; float**  Result_892_0;
private:

    
std::vector<int> getArgs() override {
    return std::vector<int>();
}

     void BatchNormInference_float_float_float_float_float_float_cuda_BatchNormInference_530_Call(const dim3 &grids, const dim3 &blocks, unsigned mem, cudaStream_t stream, float* input0, float* input1, float* input2, float* input3, float* input4, float* output0) {
    inception3_BatchNormInference_float_float_float_float_float_float_cuda_BatchNormInference_530<<<grids, blocks, mem, stream>>>(input0, input1, input2, input3, input4, output0);
}

    void executeImpl(cudaStream_t stream) {
        this->BatchNormInference_float_float_float_float_float_float_cuda_BatchNormInference_530_Call(grids, blocks, mem, stream, input0, input1, input2, input3, input4, output0);
    }
};


class inception3_Reshape_float_float_cuda_Reshape_509_CallKernel : public Kernel {
public:
    inception3_Reshape_float_float_cuda_Reshape_509_CallKernel(const dim3 & grids, const dim3 & blocks, unsigned  mem, cudaStream_t  stream, float*  input0, float*  output0, float*  Parameter_0_0, float**  Result_892_0) {
        this->grids = grids, this->blocks = blocks, this->mem = mem, this->stream = stream, this->input0 = input0, this->output0 = output0, this->Parameter_0_0 = Parameter_0_0, this->Result_892_0 = Result_892_0;
        this->kernelName = "inception3_Reshape_float_float_cuda_Reshape_509_Call";
        this->Id = 0;
        this->mixable = 0;
    }

    void initParams() override {
        // empty implementation
    }

    void loadKernel() override {
        // Empty implementation
    }

        dim3  grids; dim3  blocks; unsigned  mem; cudaStream_t  stream; float*  input0; float*  output0;
    float*  Parameter_0_0; float**  Result_892_0;
private:

    
std::vector<int> getArgs() override {
    return std::vector<int>();
}

     void Reshape_float_float_cuda_Reshape_509_Call(const dim3 &grids, const dim3 &blocks, unsigned mem, cudaStream_t stream, float* input0, float* output0) {
    inception3_Reshape_float_float_cuda_Reshape_509<<<grids, blocks, mem, stream>>>(input0, output0);
}

    void executeImpl(cudaStream_t stream) {
        this->Reshape_float_float_cuda_Reshape_509_Call(grids, blocks, mem, stream, input0, output0);
    }
};


class inception3_Convolution_float_float_float_cuda_lib_Convolution_510Kernel : public Kernel {
public:
    inception3_Convolution_float_float_float_cuda_lib_Convolution_510Kernel(cudnnHandle_t  cudnn_handle, float*  input0, float*  input1, float*  output0, float*  Parameter_0_0, float**  Result_892_0) {
        this->cudnn_handle = cudnn_handle, this->input0 = input0, this->input1 = input1, this->output0 = output0, this->Parameter_0_0 = Parameter_0_0, this->Result_892_0 = Result_892_0;
        this->kernelName = "inception3_Convolution_float_float_float_cuda_lib_Convolution_510";
        this->Id = 0;
        this->mixable = 2;
    }

    void initParams() override {
        // empty implementation
    }

    void loadKernel() override {
        // Empty implementation
    }

        cudnnHandle_t  cudnn_handle; float*  input0; float*  input1; float*  output0;
    float*  Parameter_0_0; float**  Result_892_0;
private:

    
std::vector<int> getArgs() override {
    return std::vector<int>({64, 192, 35, 35, 64, 192, 1, 1, 0, 0, 1, 1, 1, 1});
}

    void Convolution_float_float_float_cuda_lib_Convolution_510(cudnnHandle_t cudnn_handle, float* input0, float* input1, float* output0)
{
    cudnnTensorDescriptor_t tensor_desc_0;
    CUDNN_SAFE_CALL(cudnnCreateTensorDescriptor(&tensor_desc_0));
    CUDNN_SAFE_CALL(cudnnSetTensor4dDescriptor(tensor_desc_0, CUDNN_TENSOR_NCHW, CUDNN_DATA_FLOAT, 64, 192, 35, 35));
    cudnnTensorDescriptor_t tensor_desc_1;
    CUDNN_SAFE_CALL(cudnnCreateTensorDescriptor(&tensor_desc_1));
    CUDNN_SAFE_CALL(cudnnSetTensor4dDescriptor(tensor_desc_1, CUDNN_TENSOR_NCHW, CUDNN_DATA_FLOAT, 64, 64, 35, 35));
    cudnnFilterDescriptor_t filter_desc;
    CUDNN_SAFE_CALL(cudnnCreateFilterDescriptor(&filter_desc));
    CUDNN_SAFE_CALL(cudnnSetFilter4dDescriptor(filter_desc, CUDNN_DATA_FLOAT, CUDNN_TENSOR_NCHW, 64, 192, 1, 1));
    cudnnConvolutionDescriptor_t conv_desc;
    CUDNN_SAFE_CALL(cudnnCreateConvolutionDescriptor(&conv_desc));
    CUDNN_SAFE_CALL(cudnnSetConvolution2dDescriptor(conv_desc, 0, 0, 1, 1, 1, 1, CUDNN_CROSS_CORRELATION, CUDNN_DATA_FLOAT));

    static bool selected_algo = true;
    static cudnnConvolutionFwdAlgo_t conv_fwd_algo = CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM;

    if (!selected_algo) {
        int num_algos;
        int max_algos = 0;
        // cudnnGetConvolutionForwardAlgorithm_v7;
        CUDNN_SAFE_CALL(
            cudnnGetConvolutionForwardAlgorithmMaxCount(cudnn_handle, &max_algos));
        std::vector<cudnnConvolutionFwdAlgoPerf_t> results(max_algos);
        CUDNN_SAFE_CALL(cudnnFindConvolutionForwardAlgorithm(cudnn_handle,
                                                tensor_desc_0,
                                                filter_desc,
                                                conv_desc,
                                                tensor_desc_1,
                                                static_cast<int>(results.size()),
                                                &num_algos,
                                                results.data()));
        results.resize(num_algos);
        for (size_t i = 0; i != results.size(); ++i) {
            cudnnConvolutionFwdAlgoPerf_t const& result = results[i];
            if (result.status == CUDNN_STATUS_SUCCESS) {
                conv_fwd_algo = result.algo;
                break;
            }
        }
        selected_algo = true;
    }
    const float alpha = 1.0;
    const float beta = 0.0;
    static void *workspace_ptr_0 = NULL;
    static size_t workspace_size_in_bytes = 0;
    if (!workspace_ptr_0)
    {
        CUDNN_SAFE_CALL(cudnnGetConvolutionForwardWorkspaceSize(cudnn_handle, tensor_desc_0, filter_desc, conv_desc, tensor_desc_1, conv_fwd_algo, &workspace_size_in_bytes));
        CUDA_SAFE_CALL(cudaMalloc(&workspace_ptr_0, workspace_size_in_bytes));
    }
    CUDNN_SAFE_CALL(mycudnnConvolutionForward(cudnn_handle, &alpha, tensor_desc_0, input0,filter_desc, input1, conv_desc, conv_fwd_algo, workspace_ptr_0, workspace_size_in_bytes, &beta, tensor_desc_1, output0));
    CUDNN_SAFE_CALL(cudnnDestroyTensorDescriptor(tensor_desc_0));
    CUDNN_SAFE_CALL(cudnnDestroyTensorDescriptor(tensor_desc_1));
    CUDNN_SAFE_CALL(cudnnDestroyFilterDescriptor(filter_desc));
    CUDNN_SAFE_CALL(cudnnDestroyConvolutionDescriptor(conv_desc));

}

    void executeImpl(cudaStream_t stream) {
        this->Convolution_float_float_float_cuda_lib_Convolution_510(cudnn_handle, input0, input1, output0);
    }
};


class inception3_AvgPool_float_float_cuda_lib_AvgPool_515Kernel : public Kernel {
public:
    inception3_AvgPool_float_float_cuda_lib_AvgPool_515Kernel(cudnnHandle_t  cudnn_handle, float*  input0, float*  output0, float*  Parameter_0_0, float**  Result_892_0) {
        this->cudnn_handle = cudnn_handle, this->input0 = input0, this->output0 = output0, this->Parameter_0_0 = Parameter_0_0, this->Result_892_0 = Result_892_0;
        this->kernelName = "inception3_AvgPool_float_float_cuda_lib_AvgPool_515";
        this->Id = 0;
        this->mixable = 0;
    }

    void initParams() override {
        // empty implementation
    }

    void loadKernel() override {
        // Empty implementation
    }

        cudnnHandle_t  cudnn_handle; float*  input0; float*  output0;
    float*  Parameter_0_0; float**  Result_892_0;
private:

    
std::vector<int> getArgs() override {
    return std::vector<int>();
}

    void AvgPool_float_float_cuda_lib_AvgPool_515(cudnnHandle_t cudnn_handle, float* input0, float* output0)
{
    cudnnTensorDescriptor_t input_desc;
    CUDNN_SAFE_CALL(cudnnCreateTensorDescriptor(&input_desc));
    CUDNN_SAFE_CALL(cudnnSetTensor4dDescriptor(input_desc, CUDNN_TENSOR_NCHW, CUDNN_DATA_FLOAT, 64, 192, 35, 35));
    cudnnTensorDescriptor_t output_desc;
    CUDNN_SAFE_CALL(cudnnCreateTensorDescriptor(&output_desc));
    CUDNN_SAFE_CALL(cudnnSetTensor4dDescriptor(output_desc, CUDNN_TENSOR_NCHW, CUDNN_DATA_FLOAT, 64, 192, 35, 35));
    cudnnPoolingDescriptor_t desc;
    cudnnCreatePoolingDescriptor(&desc);
    CUDNN_SAFE_CALL(cudnnSetPooling2dDescriptor(desc, CUDNN_POOLING_AVERAGE_COUNT_EXCLUDE_PADDING, CUDNN_NOT_PROPAGATE_NAN,3, 3, 1, 1, 1, 1));
    const float alpha = 1.0;
    const float beta = 0.0;
    CUDNN_SAFE_CALL(cudnnPoolingForward(cudnn_handle, desc, &alpha, input_desc, input0, &beta, output_desc, output0));
    CUDNN_SAFE_CALL(cudnnDestroyTensorDescriptor(input_desc));
    CUDNN_SAFE_CALL(cudnnDestroyTensorDescriptor(output_desc));
    CUDNN_SAFE_CALL(cudnnDestroyPoolingDescriptor(desc));

}

    void executeImpl(cudaStream_t stream) {
        this->AvgPool_float_float_cuda_lib_AvgPool_515(cudnn_handle, input0, output0);
    }
};


class inception3_Reshape_float_float_cuda_Reshape_519_CallKernel : public Kernel {
public:
    inception3_Reshape_float_float_cuda_Reshape_519_CallKernel(const dim3 & grids, const dim3 & blocks, unsigned  mem, cudaStream_t  stream, float*  input0, float*  output0, float*  Parameter_0_0, float**  Result_892_0) {
        this->grids = grids, this->blocks = blocks, this->mem = mem, this->stream = stream, this->input0 = input0, this->output0 = output0, this->Parameter_0_0 = Parameter_0_0, this->Result_892_0 = Result_892_0;
        this->kernelName = "inception3_Reshape_float_float_cuda_Reshape_519_Call";
        this->Id = 0;
        this->mixable = 0;
    }

    void initParams() override {
        // empty implementation
    }

    void loadKernel() override {
        // Empty implementation
    }

        dim3  grids; dim3  blocks; unsigned  mem; cudaStream_t  stream; float*  input0; float*  output0;
    float*  Parameter_0_0; float**  Result_892_0;
private:

    
std::vector<int> getArgs() override {
    return std::vector<int>();
}

     void Reshape_float_float_cuda_Reshape_519_Call(const dim3 &grids, const dim3 &blocks, unsigned mem, cudaStream_t stream, float* input0, float* output0) {
    inception3_Reshape_float_float_cuda_Reshape_519<<<grids, blocks, mem, stream>>>(input0, output0);
}

    void executeImpl(cudaStream_t stream) {
        this->Reshape_float_float_cuda_Reshape_519_Call(grids, blocks, mem, stream, input0, output0);
    }
};


class inception3_Convolution_float_float_float_cuda_lib_Convolution_520Kernel : public Kernel {
public:
    inception3_Convolution_float_float_float_cuda_lib_Convolution_520Kernel(cudnnHandle_t  cudnn_handle, float*  input0, float*  input1, float*  output0, float*  Parameter_0_0, float**  Result_892_0) {
        this->cudnn_handle = cudnn_handle, this->input0 = input0, this->input1 = input1, this->output0 = output0, this->Parameter_0_0 = Parameter_0_0, this->Result_892_0 = Result_892_0;
        this->kernelName = "inception3_Convolution_float_float_float_cuda_lib_Convolution_520";
        this->Id = 0;
        this->mixable = 2;
    }

    void initParams() override {
        // empty implementation
    }

    void loadKernel() override {
        // Empty implementation
    }

        cudnnHandle_t  cudnn_handle; float*  input0; float*  input1; float*  output0;
    float*  Parameter_0_0; float**  Result_892_0;
private:

    
std::vector<int> getArgs() override {
    return std::vector<int>({64, 192, 35, 35, 32, 192, 1, 1, 0, 0, 1, 1, 1, 1});
}

    void Convolution_float_float_float_cuda_lib_Convolution_520(cudnnHandle_t cudnn_handle, float* input0, float* input1, float* output0)
{
    cudnnTensorDescriptor_t tensor_desc_0;
    CUDNN_SAFE_CALL(cudnnCreateTensorDescriptor(&tensor_desc_0));
    CUDNN_SAFE_CALL(cudnnSetTensor4dDescriptor(tensor_desc_0, CUDNN_TENSOR_NCHW, CUDNN_DATA_FLOAT, 64, 192, 35, 35));
    cudnnTensorDescriptor_t tensor_desc_1;
    CUDNN_SAFE_CALL(cudnnCreateTensorDescriptor(&tensor_desc_1));
    CUDNN_SAFE_CALL(cudnnSetTensor4dDescriptor(tensor_desc_1, CUDNN_TENSOR_NCHW, CUDNN_DATA_FLOAT, 64, 32, 35, 35));
    cudnnFilterDescriptor_t filter_desc;
    CUDNN_SAFE_CALL(cudnnCreateFilterDescriptor(&filter_desc));
    CUDNN_SAFE_CALL(cudnnSetFilter4dDescriptor(filter_desc, CUDNN_DATA_FLOAT, CUDNN_TENSOR_NCHW, 32, 192, 1, 1));
    cudnnConvolutionDescriptor_t conv_desc;
    CUDNN_SAFE_CALL(cudnnCreateConvolutionDescriptor(&conv_desc));
    CUDNN_SAFE_CALL(cudnnSetConvolution2dDescriptor(conv_desc, 0, 0, 1, 1, 1, 1, CUDNN_CROSS_CORRELATION, CUDNN_DATA_FLOAT));

    static bool selected_algo = true;
    static cudnnConvolutionFwdAlgo_t conv_fwd_algo = CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM;

    if (!selected_algo) {
        int num_algos;
        int max_algos = 0;
        // cudnnGetConvolutionForwardAlgorithm_v7;
        CUDNN_SAFE_CALL(
            cudnnGetConvolutionForwardAlgorithmMaxCount(cudnn_handle, &max_algos));
        std::vector<cudnnConvolutionFwdAlgoPerf_t> results(max_algos);
        CUDNN_SAFE_CALL(cudnnFindConvolutionForwardAlgorithm(cudnn_handle,
                                                tensor_desc_0,
                                                filter_desc,
                                                conv_desc,
                                                tensor_desc_1,
                                                static_cast<int>(results.size()),
                                                &num_algos,
                                                results.data()));
        results.resize(num_algos);
        for (size_t i = 0; i != results.size(); ++i) {
            cudnnConvolutionFwdAlgoPerf_t const& result = results[i];
            if (result.status == CUDNN_STATUS_SUCCESS) {
                conv_fwd_algo = result.algo;
                break;
            }
        }
        selected_algo = true;
    }
    const float alpha = 1.0;
    const float beta = 0.0;
    static void *workspace_ptr_0 = NULL;
    static size_t workspace_size_in_bytes = 0;
    if (!workspace_ptr_0)
    {
        CUDNN_SAFE_CALL(cudnnGetConvolutionForwardWorkspaceSize(cudnn_handle, tensor_desc_0, filter_desc, conv_desc, tensor_desc_1, conv_fwd_algo, &workspace_size_in_bytes));
        CUDA_SAFE_CALL(cudaMalloc(&workspace_ptr_0, workspace_size_in_bytes));
    }
    CUDNN_SAFE_CALL(mycudnnConvolutionForward(cudnn_handle, &alpha, tensor_desc_0, input0,filter_desc, input1, conv_desc, conv_fwd_algo, workspace_ptr_0, workspace_size_in_bytes, &beta, tensor_desc_1, output0));
    CUDNN_SAFE_CALL(cudnnDestroyTensorDescriptor(tensor_desc_0));
    CUDNN_SAFE_CALL(cudnnDestroyTensorDescriptor(tensor_desc_1));
    CUDNN_SAFE_CALL(cudnnDestroyFilterDescriptor(filter_desc));
    CUDNN_SAFE_CALL(cudnnDestroyConvolutionDescriptor(conv_desc));

}

    void executeImpl(cudaStream_t stream) {
        this->Convolution_float_float_float_cuda_lib_Convolution_520(cudnn_handle, input0, input1, output0);
    }
};


class inception3_BatchNormInference_float_float_float_float_float_float_cuda_BatchNormInference_524_CallKernel : public Kernel {
public:
    inception3_BatchNormInference_float_float_float_float_float_float_cuda_BatchNormInference_524_CallKernel(const dim3 & grids, const dim3 & blocks, unsigned  mem, cudaStream_t  stream, float*  input0, float*  input1, float*  input2, float*  input3, float*  input4, float*  output0, float*  Parameter_0_0, float**  Result_892_0) {
        this->grids = grids, this->blocks = blocks, this->mem = mem, this->stream = stream, this->input0 = input0, this->input1 = input1, this->input2 = input2, this->input3 = input3, this->input4 = input4, this->output0 = output0, this->Parameter_0_0 = Parameter_0_0, this->Result_892_0 = Result_892_0;
        this->kernelName = "inception3_BatchNormInference_float_float_float_float_float_float_cuda_BatchNormInference_524_Call";
        this->Id = 0;
        this->mixable = 0;
    }

    void initParams() override {
        // empty implementation
    }

    void loadKernel() override {
        // Empty implementation
    }

        dim3  grids; dim3  blocks; unsigned  mem; cudaStream_t  stream; float*  input0; float*  input1; float*  input2; float*  input3; float*  input4; float*  output0;
    float*  Parameter_0_0; float**  Result_892_0;
private:

    
std::vector<int> getArgs() override {
    return std::vector<int>();
}

     void BatchNormInference_float_float_float_float_float_float_cuda_BatchNormInference_524_Call(const dim3 &grids, const dim3 &blocks, unsigned mem, cudaStream_t stream, float* input0, float* input1, float* input2, float* input3, float* input4, float* output0) {
    inception3_BatchNormInference_float_float_float_float_float_float_cuda_BatchNormInference_524<<<grids, blocks, mem, stream>>>(input0, input1, input2, input3, input4, output0);
}

    void executeImpl(cudaStream_t stream) {
        this->BatchNormInference_float_float_float_float_float_float_cuda_BatchNormInference_524_Call(grids, blocks, mem, stream, input0, input1, input2, input3, input4, output0);
    }
};


class inception3_Reshape_float_float_cuda_Reshape_527_CallKernel : public Kernel {
public:
    inception3_Reshape_float_float_cuda_Reshape_527_CallKernel(const dim3 & grids, const dim3 & blocks, unsigned  mem, cudaStream_t  stream, float*  input0, float*  output0, float*  Parameter_0_0, float**  Result_892_0) {
        this->grids = grids, this->blocks = blocks, this->mem = mem, this->stream = stream, this->input0 = input0, this->output0 = output0, this->Parameter_0_0 = Parameter_0_0, this->Result_892_0 = Result_892_0;
        this->kernelName = "inception3_Reshape_float_float_cuda_Reshape_527_Call";
        this->Id = 0;
        this->mixable = 0;
    }

    void initParams() override {
        // empty implementation
    }

    void loadKernel() override {
        // Empty implementation
    }

        dim3  grids; dim3  blocks; unsigned  mem; cudaStream_t  stream; float*  input0; float*  output0;
    float*  Parameter_0_0; float**  Result_892_0;
private:

    
std::vector<int> getArgs() override {
    return std::vector<int>();
}

     void Reshape_float_float_cuda_Reshape_527_Call(const dim3 &grids, const dim3 &blocks, unsigned mem, cudaStream_t stream, float* input0, float* output0) {
    inception3_Reshape_float_float_cuda_Reshape_527<<<grids, blocks, mem, stream>>>(input0, output0);
}

    void executeImpl(cudaStream_t stream) {
        this->Reshape_float_float_cuda_Reshape_527_Call(grids, blocks, mem, stream, input0, output0);
    }
};


class inception3_Convolution_float_float_float_cuda_lib_Convolution_528Kernel : public Kernel {
public:
    inception3_Convolution_float_float_float_cuda_lib_Convolution_528Kernel(cudnnHandle_t  cudnn_handle, float*  input0, float*  input1, float*  output0, float*  Parameter_0_0, float**  Result_892_0) {
        this->cudnn_handle = cudnn_handle, this->input0 = input0, this->input1 = input1, this->output0 = output0, this->Parameter_0_0 = Parameter_0_0, this->Result_892_0 = Result_892_0;
        this->kernelName = "inception3_Convolution_float_float_float_cuda_lib_Convolution_528";
        this->Id = 0;
        this->mixable = 2;
    }

    void initParams() override {
        // empty implementation
    }

    void loadKernel() override {
        // Empty implementation
    }

        cudnnHandle_t  cudnn_handle; float*  input0; float*  input1; float*  output0;
    float*  Parameter_0_0; float**  Result_892_0;
private:

    
std::vector<int> getArgs() override {
    return std::vector<int>({64, 64, 35, 35, 96, 64, 3, 3, 1, 1, 1, 1, 1, 1});
}

    void Convolution_float_float_float_cuda_lib_Convolution_528(cudnnHandle_t cudnn_handle, float* input0, float* input1, float* output0)
{
    cudnnTensorDescriptor_t tensor_desc_0;
    CUDNN_SAFE_CALL(cudnnCreateTensorDescriptor(&tensor_desc_0));
    CUDNN_SAFE_CALL(cudnnSetTensor4dDescriptor(tensor_desc_0, CUDNN_TENSOR_NCHW, CUDNN_DATA_FLOAT, 64, 64, 35, 35));
    cudnnTensorDescriptor_t tensor_desc_1;
    CUDNN_SAFE_CALL(cudnnCreateTensorDescriptor(&tensor_desc_1));
    CUDNN_SAFE_CALL(cudnnSetTensor4dDescriptor(tensor_desc_1, CUDNN_TENSOR_NCHW, CUDNN_DATA_FLOAT, 64, 96, 35, 35));
    cudnnFilterDescriptor_t filter_desc;
    CUDNN_SAFE_CALL(cudnnCreateFilterDescriptor(&filter_desc));
    CUDNN_SAFE_CALL(cudnnSetFilter4dDescriptor(filter_desc, CUDNN_DATA_FLOAT, CUDNN_TENSOR_NCHW, 96, 64, 3, 3));
    cudnnConvolutionDescriptor_t conv_desc;
    CUDNN_SAFE_CALL(cudnnCreateConvolutionDescriptor(&conv_desc));
    CUDNN_SAFE_CALL(cudnnSetConvolution2dDescriptor(conv_desc, 1, 1, 1, 1, 1, 1, CUDNN_CROSS_CORRELATION, CUDNN_DATA_FLOAT));

    static bool selected_algo = true;
    static cudnnConvolutionFwdAlgo_t conv_fwd_algo = CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM;

    if (!selected_algo) {
        int num_algos;
        int max_algos = 0;
        // cudnnGetConvolutionForwardAlgorithm_v7;
        CUDNN_SAFE_CALL(
            cudnnGetConvolutionForwardAlgorithmMaxCount(cudnn_handle, &max_algos));
        std::vector<cudnnConvolutionFwdAlgoPerf_t> results(max_algos);
        CUDNN_SAFE_CALL(cudnnFindConvolutionForwardAlgorithm(cudnn_handle,
                                                tensor_desc_0,
                                                filter_desc,
                                                conv_desc,
                                                tensor_desc_1,
                                                static_cast<int>(results.size()),
                                                &num_algos,
                                                results.data()));
        results.resize(num_algos);
        for (size_t i = 0; i != results.size(); ++i) {
            cudnnConvolutionFwdAlgoPerf_t const& result = results[i];
            if (result.status == CUDNN_STATUS_SUCCESS) {
                conv_fwd_algo = result.algo;
                break;
            }
        }
        selected_algo = true;
    }
    const float alpha = 1.0;
    const float beta = 0.0;
    static void *workspace_ptr_0 = NULL;
    static size_t workspace_size_in_bytes = 0;
    if (!workspace_ptr_0)
    {
        CUDNN_SAFE_CALL(cudnnGetConvolutionForwardWorkspaceSize(cudnn_handle, tensor_desc_0, filter_desc, conv_desc, tensor_desc_1, conv_fwd_algo, &workspace_size_in_bytes));
        CUDA_SAFE_CALL(cudaMalloc(&workspace_ptr_0, workspace_size_in_bytes));
    }
    CUDNN_SAFE_CALL(mycudnnConvolutionForward(cudnn_handle, &alpha, tensor_desc_0, input0,filter_desc, input1, conv_desc, conv_fwd_algo, workspace_ptr_0, workspace_size_in_bytes, &beta, tensor_desc_1, output0));
    CUDNN_SAFE_CALL(cudnnDestroyTensorDescriptor(tensor_desc_0));
    CUDNN_SAFE_CALL(cudnnDestroyTensorDescriptor(tensor_desc_1));
    CUDNN_SAFE_CALL(cudnnDestroyFilterDescriptor(filter_desc));
    CUDNN_SAFE_CALL(cudnnDestroyConvolutionDescriptor(conv_desc));

}

    void executeImpl(cudaStream_t stream) {
        this->Convolution_float_float_float_cuda_lib_Convolution_528(cudnn_handle, input0, input1, output0);
    }
};


class inception3_BatchNormInference_float_float_float_float_float_float_cuda_BatchNormInference_531_CallKernel : public Kernel {
public:
    inception3_BatchNormInference_float_float_float_float_float_float_cuda_BatchNormInference_531_CallKernel(const dim3 & grids, const dim3 & blocks, unsigned  mem, cudaStream_t  stream, float*  input0, float*  input1, float*  input2, float*  input3, float*  input4, float*  output0, float*  Parameter_0_0, float**  Result_892_0) {
        this->grids = grids, this->blocks = blocks, this->mem = mem, this->stream = stream, this->input0 = input0, this->input1 = input1, this->input2 = input2, this->input3 = input3, this->input4 = input4, this->output0 = output0, this->Parameter_0_0 = Parameter_0_0, this->Result_892_0 = Result_892_0;
        this->kernelName = "inception3_BatchNormInference_float_float_float_float_float_float_cuda_BatchNormInference_531_Call";
        this->Id = 0;
        this->mixable = 0;
    }

    void initParams() override {
        // empty implementation
    }

    void loadKernel() override {
        // Empty implementation
    }

        dim3  grids; dim3  blocks; unsigned  mem; cudaStream_t  stream; float*  input0; float*  input1; float*  input2; float*  input3; float*  input4; float*  output0;
    float*  Parameter_0_0; float**  Result_892_0;
private:

    
std::vector<int> getArgs() override {
    return std::vector<int>();
}

     void BatchNormInference_float_float_float_float_float_float_cuda_BatchNormInference_531_Call(const dim3 &grids, const dim3 &blocks, unsigned mem, cudaStream_t stream, float* input0, float* input1, float* input2, float* input3, float* input4, float* output0) {
    inception3_BatchNormInference_float_float_float_float_float_float_cuda_BatchNormInference_531<<<grids, blocks, mem, stream>>>(input0, input1, input2, input3, input4, output0);
}

    void executeImpl(cudaStream_t stream) {
        this->BatchNormInference_float_float_float_float_float_float_cuda_BatchNormInference_531_Call(grids, blocks, mem, stream, input0, input1, input2, input3, input4, output0);
    }
};


class inception3_Reshape_float_float_cuda_Reshape_534_CallKernel : public Kernel {
public:
    inception3_Reshape_float_float_cuda_Reshape_534_CallKernel(const dim3 & grids, const dim3 & blocks, unsigned  mem, cudaStream_t  stream, float*  input0, float*  output0, float*  Parameter_0_0, float**  Result_892_0) {
        this->grids = grids, this->blocks = blocks, this->mem = mem, this->stream = stream, this->input0 = input0, this->output0 = output0, this->Parameter_0_0 = Parameter_0_0, this->Result_892_0 = Result_892_0;
        this->kernelName = "inception3_Reshape_float_float_cuda_Reshape_534_Call";
        this->Id = 0;
        this->mixable = 0;
    }

    void initParams() override {
        // empty implementation
    }

    void loadKernel() override {
        // Empty implementation
    }

        dim3  grids; dim3  blocks; unsigned  mem; cudaStream_t  stream; float*  input0; float*  output0;
    float*  Parameter_0_0; float**  Result_892_0;
private:

    
std::vector<int> getArgs() override {
    return std::vector<int>();
}

     void Reshape_float_float_cuda_Reshape_534_Call(const dim3 &grids, const dim3 &blocks, unsigned mem, cudaStream_t stream, float* input0, float* output0) {
    inception3_Reshape_float_float_cuda_Reshape_534<<<grids, blocks, mem, stream>>>(input0, output0);
}

    void executeImpl(cudaStream_t stream) {
        this->Reshape_float_float_cuda_Reshape_534_Call(grids, blocks, mem, stream, input0, output0);
    }
};


class inception3_Convolution_float_float_float_cuda_lib_Convolution_535Kernel : public Kernel {
public:
    inception3_Convolution_float_float_float_cuda_lib_Convolution_535Kernel(cudnnHandle_t  cudnn_handle, float*  input0, float*  input1, float*  output0, float*  Parameter_0_0, float**  Result_892_0) {
        this->cudnn_handle = cudnn_handle, this->input0 = input0, this->input1 = input1, this->output0 = output0, this->Parameter_0_0 = Parameter_0_0, this->Result_892_0 = Result_892_0;
        this->kernelName = "inception3_Convolution_float_float_float_cuda_lib_Convolution_535";
        this->Id = 0;
        this->mixable = 2;
    }

    void initParams() override {
        // empty implementation
    }

    void loadKernel() override {
        // Empty implementation
    }

        cudnnHandle_t  cudnn_handle; float*  input0; float*  input1; float*  output0;
    float*  Parameter_0_0; float**  Result_892_0;
private:

    
std::vector<int> getArgs() override {
    return std::vector<int>({64, 96, 35, 35, 96, 96, 3, 3, 1, 1, 1, 1, 1, 1});
}

    void Convolution_float_float_float_cuda_lib_Convolution_535(cudnnHandle_t cudnn_handle, float* input0, float* input1, float* output0)
{
    cudnnTensorDescriptor_t tensor_desc_0;
    CUDNN_SAFE_CALL(cudnnCreateTensorDescriptor(&tensor_desc_0));
    CUDNN_SAFE_CALL(cudnnSetTensor4dDescriptor(tensor_desc_0, CUDNN_TENSOR_NCHW, CUDNN_DATA_FLOAT, 64, 96, 35, 35));
    cudnnTensorDescriptor_t tensor_desc_1;
    CUDNN_SAFE_CALL(cudnnCreateTensorDescriptor(&tensor_desc_1));
    CUDNN_SAFE_CALL(cudnnSetTensor4dDescriptor(tensor_desc_1, CUDNN_TENSOR_NCHW, CUDNN_DATA_FLOAT, 64, 96, 35, 35));
    cudnnFilterDescriptor_t filter_desc;
    CUDNN_SAFE_CALL(cudnnCreateFilterDescriptor(&filter_desc));
    CUDNN_SAFE_CALL(cudnnSetFilter4dDescriptor(filter_desc, CUDNN_DATA_FLOAT, CUDNN_TENSOR_NCHW, 96, 96, 3, 3));
    cudnnConvolutionDescriptor_t conv_desc;
    CUDNN_SAFE_CALL(cudnnCreateConvolutionDescriptor(&conv_desc));
    CUDNN_SAFE_CALL(cudnnSetConvolution2dDescriptor(conv_desc, 1, 1, 1, 1, 1, 1, CUDNN_CROSS_CORRELATION, CUDNN_DATA_FLOAT));

    static bool selected_algo = true;
    static cudnnConvolutionFwdAlgo_t conv_fwd_algo = CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM;

    if (!selected_algo) {
        int num_algos;
        int max_algos = 0;
        // cudnnGetConvolutionForwardAlgorithm_v7;
        CUDNN_SAFE_CALL(
            cudnnGetConvolutionForwardAlgorithmMaxCount(cudnn_handle, &max_algos));
        std::vector<cudnnConvolutionFwdAlgoPerf_t> results(max_algos);
        CUDNN_SAFE_CALL(cudnnFindConvolutionForwardAlgorithm(cudnn_handle,
                                                tensor_desc_0,
                                                filter_desc,
                                                conv_desc,
                                                tensor_desc_1,
                                                static_cast<int>(results.size()),
                                                &num_algos,
                                                results.data()));
        results.resize(num_algos);
        for (size_t i = 0; i != results.size(); ++i) {
            cudnnConvolutionFwdAlgoPerf_t const& result = results[i];
            if (result.status == CUDNN_STATUS_SUCCESS) {
                conv_fwd_algo = result.algo;
                break;
            }
        }
        selected_algo = true;
    }
    const float alpha = 1.0;
    const float beta = 0.0;
    static void *workspace_ptr_0 = NULL;
    static size_t workspace_size_in_bytes = 0;
    if (!workspace_ptr_0)
    {
        CUDNN_SAFE_CALL(cudnnGetConvolutionForwardWorkspaceSize(cudnn_handle, tensor_desc_0, filter_desc, conv_desc, tensor_desc_1, conv_fwd_algo, &workspace_size_in_bytes));
        CUDA_SAFE_CALL(cudaMalloc(&workspace_ptr_0, workspace_size_in_bytes));
    }
    CUDNN_SAFE_CALL(mycudnnConvolutionForward(cudnn_handle, &alpha, tensor_desc_0, input0,filter_desc, input1, conv_desc, conv_fwd_algo, workspace_ptr_0, workspace_size_in_bytes, &beta, tensor_desc_1, output0));
    CUDNN_SAFE_CALL(cudnnDestroyTensorDescriptor(tensor_desc_0));
    CUDNN_SAFE_CALL(cudnnDestroyTensorDescriptor(tensor_desc_1));
    CUDNN_SAFE_CALL(cudnnDestroyFilterDescriptor(filter_desc));
    CUDNN_SAFE_CALL(cudnnDestroyConvolutionDescriptor(conv_desc));

}

    void executeImpl(cudaStream_t stream) {
        this->Convolution_float_float_float_cuda_lib_Convolution_535(cudnn_handle, input0, input1, output0);
    }
};


class inception3_Concat_float_float_float_float_float_cuda_Concat_538_CallKernel : public Kernel {
public:
    inception3_Concat_float_float_float_float_float_cuda_Concat_538_CallKernel(const dim3 & grids, const dim3 & blocks, unsigned  mem, cudaStream_t  stream, float*  input0, float*  input1, float*  input2, float*  input3, float*  output0, float*  Parameter_0_0, float**  Result_892_0) {
        this->grids = grids, this->blocks = blocks, this->mem = mem, this->stream = stream, this->input0 = input0, this->input1 = input1, this->input2 = input2, this->input3 = input3, this->output0 = output0, this->Parameter_0_0 = Parameter_0_0, this->Result_892_0 = Result_892_0;
        this->kernelName = "inception3_Concat_float_float_float_float_float_cuda_Concat_538_Call";
        this->Id = 0;
        this->mixable = 0;
    }

    void initParams() override {
        // empty implementation
    }

    void loadKernel() override {
        // Empty implementation
    }

        dim3  grids; dim3  blocks; unsigned  mem; cudaStream_t  stream; float*  input0; float*  input1; float*  input2; float*  input3; float*  output0;
    float*  Parameter_0_0; float**  Result_892_0;
private:

    
std::vector<int> getArgs() override {
    return std::vector<int>();
}

     void Concat_float_float_float_float_float_cuda_Concat_538_Call(const dim3 &grids, const dim3 &blocks, unsigned mem, cudaStream_t stream, float* input0, float* input1, float* input2, float* input3, float* output0) {
    inception3_Concat_float_float_float_float_float_cuda_Concat_538<<<grids, blocks, mem, stream>>>(input0, input1, input2, input3, output0);
}

    void executeImpl(cudaStream_t stream) {
        this->Concat_float_float_float_float_float_cuda_Concat_538_Call(grids, blocks, mem, stream, input0, input1, input2, input3, output0);
    }
};


class inception3_AvgPool_float_float_cuda_lib_AvgPool_545Kernel : public Kernel {
public:
    inception3_AvgPool_float_float_cuda_lib_AvgPool_545Kernel(cudnnHandle_t  cudnn_handle, float*  input0, float*  output0, float*  Parameter_0_0, float**  Result_892_0) {
        this->cudnn_handle = cudnn_handle, this->input0 = input0, this->output0 = output0, this->Parameter_0_0 = Parameter_0_0, this->Result_892_0 = Result_892_0;
        this->kernelName = "inception3_AvgPool_float_float_cuda_lib_AvgPool_545";
        this->Id = 0;
        this->mixable = 0;
    }

    void initParams() override {
        // empty implementation
    }

    void loadKernel() override {
        // Empty implementation
    }

        cudnnHandle_t  cudnn_handle; float*  input0; float*  output0;
    float*  Parameter_0_0; float**  Result_892_0;
private:

    
std::vector<int> getArgs() override {
    return std::vector<int>();
}

    void AvgPool_float_float_cuda_lib_AvgPool_545(cudnnHandle_t cudnn_handle, float* input0, float* output0)
{
    cudnnTensorDescriptor_t input_desc;
    CUDNN_SAFE_CALL(cudnnCreateTensorDescriptor(&input_desc));
    CUDNN_SAFE_CALL(cudnnSetTensor4dDescriptor(input_desc, CUDNN_TENSOR_NCHW, CUDNN_DATA_FLOAT, 64, 256, 35, 35));
    cudnnTensorDescriptor_t output_desc;
    CUDNN_SAFE_CALL(cudnnCreateTensorDescriptor(&output_desc));
    CUDNN_SAFE_CALL(cudnnSetTensor4dDescriptor(output_desc, CUDNN_TENSOR_NCHW, CUDNN_DATA_FLOAT, 64, 256, 35, 35));
    cudnnPoolingDescriptor_t desc;
    cudnnCreatePoolingDescriptor(&desc);
    CUDNN_SAFE_CALL(cudnnSetPooling2dDescriptor(desc, CUDNN_POOLING_AVERAGE_COUNT_EXCLUDE_PADDING, CUDNN_NOT_PROPAGATE_NAN,3, 3, 1, 1, 1, 1));
    const float alpha = 1.0;
    const float beta = 0.0;
    CUDNN_SAFE_CALL(cudnnPoolingForward(cudnn_handle, desc, &alpha, input_desc, input0, &beta, output_desc, output0));
    CUDNN_SAFE_CALL(cudnnDestroyTensorDescriptor(input_desc));
    CUDNN_SAFE_CALL(cudnnDestroyTensorDescriptor(output_desc));
    CUDNN_SAFE_CALL(cudnnDestroyPoolingDescriptor(desc));

}

    void executeImpl(cudaStream_t stream) {
        this->AvgPool_float_float_cuda_lib_AvgPool_545(cudnn_handle, input0, output0);
    }
};


class inception3_Reshape_float_float_cuda_Reshape_549_CallKernel : public Kernel {
public:
    inception3_Reshape_float_float_cuda_Reshape_549_CallKernel(const dim3 & grids, const dim3 & blocks, unsigned  mem, cudaStream_t  stream, float*  input0, float*  output0, float*  Parameter_0_0, float**  Result_892_0) {
        this->grids = grids, this->blocks = blocks, this->mem = mem, this->stream = stream, this->input0 = input0, this->output0 = output0, this->Parameter_0_0 = Parameter_0_0, this->Result_892_0 = Result_892_0;
        this->kernelName = "inception3_Reshape_float_float_cuda_Reshape_549_Call";
        this->Id = 0;
        this->mixable = 0;
    }

    void initParams() override {
        // empty implementation
    }

    void loadKernel() override {
        // Empty implementation
    }

        dim3  grids; dim3  blocks; unsigned  mem; cudaStream_t  stream; float*  input0; float*  output0;
    float*  Parameter_0_0; float**  Result_892_0;
private:

    
std::vector<int> getArgs() override {
    return std::vector<int>();
}

     void Reshape_float_float_cuda_Reshape_549_Call(const dim3 &grids, const dim3 &blocks, unsigned mem, cudaStream_t stream, float* input0, float* output0) {
    inception3_Reshape_float_float_cuda_Reshape_549<<<grids, blocks, mem, stream>>>(input0, output0);
}

    void executeImpl(cudaStream_t stream) {
        this->Reshape_float_float_cuda_Reshape_549_Call(grids, blocks, mem, stream, input0, output0);
    }
};


class inception3_Convolution_float_float_float_cuda_lib_Convolution_550Kernel : public Kernel {
public:
    inception3_Convolution_float_float_float_cuda_lib_Convolution_550Kernel(cudnnHandle_t  cudnn_handle, float*  input0, float*  input1, float*  output0, float*  Parameter_0_0, float**  Result_892_0) {
        this->cudnn_handle = cudnn_handle, this->input0 = input0, this->input1 = input1, this->output0 = output0, this->Parameter_0_0 = Parameter_0_0, this->Result_892_0 = Result_892_0;
        this->kernelName = "inception3_Convolution_float_float_float_cuda_lib_Convolution_550";
        this->Id = 0;
        this->mixable = 2;
    }

    void initParams() override {
        // empty implementation
    }

    void loadKernel() override {
        // Empty implementation
    }

        cudnnHandle_t  cudnn_handle; float*  input0; float*  input1; float*  output0;
    float*  Parameter_0_0; float**  Result_892_0;
private:

    
std::vector<int> getArgs() override {
    return std::vector<int>({64, 256, 35, 35, 64, 256, 1, 1, 0, 0, 1, 1, 1, 1});
}

    void Convolution_float_float_float_cuda_lib_Convolution_550(cudnnHandle_t cudnn_handle, float* input0, float* input1, float* output0)
{
    cudnnTensorDescriptor_t tensor_desc_0;
    CUDNN_SAFE_CALL(cudnnCreateTensorDescriptor(&tensor_desc_0));
    CUDNN_SAFE_CALL(cudnnSetTensor4dDescriptor(tensor_desc_0, CUDNN_TENSOR_NCHW, CUDNN_DATA_FLOAT, 64, 256, 35, 35));
    cudnnTensorDescriptor_t tensor_desc_1;
    CUDNN_SAFE_CALL(cudnnCreateTensorDescriptor(&tensor_desc_1));
    CUDNN_SAFE_CALL(cudnnSetTensor4dDescriptor(tensor_desc_1, CUDNN_TENSOR_NCHW, CUDNN_DATA_FLOAT, 64, 64, 35, 35));
    cudnnFilterDescriptor_t filter_desc;
    CUDNN_SAFE_CALL(cudnnCreateFilterDescriptor(&filter_desc));
    CUDNN_SAFE_CALL(cudnnSetFilter4dDescriptor(filter_desc, CUDNN_DATA_FLOAT, CUDNN_TENSOR_NCHW, 64, 256, 1, 1));
    cudnnConvolutionDescriptor_t conv_desc;
    CUDNN_SAFE_CALL(cudnnCreateConvolutionDescriptor(&conv_desc));
    CUDNN_SAFE_CALL(cudnnSetConvolution2dDescriptor(conv_desc, 0, 0, 1, 1, 1, 1, CUDNN_CROSS_CORRELATION, CUDNN_DATA_FLOAT));

    static bool selected_algo = true;
    static cudnnConvolutionFwdAlgo_t conv_fwd_algo = CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM;

    if (!selected_algo) {
        int num_algos;
        int max_algos = 0;
        // cudnnGetConvolutionForwardAlgorithm_v7;
        CUDNN_SAFE_CALL(
            cudnnGetConvolutionForwardAlgorithmMaxCount(cudnn_handle, &max_algos));
        std::vector<cudnnConvolutionFwdAlgoPerf_t> results(max_algos);
        CUDNN_SAFE_CALL(cudnnFindConvolutionForwardAlgorithm(cudnn_handle,
                                                tensor_desc_0,
                                                filter_desc,
                                                conv_desc,
                                                tensor_desc_1,
                                                static_cast<int>(results.size()),
                                                &num_algos,
                                                results.data()));
        results.resize(num_algos);
        for (size_t i = 0; i != results.size(); ++i) {
            cudnnConvolutionFwdAlgoPerf_t const& result = results[i];
            if (result.status == CUDNN_STATUS_SUCCESS) {
                conv_fwd_algo = result.algo;
                break;
            }
        }
        selected_algo = true;
    }
    const float alpha = 1.0;
    const float beta = 0.0;
    static void *workspace_ptr_0 = NULL;
    static size_t workspace_size_in_bytes = 0;
    if (!workspace_ptr_0)
    {
        CUDNN_SAFE_CALL(cudnnGetConvolutionForwardWorkspaceSize(cudnn_handle, tensor_desc_0, filter_desc, conv_desc, tensor_desc_1, conv_fwd_algo, &workspace_size_in_bytes));
        CUDA_SAFE_CALL(cudaMalloc(&workspace_ptr_0, workspace_size_in_bytes));
    }
    CUDNN_SAFE_CALL(mycudnnConvolutionForward(cudnn_handle, &alpha, tensor_desc_0, input0,filter_desc, input1, conv_desc, conv_fwd_algo, workspace_ptr_0, workspace_size_in_bytes, &beta, tensor_desc_1, output0));
    CUDNN_SAFE_CALL(cudnnDestroyTensorDescriptor(tensor_desc_0));
    CUDNN_SAFE_CALL(cudnnDestroyTensorDescriptor(tensor_desc_1));
    CUDNN_SAFE_CALL(cudnnDestroyFilterDescriptor(filter_desc));
    CUDNN_SAFE_CALL(cudnnDestroyConvolutionDescriptor(conv_desc));

}

    void executeImpl(cudaStream_t stream) {
        this->Convolution_float_float_float_cuda_lib_Convolution_550(cudnn_handle, input0, input1, output0);
    }
};


class inception3_Reshape_float_float_cuda_Reshape_541_CallKernel : public Kernel {
public:
    inception3_Reshape_float_float_cuda_Reshape_541_CallKernel(const dim3 & grids, const dim3 & blocks, unsigned  mem, cudaStream_t  stream, float*  input0, float*  output0, float*  Parameter_0_0, float**  Result_892_0) {
        this->grids = grids, this->blocks = blocks, this->mem = mem, this->stream = stream, this->input0 = input0, this->output0 = output0, this->Parameter_0_0 = Parameter_0_0, this->Result_892_0 = Result_892_0;
        this->kernelName = "inception3_Reshape_float_float_cuda_Reshape_541_Call";
        this->Id = 0;
        this->mixable = 0;
    }

    void initParams() override {
        // empty implementation
    }

    void loadKernel() override {
        // Empty implementation
    }

        dim3  grids; dim3  blocks; unsigned  mem; cudaStream_t  stream; float*  input0; float*  output0;
    float*  Parameter_0_0; float**  Result_892_0;
private:

    
std::vector<int> getArgs() override {
    return std::vector<int>();
}

     void Reshape_float_float_cuda_Reshape_541_Call(const dim3 &grids, const dim3 &blocks, unsigned mem, cudaStream_t stream, float* input0, float* output0) {
    inception3_Reshape_float_float_cuda_Reshape_541<<<grids, blocks, mem, stream>>>(input0, output0);
}

    void executeImpl(cudaStream_t stream) {
        this->Reshape_float_float_cuda_Reshape_541_Call(grids, blocks, mem, stream, input0, output0);
    }
};


class inception3_Convolution_float_float_float_cuda_lib_Convolution_542Kernel : public Kernel {
public:
    inception3_Convolution_float_float_float_cuda_lib_Convolution_542Kernel(cudnnHandle_t  cudnn_handle, float*  input0, float*  input1, float*  output0, float*  Parameter_0_0, float**  Result_892_0) {
        this->cudnn_handle = cudnn_handle, this->input0 = input0, this->input1 = input1, this->output0 = output0, this->Parameter_0_0 = Parameter_0_0, this->Result_892_0 = Result_892_0;
        this->kernelName = "inception3_Convolution_float_float_float_cuda_lib_Convolution_542";
        this->Id = 0;
        this->mixable = 2;
    }

    void initParams() override {
        // empty implementation
    }

    void loadKernel() override {
        // Empty implementation
    }

        cudnnHandle_t  cudnn_handle; float*  input0; float*  input1; float*  output0;
    float*  Parameter_0_0; float**  Result_892_0;
private:

    
std::vector<int> getArgs() override {
    return std::vector<int>({64, 256, 35, 35, 48, 256, 1, 1, 0, 0, 1, 1, 1, 1});
}

    void Convolution_float_float_float_cuda_lib_Convolution_542(cudnnHandle_t cudnn_handle, float* input0, float* input1, float* output0)
{
    cudnnTensorDescriptor_t tensor_desc_0;
    CUDNN_SAFE_CALL(cudnnCreateTensorDescriptor(&tensor_desc_0));
    CUDNN_SAFE_CALL(cudnnSetTensor4dDescriptor(tensor_desc_0, CUDNN_TENSOR_NCHW, CUDNN_DATA_FLOAT, 64, 256, 35, 35));
    cudnnTensorDescriptor_t tensor_desc_1;
    CUDNN_SAFE_CALL(cudnnCreateTensorDescriptor(&tensor_desc_1));
    CUDNN_SAFE_CALL(cudnnSetTensor4dDescriptor(tensor_desc_1, CUDNN_TENSOR_NCHW, CUDNN_DATA_FLOAT, 64, 48, 35, 35));
    cudnnFilterDescriptor_t filter_desc;
    CUDNN_SAFE_CALL(cudnnCreateFilterDescriptor(&filter_desc));
    CUDNN_SAFE_CALL(cudnnSetFilter4dDescriptor(filter_desc, CUDNN_DATA_FLOAT, CUDNN_TENSOR_NCHW, 48, 256, 1, 1));
    cudnnConvolutionDescriptor_t conv_desc;
    CUDNN_SAFE_CALL(cudnnCreateConvolutionDescriptor(&conv_desc));
    CUDNN_SAFE_CALL(cudnnSetConvolution2dDescriptor(conv_desc, 0, 0, 1, 1, 1, 1, CUDNN_CROSS_CORRELATION, CUDNN_DATA_FLOAT));

    static bool selected_algo = true;
    static cudnnConvolutionFwdAlgo_t conv_fwd_algo = CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM;

    if (!selected_algo) {
        int num_algos;
        int max_algos = 0;
        // cudnnGetConvolutionForwardAlgorithm_v7;
        CUDNN_SAFE_CALL(
            cudnnGetConvolutionForwardAlgorithmMaxCount(cudnn_handle, &max_algos));
        std::vector<cudnnConvolutionFwdAlgoPerf_t> results(max_algos);
        CUDNN_SAFE_CALL(cudnnFindConvolutionForwardAlgorithm(cudnn_handle,
                                                tensor_desc_0,
                                                filter_desc,
                                                conv_desc,
                                                tensor_desc_1,
                                                static_cast<int>(results.size()),
                                                &num_algos,
                                                results.data()));
        results.resize(num_algos);
        for (size_t i = 0; i != results.size(); ++i) {
            cudnnConvolutionFwdAlgoPerf_t const& result = results[i];
            if (result.status == CUDNN_STATUS_SUCCESS) {
                conv_fwd_algo = result.algo;
                break;
            }
        }
        selected_algo = true;
    }
    const float alpha = 1.0;
    const float beta = 0.0;
    static void *workspace_ptr_0 = NULL;
    static size_t workspace_size_in_bytes = 0;
    if (!workspace_ptr_0)
    {
        CUDNN_SAFE_CALL(cudnnGetConvolutionForwardWorkspaceSize(cudnn_handle, tensor_desc_0, filter_desc, conv_desc, tensor_desc_1, conv_fwd_algo, &workspace_size_in_bytes));
        CUDA_SAFE_CALL(cudaMalloc(&workspace_ptr_0, workspace_size_in_bytes));
    }
    CUDNN_SAFE_CALL(mycudnnConvolutionForward(cudnn_handle, &alpha, tensor_desc_0, input0,filter_desc, input1, conv_desc, conv_fwd_algo, workspace_ptr_0, workspace_size_in_bytes, &beta, tensor_desc_1, output0));
    CUDNN_SAFE_CALL(cudnnDestroyTensorDescriptor(tensor_desc_0));
    CUDNN_SAFE_CALL(cudnnDestroyTensorDescriptor(tensor_desc_1));
    CUDNN_SAFE_CALL(cudnnDestroyFilterDescriptor(filter_desc));
    CUDNN_SAFE_CALL(cudnnDestroyConvolutionDescriptor(conv_desc));

}

    void executeImpl(cudaStream_t stream) {
        this->Convolution_float_float_float_cuda_lib_Convolution_542(cudnn_handle, input0, input1, output0);
    }
};


class inception3_Concat_float_float_float_float_float_cuda_Concat_568_CallKernel : public Kernel {
public:
    inception3_Concat_float_float_float_float_float_cuda_Concat_568_CallKernel(const dim3 & grids, const dim3 & blocks, unsigned  mem, cudaStream_t  stream, float*  input0, float*  input1, float*  input2, float*  input3, float*  output0, float*  Parameter_0_0, float**  Result_892_0) {
        this->grids = grids, this->blocks = blocks, this->mem = mem, this->stream = stream, this->input0 = input0, this->input1 = input1, this->input2 = input2, this->input3 = input3, this->output0 = output0, this->Parameter_0_0 = Parameter_0_0, this->Result_892_0 = Result_892_0;
        this->kernelName = "inception3_Concat_float_float_float_float_float_cuda_Concat_568_Call";
        this->Id = 0;
        this->mixable = 0;
    }

    void initParams() override {
        // empty implementation
    }

    void loadKernel() override {
        // Empty implementation
    }

        dim3  grids; dim3  blocks; unsigned  mem; cudaStream_t  stream; float*  input0; float*  input1; float*  input2; float*  input3; float*  output0;
    float*  Parameter_0_0; float**  Result_892_0;
private:

    
std::vector<int> getArgs() override {
    return std::vector<int>();
}

     void Concat_float_float_float_float_float_cuda_Concat_568_Call(const dim3 &grids, const dim3 &blocks, unsigned mem, cudaStream_t stream, float* input0, float* input1, float* input2, float* input3, float* output0) {
    inception3_Concat_float_float_float_float_float_cuda_Concat_568<<<grids, blocks, mem, stream>>>(input0, input1, input2, input3, output0);
}

    void executeImpl(cudaStream_t stream) {
        this->Concat_float_float_float_float_float_cuda_Concat_568_Call(grids, blocks, mem, stream, input0, input1, input2, input3, output0);
    }
};


class inception3_AvgPool_float_float_cuda_lib_AvgPool_575Kernel : public Kernel {
public:
    inception3_AvgPool_float_float_cuda_lib_AvgPool_575Kernel(cudnnHandle_t  cudnn_handle, float*  input0, float*  output0, float*  Parameter_0_0, float**  Result_892_0) {
        this->cudnn_handle = cudnn_handle, this->input0 = input0, this->output0 = output0, this->Parameter_0_0 = Parameter_0_0, this->Result_892_0 = Result_892_0;
        this->kernelName = "inception3_AvgPool_float_float_cuda_lib_AvgPool_575";
        this->Id = 0;
        this->mixable = 0;
    }

    void initParams() override {
        // empty implementation
    }

    void loadKernel() override {
        // Empty implementation
    }

        cudnnHandle_t  cudnn_handle; float*  input0; float*  output0;
    float*  Parameter_0_0; float**  Result_892_0;
private:

    
std::vector<int> getArgs() override {
    return std::vector<int>();
}

    void AvgPool_float_float_cuda_lib_AvgPool_575(cudnnHandle_t cudnn_handle, float* input0, float* output0)
{
    cudnnTensorDescriptor_t input_desc;
    CUDNN_SAFE_CALL(cudnnCreateTensorDescriptor(&input_desc));
    CUDNN_SAFE_CALL(cudnnSetTensor4dDescriptor(input_desc, CUDNN_TENSOR_NCHW, CUDNN_DATA_FLOAT, 64, 288, 35, 35));
    cudnnTensorDescriptor_t output_desc;
    CUDNN_SAFE_CALL(cudnnCreateTensorDescriptor(&output_desc));
    CUDNN_SAFE_CALL(cudnnSetTensor4dDescriptor(output_desc, CUDNN_TENSOR_NCHW, CUDNN_DATA_FLOAT, 64, 288, 35, 35));
    cudnnPoolingDescriptor_t desc;
    cudnnCreatePoolingDescriptor(&desc);
    CUDNN_SAFE_CALL(cudnnSetPooling2dDescriptor(desc, CUDNN_POOLING_AVERAGE_COUNT_EXCLUDE_PADDING, CUDNN_NOT_PROPAGATE_NAN,3, 3, 1, 1, 1, 1));
    const float alpha = 1.0;
    const float beta = 0.0;
    CUDNN_SAFE_CALL(cudnnPoolingForward(cudnn_handle, desc, &alpha, input_desc, input0, &beta, output_desc, output0));
    CUDNN_SAFE_CALL(cudnnDestroyTensorDescriptor(input_desc));
    CUDNN_SAFE_CALL(cudnnDestroyTensorDescriptor(output_desc));
    CUDNN_SAFE_CALL(cudnnDestroyPoolingDescriptor(desc));

}

    void executeImpl(cudaStream_t stream) {
        this->AvgPool_float_float_cuda_lib_AvgPool_575(cudnn_handle, input0, output0);
    }
};


class inception3_Reshape_float_float_cuda_Reshape_579_CallKernel : public Kernel {
public:
    inception3_Reshape_float_float_cuda_Reshape_579_CallKernel(const dim3 & grids, const dim3 & blocks, unsigned  mem, cudaStream_t  stream, float*  input0, float*  output0, float*  Parameter_0_0, float**  Result_892_0) {
        this->grids = grids, this->blocks = blocks, this->mem = mem, this->stream = stream, this->input0 = input0, this->output0 = output0, this->Parameter_0_0 = Parameter_0_0, this->Result_892_0 = Result_892_0;
        this->kernelName = "inception3_Reshape_float_float_cuda_Reshape_579_Call";
        this->Id = 0;
        this->mixable = 0;
    }

    void initParams() override {
        // empty implementation
    }

    void loadKernel() override {
        // Empty implementation
    }

        dim3  grids; dim3  blocks; unsigned  mem; cudaStream_t  stream; float*  input0; float*  output0;
    float*  Parameter_0_0; float**  Result_892_0;
private:

    
std::vector<int> getArgs() override {
    return std::vector<int>();
}

     void Reshape_float_float_cuda_Reshape_579_Call(const dim3 &grids, const dim3 &blocks, unsigned mem, cudaStream_t stream, float* input0, float* output0) {
    inception3_Reshape_float_float_cuda_Reshape_579<<<grids, blocks, mem, stream>>>(input0, output0);
}

    void executeImpl(cudaStream_t stream) {
        this->Reshape_float_float_cuda_Reshape_579_Call(grids, blocks, mem, stream, input0, output0);
    }
};


class inception3_Convolution_float_float_float_cuda_lib_Convolution_580Kernel : public Kernel {
public:
    inception3_Convolution_float_float_float_cuda_lib_Convolution_580Kernel(cudnnHandle_t  cudnn_handle, float*  input0, float*  input1, float*  output0, float*  Parameter_0_0, float**  Result_892_0) {
        this->cudnn_handle = cudnn_handle, this->input0 = input0, this->input1 = input1, this->output0 = output0, this->Parameter_0_0 = Parameter_0_0, this->Result_892_0 = Result_892_0;
        this->kernelName = "inception3_Convolution_float_float_float_cuda_lib_Convolution_580";
        this->Id = 0;
        this->mixable = 2;
    }

    void initParams() override {
        // empty implementation
    }

    void loadKernel() override {
        // Empty implementation
    }

        cudnnHandle_t  cudnn_handle; float*  input0; float*  input1; float*  output0;
    float*  Parameter_0_0; float**  Result_892_0;
private:

    
std::vector<int> getArgs() override {
    return std::vector<int>({64, 288, 35, 35, 64, 288, 1, 1, 0, 0, 1, 1, 1, 1});
}

    void Convolution_float_float_float_cuda_lib_Convolution_580(cudnnHandle_t cudnn_handle, float* input0, float* input1, float* output0)
{
    cudnnTensorDescriptor_t tensor_desc_0;
    CUDNN_SAFE_CALL(cudnnCreateTensorDescriptor(&tensor_desc_0));
    CUDNN_SAFE_CALL(cudnnSetTensor4dDescriptor(tensor_desc_0, CUDNN_TENSOR_NCHW, CUDNN_DATA_FLOAT, 64, 288, 35, 35));
    cudnnTensorDescriptor_t tensor_desc_1;
    CUDNN_SAFE_CALL(cudnnCreateTensorDescriptor(&tensor_desc_1));
    CUDNN_SAFE_CALL(cudnnSetTensor4dDescriptor(tensor_desc_1, CUDNN_TENSOR_NCHW, CUDNN_DATA_FLOAT, 64, 64, 35, 35));
    cudnnFilterDescriptor_t filter_desc;
    CUDNN_SAFE_CALL(cudnnCreateFilterDescriptor(&filter_desc));
    CUDNN_SAFE_CALL(cudnnSetFilter4dDescriptor(filter_desc, CUDNN_DATA_FLOAT, CUDNN_TENSOR_NCHW, 64, 288, 1, 1));
    cudnnConvolutionDescriptor_t conv_desc;
    CUDNN_SAFE_CALL(cudnnCreateConvolutionDescriptor(&conv_desc));
    CUDNN_SAFE_CALL(cudnnSetConvolution2dDescriptor(conv_desc, 0, 0, 1, 1, 1, 1, CUDNN_CROSS_CORRELATION, CUDNN_DATA_FLOAT));

    static bool selected_algo = true;
    static cudnnConvolutionFwdAlgo_t conv_fwd_algo = CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM;

    if (!selected_algo) {
        int num_algos;
        int max_algos = 0;
        // cudnnGetConvolutionForwardAlgorithm_v7;
        CUDNN_SAFE_CALL(
            cudnnGetConvolutionForwardAlgorithmMaxCount(cudnn_handle, &max_algos));
        std::vector<cudnnConvolutionFwdAlgoPerf_t> results(max_algos);
        CUDNN_SAFE_CALL(cudnnFindConvolutionForwardAlgorithm(cudnn_handle,
                                                tensor_desc_0,
                                                filter_desc,
                                                conv_desc,
                                                tensor_desc_1,
                                                static_cast<int>(results.size()),
                                                &num_algos,
                                                results.data()));
        results.resize(num_algos);
        for (size_t i = 0; i != results.size(); ++i) {
            cudnnConvolutionFwdAlgoPerf_t const& result = results[i];
            if (result.status == CUDNN_STATUS_SUCCESS) {
                conv_fwd_algo = result.algo;
                break;
            }
        }
        selected_algo = true;
    }
    const float alpha = 1.0;
    const float beta = 0.0;
    static void *workspace_ptr_0 = NULL;
    static size_t workspace_size_in_bytes = 0;
    if (!workspace_ptr_0)
    {
        CUDNN_SAFE_CALL(cudnnGetConvolutionForwardWorkspaceSize(cudnn_handle, tensor_desc_0, filter_desc, conv_desc, tensor_desc_1, conv_fwd_algo, &workspace_size_in_bytes));
        CUDA_SAFE_CALL(cudaMalloc(&workspace_ptr_0, workspace_size_in_bytes));
    }
    CUDNN_SAFE_CALL(mycudnnConvolutionForward(cudnn_handle, &alpha, tensor_desc_0, input0,filter_desc, input1, conv_desc, conv_fwd_algo, workspace_ptr_0, workspace_size_in_bytes, &beta, tensor_desc_1, output0));
    CUDNN_SAFE_CALL(cudnnDestroyTensorDescriptor(tensor_desc_0));
    CUDNN_SAFE_CALL(cudnnDestroyTensorDescriptor(tensor_desc_1));
    CUDNN_SAFE_CALL(cudnnDestroyFilterDescriptor(filter_desc));
    CUDNN_SAFE_CALL(cudnnDestroyConvolutionDescriptor(conv_desc));

}

    void executeImpl(cudaStream_t stream) {
        this->Convolution_float_float_float_cuda_lib_Convolution_580(cudnn_handle, input0, input1, output0);
    }
};


class inception3_Reshape_float_float_cuda_Reshape_571_CallKernel : public Kernel {
public:
    inception3_Reshape_float_float_cuda_Reshape_571_CallKernel(const dim3 & grids, const dim3 & blocks, unsigned  mem, cudaStream_t  stream, float*  input0, float*  output0, float*  Parameter_0_0, float**  Result_892_0) {
        this->grids = grids, this->blocks = blocks, this->mem = mem, this->stream = stream, this->input0 = input0, this->output0 = output0, this->Parameter_0_0 = Parameter_0_0, this->Result_892_0 = Result_892_0;
        this->kernelName = "inception3_Reshape_float_float_cuda_Reshape_571_Call";
        this->Id = 0;
        this->mixable = 0;
    }

    void initParams() override {
        // empty implementation
    }

    void loadKernel() override {
        // Empty implementation
    }

        dim3  grids; dim3  blocks; unsigned  mem; cudaStream_t  stream; float*  input0; float*  output0;
    float*  Parameter_0_0; float**  Result_892_0;
private:

    
std::vector<int> getArgs() override {
    return std::vector<int>();
}

     void Reshape_float_float_cuda_Reshape_571_Call(const dim3 &grids, const dim3 &blocks, unsigned mem, cudaStream_t stream, float* input0, float* output0) {
    inception3_Reshape_float_float_cuda_Reshape_571<<<grids, blocks, mem, stream>>>(input0, output0);
}

    void executeImpl(cudaStream_t stream) {
        this->Reshape_float_float_cuda_Reshape_571_Call(grids, blocks, mem, stream, input0, output0);
    }
};


class inception3_Convolution_float_float_float_cuda_lib_Convolution_572Kernel : public Kernel {
public:
    inception3_Convolution_float_float_float_cuda_lib_Convolution_572Kernel(cudnnHandle_t  cudnn_handle, float*  input0, float*  input1, float*  output0, float*  Parameter_0_0, float**  Result_892_0) {
        this->cudnn_handle = cudnn_handle, this->input0 = input0, this->input1 = input1, this->output0 = output0, this->Parameter_0_0 = Parameter_0_0, this->Result_892_0 = Result_892_0;
        this->kernelName = "inception3_Convolution_float_float_float_cuda_lib_Convolution_572";
        this->Id = 0;
        this->mixable = 2;
    }

    void initParams() override {
        // empty implementation
    }

    void loadKernel() override {
        // Empty implementation
    }

        cudnnHandle_t  cudnn_handle; float*  input0; float*  input1; float*  output0;
    float*  Parameter_0_0; float**  Result_892_0;
private:

    
std::vector<int> getArgs() override {
    return std::vector<int>({64, 288, 35, 35, 48, 288, 1, 1, 0, 0, 1, 1, 1, 1});
}

    void Convolution_float_float_float_cuda_lib_Convolution_572(cudnnHandle_t cudnn_handle, float* input0, float* input1, float* output0)
{
    cudnnTensorDescriptor_t tensor_desc_0;
    CUDNN_SAFE_CALL(cudnnCreateTensorDescriptor(&tensor_desc_0));
    CUDNN_SAFE_CALL(cudnnSetTensor4dDescriptor(tensor_desc_0, CUDNN_TENSOR_NCHW, CUDNN_DATA_FLOAT, 64, 288, 35, 35));
    cudnnTensorDescriptor_t tensor_desc_1;
    CUDNN_SAFE_CALL(cudnnCreateTensorDescriptor(&tensor_desc_1));
    CUDNN_SAFE_CALL(cudnnSetTensor4dDescriptor(tensor_desc_1, CUDNN_TENSOR_NCHW, CUDNN_DATA_FLOAT, 64, 48, 35, 35));
    cudnnFilterDescriptor_t filter_desc;
    CUDNN_SAFE_CALL(cudnnCreateFilterDescriptor(&filter_desc));
    CUDNN_SAFE_CALL(cudnnSetFilter4dDescriptor(filter_desc, CUDNN_DATA_FLOAT, CUDNN_TENSOR_NCHW, 48, 288, 1, 1));
    cudnnConvolutionDescriptor_t conv_desc;
    CUDNN_SAFE_CALL(cudnnCreateConvolutionDescriptor(&conv_desc));
    CUDNN_SAFE_CALL(cudnnSetConvolution2dDescriptor(conv_desc, 0, 0, 1, 1, 1, 1, CUDNN_CROSS_CORRELATION, CUDNN_DATA_FLOAT));

    static bool selected_algo = true;
    static cudnnConvolutionFwdAlgo_t conv_fwd_algo = CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM;

    if (!selected_algo) {
        int num_algos;
        int max_algos = 0;
        // cudnnGetConvolutionForwardAlgorithm_v7;
        CUDNN_SAFE_CALL(
            cudnnGetConvolutionForwardAlgorithmMaxCount(cudnn_handle, &max_algos));
        std::vector<cudnnConvolutionFwdAlgoPerf_t> results(max_algos);
        CUDNN_SAFE_CALL(cudnnFindConvolutionForwardAlgorithm(cudnn_handle,
                                                tensor_desc_0,
                                                filter_desc,
                                                conv_desc,
                                                tensor_desc_1,
                                                static_cast<int>(results.size()),
                                                &num_algos,
                                                results.data()));
        results.resize(num_algos);
        for (size_t i = 0; i != results.size(); ++i) {
            cudnnConvolutionFwdAlgoPerf_t const& result = results[i];
            if (result.status == CUDNN_STATUS_SUCCESS) {
                conv_fwd_algo = result.algo;
                break;
            }
        }
        selected_algo = true;
    }
    const float alpha = 1.0;
    const float beta = 0.0;
    static void *workspace_ptr_0 = NULL;
    static size_t workspace_size_in_bytes = 0;
    if (!workspace_ptr_0)
    {
        CUDNN_SAFE_CALL(cudnnGetConvolutionForwardWorkspaceSize(cudnn_handle, tensor_desc_0, filter_desc, conv_desc, tensor_desc_1, conv_fwd_algo, &workspace_size_in_bytes));
        CUDA_SAFE_CALL(cudaMalloc(&workspace_ptr_0, workspace_size_in_bytes));
    }
    CUDNN_SAFE_CALL(mycudnnConvolutionForward(cudnn_handle, &alpha, tensor_desc_0, input0,filter_desc, input1, conv_desc, conv_fwd_algo, workspace_ptr_0, workspace_size_in_bytes, &beta, tensor_desc_1, output0));
    CUDNN_SAFE_CALL(cudnnDestroyTensorDescriptor(tensor_desc_0));
    CUDNN_SAFE_CALL(cudnnDestroyTensorDescriptor(tensor_desc_1));
    CUDNN_SAFE_CALL(cudnnDestroyFilterDescriptor(filter_desc));
    CUDNN_SAFE_CALL(cudnnDestroyConvolutionDescriptor(conv_desc));

}

    void executeImpl(cudaStream_t stream) {
        this->Convolution_float_float_float_cuda_lib_Convolution_572(cudnn_handle, input0, input1, output0);
    }
};


class inception3_MaxPool_float_float_cuda_lib_MaxPool_603Kernel : public Kernel {
public:
    inception3_MaxPool_float_float_cuda_lib_MaxPool_603Kernel(cudnnHandle_t  cudnn_handle, float*  input0, float*  output0, float*  Parameter_0_0, float**  Result_892_0) {
        this->cudnn_handle = cudnn_handle, this->input0 = input0, this->output0 = output0, this->Parameter_0_0 = Parameter_0_0, this->Result_892_0 = Result_892_0;
        this->kernelName = "inception3_MaxPool_float_float_cuda_lib_MaxPool_603";
        this->Id = 0;
        this->mixable = 0;
    }

    void initParams() override {
        // empty implementation
    }

    void loadKernel() override {
        // Empty implementation
    }

        cudnnHandle_t  cudnn_handle; float*  input0; float*  output0;
    float*  Parameter_0_0; float**  Result_892_0;
private:

    
std::vector<int> getArgs() override {
    return std::vector<int>();
}

    void MaxPool_float_float_cuda_lib_MaxPool_603(cudnnHandle_t cudnn_handle, float* input0, float* output0)
{
    cudnnTensorDescriptor_t input_desc;
    CUDNN_SAFE_CALL(cudnnCreateTensorDescriptor(&input_desc));
    CUDNN_SAFE_CALL(cudnnSetTensor4dDescriptor(input_desc, CUDNN_TENSOR_NCHW, CUDNN_DATA_FLOAT, 64, 288, 35, 35));
    cudnnTensorDescriptor_t output_desc;
    CUDNN_SAFE_CALL(cudnnCreateTensorDescriptor(&output_desc));
    CUDNN_SAFE_CALL(cudnnSetTensor4dDescriptor(output_desc, CUDNN_TENSOR_NCHW, CUDNN_DATA_FLOAT, 64, 288, 17, 17));
    cudnnPoolingDescriptor_t desc;
    cudnnCreatePoolingDescriptor(&desc);
    CUDNN_SAFE_CALL(cudnnSetPooling2dDescriptor(desc, CUDNN_POOLING_MAX, CUDNN_NOT_PROPAGATE_NAN,3, 3, 0, 0, 2, 2));
    const float alpha = 1.0;
    const float beta = 0.0;
    CUDNN_SAFE_CALL(cudnnPoolingForward(cudnn_handle, desc, &alpha, input_desc, input0, &beta, output_desc, output0));
    CUDNN_SAFE_CALL(cudnnDestroyTensorDescriptor(input_desc));
    CUDNN_SAFE_CALL(cudnnDestroyTensorDescriptor(output_desc));
    CUDNN_SAFE_CALL(cudnnDestroyPoolingDescriptor(desc));

}

    void executeImpl(cudaStream_t stream) {
        this->MaxPool_float_float_cuda_lib_MaxPool_603(cudnn_handle, input0, output0);
    }
};


class inception3_Convolution_float_float_float_cuda_lib_Convolution_613Kernel : public Kernel {
public:
    inception3_Convolution_float_float_float_cuda_lib_Convolution_613Kernel(cudnnHandle_t  cudnn_handle, float*  input0, float*  input1, float*  output0, float*  Parameter_0_0, float**  Result_892_0) {
        this->cudnn_handle = cudnn_handle, this->input0 = input0, this->input1 = input1, this->output0 = output0, this->Parameter_0_0 = Parameter_0_0, this->Result_892_0 = Result_892_0;
        this->kernelName = "inception3_Convolution_float_float_float_cuda_lib_Convolution_613";
        this->Id = 0;
        this->mixable = 2;
    }

    void initParams() override {
        // empty implementation
    }

    void loadKernel() override {
        // Empty implementation
    }

        cudnnHandle_t  cudnn_handle; float*  input0; float*  input1; float*  output0;
    float*  Parameter_0_0; float**  Result_892_0;
private:

    
std::vector<int> getArgs() override {
    return std::vector<int>({64, 96, 35, 35, 96, 96, 3, 3, 0, 0, 2, 2, 1, 1});
}

    void Convolution_float_float_float_cuda_lib_Convolution_613(cudnnHandle_t cudnn_handle, float* input0, float* input1, float* output0)
{
    cudnnTensorDescriptor_t tensor_desc_0;
    CUDNN_SAFE_CALL(cudnnCreateTensorDescriptor(&tensor_desc_0));
    CUDNN_SAFE_CALL(cudnnSetTensor4dDescriptor(tensor_desc_0, CUDNN_TENSOR_NCHW, CUDNN_DATA_FLOAT, 64, 96, 35, 35));
    cudnnTensorDescriptor_t tensor_desc_1;
    CUDNN_SAFE_CALL(cudnnCreateTensorDescriptor(&tensor_desc_1));
    CUDNN_SAFE_CALL(cudnnSetTensor4dDescriptor(tensor_desc_1, CUDNN_TENSOR_NCHW, CUDNN_DATA_FLOAT, 64, 96, 17, 17));
    cudnnFilterDescriptor_t filter_desc;
    CUDNN_SAFE_CALL(cudnnCreateFilterDescriptor(&filter_desc));
    CUDNN_SAFE_CALL(cudnnSetFilter4dDescriptor(filter_desc, CUDNN_DATA_FLOAT, CUDNN_TENSOR_NCHW, 96, 96, 3, 3));
    cudnnConvolutionDescriptor_t conv_desc;
    CUDNN_SAFE_CALL(cudnnCreateConvolutionDescriptor(&conv_desc));
    CUDNN_SAFE_CALL(cudnnSetConvolution2dDescriptor(conv_desc, 0, 0, 2, 2, 1, 1, CUDNN_CROSS_CORRELATION, CUDNN_DATA_FLOAT));

    static bool selected_algo = true;
    static cudnnConvolutionFwdAlgo_t conv_fwd_algo = CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM;

    if (!selected_algo) {
        int num_algos;
        int max_algos = 0;
        // cudnnGetConvolutionForwardAlgorithm_v7;
        CUDNN_SAFE_CALL(
            cudnnGetConvolutionForwardAlgorithmMaxCount(cudnn_handle, &max_algos));
        std::vector<cudnnConvolutionFwdAlgoPerf_t> results(max_algos);
        CUDNN_SAFE_CALL(cudnnFindConvolutionForwardAlgorithm(cudnn_handle,
                                                tensor_desc_0,
                                                filter_desc,
                                                conv_desc,
                                                tensor_desc_1,
                                                static_cast<int>(results.size()),
                                                &num_algos,
                                                results.data()));
        results.resize(num_algos);
        for (size_t i = 0; i != results.size(); ++i) {
            cudnnConvolutionFwdAlgoPerf_t const& result = results[i];
            if (result.status == CUDNN_STATUS_SUCCESS) {
                conv_fwd_algo = result.algo;
                break;
            }
        }
        selected_algo = true;
    }
    const float alpha = 1.0;
    const float beta = 0.0;
    static void *workspace_ptr_0 = NULL;
    static size_t workspace_size_in_bytes = 0;
    if (!workspace_ptr_0)
    {
        CUDNN_SAFE_CALL(cudnnGetConvolutionForwardWorkspaceSize(cudnn_handle, tensor_desc_0, filter_desc, conv_desc, tensor_desc_1, conv_fwd_algo, &workspace_size_in_bytes));
        CUDA_SAFE_CALL(cudaMalloc(&workspace_ptr_0, workspace_size_in_bytes));
    }
    CUDNN_SAFE_CALL(mycudnnConvolutionForward(cudnn_handle, &alpha, tensor_desc_0, input0,filter_desc, input1, conv_desc, conv_fwd_algo, workspace_ptr_0, workspace_size_in_bytes, &beta, tensor_desc_1, output0));
    CUDNN_SAFE_CALL(cudnnDestroyTensorDescriptor(tensor_desc_0));
    CUDNN_SAFE_CALL(cudnnDestroyTensorDescriptor(tensor_desc_1));
    CUDNN_SAFE_CALL(cudnnDestroyFilterDescriptor(filter_desc));
    CUDNN_SAFE_CALL(cudnnDestroyConvolutionDescriptor(conv_desc));

}

    void executeImpl(cudaStream_t stream) {
        this->Convolution_float_float_float_cuda_lib_Convolution_613(cudnn_handle, input0, input1, output0);
    }
};


class inception3_BatchNormInference_float_float_float_float_float_float_cuda_BatchNormInference_614_CallKernel : public Kernel {
public:
    inception3_BatchNormInference_float_float_float_float_float_float_cuda_BatchNormInference_614_CallKernel(const dim3 & grids, const dim3 & blocks, unsigned  mem, cudaStream_t  stream, float*  input0, float*  input1, float*  input2, float*  input3, float*  input4, float*  output0, float*  Parameter_0_0, float**  Result_892_0) {
        this->grids = grids, this->blocks = blocks, this->mem = mem, this->stream = stream, this->input0 = input0, this->input1 = input1, this->input2 = input2, this->input3 = input3, this->input4 = input4, this->output0 = output0, this->Parameter_0_0 = Parameter_0_0, this->Result_892_0 = Result_892_0;
        this->kernelName = "inception3_BatchNormInference_float_float_float_float_float_float_cuda_BatchNormInference_614_Call";
        this->Id = 0;
        this->mixable = 0;
    }

    void initParams() override {
        // empty implementation
    }

    void loadKernel() override {
        // Empty implementation
    }

        dim3  grids; dim3  blocks; unsigned  mem; cudaStream_t  stream; float*  input0; float*  input1; float*  input2; float*  input3; float*  input4; float*  output0;
    float*  Parameter_0_0; float**  Result_892_0;
private:

    
std::vector<int> getArgs() override {
    return std::vector<int>();
}

     void BatchNormInference_float_float_float_float_float_float_cuda_BatchNormInference_614_Call(const dim3 &grids, const dim3 &blocks, unsigned mem, cudaStream_t stream, float* input0, float* input1, float* input2, float* input3, float* input4, float* output0) {
    inception3_BatchNormInference_float_float_float_float_float_float_cuda_BatchNormInference_614<<<grids, blocks, mem, stream>>>(input0, input1, input2, input3, input4, output0);
}

    void executeImpl(cudaStream_t stream) {
        this->BatchNormInference_float_float_float_float_float_float_cuda_BatchNormInference_614_Call(grids, blocks, mem, stream, input0, input1, input2, input3, input4, output0);
    }
};


class inception3_Reshape_float_float_cuda_Reshape_599_CallKernel : public Kernel {
public:
    inception3_Reshape_float_float_cuda_Reshape_599_CallKernel(const dim3 & grids, const dim3 & blocks, unsigned  mem, cudaStream_t  stream, float*  input0, float*  output0, float*  Parameter_0_0, float**  Result_892_0) {
        this->grids = grids, this->blocks = blocks, this->mem = mem, this->stream = stream, this->input0 = input0, this->output0 = output0, this->Parameter_0_0 = Parameter_0_0, this->Result_892_0 = Result_892_0;
        this->kernelName = "inception3_Reshape_float_float_cuda_Reshape_599_Call";
        this->Id = 0;
        this->mixable = 0;
    }

    void initParams() override {
        // empty implementation
    }

    void loadKernel() override {
        // Empty implementation
    }

        dim3  grids; dim3  blocks; unsigned  mem; cudaStream_t  stream; float*  input0; float*  output0;
    float*  Parameter_0_0; float**  Result_892_0;
private:

    
std::vector<int> getArgs() override {
    return std::vector<int>();
}

     void Reshape_float_float_cuda_Reshape_599_Call(const dim3 &grids, const dim3 &blocks, unsigned mem, cudaStream_t stream, float* input0, float* output0) {
    inception3_Reshape_float_float_cuda_Reshape_599<<<grids, blocks, mem, stream>>>(input0, output0);
}

    void executeImpl(cudaStream_t stream) {
        this->Reshape_float_float_cuda_Reshape_599_Call(grids, blocks, mem, stream, input0, output0);
    }
};


class inception3_Convolution_float_float_float_cuda_lib_Convolution_600Kernel : public Kernel {
public:
    inception3_Convolution_float_float_float_cuda_lib_Convolution_600Kernel(cudnnHandle_t  cudnn_handle, float*  input0, float*  input1, float*  output0, float*  Parameter_0_0, float**  Result_892_0) {
        this->cudnn_handle = cudnn_handle, this->input0 = input0, this->input1 = input1, this->output0 = output0, this->Parameter_0_0 = Parameter_0_0, this->Result_892_0 = Result_892_0;
        this->kernelName = "inception3_Convolution_float_float_float_cuda_lib_Convolution_600";
        this->Id = 0;
        this->mixable = 2;
    }

    void initParams() override {
        // empty implementation
    }

    void loadKernel() override {
        // Empty implementation
    }

        cudnnHandle_t  cudnn_handle; float*  input0; float*  input1; float*  output0;
    float*  Parameter_0_0; float**  Result_892_0;
private:

    
std::vector<int> getArgs() override {
    return std::vector<int>({64, 288, 35, 35, 384, 288, 3, 3, 0, 0, 2, 2, 1, 1});
}

    void Convolution_float_float_float_cuda_lib_Convolution_600(cudnnHandle_t cudnn_handle, float* input0, float* input1, float* output0)
{
    cudnnTensorDescriptor_t tensor_desc_0;
    CUDNN_SAFE_CALL(cudnnCreateTensorDescriptor(&tensor_desc_0));
    CUDNN_SAFE_CALL(cudnnSetTensor4dDescriptor(tensor_desc_0, CUDNN_TENSOR_NCHW, CUDNN_DATA_FLOAT, 64, 288, 35, 35));
    cudnnTensorDescriptor_t tensor_desc_1;
    CUDNN_SAFE_CALL(cudnnCreateTensorDescriptor(&tensor_desc_1));
    CUDNN_SAFE_CALL(cudnnSetTensor4dDescriptor(tensor_desc_1, CUDNN_TENSOR_NCHW, CUDNN_DATA_FLOAT, 64, 384, 17, 17));
    cudnnFilterDescriptor_t filter_desc;
    CUDNN_SAFE_CALL(cudnnCreateFilterDescriptor(&filter_desc));
    CUDNN_SAFE_CALL(cudnnSetFilter4dDescriptor(filter_desc, CUDNN_DATA_FLOAT, CUDNN_TENSOR_NCHW, 384, 288, 3, 3));
    cudnnConvolutionDescriptor_t conv_desc;
    CUDNN_SAFE_CALL(cudnnCreateConvolutionDescriptor(&conv_desc));
    CUDNN_SAFE_CALL(cudnnSetConvolution2dDescriptor(conv_desc, 0, 0, 2, 2, 1, 1, CUDNN_CROSS_CORRELATION, CUDNN_DATA_FLOAT));

    static bool selected_algo = true;
    static cudnnConvolutionFwdAlgo_t conv_fwd_algo = CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM;

    if (!selected_algo) {
        int num_algos;
        int max_algos = 0;
        // cudnnGetConvolutionForwardAlgorithm_v7;
        CUDNN_SAFE_CALL(
            cudnnGetConvolutionForwardAlgorithmMaxCount(cudnn_handle, &max_algos));
        std::vector<cudnnConvolutionFwdAlgoPerf_t> results(max_algos);
        CUDNN_SAFE_CALL(cudnnFindConvolutionForwardAlgorithm(cudnn_handle,
                                                tensor_desc_0,
                                                filter_desc,
                                                conv_desc,
                                                tensor_desc_1,
                                                static_cast<int>(results.size()),
                                                &num_algos,
                                                results.data()));
        results.resize(num_algos);
        for (size_t i = 0; i != results.size(); ++i) {
            cudnnConvolutionFwdAlgoPerf_t const& result = results[i];
            if (result.status == CUDNN_STATUS_SUCCESS) {
                conv_fwd_algo = result.algo;
                break;
            }
        }
        selected_algo = true;
    }
    const float alpha = 1.0;
    const float beta = 0.0;
    static void *workspace_ptr_0 = NULL;
    static size_t workspace_size_in_bytes = 0;
    if (!workspace_ptr_0)
    {
        CUDNN_SAFE_CALL(cudnnGetConvolutionForwardWorkspaceSize(cudnn_handle, tensor_desc_0, filter_desc, conv_desc, tensor_desc_1, conv_fwd_algo, &workspace_size_in_bytes));
        CUDA_SAFE_CALL(cudaMalloc(&workspace_ptr_0, workspace_size_in_bytes));
    }
    CUDNN_SAFE_CALL(mycudnnConvolutionForward(cudnn_handle, &alpha, tensor_desc_0, input0,filter_desc, input1, conv_desc, conv_fwd_algo, workspace_ptr_0, workspace_size_in_bytes, &beta, tensor_desc_1, output0));
    CUDNN_SAFE_CALL(cudnnDestroyTensorDescriptor(tensor_desc_0));
    CUDNN_SAFE_CALL(cudnnDestroyTensorDescriptor(tensor_desc_1));
    CUDNN_SAFE_CALL(cudnnDestroyFilterDescriptor(filter_desc));
    CUDNN_SAFE_CALL(cudnnDestroyConvolutionDescriptor(conv_desc));

}

    void executeImpl(cudaStream_t stream) {
        this->Convolution_float_float_float_cuda_lib_Convolution_600(cudnn_handle, input0, input1, output0);
    }
};


class inception3_BatchNormInference_float_float_float_float_float_float_cuda_BatchNormInference_604_CallKernel : public Kernel {
public:
    inception3_BatchNormInference_float_float_float_float_float_float_cuda_BatchNormInference_604_CallKernel(const dim3 & grids, const dim3 & blocks, unsigned  mem, cudaStream_t  stream, float*  input0, float*  input1, float*  input2, float*  input3, float*  input4, float*  output0, float*  Parameter_0_0, float**  Result_892_0) {
        this->grids = grids, this->blocks = blocks, this->mem = mem, this->stream = stream, this->input0 = input0, this->input1 = input1, this->input2 = input2, this->input3 = input3, this->input4 = input4, this->output0 = output0, this->Parameter_0_0 = Parameter_0_0, this->Result_892_0 = Result_892_0;
        this->kernelName = "inception3_BatchNormInference_float_float_float_float_float_float_cuda_BatchNormInference_604_Call";
        this->Id = 0;
        this->mixable = 0;
    }

    void initParams() override {
        // empty implementation
    }

    void loadKernel() override {
        // Empty implementation
    }

        dim3  grids; dim3  blocks; unsigned  mem; cudaStream_t  stream; float*  input0; float*  input1; float*  input2; float*  input3; float*  input4; float*  output0;
    float*  Parameter_0_0; float**  Result_892_0;
private:

    
std::vector<int> getArgs() override {
    return std::vector<int>();
}

     void BatchNormInference_float_float_float_float_float_float_cuda_BatchNormInference_604_Call(const dim3 &grids, const dim3 &blocks, unsigned mem, cudaStream_t stream, float* input0, float* input1, float* input2, float* input3, float* input4, float* output0) {
    inception3_BatchNormInference_float_float_float_float_float_float_cuda_BatchNormInference_604<<<grids, blocks, mem, stream>>>(input0, input1, input2, input3, input4, output0);
}

    void executeImpl(cudaStream_t stream) {
        this->BatchNormInference_float_float_float_float_float_float_cuda_BatchNormInference_604_Call(grids, blocks, mem, stream, input0, input1, input2, input3, input4, output0);
    }
};


class inception3_Concat_float_float_float_float_cuda_Concat_616_CallKernel : public Kernel {
public:
    inception3_Concat_float_float_float_float_cuda_Concat_616_CallKernel(const dim3 & grids, const dim3 & blocks, unsigned  mem, cudaStream_t  stream, float*  input0, float*  input1, float*  input2, float*  output0, float*  Parameter_0_0, float**  Result_892_0) {
        this->grids = grids, this->blocks = blocks, this->mem = mem, this->stream = stream, this->input0 = input0, this->input1 = input1, this->input2 = input2, this->output0 = output0, this->Parameter_0_0 = Parameter_0_0, this->Result_892_0 = Result_892_0;
        this->kernelName = "inception3_Concat_float_float_float_float_cuda_Concat_616_Call";
        this->Id = 0;
        this->mixable = 0;
    }

    void initParams() override {
        // empty implementation
    }

    void loadKernel() override {
        // Empty implementation
    }

        dim3  grids; dim3  blocks; unsigned  mem; cudaStream_t  stream; float*  input0; float*  input1; float*  input2; float*  output0;
    float*  Parameter_0_0; float**  Result_892_0;
private:

    
std::vector<int> getArgs() override {
    return std::vector<int>();
}

     void Concat_float_float_float_float_cuda_Concat_616_Call(const dim3 &grids, const dim3 &blocks, unsigned mem, cudaStream_t stream, float* input0, float* input1, float* input2, float* output0) {
    inception3_Concat_float_float_float_float_cuda_Concat_616<<<grids, blocks, mem, stream>>>(input0, input1, input2, output0);
}

    void executeImpl(cudaStream_t stream) {
        this->Concat_float_float_float_float_cuda_Concat_616_Call(grids, blocks, mem, stream, input0, input1, input2, output0);
    }
};


class inception3_AvgPool_float_float_cuda_lib_AvgPool_623Kernel : public Kernel {
public:
    inception3_AvgPool_float_float_cuda_lib_AvgPool_623Kernel(cudnnHandle_t  cudnn_handle, float*  input0, float*  output0, float*  Parameter_0_0, float**  Result_892_0) {
        this->cudnn_handle = cudnn_handle, this->input0 = input0, this->output0 = output0, this->Parameter_0_0 = Parameter_0_0, this->Result_892_0 = Result_892_0;
        this->kernelName = "inception3_AvgPool_float_float_cuda_lib_AvgPool_623";
        this->Id = 0;
        this->mixable = 0;
    }

    void initParams() override {
        // empty implementation
    }

    void loadKernel() override {
        // Empty implementation
    }

        cudnnHandle_t  cudnn_handle; float*  input0; float*  output0;
    float*  Parameter_0_0; float**  Result_892_0;
private:

    
std::vector<int> getArgs() override {
    return std::vector<int>();
}

    void AvgPool_float_float_cuda_lib_AvgPool_623(cudnnHandle_t cudnn_handle, float* input0, float* output0)
{
    cudnnTensorDescriptor_t input_desc;
    CUDNN_SAFE_CALL(cudnnCreateTensorDescriptor(&input_desc));
    CUDNN_SAFE_CALL(cudnnSetTensor4dDescriptor(input_desc, CUDNN_TENSOR_NCHW, CUDNN_DATA_FLOAT, 64, 768, 17, 17));
    cudnnTensorDescriptor_t output_desc;
    CUDNN_SAFE_CALL(cudnnCreateTensorDescriptor(&output_desc));
    CUDNN_SAFE_CALL(cudnnSetTensor4dDescriptor(output_desc, CUDNN_TENSOR_NCHW, CUDNN_DATA_FLOAT, 64, 768, 17, 17));
    cudnnPoolingDescriptor_t desc;
    cudnnCreatePoolingDescriptor(&desc);
    CUDNN_SAFE_CALL(cudnnSetPooling2dDescriptor(desc, CUDNN_POOLING_AVERAGE_COUNT_EXCLUDE_PADDING, CUDNN_NOT_PROPAGATE_NAN,3, 3, 1, 1, 1, 1));
    const float alpha = 1.0;
    const float beta = 0.0;
    CUDNN_SAFE_CALL(cudnnPoolingForward(cudnn_handle, desc, &alpha, input_desc, input0, &beta, output_desc, output0));
    CUDNN_SAFE_CALL(cudnnDestroyTensorDescriptor(input_desc));
    CUDNN_SAFE_CALL(cudnnDestroyTensorDescriptor(output_desc));
    CUDNN_SAFE_CALL(cudnnDestroyPoolingDescriptor(desc));

}

    void executeImpl(cudaStream_t stream) {
        this->AvgPool_float_float_cuda_lib_AvgPool_623(cudnn_handle, input0, output0);
    }
};


class inception3_Reshape_float_float_cuda_Reshape_627_CallKernel : public Kernel {
public:
    inception3_Reshape_float_float_cuda_Reshape_627_CallKernel(const dim3 & grids, const dim3 & blocks, unsigned  mem, cudaStream_t  stream, float*  input0, float*  output0, float*  Parameter_0_0, float**  Result_892_0) {
        this->grids = grids, this->blocks = blocks, this->mem = mem, this->stream = stream, this->input0 = input0, this->output0 = output0, this->Parameter_0_0 = Parameter_0_0, this->Result_892_0 = Result_892_0;
        this->kernelName = "inception3_Reshape_float_float_cuda_Reshape_627_Call";
        this->Id = 0;
        this->mixable = 0;
    }

    void initParams() override {
        // empty implementation
    }

    void loadKernel() override {
        // Empty implementation
    }

        dim3  grids; dim3  blocks; unsigned  mem; cudaStream_t  stream; float*  input0; float*  output0;
    float*  Parameter_0_0; float**  Result_892_0;
private:

    
std::vector<int> getArgs() override {
    return std::vector<int>();
}

     void Reshape_float_float_cuda_Reshape_627_Call(const dim3 &grids, const dim3 &blocks, unsigned mem, cudaStream_t stream, float* input0, float* output0) {
    inception3_Reshape_float_float_cuda_Reshape_627<<<grids, blocks, mem, stream>>>(input0, output0);
}

    void executeImpl(cudaStream_t stream) {
        this->Reshape_float_float_cuda_Reshape_627_Call(grids, blocks, mem, stream, input0, output0);
    }
};


class inception3_Convolution_float_float_float_cuda_lib_Convolution_628Kernel : public Kernel {
public:
    inception3_Convolution_float_float_float_cuda_lib_Convolution_628Kernel(cudnnHandle_t  cudnn_handle, float*  input0, float*  input1, float*  output0, float*  Parameter_0_0, float**  Result_892_0) {
        this->cudnn_handle = cudnn_handle, this->input0 = input0, this->input1 = input1, this->output0 = output0, this->Parameter_0_0 = Parameter_0_0, this->Result_892_0 = Result_892_0;
        this->kernelName = "inception3_Convolution_float_float_float_cuda_lib_Convolution_628";
        this->Id = 0;
        this->mixable = 2;
    }

    void initParams() override {
        // empty implementation
    }

    void loadKernel() override {
        // Empty implementation
    }

        cudnnHandle_t  cudnn_handle; float*  input0; float*  input1; float*  output0;
    float*  Parameter_0_0; float**  Result_892_0;
private:

    
std::vector<int> getArgs() override {
    return std::vector<int>({64, 768, 17, 17, 192, 768, 1, 1, 0, 0, 1, 1, 1, 1});
}

    void Convolution_float_float_float_cuda_lib_Convolution_628(cudnnHandle_t cudnn_handle, float* input0, float* input1, float* output0)
{
    cudnnTensorDescriptor_t tensor_desc_0;
    CUDNN_SAFE_CALL(cudnnCreateTensorDescriptor(&tensor_desc_0));
    CUDNN_SAFE_CALL(cudnnSetTensor4dDescriptor(tensor_desc_0, CUDNN_TENSOR_NCHW, CUDNN_DATA_FLOAT, 64, 768, 17, 17));
    cudnnTensorDescriptor_t tensor_desc_1;
    CUDNN_SAFE_CALL(cudnnCreateTensorDescriptor(&tensor_desc_1));
    CUDNN_SAFE_CALL(cudnnSetTensor4dDescriptor(tensor_desc_1, CUDNN_TENSOR_NCHW, CUDNN_DATA_FLOAT, 64, 192, 17, 17));
    cudnnFilterDescriptor_t filter_desc;
    CUDNN_SAFE_CALL(cudnnCreateFilterDescriptor(&filter_desc));
    CUDNN_SAFE_CALL(cudnnSetFilter4dDescriptor(filter_desc, CUDNN_DATA_FLOAT, CUDNN_TENSOR_NCHW, 192, 768, 1, 1));
    cudnnConvolutionDescriptor_t conv_desc;
    CUDNN_SAFE_CALL(cudnnCreateConvolutionDescriptor(&conv_desc));
    CUDNN_SAFE_CALL(cudnnSetConvolution2dDescriptor(conv_desc, 0, 0, 1, 1, 1, 1, CUDNN_CROSS_CORRELATION, CUDNN_DATA_FLOAT));

    static bool selected_algo = true;
    static cudnnConvolutionFwdAlgo_t conv_fwd_algo = CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM;

    if (!selected_algo) {
        int num_algos;
        int max_algos = 0;
        // cudnnGetConvolutionForwardAlgorithm_v7;
        CUDNN_SAFE_CALL(
            cudnnGetConvolutionForwardAlgorithmMaxCount(cudnn_handle, &max_algos));
        std::vector<cudnnConvolutionFwdAlgoPerf_t> results(max_algos);
        CUDNN_SAFE_CALL(cudnnFindConvolutionForwardAlgorithm(cudnn_handle,
                                                tensor_desc_0,
                                                filter_desc,
                                                conv_desc,
                                                tensor_desc_1,
                                                static_cast<int>(results.size()),
                                                &num_algos,
                                                results.data()));
        results.resize(num_algos);
        for (size_t i = 0; i != results.size(); ++i) {
            cudnnConvolutionFwdAlgoPerf_t const& result = results[i];
            if (result.status == CUDNN_STATUS_SUCCESS) {
                conv_fwd_algo = result.algo;
                break;
            }
        }
        selected_algo = true;
    }
    const float alpha = 1.0;
    const float beta = 0.0;
    static void *workspace_ptr_0 = NULL;
    static size_t workspace_size_in_bytes = 0;
    if (!workspace_ptr_0)
    {
        CUDNN_SAFE_CALL(cudnnGetConvolutionForwardWorkspaceSize(cudnn_handle, tensor_desc_0, filter_desc, conv_desc, tensor_desc_1, conv_fwd_algo, &workspace_size_in_bytes));
        CUDA_SAFE_CALL(cudaMalloc(&workspace_ptr_0, workspace_size_in_bytes));
    }
    CUDNN_SAFE_CALL(mycudnnConvolutionForward(cudnn_handle, &alpha, tensor_desc_0, input0,filter_desc, input1, conv_desc, conv_fwd_algo, workspace_ptr_0, workspace_size_in_bytes, &beta, tensor_desc_1, output0));
    CUDNN_SAFE_CALL(cudnnDestroyTensorDescriptor(tensor_desc_0));
    CUDNN_SAFE_CALL(cudnnDestroyTensorDescriptor(tensor_desc_1));
    CUDNN_SAFE_CALL(cudnnDestroyFilterDescriptor(filter_desc));
    CUDNN_SAFE_CALL(cudnnDestroyConvolutionDescriptor(conv_desc));

}

    void executeImpl(cudaStream_t stream) {
        this->Convolution_float_float_float_cuda_lib_Convolution_628(cudnn_handle, input0, input1, output0);
    }
};


class inception3_BatchNormInference_float_float_float_float_float_float_cuda_BatchNormInference_632_CallKernel : public Kernel {
public:
    inception3_BatchNormInference_float_float_float_float_float_float_cuda_BatchNormInference_632_CallKernel(const dim3 & grids, const dim3 & blocks, unsigned  mem, cudaStream_t  stream, float*  input0, float*  input1, float*  input2, float*  input3, float*  input4, float*  output0, float*  Parameter_0_0, float**  Result_892_0) {
        this->grids = grids, this->blocks = blocks, this->mem = mem, this->stream = stream, this->input0 = input0, this->input1 = input1, this->input2 = input2, this->input3 = input3, this->input4 = input4, this->output0 = output0, this->Parameter_0_0 = Parameter_0_0, this->Result_892_0 = Result_892_0;
        this->kernelName = "inception3_BatchNormInference_float_float_float_float_float_float_cuda_BatchNormInference_632_Call";
        this->Id = 0;
        this->mixable = 0;
    }

    void initParams() override {
        // empty implementation
    }

    void loadKernel() override {
        // Empty implementation
    }

        dim3  grids; dim3  blocks; unsigned  mem; cudaStream_t  stream; float*  input0; float*  input1; float*  input2; float*  input3; float*  input4; float*  output0;
    float*  Parameter_0_0; float**  Result_892_0;
private:

    
std::vector<int> getArgs() override {
    return std::vector<int>();
}

     void BatchNormInference_float_float_float_float_float_float_cuda_BatchNormInference_632_Call(const dim3 &grids, const dim3 &blocks, unsigned mem, cudaStream_t stream, float* input0, float* input1, float* input2, float* input3, float* input4, float* output0) {
    inception3_BatchNormInference_float_float_float_float_float_float_cuda_BatchNormInference_632<<<grids, blocks, mem, stream>>>(input0, input1, input2, input3, input4, output0);
}

    void executeImpl(cudaStream_t stream) {
        this->BatchNormInference_float_float_float_float_float_float_cuda_BatchNormInference_632_Call(grids, blocks, mem, stream, input0, input1, input2, input3, input4, output0);
    }
};


class inception3_Reshape_float_float_cuda_Reshape_621_CallKernel : public Kernel {
public:
    inception3_Reshape_float_float_cuda_Reshape_621_CallKernel(const dim3 & grids, const dim3 & blocks, unsigned  mem, cudaStream_t  stream, float*  input0, float*  output0, float*  Parameter_0_0, float**  Result_892_0) {
        this->grids = grids, this->blocks = blocks, this->mem = mem, this->stream = stream, this->input0 = input0, this->output0 = output0, this->Parameter_0_0 = Parameter_0_0, this->Result_892_0 = Result_892_0;
        this->kernelName = "inception3_Reshape_float_float_cuda_Reshape_621_Call";
        this->Id = 0;
        this->mixable = 0;
    }

    void initParams() override {
        // empty implementation
    }

    void loadKernel() override {
        // Empty implementation
    }

        dim3  grids; dim3  blocks; unsigned  mem; cudaStream_t  stream; float*  input0; float*  output0;
    float*  Parameter_0_0; float**  Result_892_0;
private:

    
std::vector<int> getArgs() override {
    return std::vector<int>();
}

     void Reshape_float_float_cuda_Reshape_621_Call(const dim3 &grids, const dim3 &blocks, unsigned mem, cudaStream_t stream, float* input0, float* output0) {
    inception3_Reshape_float_float_cuda_Reshape_621<<<grids, blocks, mem, stream>>>(input0, output0);
}

    void executeImpl(cudaStream_t stream) {
        this->Reshape_float_float_cuda_Reshape_621_Call(grids, blocks, mem, stream, input0, output0);
    }
};


class inception3_Convolution_float_float_float_cuda_lib_Convolution_622Kernel : public Kernel {
public:
    inception3_Convolution_float_float_float_cuda_lib_Convolution_622Kernel(cudnnHandle_t  cudnn_handle, float*  input0, float*  input1, float*  output0, float*  Parameter_0_0, float**  Result_892_0) {
        this->cudnn_handle = cudnn_handle, this->input0 = input0, this->input1 = input1, this->output0 = output0, this->Parameter_0_0 = Parameter_0_0, this->Result_892_0 = Result_892_0;
        this->kernelName = "inception3_Convolution_float_float_float_cuda_lib_Convolution_622";
        this->Id = 0;
        this->mixable = 2;
    }

    void initParams() override {
        // empty implementation
    }

    void loadKernel() override {
        // Empty implementation
    }

        cudnnHandle_t  cudnn_handle; float*  input0; float*  input1; float*  output0;
    float*  Parameter_0_0; float**  Result_892_0;
private:

    
std::vector<int> getArgs() override {
    return std::vector<int>({64, 768, 17, 17, 128, 768, 1, 1, 0, 0, 1, 1, 1, 1});
}

    void Convolution_float_float_float_cuda_lib_Convolution_622(cudnnHandle_t cudnn_handle, float* input0, float* input1, float* output0)
{
    cudnnTensorDescriptor_t tensor_desc_0;
    CUDNN_SAFE_CALL(cudnnCreateTensorDescriptor(&tensor_desc_0));
    CUDNN_SAFE_CALL(cudnnSetTensor4dDescriptor(tensor_desc_0, CUDNN_TENSOR_NCHW, CUDNN_DATA_FLOAT, 64, 768, 17, 17));
    cudnnTensorDescriptor_t tensor_desc_1;
    CUDNN_SAFE_CALL(cudnnCreateTensorDescriptor(&tensor_desc_1));
    CUDNN_SAFE_CALL(cudnnSetTensor4dDescriptor(tensor_desc_1, CUDNN_TENSOR_NCHW, CUDNN_DATA_FLOAT, 64, 128, 17, 17));
    cudnnFilterDescriptor_t filter_desc;
    CUDNN_SAFE_CALL(cudnnCreateFilterDescriptor(&filter_desc));
    CUDNN_SAFE_CALL(cudnnSetFilter4dDescriptor(filter_desc, CUDNN_DATA_FLOAT, CUDNN_TENSOR_NCHW, 128, 768, 1, 1));
    cudnnConvolutionDescriptor_t conv_desc;
    CUDNN_SAFE_CALL(cudnnCreateConvolutionDescriptor(&conv_desc));
    CUDNN_SAFE_CALL(cudnnSetConvolution2dDescriptor(conv_desc, 0, 0, 1, 1, 1, 1, CUDNN_CROSS_CORRELATION, CUDNN_DATA_FLOAT));

    static bool selected_algo = true;
    static cudnnConvolutionFwdAlgo_t conv_fwd_algo = CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM;

    if (!selected_algo) {
        int num_algos;
        int max_algos = 0;
        // cudnnGetConvolutionForwardAlgorithm_v7;
        CUDNN_SAFE_CALL(
            cudnnGetConvolutionForwardAlgorithmMaxCount(cudnn_handle, &max_algos));
        std::vector<cudnnConvolutionFwdAlgoPerf_t> results(max_algos);
        CUDNN_SAFE_CALL(cudnnFindConvolutionForwardAlgorithm(cudnn_handle,
                                                tensor_desc_0,
                                                filter_desc,
                                                conv_desc,
                                                tensor_desc_1,
                                                static_cast<int>(results.size()),
                                                &num_algos,
                                                results.data()));
        results.resize(num_algos);
        for (size_t i = 0; i != results.size(); ++i) {
            cudnnConvolutionFwdAlgoPerf_t const& result = results[i];
            if (result.status == CUDNN_STATUS_SUCCESS) {
                conv_fwd_algo = result.algo;
                break;
            }
        }
        selected_algo = true;
    }
    const float alpha = 1.0;
    const float beta = 0.0;
    static void *workspace_ptr_0 = NULL;
    static size_t workspace_size_in_bytes = 0;
    if (!workspace_ptr_0)
    {
        CUDNN_SAFE_CALL(cudnnGetConvolutionForwardWorkspaceSize(cudnn_handle, tensor_desc_0, filter_desc, conv_desc, tensor_desc_1, conv_fwd_algo, &workspace_size_in_bytes));
        CUDA_SAFE_CALL(cudaMalloc(&workspace_ptr_0, workspace_size_in_bytes));
    }
    CUDNN_SAFE_CALL(mycudnnConvolutionForward(cudnn_handle, &alpha, tensor_desc_0, input0,filter_desc, input1, conv_desc, conv_fwd_algo, workspace_ptr_0, workspace_size_in_bytes, &beta, tensor_desc_1, output0));
    CUDNN_SAFE_CALL(cudnnDestroyTensorDescriptor(tensor_desc_0));
    CUDNN_SAFE_CALL(cudnnDestroyTensorDescriptor(tensor_desc_1));
    CUDNN_SAFE_CALL(cudnnDestroyFilterDescriptor(filter_desc));
    CUDNN_SAFE_CALL(cudnnDestroyConvolutionDescriptor(conv_desc));

}

    void executeImpl(cudaStream_t stream) {
        this->Convolution_float_float_float_cuda_lib_Convolution_622(cudnn_handle, input0, input1, output0);
    }
};


class inception3_BatchNormInference_float_float_float_float_float_float_cuda_BatchNormInference_626_CallKernel : public Kernel {
public:
    inception3_BatchNormInference_float_float_float_float_float_float_cuda_BatchNormInference_626_CallKernel(const dim3 & grids, const dim3 & blocks, unsigned  mem, cudaStream_t  stream, float*  input0, float*  input1, float*  input2, float*  input3, float*  input4, float*  output0, float*  Parameter_0_0, float**  Result_892_0) {
        this->grids = grids, this->blocks = blocks, this->mem = mem, this->stream = stream, this->input0 = input0, this->input1 = input1, this->input2 = input2, this->input3 = input3, this->input4 = input4, this->output0 = output0, this->Parameter_0_0 = Parameter_0_0, this->Result_892_0 = Result_892_0;
        this->kernelName = "inception3_BatchNormInference_float_float_float_float_float_float_cuda_BatchNormInference_626_Call";
        this->Id = 0;
        this->mixable = 0;
    }

    void initParams() override {
        // empty implementation
    }

    void loadKernel() override {
        // Empty implementation
    }

        dim3  grids; dim3  blocks; unsigned  mem; cudaStream_t  stream; float*  input0; float*  input1; float*  input2; float*  input3; float*  input4; float*  output0;
    float*  Parameter_0_0; float**  Result_892_0;
private:

    
std::vector<int> getArgs() override {
    return std::vector<int>();
}

     void BatchNormInference_float_float_float_float_float_float_cuda_BatchNormInference_626_Call(const dim3 &grids, const dim3 &blocks, unsigned mem, cudaStream_t stream, float* input0, float* input1, float* input2, float* input3, float* input4, float* output0) {
    inception3_BatchNormInference_float_float_float_float_float_float_cuda_BatchNormInference_626<<<grids, blocks, mem, stream>>>(input0, input1, input2, input3, input4, output0);
}

    void executeImpl(cudaStream_t stream) {
        this->BatchNormInference_float_float_float_float_float_float_cuda_BatchNormInference_626_Call(grids, blocks, mem, stream, input0, input1, input2, input3, input4, output0);
    }
};


class inception3_Reshape_float_float_cuda_Reshape_635_CallKernel : public Kernel {
public:
    inception3_Reshape_float_float_cuda_Reshape_635_CallKernel(const dim3 & grids, const dim3 & blocks, unsigned  mem, cudaStream_t  stream, float*  input0, float*  output0, float*  Parameter_0_0, float**  Result_892_0) {
        this->grids = grids, this->blocks = blocks, this->mem = mem, this->stream = stream, this->input0 = input0, this->output0 = output0, this->Parameter_0_0 = Parameter_0_0, this->Result_892_0 = Result_892_0;
        this->kernelName = "inception3_Reshape_float_float_cuda_Reshape_635_Call";
        this->Id = 0;
        this->mixable = 0;
    }

    void initParams() override {
        // empty implementation
    }

    void loadKernel() override {
        // Empty implementation
    }

        dim3  grids; dim3  blocks; unsigned  mem; cudaStream_t  stream; float*  input0; float*  output0;
    float*  Parameter_0_0; float**  Result_892_0;
private:

    
std::vector<int> getArgs() override {
    return std::vector<int>();
}

     void Reshape_float_float_cuda_Reshape_635_Call(const dim3 &grids, const dim3 &blocks, unsigned mem, cudaStream_t stream, float* input0, float* output0) {
    inception3_Reshape_float_float_cuda_Reshape_635<<<grids, blocks, mem, stream>>>(input0, output0);
}

    void executeImpl(cudaStream_t stream) {
        this->Reshape_float_float_cuda_Reshape_635_Call(grids, blocks, mem, stream, input0, output0);
    }
};


class inception3_Convolution_float_float_float_cuda_lib_Convolution_636Kernel : public Kernel {
public:
    inception3_Convolution_float_float_float_cuda_lib_Convolution_636Kernel(cudnnHandle_t  cudnn_handle, float*  input0, float*  input1, float*  output0, float*  Parameter_0_0, float**  Result_892_0) {
        this->cudnn_handle = cudnn_handle, this->input0 = input0, this->input1 = input1, this->output0 = output0, this->Parameter_0_0 = Parameter_0_0, this->Result_892_0 = Result_892_0;
        this->kernelName = "inception3_Convolution_float_float_float_cuda_lib_Convolution_636";
        this->Id = 0;
        this->mixable = 2;
    }

    void initParams() override {
        // empty implementation
    }

    void loadKernel() override {
        // Empty implementation
    }

        cudnnHandle_t  cudnn_handle; float*  input0; float*  input1; float*  output0;
    float*  Parameter_0_0; float**  Result_892_0;
private:

    
std::vector<int> getArgs() override {
    return std::vector<int>({64, 128, 17, 17, 128, 128, 7, 1, 3, 0, 1, 1, 1, 1});
}

    void Convolution_float_float_float_cuda_lib_Convolution_636(cudnnHandle_t cudnn_handle, float* input0, float* input1, float* output0)
{
    cudnnTensorDescriptor_t tensor_desc_0;
    CUDNN_SAFE_CALL(cudnnCreateTensorDescriptor(&tensor_desc_0));
    CUDNN_SAFE_CALL(cudnnSetTensor4dDescriptor(tensor_desc_0, CUDNN_TENSOR_NCHW, CUDNN_DATA_FLOAT, 64, 128, 17, 17));
    cudnnTensorDescriptor_t tensor_desc_1;
    CUDNN_SAFE_CALL(cudnnCreateTensorDescriptor(&tensor_desc_1));
    CUDNN_SAFE_CALL(cudnnSetTensor4dDescriptor(tensor_desc_1, CUDNN_TENSOR_NCHW, CUDNN_DATA_FLOAT, 64, 128, 17, 17));
    cudnnFilterDescriptor_t filter_desc;
    CUDNN_SAFE_CALL(cudnnCreateFilterDescriptor(&filter_desc));
    CUDNN_SAFE_CALL(cudnnSetFilter4dDescriptor(filter_desc, CUDNN_DATA_FLOAT, CUDNN_TENSOR_NCHW, 128, 128, 7, 1));
    cudnnConvolutionDescriptor_t conv_desc;
    CUDNN_SAFE_CALL(cudnnCreateConvolutionDescriptor(&conv_desc));
    CUDNN_SAFE_CALL(cudnnSetConvolution2dDescriptor(conv_desc, 3, 0, 1, 1, 1, 1, CUDNN_CROSS_CORRELATION, CUDNN_DATA_FLOAT));

    static bool selected_algo = true;
    static cudnnConvolutionFwdAlgo_t conv_fwd_algo = CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM;

    if (!selected_algo) {
        int num_algos;
        int max_algos = 0;
        // cudnnGetConvolutionForwardAlgorithm_v7;
        CUDNN_SAFE_CALL(
            cudnnGetConvolutionForwardAlgorithmMaxCount(cudnn_handle, &max_algos));
        std::vector<cudnnConvolutionFwdAlgoPerf_t> results(max_algos);
        CUDNN_SAFE_CALL(cudnnFindConvolutionForwardAlgorithm(cudnn_handle,
                                                tensor_desc_0,
                                                filter_desc,
                                                conv_desc,
                                                tensor_desc_1,
                                                static_cast<int>(results.size()),
                                                &num_algos,
                                                results.data()));
        results.resize(num_algos);
        for (size_t i = 0; i != results.size(); ++i) {
            cudnnConvolutionFwdAlgoPerf_t const& result = results[i];
            if (result.status == CUDNN_STATUS_SUCCESS) {
                conv_fwd_algo = result.algo;
                break;
            }
        }
        selected_algo = true;
    }
    const float alpha = 1.0;
    const float beta = 0.0;
    static void *workspace_ptr_0 = NULL;
    static size_t workspace_size_in_bytes = 0;
    if (!workspace_ptr_0)
    {
        CUDNN_SAFE_CALL(cudnnGetConvolutionForwardWorkspaceSize(cudnn_handle, tensor_desc_0, filter_desc, conv_desc, tensor_desc_1, conv_fwd_algo, &workspace_size_in_bytes));
        CUDA_SAFE_CALL(cudaMalloc(&workspace_ptr_0, workspace_size_in_bytes));
    }
    CUDNN_SAFE_CALL(mycudnnConvolutionForward(cudnn_handle, &alpha, tensor_desc_0, input0,filter_desc, input1, conv_desc, conv_fwd_algo, workspace_ptr_0, workspace_size_in_bytes, &beta, tensor_desc_1, output0));
    CUDNN_SAFE_CALL(cudnnDestroyTensorDescriptor(tensor_desc_0));
    CUDNN_SAFE_CALL(cudnnDestroyTensorDescriptor(tensor_desc_1));
    CUDNN_SAFE_CALL(cudnnDestroyFilterDescriptor(filter_desc));
    CUDNN_SAFE_CALL(cudnnDestroyConvolutionDescriptor(conv_desc));

}

    void executeImpl(cudaStream_t stream) {
        this->Convolution_float_float_float_cuda_lib_Convolution_636(cudnn_handle, input0, input1, output0);
    }
};


class inception3_Convolution_float_float_float_cuda_lib_Convolution_645Kernel : public Kernel {
public:
    inception3_Convolution_float_float_float_cuda_lib_Convolution_645Kernel(cudnnHandle_t  cudnn_handle, float*  input0, float*  input1, float*  output0, float*  Parameter_0_0, float**  Result_892_0) {
        this->cudnn_handle = cudnn_handle, this->input0 = input0, this->input1 = input1, this->output0 = output0, this->Parameter_0_0 = Parameter_0_0, this->Result_892_0 = Result_892_0;
        this->kernelName = "inception3_Convolution_float_float_float_cuda_lib_Convolution_645";
        this->Id = 0;
        this->mixable = 2;
    }

    void initParams() override {
        // empty implementation
    }

    void loadKernel() override {
        // Empty implementation
    }

        cudnnHandle_t  cudnn_handle; float*  input0; float*  input1; float*  output0;
    float*  Parameter_0_0; float**  Result_892_0;
private:

    
std::vector<int> getArgs() override {
    return std::vector<int>({64, 128, 17, 17, 128, 128, 1, 7, 0, 3, 1, 1, 1, 1});
}

    void Convolution_float_float_float_cuda_lib_Convolution_645(cudnnHandle_t cudnn_handle, float* input0, float* input1, float* output0)
{
    cudnnTensorDescriptor_t tensor_desc_0;
    CUDNN_SAFE_CALL(cudnnCreateTensorDescriptor(&tensor_desc_0));
    CUDNN_SAFE_CALL(cudnnSetTensor4dDescriptor(tensor_desc_0, CUDNN_TENSOR_NCHW, CUDNN_DATA_FLOAT, 64, 128, 17, 17));
    cudnnTensorDescriptor_t tensor_desc_1;
    CUDNN_SAFE_CALL(cudnnCreateTensorDescriptor(&tensor_desc_1));
    CUDNN_SAFE_CALL(cudnnSetTensor4dDescriptor(tensor_desc_1, CUDNN_TENSOR_NCHW, CUDNN_DATA_FLOAT, 64, 128, 17, 17));
    cudnnFilterDescriptor_t filter_desc;
    CUDNN_SAFE_CALL(cudnnCreateFilterDescriptor(&filter_desc));
    CUDNN_SAFE_CALL(cudnnSetFilter4dDescriptor(filter_desc, CUDNN_DATA_FLOAT, CUDNN_TENSOR_NCHW, 128, 128, 1, 7));
    cudnnConvolutionDescriptor_t conv_desc;
    CUDNN_SAFE_CALL(cudnnCreateConvolutionDescriptor(&conv_desc));
    CUDNN_SAFE_CALL(cudnnSetConvolution2dDescriptor(conv_desc, 0, 3, 1, 1, 1, 1, CUDNN_CROSS_CORRELATION, CUDNN_DATA_FLOAT));

    static bool selected_algo = true;
    static cudnnConvolutionFwdAlgo_t conv_fwd_algo = CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM;

    if (!selected_algo) {
        int num_algos;
        int max_algos = 0;
        // cudnnGetConvolutionForwardAlgorithm_v7;
        CUDNN_SAFE_CALL(
            cudnnGetConvolutionForwardAlgorithmMaxCount(cudnn_handle, &max_algos));
        std::vector<cudnnConvolutionFwdAlgoPerf_t> results(max_algos);
        CUDNN_SAFE_CALL(cudnnFindConvolutionForwardAlgorithm(cudnn_handle,
                                                tensor_desc_0,
                                                filter_desc,
                                                conv_desc,
                                                tensor_desc_1,
                                                static_cast<int>(results.size()),
                                                &num_algos,
                                                results.data()));
        results.resize(num_algos);
        for (size_t i = 0; i != results.size(); ++i) {
            cudnnConvolutionFwdAlgoPerf_t const& result = results[i];
            if (result.status == CUDNN_STATUS_SUCCESS) {
                conv_fwd_algo = result.algo;
                break;
            }
        }
        selected_algo = true;
    }
    const float alpha = 1.0;
    const float beta = 0.0;
    static void *workspace_ptr_0 = NULL;
    static size_t workspace_size_in_bytes = 0;
    if (!workspace_ptr_0)
    {
        CUDNN_SAFE_CALL(cudnnGetConvolutionForwardWorkspaceSize(cudnn_handle, tensor_desc_0, filter_desc, conv_desc, tensor_desc_1, conv_fwd_algo, &workspace_size_in_bytes));
        CUDA_SAFE_CALL(cudaMalloc(&workspace_ptr_0, workspace_size_in_bytes));
    }
    CUDNN_SAFE_CALL(mycudnnConvolutionForward(cudnn_handle, &alpha, tensor_desc_0, input0,filter_desc, input1, conv_desc, conv_fwd_algo, workspace_ptr_0, workspace_size_in_bytes, &beta, tensor_desc_1, output0));
    CUDNN_SAFE_CALL(cudnnDestroyTensorDescriptor(tensor_desc_0));
    CUDNN_SAFE_CALL(cudnnDestroyTensorDescriptor(tensor_desc_1));
    CUDNN_SAFE_CALL(cudnnDestroyFilterDescriptor(filter_desc));
    CUDNN_SAFE_CALL(cudnnDestroyConvolutionDescriptor(conv_desc));

}

    void executeImpl(cudaStream_t stream) {
        this->Convolution_float_float_float_cuda_lib_Convolution_645(cudnn_handle, input0, input1, output0);
    }
};


class inception3_Reshape_float_float_cuda_Reshape_654_CallKernel : public Kernel {
public:
    inception3_Reshape_float_float_cuda_Reshape_654_CallKernel(const dim3 & grids, const dim3 & blocks, unsigned  mem, cudaStream_t  stream, float*  input0, float*  output0, float*  Parameter_0_0, float**  Result_892_0) {
        this->grids = grids, this->blocks = blocks, this->mem = mem, this->stream = stream, this->input0 = input0, this->output0 = output0, this->Parameter_0_0 = Parameter_0_0, this->Result_892_0 = Result_892_0;
        this->kernelName = "inception3_Reshape_float_float_cuda_Reshape_654_Call";
        this->Id = 0;
        this->mixable = 0;
    }

    void initParams() override {
        // empty implementation
    }

    void loadKernel() override {
        // Empty implementation
    }

        dim3  grids; dim3  blocks; unsigned  mem; cudaStream_t  stream; float*  input0; float*  output0;
    float*  Parameter_0_0; float**  Result_892_0;
private:

    
std::vector<int> getArgs() override {
    return std::vector<int>();
}

     void Reshape_float_float_cuda_Reshape_654_Call(const dim3 &grids, const dim3 &blocks, unsigned mem, cudaStream_t stream, float* input0, float* output0) {
    inception3_Reshape_float_float_cuda_Reshape_654<<<grids, blocks, mem, stream>>>(input0, output0);
}

    void executeImpl(cudaStream_t stream) {
        this->Reshape_float_float_cuda_Reshape_654_Call(grids, blocks, mem, stream, input0, output0);
    }
};


class inception3_Convolution_float_float_float_cuda_lib_Convolution_655Kernel : public Kernel {
public:
    inception3_Convolution_float_float_float_cuda_lib_Convolution_655Kernel(cudnnHandle_t  cudnn_handle, float*  input0, float*  input1, float*  output0, float*  Parameter_0_0, float**  Result_892_0) {
        this->cudnn_handle = cudnn_handle, this->input0 = input0, this->input1 = input1, this->output0 = output0, this->Parameter_0_0 = Parameter_0_0, this->Result_892_0 = Result_892_0;
        this->kernelName = "inception3_Convolution_float_float_float_cuda_lib_Convolution_655";
        this->Id = 0;
        this->mixable = 2;
    }

    void initParams() override {
        // empty implementation
    }

    void loadKernel() override {
        // Empty implementation
    }

        cudnnHandle_t  cudnn_handle; float*  input0; float*  input1; float*  output0;
    float*  Parameter_0_0; float**  Result_892_0;
private:

    
std::vector<int> getArgs() override {
    return std::vector<int>({64, 128, 17, 17, 192, 128, 1, 7, 0, 3, 1, 1, 1, 1});
}

    void Convolution_float_float_float_cuda_lib_Convolution_655(cudnnHandle_t cudnn_handle, float* input0, float* input1, float* output0)
{
    cudnnTensorDescriptor_t tensor_desc_0;
    CUDNN_SAFE_CALL(cudnnCreateTensorDescriptor(&tensor_desc_0));
    CUDNN_SAFE_CALL(cudnnSetTensor4dDescriptor(tensor_desc_0, CUDNN_TENSOR_NCHW, CUDNN_DATA_FLOAT, 64, 128, 17, 17));
    cudnnTensorDescriptor_t tensor_desc_1;
    CUDNN_SAFE_CALL(cudnnCreateTensorDescriptor(&tensor_desc_1));
    CUDNN_SAFE_CALL(cudnnSetTensor4dDescriptor(tensor_desc_1, CUDNN_TENSOR_NCHW, CUDNN_DATA_FLOAT, 64, 192, 17, 17));
    cudnnFilterDescriptor_t filter_desc;
    CUDNN_SAFE_CALL(cudnnCreateFilterDescriptor(&filter_desc));
    CUDNN_SAFE_CALL(cudnnSetFilter4dDescriptor(filter_desc, CUDNN_DATA_FLOAT, CUDNN_TENSOR_NCHW, 192, 128, 1, 7));
    cudnnConvolutionDescriptor_t conv_desc;
    CUDNN_SAFE_CALL(cudnnCreateConvolutionDescriptor(&conv_desc));
    CUDNN_SAFE_CALL(cudnnSetConvolution2dDescriptor(conv_desc, 0, 3, 1, 1, 1, 1, CUDNN_CROSS_CORRELATION, CUDNN_DATA_FLOAT));

    static bool selected_algo = true;
    static cudnnConvolutionFwdAlgo_t conv_fwd_algo = CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM;

    if (!selected_algo) {
        int num_algos;
        int max_algos = 0;
        // cudnnGetConvolutionForwardAlgorithm_v7;
        CUDNN_SAFE_CALL(
            cudnnGetConvolutionForwardAlgorithmMaxCount(cudnn_handle, &max_algos));
        std::vector<cudnnConvolutionFwdAlgoPerf_t> results(max_algos);
        CUDNN_SAFE_CALL(cudnnFindConvolutionForwardAlgorithm(cudnn_handle,
                                                tensor_desc_0,
                                                filter_desc,
                                                conv_desc,
                                                tensor_desc_1,
                                                static_cast<int>(results.size()),
                                                &num_algos,
                                                results.data()));
        results.resize(num_algos);
        for (size_t i = 0; i != results.size(); ++i) {
            cudnnConvolutionFwdAlgoPerf_t const& result = results[i];
            if (result.status == CUDNN_STATUS_SUCCESS) {
                conv_fwd_algo = result.algo;
                break;
            }
        }
        selected_algo = true;
    }
    const float alpha = 1.0;
    const float beta = 0.0;
    static void *workspace_ptr_0 = NULL;
    static size_t workspace_size_in_bytes = 0;
    if (!workspace_ptr_0)
    {
        CUDNN_SAFE_CALL(cudnnGetConvolutionForwardWorkspaceSize(cudnn_handle, tensor_desc_0, filter_desc, conv_desc, tensor_desc_1, conv_fwd_algo, &workspace_size_in_bytes));
        CUDA_SAFE_CALL(cudaMalloc(&workspace_ptr_0, workspace_size_in_bytes));
    }
    CUDNN_SAFE_CALL(mycudnnConvolutionForward(cudnn_handle, &alpha, tensor_desc_0, input0,filter_desc, input1, conv_desc, conv_fwd_algo, workspace_ptr_0, workspace_size_in_bytes, &beta, tensor_desc_1, output0));
    CUDNN_SAFE_CALL(cudnnDestroyTensorDescriptor(tensor_desc_0));
    CUDNN_SAFE_CALL(cudnnDestroyTensorDescriptor(tensor_desc_1));
    CUDNN_SAFE_CALL(cudnnDestroyFilterDescriptor(filter_desc));
    CUDNN_SAFE_CALL(cudnnDestroyConvolutionDescriptor(conv_desc));

}

    void executeImpl(cudaStream_t stream) {
        this->Convolution_float_float_float_cuda_lib_Convolution_655(cudnn_handle, input0, input1, output0);
    }
};


class inception3_Convolution_float_float_float_cuda_lib_Convolution_643Kernel : public Kernel {
public:
    inception3_Convolution_float_float_float_cuda_lib_Convolution_643Kernel(cudnnHandle_t  cudnn_handle, float*  input0, float*  input1, float*  output0, float*  Parameter_0_0, float**  Result_892_0) {
        this->cudnn_handle = cudnn_handle, this->input0 = input0, this->input1 = input1, this->output0 = output0, this->Parameter_0_0 = Parameter_0_0, this->Result_892_0 = Result_892_0;
        this->kernelName = "inception3_Convolution_float_float_float_cuda_lib_Convolution_643";
        this->Id = 0;
        this->mixable = 2;
    }

    void initParams() override {
        // empty implementation
    }

    void loadKernel() override {
        // Empty implementation
    }

        cudnnHandle_t  cudnn_handle; float*  input0; float*  input1; float*  output0;
    float*  Parameter_0_0; float**  Result_892_0;
private:

    
std::vector<int> getArgs() override {
    return std::vector<int>({64, 128, 17, 17, 192, 128, 7, 1, 3, 0, 1, 1, 1, 1});
}

    void Convolution_float_float_float_cuda_lib_Convolution_643(cudnnHandle_t cudnn_handle, float* input0, float* input1, float* output0)
{
    cudnnTensorDescriptor_t tensor_desc_0;
    CUDNN_SAFE_CALL(cudnnCreateTensorDescriptor(&tensor_desc_0));
    CUDNN_SAFE_CALL(cudnnSetTensor4dDescriptor(tensor_desc_0, CUDNN_TENSOR_NCHW, CUDNN_DATA_FLOAT, 64, 128, 17, 17));
    cudnnTensorDescriptor_t tensor_desc_1;
    CUDNN_SAFE_CALL(cudnnCreateTensorDescriptor(&tensor_desc_1));
    CUDNN_SAFE_CALL(cudnnSetTensor4dDescriptor(tensor_desc_1, CUDNN_TENSOR_NCHW, CUDNN_DATA_FLOAT, 64, 192, 17, 17));
    cudnnFilterDescriptor_t filter_desc;
    CUDNN_SAFE_CALL(cudnnCreateFilterDescriptor(&filter_desc));
    CUDNN_SAFE_CALL(cudnnSetFilter4dDescriptor(filter_desc, CUDNN_DATA_FLOAT, CUDNN_TENSOR_NCHW, 192, 128, 7, 1));
    cudnnConvolutionDescriptor_t conv_desc;
    CUDNN_SAFE_CALL(cudnnCreateConvolutionDescriptor(&conv_desc));
    CUDNN_SAFE_CALL(cudnnSetConvolution2dDescriptor(conv_desc, 3, 0, 1, 1, 1, 1, CUDNN_CROSS_CORRELATION, CUDNN_DATA_FLOAT));

    static bool selected_algo = true;
    static cudnnConvolutionFwdAlgo_t conv_fwd_algo = CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM;

    if (!selected_algo) {
        int num_algos;
        int max_algos = 0;
        // cudnnGetConvolutionForwardAlgorithm_v7;
        CUDNN_SAFE_CALL(
            cudnnGetConvolutionForwardAlgorithmMaxCount(cudnn_handle, &max_algos));
        std::vector<cudnnConvolutionFwdAlgoPerf_t> results(max_algos);
        CUDNN_SAFE_CALL(cudnnFindConvolutionForwardAlgorithm(cudnn_handle,
                                                tensor_desc_0,
                                                filter_desc,
                                                conv_desc,
                                                tensor_desc_1,
                                                static_cast<int>(results.size()),
                                                &num_algos,
                                                results.data()));
        results.resize(num_algos);
        for (size_t i = 0; i != results.size(); ++i) {
            cudnnConvolutionFwdAlgoPerf_t const& result = results[i];
            if (result.status == CUDNN_STATUS_SUCCESS) {
                conv_fwd_algo = result.algo;
                break;
            }
        }
        selected_algo = true;
    }
    const float alpha = 1.0;
    const float beta = 0.0;
    static void *workspace_ptr_0 = NULL;
    static size_t workspace_size_in_bytes = 0;
    if (!workspace_ptr_0)
    {
        CUDNN_SAFE_CALL(cudnnGetConvolutionForwardWorkspaceSize(cudnn_handle, tensor_desc_0, filter_desc, conv_desc, tensor_desc_1, conv_fwd_algo, &workspace_size_in_bytes));
        CUDA_SAFE_CALL(cudaMalloc(&workspace_ptr_0, workspace_size_in_bytes));
    }
    CUDNN_SAFE_CALL(mycudnnConvolutionForward(cudnn_handle, &alpha, tensor_desc_0, input0,filter_desc, input1, conv_desc, conv_fwd_algo, workspace_ptr_0, workspace_size_in_bytes, &beta, tensor_desc_1, output0));
    CUDNN_SAFE_CALL(cudnnDestroyTensorDescriptor(tensor_desc_0));
    CUDNN_SAFE_CALL(cudnnDestroyTensorDescriptor(tensor_desc_1));
    CUDNN_SAFE_CALL(cudnnDestroyFilterDescriptor(filter_desc));
    CUDNN_SAFE_CALL(cudnnDestroyConvolutionDescriptor(conv_desc));

}

    void executeImpl(cudaStream_t stream) {
        this->Convolution_float_float_float_cuda_lib_Convolution_643(cudnn_handle, input0, input1, output0);
    }
};


class inception3_Concat_float_float_float_float_float_cuda_Concat_658_CallKernel : public Kernel {
public:
    inception3_Concat_float_float_float_float_float_cuda_Concat_658_CallKernel(const dim3 & grids, const dim3 & blocks, unsigned  mem, cudaStream_t  stream, float*  input0, float*  input1, float*  input2, float*  input3, float*  output0, float*  Parameter_0_0, float**  Result_892_0) {
        this->grids = grids, this->blocks = blocks, this->mem = mem, this->stream = stream, this->input0 = input0, this->input1 = input1, this->input2 = input2, this->input3 = input3, this->output0 = output0, this->Parameter_0_0 = Parameter_0_0, this->Result_892_0 = Result_892_0;
        this->kernelName = "inception3_Concat_float_float_float_float_float_cuda_Concat_658_Call";
        this->Id = 0;
        this->mixable = 0;
    }

    void initParams() override {
        // empty implementation
    }

    void loadKernel() override {
        // Empty implementation
    }

        dim3  grids; dim3  blocks; unsigned  mem; cudaStream_t  stream; float*  input0; float*  input1; float*  input2; float*  input3; float*  output0;
    float*  Parameter_0_0; float**  Result_892_0;
private:

    
std::vector<int> getArgs() override {
    return std::vector<int>();
}

     void Concat_float_float_float_float_float_cuda_Concat_658_Call(const dim3 &grids, const dim3 &blocks, unsigned mem, cudaStream_t stream, float* input0, float* input1, float* input2, float* input3, float* output0) {
    inception3_Concat_float_float_float_float_float_cuda_Concat_658<<<grids, blocks, mem, stream>>>(input0, input1, input2, input3, output0);
}

    void executeImpl(cudaStream_t stream) {
        this->Concat_float_float_float_float_float_cuda_Concat_658_Call(grids, blocks, mem, stream, input0, input1, input2, input3, output0);
    }
};


class inception3_Reshape_float_float_cuda_Reshape_663_CallKernel : public Kernel {
public:
    inception3_Reshape_float_float_cuda_Reshape_663_CallKernel(const dim3 & grids, const dim3 & blocks, unsigned  mem, cudaStream_t  stream, float*  input0, float*  output0, float*  Parameter_0_0, float**  Result_892_0) {
        this->grids = grids, this->blocks = blocks, this->mem = mem, this->stream = stream, this->input0 = input0, this->output0 = output0, this->Parameter_0_0 = Parameter_0_0, this->Result_892_0 = Result_892_0;
        this->kernelName = "inception3_Reshape_float_float_cuda_Reshape_663_Call";
        this->Id = 0;
        this->mixable = 0;
    }

    void initParams() override {
        // empty implementation
    }

    void loadKernel() override {
        // Empty implementation
    }

        dim3  grids; dim3  blocks; unsigned  mem; cudaStream_t  stream; float*  input0; float*  output0;
    float*  Parameter_0_0; float**  Result_892_0;
private:

    
std::vector<int> getArgs() override {
    return std::vector<int>();
}

     void Reshape_float_float_cuda_Reshape_663_Call(const dim3 &grids, const dim3 &blocks, unsigned mem, cudaStream_t stream, float* input0, float* output0) {
    inception3_Reshape_float_float_cuda_Reshape_663<<<grids, blocks, mem, stream>>>(input0, output0);
}

    void executeImpl(cudaStream_t stream) {
        this->Reshape_float_float_cuda_Reshape_663_Call(grids, blocks, mem, stream, input0, output0);
    }
};


class inception3_Convolution_float_float_float_cuda_lib_Convolution_664Kernel : public Kernel {
public:
    inception3_Convolution_float_float_float_cuda_lib_Convolution_664Kernel(cudnnHandle_t  cudnn_handle, float*  input0, float*  input1, float*  output0, float*  Parameter_0_0, float**  Result_892_0) {
        this->cudnn_handle = cudnn_handle, this->input0 = input0, this->input1 = input1, this->output0 = output0, this->Parameter_0_0 = Parameter_0_0, this->Result_892_0 = Result_892_0;
        this->kernelName = "inception3_Convolution_float_float_float_cuda_lib_Convolution_664";
        this->Id = 0;
        this->mixable = 2;
    }

    void initParams() override {
        // empty implementation
    }

    void loadKernel() override {
        // Empty implementation
    }

        cudnnHandle_t  cudnn_handle; float*  input0; float*  input1; float*  output0;
    float*  Parameter_0_0; float**  Result_892_0;
private:

    
std::vector<int> getArgs() override {
    return std::vector<int>({64, 768, 17, 17, 160, 768, 1, 1, 0, 0, 1, 1, 1, 1});
}

    void Convolution_float_float_float_cuda_lib_Convolution_664(cudnnHandle_t cudnn_handle, float* input0, float* input1, float* output0)
{
    cudnnTensorDescriptor_t tensor_desc_0;
    CUDNN_SAFE_CALL(cudnnCreateTensorDescriptor(&tensor_desc_0));
    CUDNN_SAFE_CALL(cudnnSetTensor4dDescriptor(tensor_desc_0, CUDNN_TENSOR_NCHW, CUDNN_DATA_FLOAT, 64, 768, 17, 17));
    cudnnTensorDescriptor_t tensor_desc_1;
    CUDNN_SAFE_CALL(cudnnCreateTensorDescriptor(&tensor_desc_1));
    CUDNN_SAFE_CALL(cudnnSetTensor4dDescriptor(tensor_desc_1, CUDNN_TENSOR_NCHW, CUDNN_DATA_FLOAT, 64, 160, 17, 17));
    cudnnFilterDescriptor_t filter_desc;
    CUDNN_SAFE_CALL(cudnnCreateFilterDescriptor(&filter_desc));
    CUDNN_SAFE_CALL(cudnnSetFilter4dDescriptor(filter_desc, CUDNN_DATA_FLOAT, CUDNN_TENSOR_NCHW, 160, 768, 1, 1));
    cudnnConvolutionDescriptor_t conv_desc;
    CUDNN_SAFE_CALL(cudnnCreateConvolutionDescriptor(&conv_desc));
    CUDNN_SAFE_CALL(cudnnSetConvolution2dDescriptor(conv_desc, 0, 0, 1, 1, 1, 1, CUDNN_CROSS_CORRELATION, CUDNN_DATA_FLOAT));

    static bool selected_algo = true;
    static cudnnConvolutionFwdAlgo_t conv_fwd_algo = CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM;

    if (!selected_algo) {
        int num_algos;
        int max_algos = 0;
        // cudnnGetConvolutionForwardAlgorithm_v7;
        CUDNN_SAFE_CALL(
            cudnnGetConvolutionForwardAlgorithmMaxCount(cudnn_handle, &max_algos));
        std::vector<cudnnConvolutionFwdAlgoPerf_t> results(max_algos);
        CUDNN_SAFE_CALL(cudnnFindConvolutionForwardAlgorithm(cudnn_handle,
                                                tensor_desc_0,
                                                filter_desc,
                                                conv_desc,
                                                tensor_desc_1,
                                                static_cast<int>(results.size()),
                                                &num_algos,
                                                results.data()));
        results.resize(num_algos);
        for (size_t i = 0; i != results.size(); ++i) {
            cudnnConvolutionFwdAlgoPerf_t const& result = results[i];
            if (result.status == CUDNN_STATUS_SUCCESS) {
                conv_fwd_algo = result.algo;
                break;
            }
        }
        selected_algo = true;
    }
    const float alpha = 1.0;
    const float beta = 0.0;
    static void *workspace_ptr_0 = NULL;
    static size_t workspace_size_in_bytes = 0;
    if (!workspace_ptr_0)
    {
        CUDNN_SAFE_CALL(cudnnGetConvolutionForwardWorkspaceSize(cudnn_handle, tensor_desc_0, filter_desc, conv_desc, tensor_desc_1, conv_fwd_algo, &workspace_size_in_bytes));
        CUDA_SAFE_CALL(cudaMalloc(&workspace_ptr_0, workspace_size_in_bytes));
    }
    CUDNN_SAFE_CALL(mycudnnConvolutionForward(cudnn_handle, &alpha, tensor_desc_0, input0,filter_desc, input1, conv_desc, conv_fwd_algo, workspace_ptr_0, workspace_size_in_bytes, &beta, tensor_desc_1, output0));
    CUDNN_SAFE_CALL(cudnnDestroyTensorDescriptor(tensor_desc_0));
    CUDNN_SAFE_CALL(cudnnDestroyTensorDescriptor(tensor_desc_1));
    CUDNN_SAFE_CALL(cudnnDestroyFilterDescriptor(filter_desc));
    CUDNN_SAFE_CALL(cudnnDestroyConvolutionDescriptor(conv_desc));

}

    void executeImpl(cudaStream_t stream) {
        this->Convolution_float_float_float_cuda_lib_Convolution_664(cudnn_handle, input0, input1, output0);
    }
};


class inception3_BatchNormInference_float_float_float_float_float_float_cuda_BatchNormInference_668_CallKernel : public Kernel {
public:
    inception3_BatchNormInference_float_float_float_float_float_float_cuda_BatchNormInference_668_CallKernel(const dim3 & grids, const dim3 & blocks, unsigned  mem, cudaStream_t  stream, float*  input0, float*  input1, float*  input2, float*  input3, float*  input4, float*  output0, float*  Parameter_0_0, float**  Result_892_0) {
        this->grids = grids, this->blocks = blocks, this->mem = mem, this->stream = stream, this->input0 = input0, this->input1 = input1, this->input2 = input2, this->input3 = input3, this->input4 = input4, this->output0 = output0, this->Parameter_0_0 = Parameter_0_0, this->Result_892_0 = Result_892_0;
        this->kernelName = "inception3_BatchNormInference_float_float_float_float_float_float_cuda_BatchNormInference_668_Call";
        this->Id = 0;
        this->mixable = 0;
    }

    void initParams() override {
        // empty implementation
    }

    void loadKernel() override {
        // Empty implementation
    }

        dim3  grids; dim3  blocks; unsigned  mem; cudaStream_t  stream; float*  input0; float*  input1; float*  input2; float*  input3; float*  input4; float*  output0;
    float*  Parameter_0_0; float**  Result_892_0;
private:

    
std::vector<int> getArgs() override {
    return std::vector<int>();
}

     void BatchNormInference_float_float_float_float_float_float_cuda_BatchNormInference_668_Call(const dim3 &grids, const dim3 &blocks, unsigned mem, cudaStream_t stream, float* input0, float* input1, float* input2, float* input3, float* input4, float* output0) {
    inception3_BatchNormInference_float_float_float_float_float_float_cuda_BatchNormInference_668<<<grids, blocks, mem, stream>>>(input0, input1, input2, input3, input4, output0);
}

    void executeImpl(cudaStream_t stream) {
        this->BatchNormInference_float_float_float_float_float_float_cuda_BatchNormInference_668_Call(grids, blocks, mem, stream, input0, input1, input2, input3, input4, output0);
    }
};


class inception3_Reshape_float_float_cuda_Reshape_677_CallKernel : public Kernel {
public:
    inception3_Reshape_float_float_cuda_Reshape_677_CallKernel(const dim3 & grids, const dim3 & blocks, unsigned  mem, cudaStream_t  stream, float*  input0, float*  output0, float*  Parameter_0_0, float**  Result_892_0) {
        this->grids = grids, this->blocks = blocks, this->mem = mem, this->stream = stream, this->input0 = input0, this->output0 = output0, this->Parameter_0_0 = Parameter_0_0, this->Result_892_0 = Result_892_0;
        this->kernelName = "inception3_Reshape_float_float_cuda_Reshape_677_Call";
        this->Id = 0;
        this->mixable = 0;
    }

    void initParams() override {
        // empty implementation
    }

    void loadKernel() override {
        // Empty implementation
    }

        dim3  grids; dim3  blocks; unsigned  mem; cudaStream_t  stream; float*  input0; float*  output0;
    float*  Parameter_0_0; float**  Result_892_0;
private:

    
std::vector<int> getArgs() override {
    return std::vector<int>();
}

     void Reshape_float_float_cuda_Reshape_677_Call(const dim3 &grids, const dim3 &blocks, unsigned mem, cudaStream_t stream, float* input0, float* output0) {
    inception3_Reshape_float_float_cuda_Reshape_677<<<grids, blocks, mem, stream>>>(input0, output0);
}

    void executeImpl(cudaStream_t stream) {
        this->Reshape_float_float_cuda_Reshape_677_Call(grids, blocks, mem, stream, input0, output0);
    }
};


class inception3_Convolution_float_float_float_cuda_lib_Convolution_678Kernel : public Kernel {
public:
    inception3_Convolution_float_float_float_cuda_lib_Convolution_678Kernel(cudnnHandle_t  cudnn_handle, float*  input0, float*  input1, float*  output0, float*  Parameter_0_0, float**  Result_892_0) {
        this->cudnn_handle = cudnn_handle, this->input0 = input0, this->input1 = input1, this->output0 = output0, this->Parameter_0_0 = Parameter_0_0, this->Result_892_0 = Result_892_0;
        this->kernelName = "inception3_Convolution_float_float_float_cuda_lib_Convolution_678";
        this->Id = 0;
        this->mixable = 2;
    }

    void initParams() override {
        // empty implementation
    }

    void loadKernel() override {
        // Empty implementation
    }

        cudnnHandle_t  cudnn_handle; float*  input0; float*  input1; float*  output0;
    float*  Parameter_0_0; float**  Result_892_0;
private:

    
std::vector<int> getArgs() override {
    return std::vector<int>({64, 160, 17, 17, 160, 160, 7, 1, 3, 0, 1, 1, 1, 1});
}

    void Convolution_float_float_float_cuda_lib_Convolution_678(cudnnHandle_t cudnn_handle, float* input0, float* input1, float* output0)
{
    cudnnTensorDescriptor_t tensor_desc_0;
    CUDNN_SAFE_CALL(cudnnCreateTensorDescriptor(&tensor_desc_0));
    CUDNN_SAFE_CALL(cudnnSetTensor4dDescriptor(tensor_desc_0, CUDNN_TENSOR_NCHW, CUDNN_DATA_FLOAT, 64, 160, 17, 17));
    cudnnTensorDescriptor_t tensor_desc_1;
    CUDNN_SAFE_CALL(cudnnCreateTensorDescriptor(&tensor_desc_1));
    CUDNN_SAFE_CALL(cudnnSetTensor4dDescriptor(tensor_desc_1, CUDNN_TENSOR_NCHW, CUDNN_DATA_FLOAT, 64, 160, 17, 17));
    cudnnFilterDescriptor_t filter_desc;
    CUDNN_SAFE_CALL(cudnnCreateFilterDescriptor(&filter_desc));
    CUDNN_SAFE_CALL(cudnnSetFilter4dDescriptor(filter_desc, CUDNN_DATA_FLOAT, CUDNN_TENSOR_NCHW, 160, 160, 7, 1));
    cudnnConvolutionDescriptor_t conv_desc;
    CUDNN_SAFE_CALL(cudnnCreateConvolutionDescriptor(&conv_desc));
    CUDNN_SAFE_CALL(cudnnSetConvolution2dDescriptor(conv_desc, 3, 0, 1, 1, 1, 1, CUDNN_CROSS_CORRELATION, CUDNN_DATA_FLOAT));

    static bool selected_algo = true;
    static cudnnConvolutionFwdAlgo_t conv_fwd_algo = CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM;

    if (!selected_algo) {
        int num_algos;
        int max_algos = 0;
        // cudnnGetConvolutionForwardAlgorithm_v7;
        CUDNN_SAFE_CALL(
            cudnnGetConvolutionForwardAlgorithmMaxCount(cudnn_handle, &max_algos));
        std::vector<cudnnConvolutionFwdAlgoPerf_t> results(max_algos);
        CUDNN_SAFE_CALL(cudnnFindConvolutionForwardAlgorithm(cudnn_handle,
                                                tensor_desc_0,
                                                filter_desc,
                                                conv_desc,
                                                tensor_desc_1,
                                                static_cast<int>(results.size()),
                                                &num_algos,
                                                results.data()));
        results.resize(num_algos);
        for (size_t i = 0; i != results.size(); ++i) {
            cudnnConvolutionFwdAlgoPerf_t const& result = results[i];
            if (result.status == CUDNN_STATUS_SUCCESS) {
                conv_fwd_algo = result.algo;
                break;
            }
        }
        selected_algo = true;
    }
    const float alpha = 1.0;
    const float beta = 0.0;
    static void *workspace_ptr_0 = NULL;
    static size_t workspace_size_in_bytes = 0;
    if (!workspace_ptr_0)
    {
        CUDNN_SAFE_CALL(cudnnGetConvolutionForwardWorkspaceSize(cudnn_handle, tensor_desc_0, filter_desc, conv_desc, tensor_desc_1, conv_fwd_algo, &workspace_size_in_bytes));
        CUDA_SAFE_CALL(cudaMalloc(&workspace_ptr_0, workspace_size_in_bytes));
    }
    CUDNN_SAFE_CALL(mycudnnConvolutionForward(cudnn_handle, &alpha, tensor_desc_0, input0,filter_desc, input1, conv_desc, conv_fwd_algo, workspace_ptr_0, workspace_size_in_bytes, &beta, tensor_desc_1, output0));
    CUDNN_SAFE_CALL(cudnnDestroyTensorDescriptor(tensor_desc_0));
    CUDNN_SAFE_CALL(cudnnDestroyTensorDescriptor(tensor_desc_1));
    CUDNN_SAFE_CALL(cudnnDestroyFilterDescriptor(filter_desc));
    CUDNN_SAFE_CALL(cudnnDestroyConvolutionDescriptor(conv_desc));

}

    void executeImpl(cudaStream_t stream) {
        this->Convolution_float_float_float_cuda_lib_Convolution_678(cudnn_handle, input0, input1, output0);
    }
};


class inception3_Convolution_float_float_float_cuda_lib_Convolution_687Kernel : public Kernel {
public:
    inception3_Convolution_float_float_float_cuda_lib_Convolution_687Kernel(cudnnHandle_t  cudnn_handle, float*  input0, float*  input1, float*  output0, float*  Parameter_0_0, float**  Result_892_0) {
        this->cudnn_handle = cudnn_handle, this->input0 = input0, this->input1 = input1, this->output0 = output0, this->Parameter_0_0 = Parameter_0_0, this->Result_892_0 = Result_892_0;
        this->kernelName = "inception3_Convolution_float_float_float_cuda_lib_Convolution_687";
        this->Id = 0;
        this->mixable = 2;
    }

    void initParams() override {
        // empty implementation
    }

    void loadKernel() override {
        // Empty implementation
    }

        cudnnHandle_t  cudnn_handle; float*  input0; float*  input1; float*  output0;
    float*  Parameter_0_0; float**  Result_892_0;
private:

    
std::vector<int> getArgs() override {
    return std::vector<int>({64, 160, 17, 17, 160, 160, 1, 7, 0, 3, 1, 1, 1, 1});
}

    void Convolution_float_float_float_cuda_lib_Convolution_687(cudnnHandle_t cudnn_handle, float* input0, float* input1, float* output0)
{
    cudnnTensorDescriptor_t tensor_desc_0;
    CUDNN_SAFE_CALL(cudnnCreateTensorDescriptor(&tensor_desc_0));
    CUDNN_SAFE_CALL(cudnnSetTensor4dDescriptor(tensor_desc_0, CUDNN_TENSOR_NCHW, CUDNN_DATA_FLOAT, 64, 160, 17, 17));
    cudnnTensorDescriptor_t tensor_desc_1;
    CUDNN_SAFE_CALL(cudnnCreateTensorDescriptor(&tensor_desc_1));
    CUDNN_SAFE_CALL(cudnnSetTensor4dDescriptor(tensor_desc_1, CUDNN_TENSOR_NCHW, CUDNN_DATA_FLOAT, 64, 160, 17, 17));
    cudnnFilterDescriptor_t filter_desc;
    CUDNN_SAFE_CALL(cudnnCreateFilterDescriptor(&filter_desc));
    CUDNN_SAFE_CALL(cudnnSetFilter4dDescriptor(filter_desc, CUDNN_DATA_FLOAT, CUDNN_TENSOR_NCHW, 160, 160, 1, 7));
    cudnnConvolutionDescriptor_t conv_desc;
    CUDNN_SAFE_CALL(cudnnCreateConvolutionDescriptor(&conv_desc));
    CUDNN_SAFE_CALL(cudnnSetConvolution2dDescriptor(conv_desc, 0, 3, 1, 1, 1, 1, CUDNN_CROSS_CORRELATION, CUDNN_DATA_FLOAT));

    static bool selected_algo = true;
    static cudnnConvolutionFwdAlgo_t conv_fwd_algo = CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM;

    if (!selected_algo) {
        int num_algos;
        int max_algos = 0;
        // cudnnGetConvolutionForwardAlgorithm_v7;
        CUDNN_SAFE_CALL(
            cudnnGetConvolutionForwardAlgorithmMaxCount(cudnn_handle, &max_algos));
        std::vector<cudnnConvolutionFwdAlgoPerf_t> results(max_algos);
        CUDNN_SAFE_CALL(cudnnFindConvolutionForwardAlgorithm(cudnn_handle,
                                                tensor_desc_0,
                                                filter_desc,
                                                conv_desc,
                                                tensor_desc_1,
                                                static_cast<int>(results.size()),
                                                &num_algos,
                                                results.data()));
        results.resize(num_algos);
        for (size_t i = 0; i != results.size(); ++i) {
            cudnnConvolutionFwdAlgoPerf_t const& result = results[i];
            if (result.status == CUDNN_STATUS_SUCCESS) {
                conv_fwd_algo = result.algo;
                break;
            }
        }
        selected_algo = true;
    }
    const float alpha = 1.0;
    const float beta = 0.0;
    static void *workspace_ptr_0 = NULL;
    static size_t workspace_size_in_bytes = 0;
    if (!workspace_ptr_0)
    {
        CUDNN_SAFE_CALL(cudnnGetConvolutionForwardWorkspaceSize(cudnn_handle, tensor_desc_0, filter_desc, conv_desc, tensor_desc_1, conv_fwd_algo, &workspace_size_in_bytes));
        CUDA_SAFE_CALL(cudaMalloc(&workspace_ptr_0, workspace_size_in_bytes));
    }
    CUDNN_SAFE_CALL(mycudnnConvolutionForward(cudnn_handle, &alpha, tensor_desc_0, input0,filter_desc, input1, conv_desc, conv_fwd_algo, workspace_ptr_0, workspace_size_in_bytes, &beta, tensor_desc_1, output0));
    CUDNN_SAFE_CALL(cudnnDestroyTensorDescriptor(tensor_desc_0));
    CUDNN_SAFE_CALL(cudnnDestroyTensorDescriptor(tensor_desc_1));
    CUDNN_SAFE_CALL(cudnnDestroyFilterDescriptor(filter_desc));
    CUDNN_SAFE_CALL(cudnnDestroyConvolutionDescriptor(conv_desc));

}

    void executeImpl(cudaStream_t stream) {
        this->Convolution_float_float_float_cuda_lib_Convolution_687(cudnn_handle, input0, input1, output0);
    }
};


class inception3_Reshape_float_float_cuda_Reshape_696_CallKernel : public Kernel {
public:
    inception3_Reshape_float_float_cuda_Reshape_696_CallKernel(const dim3 & grids, const dim3 & blocks, unsigned  mem, cudaStream_t  stream, float*  input0, float*  output0, float*  Parameter_0_0, float**  Result_892_0) {
        this->grids = grids, this->blocks = blocks, this->mem = mem, this->stream = stream, this->input0 = input0, this->output0 = output0, this->Parameter_0_0 = Parameter_0_0, this->Result_892_0 = Result_892_0;
        this->kernelName = "inception3_Reshape_float_float_cuda_Reshape_696_Call";
        this->Id = 0;
        this->mixable = 0;
    }

    void initParams() override {
        // empty implementation
    }

    void loadKernel() override {
        // Empty implementation
    }

        dim3  grids; dim3  blocks; unsigned  mem; cudaStream_t  stream; float*  input0; float*  output0;
    float*  Parameter_0_0; float**  Result_892_0;
private:

    
std::vector<int> getArgs() override {
    return std::vector<int>();
}

     void Reshape_float_float_cuda_Reshape_696_Call(const dim3 &grids, const dim3 &blocks, unsigned mem, cudaStream_t stream, float* input0, float* output0) {
    inception3_Reshape_float_float_cuda_Reshape_696<<<grids, blocks, mem, stream>>>(input0, output0);
}

    void executeImpl(cudaStream_t stream) {
        this->Reshape_float_float_cuda_Reshape_696_Call(grids, blocks, mem, stream, input0, output0);
    }
};


class inception3_Convolution_float_float_float_cuda_lib_Convolution_697Kernel : public Kernel {
public:
    inception3_Convolution_float_float_float_cuda_lib_Convolution_697Kernel(cudnnHandle_t  cudnn_handle, float*  input0, float*  input1, float*  output0, float*  Parameter_0_0, float**  Result_892_0) {
        this->cudnn_handle = cudnn_handle, this->input0 = input0, this->input1 = input1, this->output0 = output0, this->Parameter_0_0 = Parameter_0_0, this->Result_892_0 = Result_892_0;
        this->kernelName = "inception3_Convolution_float_float_float_cuda_lib_Convolution_697";
        this->Id = 0;
        this->mixable = 2;
    }

    void initParams() override {
        // empty implementation
    }

    void loadKernel() override {
        // Empty implementation
    }

        cudnnHandle_t  cudnn_handle; float*  input0; float*  input1; float*  output0;
    float*  Parameter_0_0; float**  Result_892_0;
private:

    
std::vector<int> getArgs() override {
    return std::vector<int>({64, 160, 17, 17, 192, 160, 1, 7, 0, 3, 1, 1, 1, 1});
}

    void Convolution_float_float_float_cuda_lib_Convolution_697(cudnnHandle_t cudnn_handle, float* input0, float* input1, float* output0)
{
    cudnnTensorDescriptor_t tensor_desc_0;
    CUDNN_SAFE_CALL(cudnnCreateTensorDescriptor(&tensor_desc_0));
    CUDNN_SAFE_CALL(cudnnSetTensor4dDescriptor(tensor_desc_0, CUDNN_TENSOR_NCHW, CUDNN_DATA_FLOAT, 64, 160, 17, 17));
    cudnnTensorDescriptor_t tensor_desc_1;
    CUDNN_SAFE_CALL(cudnnCreateTensorDescriptor(&tensor_desc_1));
    CUDNN_SAFE_CALL(cudnnSetTensor4dDescriptor(tensor_desc_1, CUDNN_TENSOR_NCHW, CUDNN_DATA_FLOAT, 64, 192, 17, 17));
    cudnnFilterDescriptor_t filter_desc;
    CUDNN_SAFE_CALL(cudnnCreateFilterDescriptor(&filter_desc));
    CUDNN_SAFE_CALL(cudnnSetFilter4dDescriptor(filter_desc, CUDNN_DATA_FLOAT, CUDNN_TENSOR_NCHW, 192, 160, 1, 7));
    cudnnConvolutionDescriptor_t conv_desc;
    CUDNN_SAFE_CALL(cudnnCreateConvolutionDescriptor(&conv_desc));
    CUDNN_SAFE_CALL(cudnnSetConvolution2dDescriptor(conv_desc, 0, 3, 1, 1, 1, 1, CUDNN_CROSS_CORRELATION, CUDNN_DATA_FLOAT));

    static bool selected_algo = true;
    static cudnnConvolutionFwdAlgo_t conv_fwd_algo = CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM;

    if (!selected_algo) {
        int num_algos;
        int max_algos = 0;
        // cudnnGetConvolutionForwardAlgorithm_v7;
        CUDNN_SAFE_CALL(
            cudnnGetConvolutionForwardAlgorithmMaxCount(cudnn_handle, &max_algos));
        std::vector<cudnnConvolutionFwdAlgoPerf_t> results(max_algos);
        CUDNN_SAFE_CALL(cudnnFindConvolutionForwardAlgorithm(cudnn_handle,
                                                tensor_desc_0,
                                                filter_desc,
                                                conv_desc,
                                                tensor_desc_1,
                                                static_cast<int>(results.size()),
                                                &num_algos,
                                                results.data()));
        results.resize(num_algos);
        for (size_t i = 0; i != results.size(); ++i) {
            cudnnConvolutionFwdAlgoPerf_t const& result = results[i];
            if (result.status == CUDNN_STATUS_SUCCESS) {
                conv_fwd_algo = result.algo;
                break;
            }
        }
        selected_algo = true;
    }
    const float alpha = 1.0;
    const float beta = 0.0;
    static void *workspace_ptr_0 = NULL;
    static size_t workspace_size_in_bytes = 0;
    if (!workspace_ptr_0)
    {
        CUDNN_SAFE_CALL(cudnnGetConvolutionForwardWorkspaceSize(cudnn_handle, tensor_desc_0, filter_desc, conv_desc, tensor_desc_1, conv_fwd_algo, &workspace_size_in_bytes));
        CUDA_SAFE_CALL(cudaMalloc(&workspace_ptr_0, workspace_size_in_bytes));
    }
    CUDNN_SAFE_CALL(mycudnnConvolutionForward(cudnn_handle, &alpha, tensor_desc_0, input0,filter_desc, input1, conv_desc, conv_fwd_algo, workspace_ptr_0, workspace_size_in_bytes, &beta, tensor_desc_1, output0));
    CUDNN_SAFE_CALL(cudnnDestroyTensorDescriptor(tensor_desc_0));
    CUDNN_SAFE_CALL(cudnnDestroyTensorDescriptor(tensor_desc_1));
    CUDNN_SAFE_CALL(cudnnDestroyFilterDescriptor(filter_desc));
    CUDNN_SAFE_CALL(cudnnDestroyConvolutionDescriptor(conv_desc));

}

    void executeImpl(cudaStream_t stream) {
        this->Convolution_float_float_float_cuda_lib_Convolution_697(cudnn_handle, input0, input1, output0);
    }
};


class inception3_Convolution_float_float_float_cuda_lib_Convolution_685Kernel : public Kernel {
public:
    inception3_Convolution_float_float_float_cuda_lib_Convolution_685Kernel(cudnnHandle_t  cudnn_handle, float*  input0, float*  input1, float*  output0, float*  Parameter_0_0, float**  Result_892_0) {
        this->cudnn_handle = cudnn_handle, this->input0 = input0, this->input1 = input1, this->output0 = output0, this->Parameter_0_0 = Parameter_0_0, this->Result_892_0 = Result_892_0;
        this->kernelName = "inception3_Convolution_float_float_float_cuda_lib_Convolution_685";
        this->Id = 0;
        this->mixable = 2;
    }

    void initParams() override {
        // empty implementation
    }

    void loadKernel() override {
        // Empty implementation
    }

        cudnnHandle_t  cudnn_handle; float*  input0; float*  input1; float*  output0;
    float*  Parameter_0_0; float**  Result_892_0;
private:

    
std::vector<int> getArgs() override {
    return std::vector<int>({64, 160, 17, 17, 192, 160, 7, 1, 3, 0, 1, 1, 1, 1});
}

    void Convolution_float_float_float_cuda_lib_Convolution_685(cudnnHandle_t cudnn_handle, float* input0, float* input1, float* output0)
{
    cudnnTensorDescriptor_t tensor_desc_0;
    CUDNN_SAFE_CALL(cudnnCreateTensorDescriptor(&tensor_desc_0));
    CUDNN_SAFE_CALL(cudnnSetTensor4dDescriptor(tensor_desc_0, CUDNN_TENSOR_NCHW, CUDNN_DATA_FLOAT, 64, 160, 17, 17));
    cudnnTensorDescriptor_t tensor_desc_1;
    CUDNN_SAFE_CALL(cudnnCreateTensorDescriptor(&tensor_desc_1));
    CUDNN_SAFE_CALL(cudnnSetTensor4dDescriptor(tensor_desc_1, CUDNN_TENSOR_NCHW, CUDNN_DATA_FLOAT, 64, 192, 17, 17));
    cudnnFilterDescriptor_t filter_desc;
    CUDNN_SAFE_CALL(cudnnCreateFilterDescriptor(&filter_desc));
    CUDNN_SAFE_CALL(cudnnSetFilter4dDescriptor(filter_desc, CUDNN_DATA_FLOAT, CUDNN_TENSOR_NCHW, 192, 160, 7, 1));
    cudnnConvolutionDescriptor_t conv_desc;
    CUDNN_SAFE_CALL(cudnnCreateConvolutionDescriptor(&conv_desc));
    CUDNN_SAFE_CALL(cudnnSetConvolution2dDescriptor(conv_desc, 3, 0, 1, 1, 1, 1, CUDNN_CROSS_CORRELATION, CUDNN_DATA_FLOAT));

    static bool selected_algo = true;
    static cudnnConvolutionFwdAlgo_t conv_fwd_algo = CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM;

    if (!selected_algo) {
        int num_algos;
        int max_algos = 0;
        // cudnnGetConvolutionForwardAlgorithm_v7;
        CUDNN_SAFE_CALL(
            cudnnGetConvolutionForwardAlgorithmMaxCount(cudnn_handle, &max_algos));
        std::vector<cudnnConvolutionFwdAlgoPerf_t> results(max_algos);
        CUDNN_SAFE_CALL(cudnnFindConvolutionForwardAlgorithm(cudnn_handle,
                                                tensor_desc_0,
                                                filter_desc,
                                                conv_desc,
                                                tensor_desc_1,
                                                static_cast<int>(results.size()),
                                                &num_algos,
                                                results.data()));
        results.resize(num_algos);
        for (size_t i = 0; i != results.size(); ++i) {
            cudnnConvolutionFwdAlgoPerf_t const& result = results[i];
            if (result.status == CUDNN_STATUS_SUCCESS) {
                conv_fwd_algo = result.algo;
                break;
            }
        }
        selected_algo = true;
    }
    const float alpha = 1.0;
    const float beta = 0.0;
    static void *workspace_ptr_0 = NULL;
    static size_t workspace_size_in_bytes = 0;
    if (!workspace_ptr_0)
    {
        CUDNN_SAFE_CALL(cudnnGetConvolutionForwardWorkspaceSize(cudnn_handle, tensor_desc_0, filter_desc, conv_desc, tensor_desc_1, conv_fwd_algo, &workspace_size_in_bytes));
        CUDA_SAFE_CALL(cudaMalloc(&workspace_ptr_0, workspace_size_in_bytes));
    }
    CUDNN_SAFE_CALL(mycudnnConvolutionForward(cudnn_handle, &alpha, tensor_desc_0, input0,filter_desc, input1, conv_desc, conv_fwd_algo, workspace_ptr_0, workspace_size_in_bytes, &beta, tensor_desc_1, output0));
    CUDNN_SAFE_CALL(cudnnDestroyTensorDescriptor(tensor_desc_0));
    CUDNN_SAFE_CALL(cudnnDestroyTensorDescriptor(tensor_desc_1));
    CUDNN_SAFE_CALL(cudnnDestroyFilterDescriptor(filter_desc));
    CUDNN_SAFE_CALL(cudnnDestroyConvolutionDescriptor(conv_desc));

}

    void executeImpl(cudaStream_t stream) {
        this->Convolution_float_float_float_cuda_lib_Convolution_685(cudnn_handle, input0, input1, output0);
    }
};


class inception3_Reshape_float_float_cuda_Reshape_761_CallKernel : public Kernel {
public:
    inception3_Reshape_float_float_cuda_Reshape_761_CallKernel(const dim3 & grids, const dim3 & blocks, unsigned  mem, cudaStream_t  stream, float*  input0, float*  output0, float*  Parameter_0_0, float**  Result_892_0) {
        this->grids = grids, this->blocks = blocks, this->mem = mem, this->stream = stream, this->input0 = input0, this->output0 = output0, this->Parameter_0_0 = Parameter_0_0, this->Result_892_0 = Result_892_0;
        this->kernelName = "inception3_Reshape_float_float_cuda_Reshape_761_Call";
        this->Id = 0;
        this->mixable = 0;
    }

    void initParams() override {
        // empty implementation
    }

    void loadKernel() override {
        // Empty implementation
    }

        dim3  grids; dim3  blocks; unsigned  mem; cudaStream_t  stream; float*  input0; float*  output0;
    float*  Parameter_0_0; float**  Result_892_0;
private:

    
std::vector<int> getArgs() override {
    return std::vector<int>();
}

     void Reshape_float_float_cuda_Reshape_761_Call(const dim3 &grids, const dim3 &blocks, unsigned mem, cudaStream_t stream, float* input0, float* output0) {
    inception3_Reshape_float_float_cuda_Reshape_761<<<grids, blocks, mem, stream>>>(input0, output0);
}

    void executeImpl(cudaStream_t stream) {
        this->Reshape_float_float_cuda_Reshape_761_Call(grids, blocks, mem, stream, input0, output0);
    }
};


class inception3_Convolution_float_float_float_cuda_lib_Convolution_762Kernel : public Kernel {
public:
    inception3_Convolution_float_float_float_cuda_lib_Convolution_762Kernel(cudnnHandle_t  cudnn_handle, float*  input0, float*  input1, float*  output0, float*  Parameter_0_0, float**  Result_892_0) {
        this->cudnn_handle = cudnn_handle, this->input0 = input0, this->input1 = input1, this->output0 = output0, this->Parameter_0_0 = Parameter_0_0, this->Result_892_0 = Result_892_0;
        this->kernelName = "inception3_Convolution_float_float_float_cuda_lib_Convolution_762";
        this->Id = 0;
        this->mixable = 2;
    }

    void initParams() override {
        // empty implementation
    }

    void loadKernel() override {
        // Empty implementation
    }

        cudnnHandle_t  cudnn_handle; float*  input0; float*  input1; float*  output0;
    float*  Parameter_0_0; float**  Result_892_0;
private:

    
std::vector<int> getArgs() override {
    return std::vector<int>({64, 192, 17, 17, 192, 192, 7, 1, 3, 0, 1, 1, 1, 1});
}

    void Convolution_float_float_float_cuda_lib_Convolution_762(cudnnHandle_t cudnn_handle, float* input0, float* input1, float* output0)
{
    cudnnTensorDescriptor_t tensor_desc_0;
    CUDNN_SAFE_CALL(cudnnCreateTensorDescriptor(&tensor_desc_0));
    CUDNN_SAFE_CALL(cudnnSetTensor4dDescriptor(tensor_desc_0, CUDNN_TENSOR_NCHW, CUDNN_DATA_FLOAT, 64, 192, 17, 17));
    cudnnTensorDescriptor_t tensor_desc_1;
    CUDNN_SAFE_CALL(cudnnCreateTensorDescriptor(&tensor_desc_1));
    CUDNN_SAFE_CALL(cudnnSetTensor4dDescriptor(tensor_desc_1, CUDNN_TENSOR_NCHW, CUDNN_DATA_FLOAT, 64, 192, 17, 17));
    cudnnFilterDescriptor_t filter_desc;
    CUDNN_SAFE_CALL(cudnnCreateFilterDescriptor(&filter_desc));
    CUDNN_SAFE_CALL(cudnnSetFilter4dDescriptor(filter_desc, CUDNN_DATA_FLOAT, CUDNN_TENSOR_NCHW, 192, 192, 7, 1));
    cudnnConvolutionDescriptor_t conv_desc;
    CUDNN_SAFE_CALL(cudnnCreateConvolutionDescriptor(&conv_desc));
    CUDNN_SAFE_CALL(cudnnSetConvolution2dDescriptor(conv_desc, 3, 0, 1, 1, 1, 1, CUDNN_CROSS_CORRELATION, CUDNN_DATA_FLOAT));

    static bool selected_algo = true;
    static cudnnConvolutionFwdAlgo_t conv_fwd_algo = CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM;

    if (!selected_algo) {
        int num_algos;
        int max_algos = 0;
        // cudnnGetConvolutionForwardAlgorithm_v7;
        CUDNN_SAFE_CALL(
            cudnnGetConvolutionForwardAlgorithmMaxCount(cudnn_handle, &max_algos));
        std::vector<cudnnConvolutionFwdAlgoPerf_t> results(max_algos);
        CUDNN_SAFE_CALL(cudnnFindConvolutionForwardAlgorithm(cudnn_handle,
                                                tensor_desc_0,
                                                filter_desc,
                                                conv_desc,
                                                tensor_desc_1,
                                                static_cast<int>(results.size()),
                                                &num_algos,
                                                results.data()));
        results.resize(num_algos);
        for (size_t i = 0; i != results.size(); ++i) {
            cudnnConvolutionFwdAlgoPerf_t const& result = results[i];
            if (result.status == CUDNN_STATUS_SUCCESS) {
                conv_fwd_algo = result.algo;
                break;
            }
        }
        selected_algo = true;
    }
    const float alpha = 1.0;
    const float beta = 0.0;
    static void *workspace_ptr_0 = NULL;
    static size_t workspace_size_in_bytes = 0;
    if (!workspace_ptr_0)
    {
        CUDNN_SAFE_CALL(cudnnGetConvolutionForwardWorkspaceSize(cudnn_handle, tensor_desc_0, filter_desc, conv_desc, tensor_desc_1, conv_fwd_algo, &workspace_size_in_bytes));
        CUDA_SAFE_CALL(cudaMalloc(&workspace_ptr_0, workspace_size_in_bytes));
    }
    CUDNN_SAFE_CALL(mycudnnConvolutionForward(cudnn_handle, &alpha, tensor_desc_0, input0,filter_desc, input1, conv_desc, conv_fwd_algo, workspace_ptr_0, workspace_size_in_bytes, &beta, tensor_desc_1, output0));
    CUDNN_SAFE_CALL(cudnnDestroyTensorDescriptor(tensor_desc_0));
    CUDNN_SAFE_CALL(cudnnDestroyTensorDescriptor(tensor_desc_1));
    CUDNN_SAFE_CALL(cudnnDestroyFilterDescriptor(filter_desc));
    CUDNN_SAFE_CALL(cudnnDestroyConvolutionDescriptor(conv_desc));

}

    void executeImpl(cudaStream_t stream) {
        this->Convolution_float_float_float_cuda_lib_Convolution_762(cudnn_handle, input0, input1, output0);
    }
};


class inception3_Convolution_float_float_float_cuda_lib_Convolution_771Kernel : public Kernel {
public:
    inception3_Convolution_float_float_float_cuda_lib_Convolution_771Kernel(cudnnHandle_t  cudnn_handle, float*  input0, float*  input1, float*  output0, float*  Parameter_0_0, float**  Result_892_0) {
        this->cudnn_handle = cudnn_handle, this->input0 = input0, this->input1 = input1, this->output0 = output0, this->Parameter_0_0 = Parameter_0_0, this->Result_892_0 = Result_892_0;
        this->kernelName = "inception3_Convolution_float_float_float_cuda_lib_Convolution_771";
        this->Id = 0;
        this->mixable = 2;
    }

    void initParams() override {
        // empty implementation
    }

    void loadKernel() override {
        // Empty implementation
    }

        cudnnHandle_t  cudnn_handle; float*  input0; float*  input1; float*  output0;
    float*  Parameter_0_0; float**  Result_892_0;
private:

    
std::vector<int> getArgs() override {
    return std::vector<int>({64, 192, 17, 17, 192, 192, 1, 7, 0, 3, 1, 1, 1, 1});
}

    void Convolution_float_float_float_cuda_lib_Convolution_771(cudnnHandle_t cudnn_handle, float* input0, float* input1, float* output0)
{
    cudnnTensorDescriptor_t tensor_desc_0;
    CUDNN_SAFE_CALL(cudnnCreateTensorDescriptor(&tensor_desc_0));
    CUDNN_SAFE_CALL(cudnnSetTensor4dDescriptor(tensor_desc_0, CUDNN_TENSOR_NCHW, CUDNN_DATA_FLOAT, 64, 192, 17, 17));
    cudnnTensorDescriptor_t tensor_desc_1;
    CUDNN_SAFE_CALL(cudnnCreateTensorDescriptor(&tensor_desc_1));
    CUDNN_SAFE_CALL(cudnnSetTensor4dDescriptor(tensor_desc_1, CUDNN_TENSOR_NCHW, CUDNN_DATA_FLOAT, 64, 192, 17, 17));
    cudnnFilterDescriptor_t filter_desc;
    CUDNN_SAFE_CALL(cudnnCreateFilterDescriptor(&filter_desc));
    CUDNN_SAFE_CALL(cudnnSetFilter4dDescriptor(filter_desc, CUDNN_DATA_FLOAT, CUDNN_TENSOR_NCHW, 192, 192, 1, 7));
    cudnnConvolutionDescriptor_t conv_desc;
    CUDNN_SAFE_CALL(cudnnCreateConvolutionDescriptor(&conv_desc));
    CUDNN_SAFE_CALL(cudnnSetConvolution2dDescriptor(conv_desc, 0, 3, 1, 1, 1, 1, CUDNN_CROSS_CORRELATION, CUDNN_DATA_FLOAT));

    static bool selected_algo = true;
    static cudnnConvolutionFwdAlgo_t conv_fwd_algo = CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM;

    if (!selected_algo) {
        int num_algos;
        int max_algos = 0;
        // cudnnGetConvolutionForwardAlgorithm_v7;
        CUDNN_SAFE_CALL(
            cudnnGetConvolutionForwardAlgorithmMaxCount(cudnn_handle, &max_algos));
        std::vector<cudnnConvolutionFwdAlgoPerf_t> results(max_algos);
        CUDNN_SAFE_CALL(cudnnFindConvolutionForwardAlgorithm(cudnn_handle,
                                                tensor_desc_0,
                                                filter_desc,
                                                conv_desc,
                                                tensor_desc_1,
                                                static_cast<int>(results.size()),
                                                &num_algos,
                                                results.data()));
        results.resize(num_algos);
        for (size_t i = 0; i != results.size(); ++i) {
            cudnnConvolutionFwdAlgoPerf_t const& result = results[i];
            if (result.status == CUDNN_STATUS_SUCCESS) {
                conv_fwd_algo = result.algo;
                break;
            }
        }
        selected_algo = true;
    }
    const float alpha = 1.0;
    const float beta = 0.0;
    static void *workspace_ptr_0 = NULL;
    static size_t workspace_size_in_bytes = 0;
    if (!workspace_ptr_0)
    {
        CUDNN_SAFE_CALL(cudnnGetConvolutionForwardWorkspaceSize(cudnn_handle, tensor_desc_0, filter_desc, conv_desc, tensor_desc_1, conv_fwd_algo, &workspace_size_in_bytes));
        CUDA_SAFE_CALL(cudaMalloc(&workspace_ptr_0, workspace_size_in_bytes));
    }
    CUDNN_SAFE_CALL(mycudnnConvolutionForward(cudnn_handle, &alpha, tensor_desc_0, input0,filter_desc, input1, conv_desc, conv_fwd_algo, workspace_ptr_0, workspace_size_in_bytes, &beta, tensor_desc_1, output0));
    CUDNN_SAFE_CALL(cudnnDestroyTensorDescriptor(tensor_desc_0));
    CUDNN_SAFE_CALL(cudnnDestroyTensorDescriptor(tensor_desc_1));
    CUDNN_SAFE_CALL(cudnnDestroyFilterDescriptor(filter_desc));
    CUDNN_SAFE_CALL(cudnnDestroyConvolutionDescriptor(conv_desc));

}

    void executeImpl(cudaStream_t stream) {
        this->Convolution_float_float_float_cuda_lib_Convolution_771(cudnn_handle, input0, input1, output0);
    }
};


class inception3_MaxPool_float_float_cuda_lib_MaxPool_789Kernel : public Kernel {
public:
    inception3_MaxPool_float_float_cuda_lib_MaxPool_789Kernel(cudnnHandle_t  cudnn_handle, float*  input0, float*  output0, float*  Parameter_0_0, float**  Result_892_0) {
        this->cudnn_handle = cudnn_handle, this->input0 = input0, this->output0 = output0, this->Parameter_0_0 = Parameter_0_0, this->Result_892_0 = Result_892_0;
        this->kernelName = "inception3_MaxPool_float_float_cuda_lib_MaxPool_789";
        this->Id = 0;
        this->mixable = 0;
    }

    void initParams() override {
        // empty implementation
    }

    void loadKernel() override {
        // Empty implementation
    }

        cudnnHandle_t  cudnn_handle; float*  input0; float*  output0;
    float*  Parameter_0_0; float**  Result_892_0;
private:

    
std::vector<int> getArgs() override {
    return std::vector<int>();
}

    void MaxPool_float_float_cuda_lib_MaxPool_789(cudnnHandle_t cudnn_handle, float* input0, float* output0)
{
    cudnnTensorDescriptor_t input_desc;
    CUDNN_SAFE_CALL(cudnnCreateTensorDescriptor(&input_desc));
    CUDNN_SAFE_CALL(cudnnSetTensor4dDescriptor(input_desc, CUDNN_TENSOR_NCHW, CUDNN_DATA_FLOAT, 64, 768, 17, 17));
    cudnnTensorDescriptor_t output_desc;
    CUDNN_SAFE_CALL(cudnnCreateTensorDescriptor(&output_desc));
    CUDNN_SAFE_CALL(cudnnSetTensor4dDescriptor(output_desc, CUDNN_TENSOR_NCHW, CUDNN_DATA_FLOAT, 64, 768, 8, 8));
    cudnnPoolingDescriptor_t desc;
    cudnnCreatePoolingDescriptor(&desc);
    CUDNN_SAFE_CALL(cudnnSetPooling2dDescriptor(desc, CUDNN_POOLING_MAX, CUDNN_NOT_PROPAGATE_NAN,3, 3, 0, 0, 2, 2));
    const float alpha = 1.0;
    const float beta = 0.0;
    CUDNN_SAFE_CALL(cudnnPoolingForward(cudnn_handle, desc, &alpha, input_desc, input0, &beta, output_desc, output0));
    CUDNN_SAFE_CALL(cudnnDestroyTensorDescriptor(input_desc));
    CUDNN_SAFE_CALL(cudnnDestroyTensorDescriptor(output_desc));
    CUDNN_SAFE_CALL(cudnnDestroyPoolingDescriptor(desc));

}

    void executeImpl(cudaStream_t stream) {
        this->MaxPool_float_float_cuda_lib_MaxPool_789(cudnn_handle, input0, output0);
    }
};


class inception3_Reshape_float_float_cuda_Reshape_806_CallKernel : public Kernel {
public:
    inception3_Reshape_float_float_cuda_Reshape_806_CallKernel(const dim3 & grids, const dim3 & blocks, unsigned  mem, cudaStream_t  stream, float*  input0, float*  output0, float*  Parameter_0_0, float**  Result_892_0) {
        this->grids = grids, this->blocks = blocks, this->mem = mem, this->stream = stream, this->input0 = input0, this->output0 = output0, this->Parameter_0_0 = Parameter_0_0, this->Result_892_0 = Result_892_0;
        this->kernelName = "inception3_Reshape_float_float_cuda_Reshape_806_Call";
        this->Id = 0;
        this->mixable = 0;
    }

    void initParams() override {
        // empty implementation
    }

    void loadKernel() override {
        // Empty implementation
    }

        dim3  grids; dim3  blocks; unsigned  mem; cudaStream_t  stream; float*  input0; float*  output0;
    float*  Parameter_0_0; float**  Result_892_0;
private:

    
std::vector<int> getArgs() override {
    return std::vector<int>();
}

     void Reshape_float_float_cuda_Reshape_806_Call(const dim3 &grids, const dim3 &blocks, unsigned mem, cudaStream_t stream, float* input0, float* output0) {
    inception3_Reshape_float_float_cuda_Reshape_806<<<grids, blocks, mem, stream>>>(input0, output0);
}

    void executeImpl(cudaStream_t stream) {
        this->Reshape_float_float_cuda_Reshape_806_Call(grids, blocks, mem, stream, input0, output0);
    }
};


class inception3_Convolution_float_float_float_cuda_lib_Convolution_807Kernel : public Kernel {
public:
    inception3_Convolution_float_float_float_cuda_lib_Convolution_807Kernel(cudnnHandle_t  cudnn_handle, float*  input0, float*  input1, float*  output0, float*  Parameter_0_0, float**  Result_892_0) {
        this->cudnn_handle = cudnn_handle, this->input0 = input0, this->input1 = input1, this->output0 = output0, this->Parameter_0_0 = Parameter_0_0, this->Result_892_0 = Result_892_0;
        this->kernelName = "inception3_Convolution_float_float_float_cuda_lib_Convolution_807";
        this->Id = 0;
        this->mixable = 2;
    }

    void initParams() override {
        // empty implementation
    }

    void loadKernel() override {
        // Empty implementation
    }

        cudnnHandle_t  cudnn_handle; float*  input0; float*  input1; float*  output0;
    float*  Parameter_0_0; float**  Result_892_0;
private:

    
std::vector<int> getArgs() override {
    return std::vector<int>({64, 192, 17, 17, 192, 192, 3, 3, 0, 0, 2, 2, 1, 1});
}

    void Convolution_float_float_float_cuda_lib_Convolution_807(cudnnHandle_t cudnn_handle, float* input0, float* input1, float* output0)
{
    cudnnTensorDescriptor_t tensor_desc_0;
    CUDNN_SAFE_CALL(cudnnCreateTensorDescriptor(&tensor_desc_0));
    CUDNN_SAFE_CALL(cudnnSetTensor4dDescriptor(tensor_desc_0, CUDNN_TENSOR_NCHW, CUDNN_DATA_FLOAT, 64, 192, 17, 17));
    cudnnTensorDescriptor_t tensor_desc_1;
    CUDNN_SAFE_CALL(cudnnCreateTensorDescriptor(&tensor_desc_1));
    CUDNN_SAFE_CALL(cudnnSetTensor4dDescriptor(tensor_desc_1, CUDNN_TENSOR_NCHW, CUDNN_DATA_FLOAT, 64, 192, 8, 8));
    cudnnFilterDescriptor_t filter_desc;
    CUDNN_SAFE_CALL(cudnnCreateFilterDescriptor(&filter_desc));
    CUDNN_SAFE_CALL(cudnnSetFilter4dDescriptor(filter_desc, CUDNN_DATA_FLOAT, CUDNN_TENSOR_NCHW, 192, 192, 3, 3));
    cudnnConvolutionDescriptor_t conv_desc;
    CUDNN_SAFE_CALL(cudnnCreateConvolutionDescriptor(&conv_desc));
    CUDNN_SAFE_CALL(cudnnSetConvolution2dDescriptor(conv_desc, 0, 0, 2, 2, 1, 1, CUDNN_CROSS_CORRELATION, CUDNN_DATA_FLOAT));

    static bool selected_algo = true;
    static cudnnConvolutionFwdAlgo_t conv_fwd_algo = CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM;

    if (!selected_algo) {
        int num_algos;
        int max_algos = 0;
        // cudnnGetConvolutionForwardAlgorithm_v7;
        CUDNN_SAFE_CALL(
            cudnnGetConvolutionForwardAlgorithmMaxCount(cudnn_handle, &max_algos));
        std::vector<cudnnConvolutionFwdAlgoPerf_t> results(max_algos);
        CUDNN_SAFE_CALL(cudnnFindConvolutionForwardAlgorithm(cudnn_handle,
                                                tensor_desc_0,
                                                filter_desc,
                                                conv_desc,
                                                tensor_desc_1,
                                                static_cast<int>(results.size()),
                                                &num_algos,
                                                results.data()));
        results.resize(num_algos);
        for (size_t i = 0; i != results.size(); ++i) {
            cudnnConvolutionFwdAlgoPerf_t const& result = results[i];
            if (result.status == CUDNN_STATUS_SUCCESS) {
                conv_fwd_algo = result.algo;
                break;
            }
        }
        selected_algo = true;
    }
    const float alpha = 1.0;
    const float beta = 0.0;
    static void *workspace_ptr_0 = NULL;
    static size_t workspace_size_in_bytes = 0;
    if (!workspace_ptr_0)
    {
        CUDNN_SAFE_CALL(cudnnGetConvolutionForwardWorkspaceSize(cudnn_handle, tensor_desc_0, filter_desc, conv_desc, tensor_desc_1, conv_fwd_algo, &workspace_size_in_bytes));
        CUDA_SAFE_CALL(cudaMalloc(&workspace_ptr_0, workspace_size_in_bytes));
    }
    CUDNN_SAFE_CALL(mycudnnConvolutionForward(cudnn_handle, &alpha, tensor_desc_0, input0,filter_desc, input1, conv_desc, conv_fwd_algo, workspace_ptr_0, workspace_size_in_bytes, &beta, tensor_desc_1, output0));
    CUDNN_SAFE_CALL(cudnnDestroyTensorDescriptor(tensor_desc_0));
    CUDNN_SAFE_CALL(cudnnDestroyTensorDescriptor(tensor_desc_1));
    CUDNN_SAFE_CALL(cudnnDestroyFilterDescriptor(filter_desc));
    CUDNN_SAFE_CALL(cudnnDestroyConvolutionDescriptor(conv_desc));

}

    void executeImpl(cudaStream_t stream) {
        this->Convolution_float_float_float_cuda_lib_Convolution_807(cudnn_handle, input0, input1, output0);
    }
};


class inception3_BatchNormInference_float_float_float_float_float_float_cuda_BatchNormInference_808_CallKernel : public Kernel {
public:
    inception3_BatchNormInference_float_float_float_float_float_float_cuda_BatchNormInference_808_CallKernel(const dim3 & grids, const dim3 & blocks, unsigned  mem, cudaStream_t  stream, float*  input0, float*  input1, float*  input2, float*  input3, float*  input4, float*  output0, float*  Parameter_0_0, float**  Result_892_0) {
        this->grids = grids, this->blocks = blocks, this->mem = mem, this->stream = stream, this->input0 = input0, this->input1 = input1, this->input2 = input2, this->input3 = input3, this->input4 = input4, this->output0 = output0, this->Parameter_0_0 = Parameter_0_0, this->Result_892_0 = Result_892_0;
        this->kernelName = "inception3_BatchNormInference_float_float_float_float_float_float_cuda_BatchNormInference_808_Call";
        this->Id = 0;
        this->mixable = 0;
    }

    void initParams() override {
        // empty implementation
    }

    void loadKernel() override {
        // Empty implementation
    }

        dim3  grids; dim3  blocks; unsigned  mem; cudaStream_t  stream; float*  input0; float*  input1; float*  input2; float*  input3; float*  input4; float*  output0;
    float*  Parameter_0_0; float**  Result_892_0;
private:

    
std::vector<int> getArgs() override {
    return std::vector<int>();
}

     void BatchNormInference_float_float_float_float_float_float_cuda_BatchNormInference_808_Call(const dim3 &grids, const dim3 &blocks, unsigned mem, cudaStream_t stream, float* input0, float* input1, float* input2, float* input3, float* input4, float* output0) {
    inception3_BatchNormInference_float_float_float_float_float_float_cuda_BatchNormInference_808<<<grids, blocks, mem, stream>>>(input0, input1, input2, input3, input4, output0);
}

    void executeImpl(cudaStream_t stream) {
        this->BatchNormInference_float_float_float_float_float_float_cuda_BatchNormInference_808_Call(grids, blocks, mem, stream, input0, input1, input2, input3, input4, output0);
    }
};


class inception3_Reshape_float_float_cuda_Reshape_794_CallKernel : public Kernel {
public:
    inception3_Reshape_float_float_cuda_Reshape_794_CallKernel(const dim3 & grids, const dim3 & blocks, unsigned  mem, cudaStream_t  stream, float*  input0, float*  output0, float*  Parameter_0_0, float**  Result_892_0) {
        this->grids = grids, this->blocks = blocks, this->mem = mem, this->stream = stream, this->input0 = input0, this->output0 = output0, this->Parameter_0_0 = Parameter_0_0, this->Result_892_0 = Result_892_0;
        this->kernelName = "inception3_Reshape_float_float_cuda_Reshape_794_Call";
        this->Id = 0;
        this->mixable = 0;
    }

    void initParams() override {
        // empty implementation
    }

    void loadKernel() override {
        // Empty implementation
    }

        dim3  grids; dim3  blocks; unsigned  mem; cudaStream_t  stream; float*  input0; float*  output0;
    float*  Parameter_0_0; float**  Result_892_0;
private:

    
std::vector<int> getArgs() override {
    return std::vector<int>();
}

     void Reshape_float_float_cuda_Reshape_794_Call(const dim3 &grids, const dim3 &blocks, unsigned mem, cudaStream_t stream, float* input0, float* output0) {
    inception3_Reshape_float_float_cuda_Reshape_794<<<grids, blocks, mem, stream>>>(input0, output0);
}

    void executeImpl(cudaStream_t stream) {
        this->Reshape_float_float_cuda_Reshape_794_Call(grids, blocks, mem, stream, input0, output0);
    }
};


class inception3_Convolution_float_float_float_cuda_lib_Convolution_795Kernel : public Kernel {
public:
    inception3_Convolution_float_float_float_cuda_lib_Convolution_795Kernel(cudnnHandle_t  cudnn_handle, float*  input0, float*  input1, float*  output0, float*  Parameter_0_0, float**  Result_892_0) {
        this->cudnn_handle = cudnn_handle, this->input0 = input0, this->input1 = input1, this->output0 = output0, this->Parameter_0_0 = Parameter_0_0, this->Result_892_0 = Result_892_0;
        this->kernelName = "inception3_Convolution_float_float_float_cuda_lib_Convolution_795";
        this->Id = 0;
        this->mixable = 2;
    }

    void initParams() override {
        // empty implementation
    }

    void loadKernel() override {
        // Empty implementation
    }

        cudnnHandle_t  cudnn_handle; float*  input0; float*  input1; float*  output0;
    float*  Parameter_0_0; float**  Result_892_0;
private:

    
std::vector<int> getArgs() override {
    return std::vector<int>({64, 192, 17, 17, 320, 192, 3, 3, 0, 0, 2, 2, 1, 1});
}

    void Convolution_float_float_float_cuda_lib_Convolution_795(cudnnHandle_t cudnn_handle, float* input0, float* input1, float* output0)
{
    cudnnTensorDescriptor_t tensor_desc_0;
    CUDNN_SAFE_CALL(cudnnCreateTensorDescriptor(&tensor_desc_0));
    CUDNN_SAFE_CALL(cudnnSetTensor4dDescriptor(tensor_desc_0, CUDNN_TENSOR_NCHW, CUDNN_DATA_FLOAT, 64, 192, 17, 17));
    cudnnTensorDescriptor_t tensor_desc_1;
    CUDNN_SAFE_CALL(cudnnCreateTensorDescriptor(&tensor_desc_1));
    CUDNN_SAFE_CALL(cudnnSetTensor4dDescriptor(tensor_desc_1, CUDNN_TENSOR_NCHW, CUDNN_DATA_FLOAT, 64, 320, 8, 8));
    cudnnFilterDescriptor_t filter_desc;
    CUDNN_SAFE_CALL(cudnnCreateFilterDescriptor(&filter_desc));
    CUDNN_SAFE_CALL(cudnnSetFilter4dDescriptor(filter_desc, CUDNN_DATA_FLOAT, CUDNN_TENSOR_NCHW, 320, 192, 3, 3));
    cudnnConvolutionDescriptor_t conv_desc;
    CUDNN_SAFE_CALL(cudnnCreateConvolutionDescriptor(&conv_desc));
    CUDNN_SAFE_CALL(cudnnSetConvolution2dDescriptor(conv_desc, 0, 0, 2, 2, 1, 1, CUDNN_CROSS_CORRELATION, CUDNN_DATA_FLOAT));

    static bool selected_algo = true;
    static cudnnConvolutionFwdAlgo_t conv_fwd_algo = CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM;

    if (!selected_algo) {
        int num_algos;
        int max_algos = 0;
        // cudnnGetConvolutionForwardAlgorithm_v7;
        CUDNN_SAFE_CALL(
            cudnnGetConvolutionForwardAlgorithmMaxCount(cudnn_handle, &max_algos));
        std::vector<cudnnConvolutionFwdAlgoPerf_t> results(max_algos);
        CUDNN_SAFE_CALL(cudnnFindConvolutionForwardAlgorithm(cudnn_handle,
                                                tensor_desc_0,
                                                filter_desc,
                                                conv_desc,
                                                tensor_desc_1,
                                                static_cast<int>(results.size()),
                                                &num_algos,
                                                results.data()));
        results.resize(num_algos);
        for (size_t i = 0; i != results.size(); ++i) {
            cudnnConvolutionFwdAlgoPerf_t const& result = results[i];
            if (result.status == CUDNN_STATUS_SUCCESS) {
                conv_fwd_algo = result.algo;
                break;
            }
        }
        selected_algo = true;
    }
    const float alpha = 1.0;
    const float beta = 0.0;
    static void *workspace_ptr_0 = NULL;
    static size_t workspace_size_in_bytes = 0;
    if (!workspace_ptr_0)
    {
        CUDNN_SAFE_CALL(cudnnGetConvolutionForwardWorkspaceSize(cudnn_handle, tensor_desc_0, filter_desc, conv_desc, tensor_desc_1, conv_fwd_algo, &workspace_size_in_bytes));
        CUDA_SAFE_CALL(cudaMalloc(&workspace_ptr_0, workspace_size_in_bytes));
    }
    CUDNN_SAFE_CALL(mycudnnConvolutionForward(cudnn_handle, &alpha, tensor_desc_0, input0,filter_desc, input1, conv_desc, conv_fwd_algo, workspace_ptr_0, workspace_size_in_bytes, &beta, tensor_desc_1, output0));
    CUDNN_SAFE_CALL(cudnnDestroyTensorDescriptor(tensor_desc_0));
    CUDNN_SAFE_CALL(cudnnDestroyTensorDescriptor(tensor_desc_1));
    CUDNN_SAFE_CALL(cudnnDestroyFilterDescriptor(filter_desc));
    CUDNN_SAFE_CALL(cudnnDestroyConvolutionDescriptor(conv_desc));

}

    void executeImpl(cudaStream_t stream) {
        this->Convolution_float_float_float_cuda_lib_Convolution_795(cudnn_handle, input0, input1, output0);
    }
};


class inception3_BatchNormInference_float_float_float_float_float_float_cuda_BatchNormInference_798_CallKernel : public Kernel {
public:
    inception3_BatchNormInference_float_float_float_float_float_float_cuda_BatchNormInference_798_CallKernel(const dim3 & grids, const dim3 & blocks, unsigned  mem, cudaStream_t  stream, float*  input0, float*  input1, float*  input2, float*  input3, float*  input4, float*  output0, float*  Parameter_0_0, float**  Result_892_0) {
        this->grids = grids, this->blocks = blocks, this->mem = mem, this->stream = stream, this->input0 = input0, this->input1 = input1, this->input2 = input2, this->input3 = input3, this->input4 = input4, this->output0 = output0, this->Parameter_0_0 = Parameter_0_0, this->Result_892_0 = Result_892_0;
        this->kernelName = "inception3_BatchNormInference_float_float_float_float_float_float_cuda_BatchNormInference_798_Call";
        this->Id = 0;
        this->mixable = 0;
    }

    void initParams() override {
        // empty implementation
    }

    void loadKernel() override {
        // Empty implementation
    }

        dim3  grids; dim3  blocks; unsigned  mem; cudaStream_t  stream; float*  input0; float*  input1; float*  input2; float*  input3; float*  input4; float*  output0;
    float*  Parameter_0_0; float**  Result_892_0;
private:

    
std::vector<int> getArgs() override {
    return std::vector<int>();
}

     void BatchNormInference_float_float_float_float_float_float_cuda_BatchNormInference_798_Call(const dim3 &grids, const dim3 &blocks, unsigned mem, cudaStream_t stream, float* input0, float* input1, float* input2, float* input3, float* input4, float* output0) {
    inception3_BatchNormInference_float_float_float_float_float_float_cuda_BatchNormInference_798<<<grids, blocks, mem, stream>>>(input0, input1, input2, input3, input4, output0);
}

    void executeImpl(cudaStream_t stream) {
        this->BatchNormInference_float_float_float_float_float_float_cuda_BatchNormInference_798_Call(grids, blocks, mem, stream, input0, input1, input2, input3, input4, output0);
    }
};


class inception3_Concat_float_float_float_float_cuda_Concat_810_CallKernel : public Kernel {
public:
    inception3_Concat_float_float_float_float_cuda_Concat_810_CallKernel(const dim3 & grids, const dim3 & blocks, unsigned  mem, cudaStream_t  stream, float*  input0, float*  input1, float*  input2, float*  output0, float*  Parameter_0_0, float**  Result_892_0) {
        this->grids = grids, this->blocks = blocks, this->mem = mem, this->stream = stream, this->input0 = input0, this->input1 = input1, this->input2 = input2, this->output0 = output0, this->Parameter_0_0 = Parameter_0_0, this->Result_892_0 = Result_892_0;
        this->kernelName = "inception3_Concat_float_float_float_float_cuda_Concat_810_Call";
        this->Id = 0;
        this->mixable = 0;
    }

    void initParams() override {
        // empty implementation
    }

    void loadKernel() override {
        // Empty implementation
    }

        dim3  grids; dim3  blocks; unsigned  mem; cudaStream_t  stream; float*  input0; float*  input1; float*  input2; float*  output0;
    float*  Parameter_0_0; float**  Result_892_0;
private:

    
std::vector<int> getArgs() override {
    return std::vector<int>();
}

     void Concat_float_float_float_float_cuda_Concat_810_Call(const dim3 &grids, const dim3 &blocks, unsigned mem, cudaStream_t stream, float* input0, float* input1, float* input2, float* output0) {
    inception3_Concat_float_float_float_float_cuda_Concat_810<<<grids, blocks, mem, stream>>>(input0, input1, input2, output0);
}

    void executeImpl(cudaStream_t stream) {
        this->Concat_float_float_float_float_cuda_Concat_810_Call(grids, blocks, mem, stream, input0, input1, input2, output0);
    }
};


class inception3_AvgPool_float_float_cuda_lib_AvgPool_817Kernel : public Kernel {
public:
    inception3_AvgPool_float_float_cuda_lib_AvgPool_817Kernel(cudnnHandle_t  cudnn_handle, float*  input0, float*  output0, float*  Parameter_0_0, float**  Result_892_0) {
        this->cudnn_handle = cudnn_handle, this->input0 = input0, this->output0 = output0, this->Parameter_0_0 = Parameter_0_0, this->Result_892_0 = Result_892_0;
        this->kernelName = "inception3_AvgPool_float_float_cuda_lib_AvgPool_817";
        this->Id = 0;
        this->mixable = 0;
    }

    void initParams() override {
        // empty implementation
    }

    void loadKernel() override {
        // Empty implementation
    }

        cudnnHandle_t  cudnn_handle; float*  input0; float*  output0;
    float*  Parameter_0_0; float**  Result_892_0;
private:

    
std::vector<int> getArgs() override {
    return std::vector<int>();
}

    void AvgPool_float_float_cuda_lib_AvgPool_817(cudnnHandle_t cudnn_handle, float* input0, float* output0)
{
    cudnnTensorDescriptor_t input_desc;
    CUDNN_SAFE_CALL(cudnnCreateTensorDescriptor(&input_desc));
    CUDNN_SAFE_CALL(cudnnSetTensor4dDescriptor(input_desc, CUDNN_TENSOR_NCHW, CUDNN_DATA_FLOAT, 64, 1280, 8, 8));
    cudnnTensorDescriptor_t output_desc;
    CUDNN_SAFE_CALL(cudnnCreateTensorDescriptor(&output_desc));
    CUDNN_SAFE_CALL(cudnnSetTensor4dDescriptor(output_desc, CUDNN_TENSOR_NCHW, CUDNN_DATA_FLOAT, 64, 1280, 8, 8));
    cudnnPoolingDescriptor_t desc;
    cudnnCreatePoolingDescriptor(&desc);
    CUDNN_SAFE_CALL(cudnnSetPooling2dDescriptor(desc, CUDNN_POOLING_AVERAGE_COUNT_EXCLUDE_PADDING, CUDNN_NOT_PROPAGATE_NAN,3, 3, 1, 1, 1, 1));
    const float alpha = 1.0;
    const float beta = 0.0;
    CUDNN_SAFE_CALL(cudnnPoolingForward(cudnn_handle, desc, &alpha, input_desc, input0, &beta, output_desc, output0));
    CUDNN_SAFE_CALL(cudnnDestroyTensorDescriptor(input_desc));
    CUDNN_SAFE_CALL(cudnnDestroyTensorDescriptor(output_desc));
    CUDNN_SAFE_CALL(cudnnDestroyPoolingDescriptor(desc));

}

    void executeImpl(cudaStream_t stream) {
        this->AvgPool_float_float_cuda_lib_AvgPool_817(cudnn_handle, input0, output0);
    }
};


class inception3_Reshape_float_float_cuda_Reshape_821_CallKernel : public Kernel {
public:
    inception3_Reshape_float_float_cuda_Reshape_821_CallKernel(const dim3 & grids, const dim3 & blocks, unsigned  mem, cudaStream_t  stream, float*  input0, float*  output0, float*  Parameter_0_0, float**  Result_892_0) {
        this->grids = grids, this->blocks = blocks, this->mem = mem, this->stream = stream, this->input0 = input0, this->output0 = output0, this->Parameter_0_0 = Parameter_0_0, this->Result_892_0 = Result_892_0;
        this->kernelName = "inception3_Reshape_float_float_cuda_Reshape_821_Call";
        this->Id = 0;
        this->mixable = 0;
    }

    void initParams() override {
        // empty implementation
    }

    void loadKernel() override {
        // Empty implementation
    }

        dim3  grids; dim3  blocks; unsigned  mem; cudaStream_t  stream; float*  input0; float*  output0;
    float*  Parameter_0_0; float**  Result_892_0;
private:

    
std::vector<int> getArgs() override {
    return std::vector<int>();
}

     void Reshape_float_float_cuda_Reshape_821_Call(const dim3 &grids, const dim3 &blocks, unsigned mem, cudaStream_t stream, float* input0, float* output0) {
    inception3_Reshape_float_float_cuda_Reshape_821<<<grids, blocks, mem, stream>>>(input0, output0);
}

    void executeImpl(cudaStream_t stream) {
        this->Reshape_float_float_cuda_Reshape_821_Call(grids, blocks, mem, stream, input0, output0);
    }
};


class inception3_Convolution_float_float_float_cuda_lib_Convolution_822Kernel : public Kernel {
public:
    inception3_Convolution_float_float_float_cuda_lib_Convolution_822Kernel(cudnnHandle_t  cudnn_handle, float*  input0, float*  input1, float*  output0, float*  Parameter_0_0, float**  Result_892_0) {
        this->cudnn_handle = cudnn_handle, this->input0 = input0, this->input1 = input1, this->output0 = output0, this->Parameter_0_0 = Parameter_0_0, this->Result_892_0 = Result_892_0;
        this->kernelName = "inception3_Convolution_float_float_float_cuda_lib_Convolution_822";
        this->Id = 0;
        this->mixable = 2;
    }

    void initParams() override {
        // empty implementation
    }

    void loadKernel() override {
        // Empty implementation
    }

        cudnnHandle_t  cudnn_handle; float*  input0; float*  input1; float*  output0;
    float*  Parameter_0_0; float**  Result_892_0;
private:

    
std::vector<int> getArgs() override {
    return std::vector<int>({64, 1280, 8, 8, 192, 1280, 1, 1, 0, 0, 1, 1, 1, 1});
}

    void Convolution_float_float_float_cuda_lib_Convolution_822(cudnnHandle_t cudnn_handle, float* input0, float* input1, float* output0)
{
    cudnnTensorDescriptor_t tensor_desc_0;
    CUDNN_SAFE_CALL(cudnnCreateTensorDescriptor(&tensor_desc_0));
    CUDNN_SAFE_CALL(cudnnSetTensor4dDescriptor(tensor_desc_0, CUDNN_TENSOR_NCHW, CUDNN_DATA_FLOAT, 64, 1280, 8, 8));
    cudnnTensorDescriptor_t tensor_desc_1;
    CUDNN_SAFE_CALL(cudnnCreateTensorDescriptor(&tensor_desc_1));
    CUDNN_SAFE_CALL(cudnnSetTensor4dDescriptor(tensor_desc_1, CUDNN_TENSOR_NCHW, CUDNN_DATA_FLOAT, 64, 192, 8, 8));
    cudnnFilterDescriptor_t filter_desc;
    CUDNN_SAFE_CALL(cudnnCreateFilterDescriptor(&filter_desc));
    CUDNN_SAFE_CALL(cudnnSetFilter4dDescriptor(filter_desc, CUDNN_DATA_FLOAT, CUDNN_TENSOR_NCHW, 192, 1280, 1, 1));
    cudnnConvolutionDescriptor_t conv_desc;
    CUDNN_SAFE_CALL(cudnnCreateConvolutionDescriptor(&conv_desc));
    CUDNN_SAFE_CALL(cudnnSetConvolution2dDescriptor(conv_desc, 0, 0, 1, 1, 1, 1, CUDNN_CROSS_CORRELATION, CUDNN_DATA_FLOAT));

    static bool selected_algo = true;
    static cudnnConvolutionFwdAlgo_t conv_fwd_algo = CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM;

    if (!selected_algo) {
        int num_algos;
        int max_algos = 0;
        // cudnnGetConvolutionForwardAlgorithm_v7;
        CUDNN_SAFE_CALL(
            cudnnGetConvolutionForwardAlgorithmMaxCount(cudnn_handle, &max_algos));
        std::vector<cudnnConvolutionFwdAlgoPerf_t> results(max_algos);
        CUDNN_SAFE_CALL(cudnnFindConvolutionForwardAlgorithm(cudnn_handle,
                                                tensor_desc_0,
                                                filter_desc,
                                                conv_desc,
                                                tensor_desc_1,
                                                static_cast<int>(results.size()),
                                                &num_algos,
                                                results.data()));
        results.resize(num_algos);
        for (size_t i = 0; i != results.size(); ++i) {
            cudnnConvolutionFwdAlgoPerf_t const& result = results[i];
            if (result.status == CUDNN_STATUS_SUCCESS) {
                conv_fwd_algo = result.algo;
                break;
            }
        }
        selected_algo = true;
    }
    const float alpha = 1.0;
    const float beta = 0.0;
    static void *workspace_ptr_0 = NULL;
    static size_t workspace_size_in_bytes = 0;
    if (!workspace_ptr_0)
    {
        CUDNN_SAFE_CALL(cudnnGetConvolutionForwardWorkspaceSize(cudnn_handle, tensor_desc_0, filter_desc, conv_desc, tensor_desc_1, conv_fwd_algo, &workspace_size_in_bytes));
        CUDA_SAFE_CALL(cudaMalloc(&workspace_ptr_0, workspace_size_in_bytes));
    }
    CUDNN_SAFE_CALL(mycudnnConvolutionForward(cudnn_handle, &alpha, tensor_desc_0, input0,filter_desc, input1, conv_desc, conv_fwd_algo, workspace_ptr_0, workspace_size_in_bytes, &beta, tensor_desc_1, output0));
    CUDNN_SAFE_CALL(cudnnDestroyTensorDescriptor(tensor_desc_0));
    CUDNN_SAFE_CALL(cudnnDestroyTensorDescriptor(tensor_desc_1));
    CUDNN_SAFE_CALL(cudnnDestroyFilterDescriptor(filter_desc));
    CUDNN_SAFE_CALL(cudnnDestroyConvolutionDescriptor(conv_desc));

}

    void executeImpl(cudaStream_t stream) {
        this->Convolution_float_float_float_cuda_lib_Convolution_822(cudnn_handle, input0, input1, output0);
    }
};


class inception3_Reshape_float_float_cuda_Reshape_815_CallKernel : public Kernel {
public:
    inception3_Reshape_float_float_cuda_Reshape_815_CallKernel(const dim3 & grids, const dim3 & blocks, unsigned  mem, cudaStream_t  stream, float*  input0, float*  output0, float*  Parameter_0_0, float**  Result_892_0) {
        this->grids = grids, this->blocks = blocks, this->mem = mem, this->stream = stream, this->input0 = input0, this->output0 = output0, this->Parameter_0_0 = Parameter_0_0, this->Result_892_0 = Result_892_0;
        this->kernelName = "inception3_Reshape_float_float_cuda_Reshape_815_Call";
        this->Id = 0;
        this->mixable = 0;
    }

    void initParams() override {
        // empty implementation
    }

    void loadKernel() override {
        // Empty implementation
    }

        dim3  grids; dim3  blocks; unsigned  mem; cudaStream_t  stream; float*  input0; float*  output0;
    float*  Parameter_0_0; float**  Result_892_0;
private:

    
std::vector<int> getArgs() override {
    return std::vector<int>();
}

     void Reshape_float_float_cuda_Reshape_815_Call(const dim3 &grids, const dim3 &blocks, unsigned mem, cudaStream_t stream, float* input0, float* output0) {
    inception3_Reshape_float_float_cuda_Reshape_815<<<grids, blocks, mem, stream>>>(input0, output0);
}

    void executeImpl(cudaStream_t stream) {
        this->Reshape_float_float_cuda_Reshape_815_Call(grids, blocks, mem, stream, input0, output0);
    }
};


class inception3_Convolution_float_float_float_cuda_lib_Convolution_816Kernel : public Kernel {
public:
    inception3_Convolution_float_float_float_cuda_lib_Convolution_816Kernel(cudnnHandle_t  cudnn_handle, float*  input0, float*  input1, float*  output0, float*  Parameter_0_0, float**  Result_892_0) {
        this->cudnn_handle = cudnn_handle, this->input0 = input0, this->input1 = input1, this->output0 = output0, this->Parameter_0_0 = Parameter_0_0, this->Result_892_0 = Result_892_0;
        this->kernelName = "inception3_Convolution_float_float_float_cuda_lib_Convolution_816";
        this->Id = 0;
        this->mixable = 2;
    }

    void initParams() override {
        // empty implementation
    }

    void loadKernel() override {
        // Empty implementation
    }

        cudnnHandle_t  cudnn_handle; float*  input0; float*  input1; float*  output0;
    float*  Parameter_0_0; float**  Result_892_0;
private:

    
std::vector<int> getArgs() override {
    return std::vector<int>({64, 1280, 8, 8, 448, 1280, 1, 1, 0, 0, 1, 1, 1, 1});
}

    void Convolution_float_float_float_cuda_lib_Convolution_816(cudnnHandle_t cudnn_handle, float* input0, float* input1, float* output0)
{
    cudnnTensorDescriptor_t tensor_desc_0;
    CUDNN_SAFE_CALL(cudnnCreateTensorDescriptor(&tensor_desc_0));
    CUDNN_SAFE_CALL(cudnnSetTensor4dDescriptor(tensor_desc_0, CUDNN_TENSOR_NCHW, CUDNN_DATA_FLOAT, 64, 1280, 8, 8));
    cudnnTensorDescriptor_t tensor_desc_1;
    CUDNN_SAFE_CALL(cudnnCreateTensorDescriptor(&tensor_desc_1));
    CUDNN_SAFE_CALL(cudnnSetTensor4dDescriptor(tensor_desc_1, CUDNN_TENSOR_NCHW, CUDNN_DATA_FLOAT, 64, 448, 8, 8));
    cudnnFilterDescriptor_t filter_desc;
    CUDNN_SAFE_CALL(cudnnCreateFilterDescriptor(&filter_desc));
    CUDNN_SAFE_CALL(cudnnSetFilter4dDescriptor(filter_desc, CUDNN_DATA_FLOAT, CUDNN_TENSOR_NCHW, 448, 1280, 1, 1));
    cudnnConvolutionDescriptor_t conv_desc;
    CUDNN_SAFE_CALL(cudnnCreateConvolutionDescriptor(&conv_desc));
    CUDNN_SAFE_CALL(cudnnSetConvolution2dDescriptor(conv_desc, 0, 0, 1, 1, 1, 1, CUDNN_CROSS_CORRELATION, CUDNN_DATA_FLOAT));

    static bool selected_algo = true;
    static cudnnConvolutionFwdAlgo_t conv_fwd_algo = CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM;

    if (!selected_algo) {
        int num_algos;
        int max_algos = 0;
        // cudnnGetConvolutionForwardAlgorithm_v7;
        CUDNN_SAFE_CALL(
            cudnnGetConvolutionForwardAlgorithmMaxCount(cudnn_handle, &max_algos));
        std::vector<cudnnConvolutionFwdAlgoPerf_t> results(max_algos);
        CUDNN_SAFE_CALL(cudnnFindConvolutionForwardAlgorithm(cudnn_handle,
                                                tensor_desc_0,
                                                filter_desc,
                                                conv_desc,
                                                tensor_desc_1,
                                                static_cast<int>(results.size()),
                                                &num_algos,
                                                results.data()));
        results.resize(num_algos);
        for (size_t i = 0; i != results.size(); ++i) {
            cudnnConvolutionFwdAlgoPerf_t const& result = results[i];
            if (result.status == CUDNN_STATUS_SUCCESS) {
                conv_fwd_algo = result.algo;
                break;
            }
        }
        selected_algo = true;
    }
    const float alpha = 1.0;
    const float beta = 0.0;
    static void *workspace_ptr_0 = NULL;
    static size_t workspace_size_in_bytes = 0;
    if (!workspace_ptr_0)
    {
        CUDNN_SAFE_CALL(cudnnGetConvolutionForwardWorkspaceSize(cudnn_handle, tensor_desc_0, filter_desc, conv_desc, tensor_desc_1, conv_fwd_algo, &workspace_size_in_bytes));
        CUDA_SAFE_CALL(cudaMalloc(&workspace_ptr_0, workspace_size_in_bytes));
    }
    CUDNN_SAFE_CALL(mycudnnConvolutionForward(cudnn_handle, &alpha, tensor_desc_0, input0,filter_desc, input1, conv_desc, conv_fwd_algo, workspace_ptr_0, workspace_size_in_bytes, &beta, tensor_desc_1, output0));
    CUDNN_SAFE_CALL(cudnnDestroyTensorDescriptor(tensor_desc_0));
    CUDNN_SAFE_CALL(cudnnDestroyTensorDescriptor(tensor_desc_1));
    CUDNN_SAFE_CALL(cudnnDestroyFilterDescriptor(filter_desc));
    CUDNN_SAFE_CALL(cudnnDestroyConvolutionDescriptor(conv_desc));

}

    void executeImpl(cudaStream_t stream) {
        this->Convolution_float_float_float_cuda_lib_Convolution_816(cudnn_handle, input0, input1, output0);
    }
};


class inception3_BatchNormInference_float_float_float_float_float_float_cuda_BatchNormInference_820_CallKernel : public Kernel {
public:
    inception3_BatchNormInference_float_float_float_float_float_float_cuda_BatchNormInference_820_CallKernel(const dim3 & grids, const dim3 & blocks, unsigned  mem, cudaStream_t  stream, float*  input0, float*  input1, float*  input2, float*  input3, float*  input4, float*  output0, float*  Parameter_0_0, float**  Result_892_0) {
        this->grids = grids, this->blocks = blocks, this->mem = mem, this->stream = stream, this->input0 = input0, this->input1 = input1, this->input2 = input2, this->input3 = input3, this->input4 = input4, this->output0 = output0, this->Parameter_0_0 = Parameter_0_0, this->Result_892_0 = Result_892_0;
        this->kernelName = "inception3_BatchNormInference_float_float_float_float_float_float_cuda_BatchNormInference_820_Call";
        this->Id = 0;
        this->mixable = 0;
    }

    void initParams() override {
        // empty implementation
    }

    void loadKernel() override {
        // Empty implementation
    }

        dim3  grids; dim3  blocks; unsigned  mem; cudaStream_t  stream; float*  input0; float*  input1; float*  input2; float*  input3; float*  input4; float*  output0;
    float*  Parameter_0_0; float**  Result_892_0;
private:

    
std::vector<int> getArgs() override {
    return std::vector<int>();
}

     void BatchNormInference_float_float_float_float_float_float_cuda_BatchNormInference_820_Call(const dim3 &grids, const dim3 &blocks, unsigned mem, cudaStream_t stream, float* input0, float* input1, float* input2, float* input3, float* input4, float* output0) {
    inception3_BatchNormInference_float_float_float_float_float_float_cuda_BatchNormInference_820<<<grids, blocks, mem, stream>>>(input0, input1, input2, input3, input4, output0);
}

    void executeImpl(cudaStream_t stream) {
        this->BatchNormInference_float_float_float_float_float_float_cuda_BatchNormInference_820_Call(grids, blocks, mem, stream, input0, input1, input2, input3, input4, output0);
    }
};


class inception3_Reshape_float_float_cuda_Reshape_831_CallKernel : public Kernel {
public:
    inception3_Reshape_float_float_cuda_Reshape_831_CallKernel(const dim3 & grids, const dim3 & blocks, unsigned  mem, cudaStream_t  stream, float*  input0, float*  output0, float*  Parameter_0_0, float**  Result_892_0) {
        this->grids = grids, this->blocks = blocks, this->mem = mem, this->stream = stream, this->input0 = input0, this->output0 = output0, this->Parameter_0_0 = Parameter_0_0, this->Result_892_0 = Result_892_0;
        this->kernelName = "inception3_Reshape_float_float_cuda_Reshape_831_Call";
        this->Id = 0;
        this->mixable = 0;
    }

    void initParams() override {
        // empty implementation
    }

    void loadKernel() override {
        // Empty implementation
    }

        dim3  grids; dim3  blocks; unsigned  mem; cudaStream_t  stream; float*  input0; float*  output0;
    float*  Parameter_0_0; float**  Result_892_0;
private:

    
std::vector<int> getArgs() override {
    return std::vector<int>();
}

     void Reshape_float_float_cuda_Reshape_831_Call(const dim3 &grids, const dim3 &blocks, unsigned mem, cudaStream_t stream, float* input0, float* output0) {
    inception3_Reshape_float_float_cuda_Reshape_831<<<grids, blocks, mem, stream>>>(input0, output0);
}

    void executeImpl(cudaStream_t stream) {
        this->Reshape_float_float_cuda_Reshape_831_Call(grids, blocks, mem, stream, input0, output0);
    }
};


class inception3_Convolution_float_float_float_cuda_lib_Convolution_832Kernel : public Kernel {
public:
    inception3_Convolution_float_float_float_cuda_lib_Convolution_832Kernel(cudnnHandle_t  cudnn_handle, float*  input0, float*  input1, float*  output0, float*  Parameter_0_0, float**  Result_892_0) {
        this->cudnn_handle = cudnn_handle, this->input0 = input0, this->input1 = input1, this->output0 = output0, this->Parameter_0_0 = Parameter_0_0, this->Result_892_0 = Result_892_0;
        this->kernelName = "inception3_Convolution_float_float_float_cuda_lib_Convolution_832";
        this->Id = 0;
        this->mixable = 2;
    }

    void initParams() override {
        // empty implementation
    }

    void loadKernel() override {
        // Empty implementation
    }

        cudnnHandle_t  cudnn_handle; float*  input0; float*  input1; float*  output0;
    float*  Parameter_0_0; float**  Result_892_0;
private:

    
std::vector<int> getArgs() override {
    return std::vector<int>({64, 448, 8, 8, 384, 448, 3, 3, 1, 1, 1, 1, 1, 1});
}

    void Convolution_float_float_float_cuda_lib_Convolution_832(cudnnHandle_t cudnn_handle, float* input0, float* input1, float* output0)
{
    cudnnTensorDescriptor_t tensor_desc_0;
    CUDNN_SAFE_CALL(cudnnCreateTensorDescriptor(&tensor_desc_0));
    CUDNN_SAFE_CALL(cudnnSetTensor4dDescriptor(tensor_desc_0, CUDNN_TENSOR_NCHW, CUDNN_DATA_FLOAT, 64, 448, 8, 8));
    cudnnTensorDescriptor_t tensor_desc_1;
    CUDNN_SAFE_CALL(cudnnCreateTensorDescriptor(&tensor_desc_1));
    CUDNN_SAFE_CALL(cudnnSetTensor4dDescriptor(tensor_desc_1, CUDNN_TENSOR_NCHW, CUDNN_DATA_FLOAT, 64, 384, 8, 8));
    cudnnFilterDescriptor_t filter_desc;
    CUDNN_SAFE_CALL(cudnnCreateFilterDescriptor(&filter_desc));
    CUDNN_SAFE_CALL(cudnnSetFilter4dDescriptor(filter_desc, CUDNN_DATA_FLOAT, CUDNN_TENSOR_NCHW, 384, 448, 3, 3));
    cudnnConvolutionDescriptor_t conv_desc;
    CUDNN_SAFE_CALL(cudnnCreateConvolutionDescriptor(&conv_desc));
    CUDNN_SAFE_CALL(cudnnSetConvolution2dDescriptor(conv_desc, 1, 1, 1, 1, 1, 1, CUDNN_CROSS_CORRELATION, CUDNN_DATA_FLOAT));

    static bool selected_algo = true;
    static cudnnConvolutionFwdAlgo_t conv_fwd_algo = CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM;

    if (!selected_algo) {
        int num_algos;
        int max_algos = 0;
        // cudnnGetConvolutionForwardAlgorithm_v7;
        CUDNN_SAFE_CALL(
            cudnnGetConvolutionForwardAlgorithmMaxCount(cudnn_handle, &max_algos));
        std::vector<cudnnConvolutionFwdAlgoPerf_t> results(max_algos);
        CUDNN_SAFE_CALL(cudnnFindConvolutionForwardAlgorithm(cudnn_handle,
                                                tensor_desc_0,
                                                filter_desc,
                                                conv_desc,
                                                tensor_desc_1,
                                                static_cast<int>(results.size()),
                                                &num_algos,
                                                results.data()));
        results.resize(num_algos);
        for (size_t i = 0; i != results.size(); ++i) {
            cudnnConvolutionFwdAlgoPerf_t const& result = results[i];
            if (result.status == CUDNN_STATUS_SUCCESS) {
                conv_fwd_algo = result.algo;
                break;
            }
        }
        selected_algo = true;
    }
    const float alpha = 1.0;
    const float beta = 0.0;
    static void *workspace_ptr_0 = NULL;
    static size_t workspace_size_in_bytes = 0;
    if (!workspace_ptr_0)
    {
        CUDNN_SAFE_CALL(cudnnGetConvolutionForwardWorkspaceSize(cudnn_handle, tensor_desc_0, filter_desc, conv_desc, tensor_desc_1, conv_fwd_algo, &workspace_size_in_bytes));
        CUDA_SAFE_CALL(cudaMalloc(&workspace_ptr_0, workspace_size_in_bytes));
    }
    CUDNN_SAFE_CALL(mycudnnConvolutionForward(cudnn_handle, &alpha, tensor_desc_0, input0,filter_desc, input1, conv_desc, conv_fwd_algo, workspace_ptr_0, workspace_size_in_bytes, &beta, tensor_desc_1, output0));
    CUDNN_SAFE_CALL(cudnnDestroyTensorDescriptor(tensor_desc_0));
    CUDNN_SAFE_CALL(cudnnDestroyTensorDescriptor(tensor_desc_1));
    CUDNN_SAFE_CALL(cudnnDestroyFilterDescriptor(filter_desc));
    CUDNN_SAFE_CALL(cudnnDestroyConvolutionDescriptor(conv_desc));

}

    void executeImpl(cudaStream_t stream) {
        this->Convolution_float_float_float_cuda_lib_Convolution_832(cudnn_handle, input0, input1, output0);
    }
};


class inception3_BatchNormInference_float_float_float_float_float_float_cuda_BatchNormInference_836_CallKernel : public Kernel {
public:
    inception3_BatchNormInference_float_float_float_float_float_float_cuda_BatchNormInference_836_CallKernel(const dim3 & grids, const dim3 & blocks, unsigned  mem, cudaStream_t  stream, float*  input0, float*  input1, float*  input2, float*  input3, float*  input4, float*  output0, float*  Parameter_0_0, float**  Result_892_0) {
        this->grids = grids, this->blocks = blocks, this->mem = mem, this->stream = stream, this->input0 = input0, this->input1 = input1, this->input2 = input2, this->input3 = input3, this->input4 = input4, this->output0 = output0, this->Parameter_0_0 = Parameter_0_0, this->Result_892_0 = Result_892_0;
        this->kernelName = "inception3_BatchNormInference_float_float_float_float_float_float_cuda_BatchNormInference_836_Call";
        this->Id = 0;
        this->mixable = 0;
    }

    void initParams() override {
        // empty implementation
    }

    void loadKernel() override {
        // Empty implementation
    }

        dim3  grids; dim3  blocks; unsigned  mem; cudaStream_t  stream; float*  input0; float*  input1; float*  input2; float*  input3; float*  input4; float*  output0;
    float*  Parameter_0_0; float**  Result_892_0;
private:

    
std::vector<int> getArgs() override {
    return std::vector<int>();
}

     void BatchNormInference_float_float_float_float_float_float_cuda_BatchNormInference_836_Call(const dim3 &grids, const dim3 &blocks, unsigned mem, cudaStream_t stream, float* input0, float* input1, float* input2, float* input3, float* input4, float* output0) {
    inception3_BatchNormInference_float_float_float_float_float_float_cuda_BatchNormInference_836<<<grids, blocks, mem, stream>>>(input0, input1, input2, input3, input4, output0);
}

    void executeImpl(cudaStream_t stream) {
        this->BatchNormInference_float_float_float_float_float_float_cuda_BatchNormInference_836_Call(grids, blocks, mem, stream, input0, input1, input2, input3, input4, output0);
    }
};


class inception3_Reshape_float_float_cuda_Reshape_842_CallKernel : public Kernel {
public:
    inception3_Reshape_float_float_cuda_Reshape_842_CallKernel(const dim3 & grids, const dim3 & blocks, unsigned  mem, cudaStream_t  stream, float*  input0, float*  output0, float*  Parameter_0_0, float**  Result_892_0) {
        this->grids = grids, this->blocks = blocks, this->mem = mem, this->stream = stream, this->input0 = input0, this->output0 = output0, this->Parameter_0_0 = Parameter_0_0, this->Result_892_0 = Result_892_0;
        this->kernelName = "inception3_Reshape_float_float_cuda_Reshape_842_Call";
        this->Id = 0;
        this->mixable = 0;
    }

    void initParams() override {
        // empty implementation
    }

    void loadKernel() override {
        // Empty implementation
    }

        dim3  grids; dim3  blocks; unsigned  mem; cudaStream_t  stream; float*  input0; float*  output0;
    float*  Parameter_0_0; float**  Result_892_0;
private:

    
std::vector<int> getArgs() override {
    return std::vector<int>();
}

     void Reshape_float_float_cuda_Reshape_842_Call(const dim3 &grids, const dim3 &blocks, unsigned mem, cudaStream_t stream, float* input0, float* output0) {
    inception3_Reshape_float_float_cuda_Reshape_842<<<grids, blocks, mem, stream>>>(input0, output0);
}

    void executeImpl(cudaStream_t stream) {
        this->Reshape_float_float_cuda_Reshape_842_Call(grids, blocks, mem, stream, input0, output0);
    }
};


class inception3_Convolution_float_float_float_cuda_lib_Convolution_843Kernel : public Kernel {
public:
    inception3_Convolution_float_float_float_cuda_lib_Convolution_843Kernel(cudnnHandle_t  cudnn_handle, float*  input0, float*  input1, float*  output0, float*  Parameter_0_0, float**  Result_892_0) {
        this->cudnn_handle = cudnn_handle, this->input0 = input0, this->input1 = input1, this->output0 = output0, this->Parameter_0_0 = Parameter_0_0, this->Result_892_0 = Result_892_0;
        this->kernelName = "inception3_Convolution_float_float_float_cuda_lib_Convolution_843";
        this->Id = 0;
        this->mixable = 2;
    }

    void initParams() override {
        // empty implementation
    }

    void loadKernel() override {
        // Empty implementation
    }

        cudnnHandle_t  cudnn_handle; float*  input0; float*  input1; float*  output0;
    float*  Parameter_0_0; float**  Result_892_0;
private:

    
std::vector<int> getArgs() override {
    return std::vector<int>({64, 384, 8, 8, 384, 384, 3, 1, 1, 0, 1, 1, 1, 1});
}

    void Convolution_float_float_float_cuda_lib_Convolution_843(cudnnHandle_t cudnn_handle, float* input0, float* input1, float* output0)
{
    cudnnTensorDescriptor_t tensor_desc_0;
    CUDNN_SAFE_CALL(cudnnCreateTensorDescriptor(&tensor_desc_0));
    CUDNN_SAFE_CALL(cudnnSetTensor4dDescriptor(tensor_desc_0, CUDNN_TENSOR_NCHW, CUDNN_DATA_FLOAT, 64, 384, 8, 8));
    cudnnTensorDescriptor_t tensor_desc_1;
    CUDNN_SAFE_CALL(cudnnCreateTensorDescriptor(&tensor_desc_1));
    CUDNN_SAFE_CALL(cudnnSetTensor4dDescriptor(tensor_desc_1, CUDNN_TENSOR_NCHW, CUDNN_DATA_FLOAT, 64, 384, 8, 8));
    cudnnFilterDescriptor_t filter_desc;
    CUDNN_SAFE_CALL(cudnnCreateFilterDescriptor(&filter_desc));
    CUDNN_SAFE_CALL(cudnnSetFilter4dDescriptor(filter_desc, CUDNN_DATA_FLOAT, CUDNN_TENSOR_NCHW, 384, 384, 3, 1));
    cudnnConvolutionDescriptor_t conv_desc;
    CUDNN_SAFE_CALL(cudnnCreateConvolutionDescriptor(&conv_desc));
    CUDNN_SAFE_CALL(cudnnSetConvolution2dDescriptor(conv_desc, 1, 0, 1, 1, 1, 1, CUDNN_CROSS_CORRELATION, CUDNN_DATA_FLOAT));

    static bool selected_algo = true;
    static cudnnConvolutionFwdAlgo_t conv_fwd_algo = CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM;

    if (!selected_algo) {
        int num_algos;
        int max_algos = 0;
        // cudnnGetConvolutionForwardAlgorithm_v7;
        CUDNN_SAFE_CALL(
            cudnnGetConvolutionForwardAlgorithmMaxCount(cudnn_handle, &max_algos));
        std::vector<cudnnConvolutionFwdAlgoPerf_t> results(max_algos);
        CUDNN_SAFE_CALL(cudnnFindConvolutionForwardAlgorithm(cudnn_handle,
                                                tensor_desc_0,
                                                filter_desc,
                                                conv_desc,
                                                tensor_desc_1,
                                                static_cast<int>(results.size()),
                                                &num_algos,
                                                results.data()));
        results.resize(num_algos);
        for (size_t i = 0; i != results.size(); ++i) {
            cudnnConvolutionFwdAlgoPerf_t const& result = results[i];
            if (result.status == CUDNN_STATUS_SUCCESS) {
                conv_fwd_algo = result.algo;
                break;
            }
        }
        selected_algo = true;
    }
    const float alpha = 1.0;
    const float beta = 0.0;
    static void *workspace_ptr_0 = NULL;
    static size_t workspace_size_in_bytes = 0;
    if (!workspace_ptr_0)
    {
        CUDNN_SAFE_CALL(cudnnGetConvolutionForwardWorkspaceSize(cudnn_handle, tensor_desc_0, filter_desc, conv_desc, tensor_desc_1, conv_fwd_algo, &workspace_size_in_bytes));
        CUDA_SAFE_CALL(cudaMalloc(&workspace_ptr_0, workspace_size_in_bytes));
    }
    CUDNN_SAFE_CALL(mycudnnConvolutionForward(cudnn_handle, &alpha, tensor_desc_0, input0,filter_desc, input1, conv_desc, conv_fwd_algo, workspace_ptr_0, workspace_size_in_bytes, &beta, tensor_desc_1, output0));
    CUDNN_SAFE_CALL(cudnnDestroyTensorDescriptor(tensor_desc_0));
    CUDNN_SAFE_CALL(cudnnDestroyTensorDescriptor(tensor_desc_1));
    CUDNN_SAFE_CALL(cudnnDestroyFilterDescriptor(filter_desc));
    CUDNN_SAFE_CALL(cudnnDestroyConvolutionDescriptor(conv_desc));

}

    void executeImpl(cudaStream_t stream) {
        this->Convolution_float_float_float_cuda_lib_Convolution_843(cudnn_handle, input0, input1, output0);
    }
};


class inception3_Convolution_float_float_float_cuda_lib_Convolution_841Kernel : public Kernel {
public:
    inception3_Convolution_float_float_float_cuda_lib_Convolution_841Kernel(cudnnHandle_t  cudnn_handle, float*  input0, float*  input1, float*  output0, float*  Parameter_0_0, float**  Result_892_0) {
        this->cudnn_handle = cudnn_handle, this->input0 = input0, this->input1 = input1, this->output0 = output0, this->Parameter_0_0 = Parameter_0_0, this->Result_892_0 = Result_892_0;
        this->kernelName = "inception3_Convolution_float_float_float_cuda_lib_Convolution_841";
        this->Id = 0;
        this->mixable = 2;
    }

    void initParams() override {
        // empty implementation
    }

    void loadKernel() override {
        // Empty implementation
    }

        cudnnHandle_t  cudnn_handle; float*  input0; float*  input1; float*  output0;
    float*  Parameter_0_0; float**  Result_892_0;
private:

    
std::vector<int> getArgs() override {
    return std::vector<int>({64, 384, 8, 8, 384, 384, 1, 3, 0, 1, 1, 1, 1, 1});
}

    void Convolution_float_float_float_cuda_lib_Convolution_841(cudnnHandle_t cudnn_handle, float* input0, float* input1, float* output0)
{
    cudnnTensorDescriptor_t tensor_desc_0;
    CUDNN_SAFE_CALL(cudnnCreateTensorDescriptor(&tensor_desc_0));
    CUDNN_SAFE_CALL(cudnnSetTensor4dDescriptor(tensor_desc_0, CUDNN_TENSOR_NCHW, CUDNN_DATA_FLOAT, 64, 384, 8, 8));
    cudnnTensorDescriptor_t tensor_desc_1;
    CUDNN_SAFE_CALL(cudnnCreateTensorDescriptor(&tensor_desc_1));
    CUDNN_SAFE_CALL(cudnnSetTensor4dDescriptor(tensor_desc_1, CUDNN_TENSOR_NCHW, CUDNN_DATA_FLOAT, 64, 384, 8, 8));
    cudnnFilterDescriptor_t filter_desc;
    CUDNN_SAFE_CALL(cudnnCreateFilterDescriptor(&filter_desc));
    CUDNN_SAFE_CALL(cudnnSetFilter4dDescriptor(filter_desc, CUDNN_DATA_FLOAT, CUDNN_TENSOR_NCHW, 384, 384, 1, 3));
    cudnnConvolutionDescriptor_t conv_desc;
    CUDNN_SAFE_CALL(cudnnCreateConvolutionDescriptor(&conv_desc));
    CUDNN_SAFE_CALL(cudnnSetConvolution2dDescriptor(conv_desc, 0, 1, 1, 1, 1, 1, CUDNN_CROSS_CORRELATION, CUDNN_DATA_FLOAT));

    static bool selected_algo = true;
    static cudnnConvolutionFwdAlgo_t conv_fwd_algo = CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM;

    if (!selected_algo) {
        int num_algos;
        int max_algos = 0;
        // cudnnGetConvolutionForwardAlgorithm_v7;
        CUDNN_SAFE_CALL(
            cudnnGetConvolutionForwardAlgorithmMaxCount(cudnn_handle, &max_algos));
        std::vector<cudnnConvolutionFwdAlgoPerf_t> results(max_algos);
        CUDNN_SAFE_CALL(cudnnFindConvolutionForwardAlgorithm(cudnn_handle,
                                                tensor_desc_0,
                                                filter_desc,
                                                conv_desc,
                                                tensor_desc_1,
                                                static_cast<int>(results.size()),
                                                &num_algos,
                                                results.data()));
        results.resize(num_algos);
        for (size_t i = 0; i != results.size(); ++i) {
            cudnnConvolutionFwdAlgoPerf_t const& result = results[i];
            if (result.status == CUDNN_STATUS_SUCCESS) {
                conv_fwd_algo = result.algo;
                break;
            }
        }
        selected_algo = true;
    }
    const float alpha = 1.0;
    const float beta = 0.0;
    static void *workspace_ptr_0 = NULL;
    static size_t workspace_size_in_bytes = 0;
    if (!workspace_ptr_0)
    {
        CUDNN_SAFE_CALL(cudnnGetConvolutionForwardWorkspaceSize(cudnn_handle, tensor_desc_0, filter_desc, conv_desc, tensor_desc_1, conv_fwd_algo, &workspace_size_in_bytes));
        CUDA_SAFE_CALL(cudaMalloc(&workspace_ptr_0, workspace_size_in_bytes));
    }
    CUDNN_SAFE_CALL(mycudnnConvolutionForward(cudnn_handle, &alpha, tensor_desc_0, input0,filter_desc, input1, conv_desc, conv_fwd_algo, workspace_ptr_0, workspace_size_in_bytes, &beta, tensor_desc_1, output0));
    CUDNN_SAFE_CALL(cudnnDestroyTensorDescriptor(tensor_desc_0));
    CUDNN_SAFE_CALL(cudnnDestroyTensorDescriptor(tensor_desc_1));
    CUDNN_SAFE_CALL(cudnnDestroyFilterDescriptor(filter_desc));
    CUDNN_SAFE_CALL(cudnnDestroyConvolutionDescriptor(conv_desc));

}

    void executeImpl(cudaStream_t stream) {
        this->Convolution_float_float_float_cuda_lib_Convolution_841(cudnn_handle, input0, input1, output0);
    }
};


class inception3_Reshape_float_float_cuda_Reshape_813_CallKernel : public Kernel {
public:
    inception3_Reshape_float_float_cuda_Reshape_813_CallKernel(const dim3 & grids, const dim3 & blocks, unsigned  mem, cudaStream_t  stream, float*  input0, float*  output0, float*  Parameter_0_0, float**  Result_892_0) {
        this->grids = grids, this->blocks = blocks, this->mem = mem, this->stream = stream, this->input0 = input0, this->output0 = output0, this->Parameter_0_0 = Parameter_0_0, this->Result_892_0 = Result_892_0;
        this->kernelName = "inception3_Reshape_float_float_cuda_Reshape_813_Call";
        this->Id = 0;
        this->mixable = 0;
    }

    void initParams() override {
        // empty implementation
    }

    void loadKernel() override {
        // Empty implementation
    }

        dim3  grids; dim3  blocks; unsigned  mem; cudaStream_t  stream; float*  input0; float*  output0;
    float*  Parameter_0_0; float**  Result_892_0;
private:

    
std::vector<int> getArgs() override {
    return std::vector<int>();
}

     void Reshape_float_float_cuda_Reshape_813_Call(const dim3 &grids, const dim3 &blocks, unsigned mem, cudaStream_t stream, float* input0, float* output0) {
    inception3_Reshape_float_float_cuda_Reshape_813<<<grids, blocks, mem, stream>>>(input0, output0);
}

    void executeImpl(cudaStream_t stream) {
        this->Reshape_float_float_cuda_Reshape_813_Call(grids, blocks, mem, stream, input0, output0);
    }
};


class inception3_Convolution_float_float_float_cuda_lib_Convolution_814Kernel : public Kernel {
public:
    inception3_Convolution_float_float_float_cuda_lib_Convolution_814Kernel(cudnnHandle_t  cudnn_handle, float*  input0, float*  input1, float*  output0, float*  Parameter_0_0, float**  Result_892_0) {
        this->cudnn_handle = cudnn_handle, this->input0 = input0, this->input1 = input1, this->output0 = output0, this->Parameter_0_0 = Parameter_0_0, this->Result_892_0 = Result_892_0;
        this->kernelName = "inception3_Convolution_float_float_float_cuda_lib_Convolution_814";
        this->Id = 0;
        this->mixable = 2;
    }

    void initParams() override {
        // empty implementation
    }

    void loadKernel() override {
        // Empty implementation
    }

        cudnnHandle_t  cudnn_handle; float*  input0; float*  input1; float*  output0;
    float*  Parameter_0_0; float**  Result_892_0;
private:

    
std::vector<int> getArgs() override {
    return std::vector<int>({64, 1280, 8, 8, 384, 1280, 1, 1, 0, 0, 1, 1, 1, 1});
}

    void Convolution_float_float_float_cuda_lib_Convolution_814(cudnnHandle_t cudnn_handle, float* input0, float* input1, float* output0)
{
    cudnnTensorDescriptor_t tensor_desc_0;
    CUDNN_SAFE_CALL(cudnnCreateTensorDescriptor(&tensor_desc_0));
    CUDNN_SAFE_CALL(cudnnSetTensor4dDescriptor(tensor_desc_0, CUDNN_TENSOR_NCHW, CUDNN_DATA_FLOAT, 64, 1280, 8, 8));
    cudnnTensorDescriptor_t tensor_desc_1;
    CUDNN_SAFE_CALL(cudnnCreateTensorDescriptor(&tensor_desc_1));
    CUDNN_SAFE_CALL(cudnnSetTensor4dDescriptor(tensor_desc_1, CUDNN_TENSOR_NCHW, CUDNN_DATA_FLOAT, 64, 384, 8, 8));
    cudnnFilterDescriptor_t filter_desc;
    CUDNN_SAFE_CALL(cudnnCreateFilterDescriptor(&filter_desc));
    CUDNN_SAFE_CALL(cudnnSetFilter4dDescriptor(filter_desc, CUDNN_DATA_FLOAT, CUDNN_TENSOR_NCHW, 384, 1280, 1, 1));
    cudnnConvolutionDescriptor_t conv_desc;
    CUDNN_SAFE_CALL(cudnnCreateConvolutionDescriptor(&conv_desc));
    CUDNN_SAFE_CALL(cudnnSetConvolution2dDescriptor(conv_desc, 0, 0, 1, 1, 1, 1, CUDNN_CROSS_CORRELATION, CUDNN_DATA_FLOAT));

    static bool selected_algo = true;
    static cudnnConvolutionFwdAlgo_t conv_fwd_algo = CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM;

    if (!selected_algo) {
        int num_algos;
        int max_algos = 0;
        // cudnnGetConvolutionForwardAlgorithm_v7;
        CUDNN_SAFE_CALL(
            cudnnGetConvolutionForwardAlgorithmMaxCount(cudnn_handle, &max_algos));
        std::vector<cudnnConvolutionFwdAlgoPerf_t> results(max_algos);
        CUDNN_SAFE_CALL(cudnnFindConvolutionForwardAlgorithm(cudnn_handle,
                                                tensor_desc_0,
                                                filter_desc,
                                                conv_desc,
                                                tensor_desc_1,
                                                static_cast<int>(results.size()),
                                                &num_algos,
                                                results.data()));
        results.resize(num_algos);
        for (size_t i = 0; i != results.size(); ++i) {
            cudnnConvolutionFwdAlgoPerf_t const& result = results[i];
            if (result.status == CUDNN_STATUS_SUCCESS) {
                conv_fwd_algo = result.algo;
                break;
            }
        }
        selected_algo = true;
    }
    const float alpha = 1.0;
    const float beta = 0.0;
    static void *workspace_ptr_0 = NULL;
    static size_t workspace_size_in_bytes = 0;
    if (!workspace_ptr_0)
    {
        CUDNN_SAFE_CALL(cudnnGetConvolutionForwardWorkspaceSize(cudnn_handle, tensor_desc_0, filter_desc, conv_desc, tensor_desc_1, conv_fwd_algo, &workspace_size_in_bytes));
        CUDA_SAFE_CALL(cudaMalloc(&workspace_ptr_0, workspace_size_in_bytes));
    }
    CUDNN_SAFE_CALL(mycudnnConvolutionForward(cudnn_handle, &alpha, tensor_desc_0, input0,filter_desc, input1, conv_desc, conv_fwd_algo, workspace_ptr_0, workspace_size_in_bytes, &beta, tensor_desc_1, output0));
    CUDNN_SAFE_CALL(cudnnDestroyTensorDescriptor(tensor_desc_0));
    CUDNN_SAFE_CALL(cudnnDestroyTensorDescriptor(tensor_desc_1));
    CUDNN_SAFE_CALL(cudnnDestroyFilterDescriptor(filter_desc));
    CUDNN_SAFE_CALL(cudnnDestroyConvolutionDescriptor(conv_desc));

}

    void executeImpl(cudaStream_t stream) {
        this->Convolution_float_float_float_cuda_lib_Convolution_814(cudnn_handle, input0, input1, output0);
    }
};


class inception3_Reshape_float_float_cuda_Reshape_811_CallKernel : public Kernel {
public:
    inception3_Reshape_float_float_cuda_Reshape_811_CallKernel(const dim3 & grids, const dim3 & blocks, unsigned  mem, cudaStream_t  stream, float*  input0, float*  output0, float*  Parameter_0_0, float**  Result_892_0) {
        this->grids = grids, this->blocks = blocks, this->mem = mem, this->stream = stream, this->input0 = input0, this->output0 = output0, this->Parameter_0_0 = Parameter_0_0, this->Result_892_0 = Result_892_0;
        this->kernelName = "inception3_Reshape_float_float_cuda_Reshape_811_Call";
        this->Id = 0;
        this->mixable = 0;
    }

    void initParams() override {
        // empty implementation
    }

    void loadKernel() override {
        // Empty implementation
    }

        dim3  grids; dim3  blocks; unsigned  mem; cudaStream_t  stream; float*  input0; float*  output0;
    float*  Parameter_0_0; float**  Result_892_0;
private:

    
std::vector<int> getArgs() override {
    return std::vector<int>();
}

     void Reshape_float_float_cuda_Reshape_811_Call(const dim3 &grids, const dim3 &blocks, unsigned mem, cudaStream_t stream, float* input0, float* output0) {
    inception3_Reshape_float_float_cuda_Reshape_811<<<grids, blocks, mem, stream>>>(input0, output0);
}

    void executeImpl(cudaStream_t stream) {
        this->Reshape_float_float_cuda_Reshape_811_Call(grids, blocks, mem, stream, input0, output0);
    }
};


class inception3_Convolution_float_float_float_cuda_lib_Convolution_812Kernel : public Kernel {
public:
    inception3_Convolution_float_float_float_cuda_lib_Convolution_812Kernel(cudnnHandle_t  cudnn_handle, float*  input0, float*  input1, float*  output0, float*  Parameter_0_0, float**  Result_892_0) {
        this->cudnn_handle = cudnn_handle, this->input0 = input0, this->input1 = input1, this->output0 = output0, this->Parameter_0_0 = Parameter_0_0, this->Result_892_0 = Result_892_0;
        this->kernelName = "inception3_Convolution_float_float_float_cuda_lib_Convolution_812";
        this->Id = 0;
        this->mixable = 2;
    }

    void initParams() override {
        // empty implementation
    }

    void loadKernel() override {
        // Empty implementation
    }

        cudnnHandle_t  cudnn_handle; float*  input0; float*  input1; float*  output0;
    float*  Parameter_0_0; float**  Result_892_0;
private:

    
std::vector<int> getArgs() override {
    return std::vector<int>({64, 1280, 8, 8, 320, 1280, 1, 1, 0, 0, 1, 1, 1, 1});
}

    void Convolution_float_float_float_cuda_lib_Convolution_812(cudnnHandle_t cudnn_handle, float* input0, float* input1, float* output0)
{
    cudnnTensorDescriptor_t tensor_desc_0;
    CUDNN_SAFE_CALL(cudnnCreateTensorDescriptor(&tensor_desc_0));
    CUDNN_SAFE_CALL(cudnnSetTensor4dDescriptor(tensor_desc_0, CUDNN_TENSOR_NCHW, CUDNN_DATA_FLOAT, 64, 1280, 8, 8));
    cudnnTensorDescriptor_t tensor_desc_1;
    CUDNN_SAFE_CALL(cudnnCreateTensorDescriptor(&tensor_desc_1));
    CUDNN_SAFE_CALL(cudnnSetTensor4dDescriptor(tensor_desc_1, CUDNN_TENSOR_NCHW, CUDNN_DATA_FLOAT, 64, 320, 8, 8));
    cudnnFilterDescriptor_t filter_desc;
    CUDNN_SAFE_CALL(cudnnCreateFilterDescriptor(&filter_desc));
    CUDNN_SAFE_CALL(cudnnSetFilter4dDescriptor(filter_desc, CUDNN_DATA_FLOAT, CUDNN_TENSOR_NCHW, 320, 1280, 1, 1));
    cudnnConvolutionDescriptor_t conv_desc;
    CUDNN_SAFE_CALL(cudnnCreateConvolutionDescriptor(&conv_desc));
    CUDNN_SAFE_CALL(cudnnSetConvolution2dDescriptor(conv_desc, 0, 0, 1, 1, 1, 1, CUDNN_CROSS_CORRELATION, CUDNN_DATA_FLOAT));

    static bool selected_algo = true;
    static cudnnConvolutionFwdAlgo_t conv_fwd_algo = CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM;

    if (!selected_algo) {
        int num_algos;
        int max_algos = 0;
        // cudnnGetConvolutionForwardAlgorithm_v7;
        CUDNN_SAFE_CALL(
            cudnnGetConvolutionForwardAlgorithmMaxCount(cudnn_handle, &max_algos));
        std::vector<cudnnConvolutionFwdAlgoPerf_t> results(max_algos);
        CUDNN_SAFE_CALL(cudnnFindConvolutionForwardAlgorithm(cudnn_handle,
                                                tensor_desc_0,
                                                filter_desc,
                                                conv_desc,
                                                tensor_desc_1,
                                                static_cast<int>(results.size()),
                                                &num_algos,
                                                results.data()));
        results.resize(num_algos);
        for (size_t i = 0; i != results.size(); ++i) {
            cudnnConvolutionFwdAlgoPerf_t const& result = results[i];
            if (result.status == CUDNN_STATUS_SUCCESS) {
                conv_fwd_algo = result.algo;
                break;
            }
        }
        selected_algo = true;
    }
    const float alpha = 1.0;
    const float beta = 0.0;
    static void *workspace_ptr_0 = NULL;
    static size_t workspace_size_in_bytes = 0;
    if (!workspace_ptr_0)
    {
        CUDNN_SAFE_CALL(cudnnGetConvolutionForwardWorkspaceSize(cudnn_handle, tensor_desc_0, filter_desc, conv_desc, tensor_desc_1, conv_fwd_algo, &workspace_size_in_bytes));
        CUDA_SAFE_CALL(cudaMalloc(&workspace_ptr_0, workspace_size_in_bytes));
    }
    CUDNN_SAFE_CALL(mycudnnConvolutionForward(cudnn_handle, &alpha, tensor_desc_0, input0,filter_desc, input1, conv_desc, conv_fwd_algo, workspace_ptr_0, workspace_size_in_bytes, &beta, tensor_desc_1, output0));
    CUDNN_SAFE_CALL(cudnnDestroyTensorDescriptor(tensor_desc_0));
    CUDNN_SAFE_CALL(cudnnDestroyTensorDescriptor(tensor_desc_1));
    CUDNN_SAFE_CALL(cudnnDestroyFilterDescriptor(filter_desc));
    CUDNN_SAFE_CALL(cudnnDestroyConvolutionDescriptor(conv_desc));

}

    void executeImpl(cudaStream_t stream) {
        this->Convolution_float_float_float_cuda_lib_Convolution_812(cudnn_handle, input0, input1, output0);
    }
};


class inception3_Concat_float_float_float_float_float_float_float_cuda_Concat_848_CallKernel : public Kernel {
public:
    inception3_Concat_float_float_float_float_float_float_float_cuda_Concat_848_CallKernel(const dim3 & grids, const dim3 & blocks, unsigned  mem, cudaStream_t  stream, float*  input0, float*  input1, float*  input2, float*  input3, float*  input4, float*  input5, float*  output0, float*  Parameter_0_0, float**  Result_892_0) {
        this->grids = grids, this->blocks = blocks, this->mem = mem, this->stream = stream, this->input0 = input0, this->input1 = input1, this->input2 = input2, this->input3 = input3, this->input4 = input4, this->input5 = input5, this->output0 = output0, this->Parameter_0_0 = Parameter_0_0, this->Result_892_0 = Result_892_0;
        this->kernelName = "inception3_Concat_float_float_float_float_float_float_float_cuda_Concat_848_Call";
        this->Id = 0;
        this->mixable = 0;
    }

    void initParams() override {
        // empty implementation
    }

    void loadKernel() override {
        // Empty implementation
    }

        dim3  grids; dim3  blocks; unsigned  mem; cudaStream_t  stream; float*  input0; float*  input1; float*  input2; float*  input3; float*  input4; float*  input5; float*  output0;
    float*  Parameter_0_0; float**  Result_892_0;
private:

    
std::vector<int> getArgs() override {
    return std::vector<int>();
}

     void Concat_float_float_float_float_float_float_float_cuda_Concat_848_Call(const dim3 &grids, const dim3 &blocks, unsigned mem, cudaStream_t stream, float* input0, float* input1, float* input2, float* input3, float* input4, float* input5, float* output0) {
    inception3_Concat_float_float_float_float_float_float_float_cuda_Concat_848<<<grids, blocks, mem, stream>>>(input0, input1, input2, input3, input4, input5, output0);
}

    void executeImpl(cudaStream_t stream) {
        this->Concat_float_float_float_float_float_float_float_cuda_Concat_848_Call(grids, blocks, mem, stream, input0, input1, input2, input3, input4, input5, output0);
    }
};


class inception3_MaxPool_float_float_cuda_lib_MaxPool_855Kernel : public Kernel {
public:
    inception3_MaxPool_float_float_cuda_lib_MaxPool_855Kernel(cudnnHandle_t  cudnn_handle, float*  input0, float*  output0, float*  Parameter_0_0, float**  Result_892_0) {
        this->cudnn_handle = cudnn_handle, this->input0 = input0, this->output0 = output0, this->Parameter_0_0 = Parameter_0_0, this->Result_892_0 = Result_892_0;
        this->kernelName = "inception3_MaxPool_float_float_cuda_lib_MaxPool_855";
        this->Id = 0;
        this->mixable = 0;
    }

    void initParams() override {
        // empty implementation
    }

    void loadKernel() override {
        // Empty implementation
    }

        cudnnHandle_t  cudnn_handle; float*  input0; float*  output0;
    float*  Parameter_0_0; float**  Result_892_0;
private:

    
std::vector<int> getArgs() override {
    return std::vector<int>();
}

    void MaxPool_float_float_cuda_lib_MaxPool_855(cudnnHandle_t cudnn_handle, float* input0, float* output0)
{
    cudnnTensorDescriptor_t input_desc;
    CUDNN_SAFE_CALL(cudnnCreateTensorDescriptor(&input_desc));
    CUDNN_SAFE_CALL(cudnnSetTensor4dDescriptor(input_desc, CUDNN_TENSOR_NCHW, CUDNN_DATA_FLOAT, 64, 2048, 8, 8));
    cudnnTensorDescriptor_t output_desc;
    CUDNN_SAFE_CALL(cudnnCreateTensorDescriptor(&output_desc));
    CUDNN_SAFE_CALL(cudnnSetTensor4dDescriptor(output_desc, CUDNN_TENSOR_NCHW, CUDNN_DATA_FLOAT, 64, 2048, 8, 8));
    cudnnPoolingDescriptor_t desc;
    cudnnCreatePoolingDescriptor(&desc);
    CUDNN_SAFE_CALL(cudnnSetPooling2dDescriptor(desc, CUDNN_POOLING_MAX, CUDNN_NOT_PROPAGATE_NAN,3, 3, 1, 1, 1, 1));
    const float alpha = 1.0;
    const float beta = 0.0;
    CUDNN_SAFE_CALL(cudnnPoolingForward(cudnn_handle, desc, &alpha, input_desc, input0, &beta, output_desc, output0));
    CUDNN_SAFE_CALL(cudnnDestroyTensorDescriptor(input_desc));
    CUDNN_SAFE_CALL(cudnnDestroyTensorDescriptor(output_desc));
    CUDNN_SAFE_CALL(cudnnDestroyPoolingDescriptor(desc));

}

    void executeImpl(cudaStream_t stream) {
        this->MaxPool_float_float_cuda_lib_MaxPool_855(cudnn_handle, input0, output0);
    }
};


class inception3_Reshape_float_float_cuda_Reshape_859_CallKernel : public Kernel {
public:
    inception3_Reshape_float_float_cuda_Reshape_859_CallKernel(const dim3 & grids, const dim3 & blocks, unsigned  mem, cudaStream_t  stream, float*  input0, float*  output0, float*  Parameter_0_0, float**  Result_892_0) {
        this->grids = grids, this->blocks = blocks, this->mem = mem, this->stream = stream, this->input0 = input0, this->output0 = output0, this->Parameter_0_0 = Parameter_0_0, this->Result_892_0 = Result_892_0;
        this->kernelName = "inception3_Reshape_float_float_cuda_Reshape_859_Call";
        this->Id = 0;
        this->mixable = 0;
    }

    void initParams() override {
        // empty implementation
    }

    void loadKernel() override {
        // Empty implementation
    }

        dim3  grids; dim3  blocks; unsigned  mem; cudaStream_t  stream; float*  input0; float*  output0;
    float*  Parameter_0_0; float**  Result_892_0;
private:

    
std::vector<int> getArgs() override {
    return std::vector<int>();
}

     void Reshape_float_float_cuda_Reshape_859_Call(const dim3 &grids, const dim3 &blocks, unsigned mem, cudaStream_t stream, float* input0, float* output0) {
    inception3_Reshape_float_float_cuda_Reshape_859<<<grids, blocks, mem, stream>>>(input0, output0);
}

    void executeImpl(cudaStream_t stream) {
        this->Reshape_float_float_cuda_Reshape_859_Call(grids, blocks, mem, stream, input0, output0);
    }
};


class inception3_Convolution_float_float_float_cuda_lib_Convolution_860Kernel : public Kernel {
public:
    inception3_Convolution_float_float_float_cuda_lib_Convolution_860Kernel(cudnnHandle_t  cudnn_handle, float*  input0, float*  input1, float*  output0, float*  Parameter_0_0, float**  Result_892_0) {
        this->cudnn_handle = cudnn_handle, this->input0 = input0, this->input1 = input1, this->output0 = output0, this->Parameter_0_0 = Parameter_0_0, this->Result_892_0 = Result_892_0;
        this->kernelName = "inception3_Convolution_float_float_float_cuda_lib_Convolution_860";
        this->Id = 0;
        this->mixable = 2;
    }

    void initParams() override {
        // empty implementation
    }

    void loadKernel() override {
        // Empty implementation
    }

        cudnnHandle_t  cudnn_handle; float*  input0; float*  input1; float*  output0;
    float*  Parameter_0_0; float**  Result_892_0;
private:

    
std::vector<int> getArgs() override {
    return std::vector<int>({64, 2048, 8, 8, 192, 2048, 1, 1, 0, 0, 1, 1, 1, 1});
}

    void Convolution_float_float_float_cuda_lib_Convolution_860(cudnnHandle_t cudnn_handle, float* input0, float* input1, float* output0)
{
    cudnnTensorDescriptor_t tensor_desc_0;
    CUDNN_SAFE_CALL(cudnnCreateTensorDescriptor(&tensor_desc_0));
    CUDNN_SAFE_CALL(cudnnSetTensor4dDescriptor(tensor_desc_0, CUDNN_TENSOR_NCHW, CUDNN_DATA_FLOAT, 64, 2048, 8, 8));
    cudnnTensorDescriptor_t tensor_desc_1;
    CUDNN_SAFE_CALL(cudnnCreateTensorDescriptor(&tensor_desc_1));
    CUDNN_SAFE_CALL(cudnnSetTensor4dDescriptor(tensor_desc_1, CUDNN_TENSOR_NCHW, CUDNN_DATA_FLOAT, 64, 192, 8, 8));
    cudnnFilterDescriptor_t filter_desc;
    CUDNN_SAFE_CALL(cudnnCreateFilterDescriptor(&filter_desc));
    CUDNN_SAFE_CALL(cudnnSetFilter4dDescriptor(filter_desc, CUDNN_DATA_FLOAT, CUDNN_TENSOR_NCHW, 192, 2048, 1, 1));
    cudnnConvolutionDescriptor_t conv_desc;
    CUDNN_SAFE_CALL(cudnnCreateConvolutionDescriptor(&conv_desc));
    CUDNN_SAFE_CALL(cudnnSetConvolution2dDescriptor(conv_desc, 0, 0, 1, 1, 1, 1, CUDNN_CROSS_CORRELATION, CUDNN_DATA_FLOAT));

    static bool selected_algo = true;
    static cudnnConvolutionFwdAlgo_t conv_fwd_algo = CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM;

    if (!selected_algo) {
        int num_algos;
        int max_algos = 0;
        // cudnnGetConvolutionForwardAlgorithm_v7;
        CUDNN_SAFE_CALL(
            cudnnGetConvolutionForwardAlgorithmMaxCount(cudnn_handle, &max_algos));
        std::vector<cudnnConvolutionFwdAlgoPerf_t> results(max_algos);
        CUDNN_SAFE_CALL(cudnnFindConvolutionForwardAlgorithm(cudnn_handle,
                                                tensor_desc_0,
                                                filter_desc,
                                                conv_desc,
                                                tensor_desc_1,
                                                static_cast<int>(results.size()),
                                                &num_algos,
                                                results.data()));
        results.resize(num_algos);
        for (size_t i = 0; i != results.size(); ++i) {
            cudnnConvolutionFwdAlgoPerf_t const& result = results[i];
            if (result.status == CUDNN_STATUS_SUCCESS) {
                conv_fwd_algo = result.algo;
                break;
            }
        }
        selected_algo = true;
    }
    const float alpha = 1.0;
    const float beta = 0.0;
    static void *workspace_ptr_0 = NULL;
    static size_t workspace_size_in_bytes = 0;
    if (!workspace_ptr_0)
    {
        CUDNN_SAFE_CALL(cudnnGetConvolutionForwardWorkspaceSize(cudnn_handle, tensor_desc_0, filter_desc, conv_desc, tensor_desc_1, conv_fwd_algo, &workspace_size_in_bytes));
        CUDA_SAFE_CALL(cudaMalloc(&workspace_ptr_0, workspace_size_in_bytes));
    }
    CUDNN_SAFE_CALL(mycudnnConvolutionForward(cudnn_handle, &alpha, tensor_desc_0, input0,filter_desc, input1, conv_desc, conv_fwd_algo, workspace_ptr_0, workspace_size_in_bytes, &beta, tensor_desc_1, output0));
    CUDNN_SAFE_CALL(cudnnDestroyTensorDescriptor(tensor_desc_0));
    CUDNN_SAFE_CALL(cudnnDestroyTensorDescriptor(tensor_desc_1));
    CUDNN_SAFE_CALL(cudnnDestroyFilterDescriptor(filter_desc));
    CUDNN_SAFE_CALL(cudnnDestroyConvolutionDescriptor(conv_desc));

}

    void executeImpl(cudaStream_t stream) {
        this->Convolution_float_float_float_cuda_lib_Convolution_860(cudnn_handle, input0, input1, output0);
    }
};


class inception3_Reshape_float_float_cuda_Reshape_853_CallKernel : public Kernel {
public:
    inception3_Reshape_float_float_cuda_Reshape_853_CallKernel(const dim3 & grids, const dim3 & blocks, unsigned  mem, cudaStream_t  stream, float*  input0, float*  output0, float*  Parameter_0_0, float**  Result_892_0) {
        this->grids = grids, this->blocks = blocks, this->mem = mem, this->stream = stream, this->input0 = input0, this->output0 = output0, this->Parameter_0_0 = Parameter_0_0, this->Result_892_0 = Result_892_0;
        this->kernelName = "inception3_Reshape_float_float_cuda_Reshape_853_Call";
        this->Id = 0;
        this->mixable = 0;
    }

    void initParams() override {
        // empty implementation
    }

    void loadKernel() override {
        // Empty implementation
    }

        dim3  grids; dim3  blocks; unsigned  mem; cudaStream_t  stream; float*  input0; float*  output0;
    float*  Parameter_0_0; float**  Result_892_0;
private:

    
std::vector<int> getArgs() override {
    return std::vector<int>();
}

     void Reshape_float_float_cuda_Reshape_853_Call(const dim3 &grids, const dim3 &blocks, unsigned mem, cudaStream_t stream, float* input0, float* output0) {
    inception3_Reshape_float_float_cuda_Reshape_853<<<grids, blocks, mem, stream>>>(input0, output0);
}

    void executeImpl(cudaStream_t stream) {
        this->Reshape_float_float_cuda_Reshape_853_Call(grids, blocks, mem, stream, input0, output0);
    }
};


class inception3_Convolution_float_float_float_cuda_lib_Convolution_854Kernel : public Kernel {
public:
    inception3_Convolution_float_float_float_cuda_lib_Convolution_854Kernel(cudnnHandle_t  cudnn_handle, float*  input0, float*  input1, float*  output0, float*  Parameter_0_0, float**  Result_892_0) {
        this->cudnn_handle = cudnn_handle, this->input0 = input0, this->input1 = input1, this->output0 = output0, this->Parameter_0_0 = Parameter_0_0, this->Result_892_0 = Result_892_0;
        this->kernelName = "inception3_Convolution_float_float_float_cuda_lib_Convolution_854";
        this->Id = 0;
        this->mixable = 2;
    }

    void initParams() override {
        // empty implementation
    }

    void loadKernel() override {
        // Empty implementation
    }

        cudnnHandle_t  cudnn_handle; float*  input0; float*  input1; float*  output0;
    float*  Parameter_0_0; float**  Result_892_0;
private:

    
std::vector<int> getArgs() override {
    return std::vector<int>({64, 2048, 8, 8, 448, 2048, 1, 1, 0, 0, 1, 1, 1, 1});
}

    void Convolution_float_float_float_cuda_lib_Convolution_854(cudnnHandle_t cudnn_handle, float* input0, float* input1, float* output0)
{
    cudnnTensorDescriptor_t tensor_desc_0;
    CUDNN_SAFE_CALL(cudnnCreateTensorDescriptor(&tensor_desc_0));
    CUDNN_SAFE_CALL(cudnnSetTensor4dDescriptor(tensor_desc_0, CUDNN_TENSOR_NCHW, CUDNN_DATA_FLOAT, 64, 2048, 8, 8));
    cudnnTensorDescriptor_t tensor_desc_1;
    CUDNN_SAFE_CALL(cudnnCreateTensorDescriptor(&tensor_desc_1));
    CUDNN_SAFE_CALL(cudnnSetTensor4dDescriptor(tensor_desc_1, CUDNN_TENSOR_NCHW, CUDNN_DATA_FLOAT, 64, 448, 8, 8));
    cudnnFilterDescriptor_t filter_desc;
    CUDNN_SAFE_CALL(cudnnCreateFilterDescriptor(&filter_desc));
    CUDNN_SAFE_CALL(cudnnSetFilter4dDescriptor(filter_desc, CUDNN_DATA_FLOAT, CUDNN_TENSOR_NCHW, 448, 2048, 1, 1));
    cudnnConvolutionDescriptor_t conv_desc;
    CUDNN_SAFE_CALL(cudnnCreateConvolutionDescriptor(&conv_desc));
    CUDNN_SAFE_CALL(cudnnSetConvolution2dDescriptor(conv_desc, 0, 0, 1, 1, 1, 1, CUDNN_CROSS_CORRELATION, CUDNN_DATA_FLOAT));

    static bool selected_algo = true;
    static cudnnConvolutionFwdAlgo_t conv_fwd_algo = CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM;

    if (!selected_algo) {
        int num_algos;
        int max_algos = 0;
        // cudnnGetConvolutionForwardAlgorithm_v7;
        CUDNN_SAFE_CALL(
            cudnnGetConvolutionForwardAlgorithmMaxCount(cudnn_handle, &max_algos));
        std::vector<cudnnConvolutionFwdAlgoPerf_t> results(max_algos);
        CUDNN_SAFE_CALL(cudnnFindConvolutionForwardAlgorithm(cudnn_handle,
                                                tensor_desc_0,
                                                filter_desc,
                                                conv_desc,
                                                tensor_desc_1,
                                                static_cast<int>(results.size()),
                                                &num_algos,
                                                results.data()));
        results.resize(num_algos);
        for (size_t i = 0; i != results.size(); ++i) {
            cudnnConvolutionFwdAlgoPerf_t const& result = results[i];
            if (result.status == CUDNN_STATUS_SUCCESS) {
                conv_fwd_algo = result.algo;
                break;
            }
        }
        selected_algo = true;
    }
    const float alpha = 1.0;
    const float beta = 0.0;
    static void *workspace_ptr_0 = NULL;
    static size_t workspace_size_in_bytes = 0;
    if (!workspace_ptr_0)
    {
        CUDNN_SAFE_CALL(cudnnGetConvolutionForwardWorkspaceSize(cudnn_handle, tensor_desc_0, filter_desc, conv_desc, tensor_desc_1, conv_fwd_algo, &workspace_size_in_bytes));
        CUDA_SAFE_CALL(cudaMalloc(&workspace_ptr_0, workspace_size_in_bytes));
    }
    CUDNN_SAFE_CALL(mycudnnConvolutionForward(cudnn_handle, &alpha, tensor_desc_0, input0,filter_desc, input1, conv_desc, conv_fwd_algo, workspace_ptr_0, workspace_size_in_bytes, &beta, tensor_desc_1, output0));
    CUDNN_SAFE_CALL(cudnnDestroyTensorDescriptor(tensor_desc_0));
    CUDNN_SAFE_CALL(cudnnDestroyTensorDescriptor(tensor_desc_1));
    CUDNN_SAFE_CALL(cudnnDestroyFilterDescriptor(filter_desc));
    CUDNN_SAFE_CALL(cudnnDestroyConvolutionDescriptor(conv_desc));

}

    void executeImpl(cudaStream_t stream) {
        this->Convolution_float_float_float_cuda_lib_Convolution_854(cudnn_handle, input0, input1, output0);
    }
};


class inception3_Reshape_float_float_cuda_Reshape_851_CallKernel : public Kernel {
public:
    inception3_Reshape_float_float_cuda_Reshape_851_CallKernel(const dim3 & grids, const dim3 & blocks, unsigned  mem, cudaStream_t  stream, float*  input0, float*  output0, float*  Parameter_0_0, float**  Result_892_0) {
        this->grids = grids, this->blocks = blocks, this->mem = mem, this->stream = stream, this->input0 = input0, this->output0 = output0, this->Parameter_0_0 = Parameter_0_0, this->Result_892_0 = Result_892_0;
        this->kernelName = "inception3_Reshape_float_float_cuda_Reshape_851_Call";
        this->Id = 0;
        this->mixable = 0;
    }

    void initParams() override {
        // empty implementation
    }

    void loadKernel() override {
        // Empty implementation
    }

        dim3  grids; dim3  blocks; unsigned  mem; cudaStream_t  stream; float*  input0; float*  output0;
    float*  Parameter_0_0; float**  Result_892_0;
private:

    
std::vector<int> getArgs() override {
    return std::vector<int>();
}

     void Reshape_float_float_cuda_Reshape_851_Call(const dim3 &grids, const dim3 &blocks, unsigned mem, cudaStream_t stream, float* input0, float* output0) {
    inception3_Reshape_float_float_cuda_Reshape_851<<<grids, blocks, mem, stream>>>(input0, output0);
}

    void executeImpl(cudaStream_t stream) {
        this->Reshape_float_float_cuda_Reshape_851_Call(grids, blocks, mem, stream, input0, output0);
    }
};


class inception3_Convolution_float_float_float_cuda_lib_Convolution_852Kernel : public Kernel {
public:
    inception3_Convolution_float_float_float_cuda_lib_Convolution_852Kernel(cudnnHandle_t  cudnn_handle, float*  input0, float*  input1, float*  output0, float*  Parameter_0_0, float**  Result_892_0) {
        this->cudnn_handle = cudnn_handle, this->input0 = input0, this->input1 = input1, this->output0 = output0, this->Parameter_0_0 = Parameter_0_0, this->Result_892_0 = Result_892_0;
        this->kernelName = "inception3_Convolution_float_float_float_cuda_lib_Convolution_852";
        this->Id = 0;
        this->mixable = 2;
    }

    void initParams() override {
        // empty implementation
    }

    void loadKernel() override {
        // Empty implementation
    }

        cudnnHandle_t  cudnn_handle; float*  input0; float*  input1; float*  output0;
    float*  Parameter_0_0; float**  Result_892_0;
private:

    
std::vector<int> getArgs() override {
    return std::vector<int>({64, 2048, 8, 8, 384, 2048, 1, 1, 0, 0, 1, 1, 1, 1});
}

    void Convolution_float_float_float_cuda_lib_Convolution_852(cudnnHandle_t cudnn_handle, float* input0, float* input1, float* output0)
{
    cudnnTensorDescriptor_t tensor_desc_0;
    CUDNN_SAFE_CALL(cudnnCreateTensorDescriptor(&tensor_desc_0));
    CUDNN_SAFE_CALL(cudnnSetTensor4dDescriptor(tensor_desc_0, CUDNN_TENSOR_NCHW, CUDNN_DATA_FLOAT, 64, 2048, 8, 8));
    cudnnTensorDescriptor_t tensor_desc_1;
    CUDNN_SAFE_CALL(cudnnCreateTensorDescriptor(&tensor_desc_1));
    CUDNN_SAFE_CALL(cudnnSetTensor4dDescriptor(tensor_desc_1, CUDNN_TENSOR_NCHW, CUDNN_DATA_FLOAT, 64, 384, 8, 8));
    cudnnFilterDescriptor_t filter_desc;
    CUDNN_SAFE_CALL(cudnnCreateFilterDescriptor(&filter_desc));
    CUDNN_SAFE_CALL(cudnnSetFilter4dDescriptor(filter_desc, CUDNN_DATA_FLOAT, CUDNN_TENSOR_NCHW, 384, 2048, 1, 1));
    cudnnConvolutionDescriptor_t conv_desc;
    CUDNN_SAFE_CALL(cudnnCreateConvolutionDescriptor(&conv_desc));
    CUDNN_SAFE_CALL(cudnnSetConvolution2dDescriptor(conv_desc, 0, 0, 1, 1, 1, 1, CUDNN_CROSS_CORRELATION, CUDNN_DATA_FLOAT));

    static bool selected_algo = true;
    static cudnnConvolutionFwdAlgo_t conv_fwd_algo = CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM;

    if (!selected_algo) {
        int num_algos;
        int max_algos = 0;
        // cudnnGetConvolutionForwardAlgorithm_v7;
        CUDNN_SAFE_CALL(
            cudnnGetConvolutionForwardAlgorithmMaxCount(cudnn_handle, &max_algos));
        std::vector<cudnnConvolutionFwdAlgoPerf_t> results(max_algos);
        CUDNN_SAFE_CALL(cudnnFindConvolutionForwardAlgorithm(cudnn_handle,
                                                tensor_desc_0,
                                                filter_desc,
                                                conv_desc,
                                                tensor_desc_1,
                                                static_cast<int>(results.size()),
                                                &num_algos,
                                                results.data()));
        results.resize(num_algos);
        for (size_t i = 0; i != results.size(); ++i) {
            cudnnConvolutionFwdAlgoPerf_t const& result = results[i];
            if (result.status == CUDNN_STATUS_SUCCESS) {
                conv_fwd_algo = result.algo;
                break;
            }
        }
        selected_algo = true;
    }
    const float alpha = 1.0;
    const float beta = 0.0;
    static void *workspace_ptr_0 = NULL;
    static size_t workspace_size_in_bytes = 0;
    if (!workspace_ptr_0)
    {
        CUDNN_SAFE_CALL(cudnnGetConvolutionForwardWorkspaceSize(cudnn_handle, tensor_desc_0, filter_desc, conv_desc, tensor_desc_1, conv_fwd_algo, &workspace_size_in_bytes));
        CUDA_SAFE_CALL(cudaMalloc(&workspace_ptr_0, workspace_size_in_bytes));
    }
    CUDNN_SAFE_CALL(mycudnnConvolutionForward(cudnn_handle, &alpha, tensor_desc_0, input0,filter_desc, input1, conv_desc, conv_fwd_algo, workspace_ptr_0, workspace_size_in_bytes, &beta, tensor_desc_1, output0));
    CUDNN_SAFE_CALL(cudnnDestroyTensorDescriptor(tensor_desc_0));
    CUDNN_SAFE_CALL(cudnnDestroyTensorDescriptor(tensor_desc_1));
    CUDNN_SAFE_CALL(cudnnDestroyFilterDescriptor(filter_desc));
    CUDNN_SAFE_CALL(cudnnDestroyConvolutionDescriptor(conv_desc));

}

    void executeImpl(cudaStream_t stream) {
        this->Convolution_float_float_float_cuda_lib_Convolution_852(cudnn_handle, input0, input1, output0);
    }
};


class inception3_Reshape_float_float_cuda_Reshape_849_CallKernel : public Kernel {
public:
    inception3_Reshape_float_float_cuda_Reshape_849_CallKernel(const dim3 & grids, const dim3 & blocks, unsigned  mem, cudaStream_t  stream, float*  input0, float*  output0, float*  Parameter_0_0, float**  Result_892_0) {
        this->grids = grids, this->blocks = blocks, this->mem = mem, this->stream = stream, this->input0 = input0, this->output0 = output0, this->Parameter_0_0 = Parameter_0_0, this->Result_892_0 = Result_892_0;
        this->kernelName = "inception3_Reshape_float_float_cuda_Reshape_849_Call";
        this->Id = 0;
        this->mixable = 0;
    }

    void initParams() override {
        // empty implementation
    }

    void loadKernel() override {
        // Empty implementation
    }

        dim3  grids; dim3  blocks; unsigned  mem; cudaStream_t  stream; float*  input0; float*  output0;
    float*  Parameter_0_0; float**  Result_892_0;
private:

    
std::vector<int> getArgs() override {
    return std::vector<int>();
}

     void Reshape_float_float_cuda_Reshape_849_Call(const dim3 &grids, const dim3 &blocks, unsigned mem, cudaStream_t stream, float* input0, float* output0) {
    inception3_Reshape_float_float_cuda_Reshape_849<<<grids, blocks, mem, stream>>>(input0, output0);
}

    void executeImpl(cudaStream_t stream) {
        this->Reshape_float_float_cuda_Reshape_849_Call(grids, blocks, mem, stream, input0, output0);
    }
};


class inception3_Convolution_float_float_float_cuda_lib_Convolution_850Kernel : public Kernel {
public:
    inception3_Convolution_float_float_float_cuda_lib_Convolution_850Kernel(cudnnHandle_t  cudnn_handle, float*  input0, float*  input1, float*  output0, float*  Parameter_0_0, float**  Result_892_0) {
        this->cudnn_handle = cudnn_handle, this->input0 = input0, this->input1 = input1, this->output0 = output0, this->Parameter_0_0 = Parameter_0_0, this->Result_892_0 = Result_892_0;
        this->kernelName = "inception3_Convolution_float_float_float_cuda_lib_Convolution_850";
        this->Id = 0;
        this->mixable = 2;
    }

    void initParams() override {
        // empty implementation
    }

    void loadKernel() override {
        // Empty implementation
    }

        cudnnHandle_t  cudnn_handle; float*  input0; float*  input1; float*  output0;
    float*  Parameter_0_0; float**  Result_892_0;
private:

    
std::vector<int> getArgs() override {
    return std::vector<int>({64, 2048, 8, 8, 320, 2048, 1, 1, 0, 0, 1, 1, 1, 1});
}

    void Convolution_float_float_float_cuda_lib_Convolution_850(cudnnHandle_t cudnn_handle, float* input0, float* input1, float* output0)
{
    cudnnTensorDescriptor_t tensor_desc_0;
    CUDNN_SAFE_CALL(cudnnCreateTensorDescriptor(&tensor_desc_0));
    CUDNN_SAFE_CALL(cudnnSetTensor4dDescriptor(tensor_desc_0, CUDNN_TENSOR_NCHW, CUDNN_DATA_FLOAT, 64, 2048, 8, 8));
    cudnnTensorDescriptor_t tensor_desc_1;
    CUDNN_SAFE_CALL(cudnnCreateTensorDescriptor(&tensor_desc_1));
    CUDNN_SAFE_CALL(cudnnSetTensor4dDescriptor(tensor_desc_1, CUDNN_TENSOR_NCHW, CUDNN_DATA_FLOAT, 64, 320, 8, 8));
    cudnnFilterDescriptor_t filter_desc;
    CUDNN_SAFE_CALL(cudnnCreateFilterDescriptor(&filter_desc));
    CUDNN_SAFE_CALL(cudnnSetFilter4dDescriptor(filter_desc, CUDNN_DATA_FLOAT, CUDNN_TENSOR_NCHW, 320, 2048, 1, 1));
    cudnnConvolutionDescriptor_t conv_desc;
    CUDNN_SAFE_CALL(cudnnCreateConvolutionDescriptor(&conv_desc));
    CUDNN_SAFE_CALL(cudnnSetConvolution2dDescriptor(conv_desc, 0, 0, 1, 1, 1, 1, CUDNN_CROSS_CORRELATION, CUDNN_DATA_FLOAT));

    static bool selected_algo = true;
    static cudnnConvolutionFwdAlgo_t conv_fwd_algo = CUDNN_CONVOLUTION_FWD_ALGO_IMPLICIT_GEMM;

    if (!selected_algo) {
        int num_algos;
        int max_algos = 0;
        // cudnnGetConvolutionForwardAlgorithm_v7;
        CUDNN_SAFE_CALL(
            cudnnGetConvolutionForwardAlgorithmMaxCount(cudnn_handle, &max_algos));
        std::vector<cudnnConvolutionFwdAlgoPerf_t> results(max_algos);
        CUDNN_SAFE_CALL(cudnnFindConvolutionForwardAlgorithm(cudnn_handle,
                                                tensor_desc_0,
                                                filter_desc,
                                                conv_desc,
                                                tensor_desc_1,
                                                static_cast<int>(results.size()),
                                                &num_algos,
                                                results.data()));
        results.resize(num_algos);
        for (size_t i = 0; i != results.size(); ++i) {
            cudnnConvolutionFwdAlgoPerf_t const& result = results[i];
            if (result.status == CUDNN_STATUS_SUCCESS) {
                conv_fwd_algo = result.algo;
                break;
            }
        }
        selected_algo = true;
    }
    const float alpha = 1.0;
    const float beta = 0.0;
    static void *workspace_ptr_0 = NULL;
    static size_t workspace_size_in_bytes = 0;
    if (!workspace_ptr_0)
    {
        CUDNN_SAFE_CALL(cudnnGetConvolutionForwardWorkspaceSize(cudnn_handle, tensor_desc_0, filter_desc, conv_desc, tensor_desc_1, conv_fwd_algo, &workspace_size_in_bytes));
        CUDA_SAFE_CALL(cudaMalloc(&workspace_ptr_0, workspace_size_in_bytes));
    }
    CUDNN_SAFE_CALL(mycudnnConvolutionForward(cudnn_handle, &alpha, tensor_desc_0, input0,filter_desc, input1, conv_desc, conv_fwd_algo, workspace_ptr_0, workspace_size_in_bytes, &beta, tensor_desc_1, output0));
    CUDNN_SAFE_CALL(cudnnDestroyTensorDescriptor(tensor_desc_0));
    CUDNN_SAFE_CALL(cudnnDestroyTensorDescriptor(tensor_desc_1));
    CUDNN_SAFE_CALL(cudnnDestroyFilterDescriptor(filter_desc));
    CUDNN_SAFE_CALL(cudnnDestroyConvolutionDescriptor(conv_desc));

}

    void executeImpl(cudaStream_t stream) {
        this->Convolution_float_float_float_cuda_lib_Convolution_850(cudnn_handle, input0, input1, output0);
    }
};


class inception3_AvgPool_float_float_cuda_lib_AvgPool_887Kernel : public Kernel {
public:
    inception3_AvgPool_float_float_cuda_lib_AvgPool_887Kernel(cudnnHandle_t  cudnn_handle, float*  input0, float*  output0, float*  Parameter_0_0, float**  Result_892_0) {
        this->cudnn_handle = cudnn_handle, this->input0 = input0, this->output0 = output0, this->Parameter_0_0 = Parameter_0_0, this->Result_892_0 = Result_892_0;
        this->kernelName = "inception3_AvgPool_float_float_cuda_lib_AvgPool_887";
        this->Id = 0;
        this->mixable = 0;
    }

    void initParams() override {
        // empty implementation
    }

    void loadKernel() override {
        // Empty implementation
    }

        cudnnHandle_t  cudnn_handle; float*  input0; float*  output0;
    float*  Parameter_0_0; float**  Result_892_0;
private:

    
std::vector<int> getArgs() override {
    return std::vector<int>();
}

    void AvgPool_float_float_cuda_lib_AvgPool_887(cudnnHandle_t cudnn_handle, float* input0, float* output0)
{
    cudnnTensorDescriptor_t input_desc;
    CUDNN_SAFE_CALL(cudnnCreateTensorDescriptor(&input_desc));
    CUDNN_SAFE_CALL(cudnnSetTensor4dDescriptor(input_desc, CUDNN_TENSOR_NCHW, CUDNN_DATA_FLOAT, 64, 2048, 8, 8));
    cudnnTensorDescriptor_t output_desc;
    CUDNN_SAFE_CALL(cudnnCreateTensorDescriptor(&output_desc));
    CUDNN_SAFE_CALL(cudnnSetTensor4dDescriptor(output_desc, CUDNN_TENSOR_NCHW, CUDNN_DATA_FLOAT, 64, 2048, 1, 1));
    cudnnPoolingDescriptor_t desc;
    cudnnCreatePoolingDescriptor(&desc);
    CUDNN_SAFE_CALL(cudnnSetPooling2dDescriptor(desc, CUDNN_POOLING_AVERAGE_COUNT_EXCLUDE_PADDING, CUDNN_NOT_PROPAGATE_NAN,8, 8, 0, 0, 1, 1));
    const float alpha = 1.0;
    const float beta = 0.0;
    CUDNN_SAFE_CALL(cudnnPoolingForward(cudnn_handle, desc, &alpha, input_desc, input0, &beta, output_desc, output0));
    CUDNN_SAFE_CALL(cudnnDestroyTensorDescriptor(input_desc));
    CUDNN_SAFE_CALL(cudnnDestroyTensorDescriptor(output_desc));
    CUDNN_SAFE_CALL(cudnnDestroyPoolingDescriptor(desc));

}

    void executeImpl(cudaStream_t stream) {
        this->AvgPool_float_float_cuda_lib_AvgPool_887(cudnn_handle, input0, output0);
    }
};


class inception3_Dot_float_float_float_cuda_lib_Dot_889Kernel : public Kernel {
public:
    inception3_Dot_float_float_float_cuda_lib_Dot_889Kernel(cublasHandle_t  cublas_handle, float*  input0, float*  input1, float*  output0, float*  Parameter_0_0, float**  Result_892_0) {
        this->cublas_handle = cublas_handle, this->input0 = input0, this->input1 = input1, this->output0 = output0, this->Parameter_0_0 = Parameter_0_0, this->Result_892_0 = Result_892_0;
        this->kernelName = "inception3_Dot_float_float_float_cuda_lib_Dot_889";
        this->Id = 0;
        this->mixable = 1;
    }

    void initParams() override {
        // empty implementation
    }

    void loadKernel() override {
        // Empty implementation
    }

        cublasHandle_t  cublas_handle; float*  input0; float*  input1; float*  output0;
    float*  Parameter_0_0; float**  Result_892_0;
private:

    
std::vector<int> getArgs() override {
    std::vector<int> ret(3);
    ret[0] = 1001;
    ret[1] = 64;
    ret[2] = 2048;
    return ret;
}

    void Dot_float_float_float_cuda_lib_Dot_889(cublasHandle_t cublas_handle, float* input0, float* input1, float* output0)
{
    const float alpha = 1.0;
    const float beta = 0;
    CUBLAS_SAFE_CALL(mycublasSgemm(cublas_handle, CUBLAS_OP_N, CUBLAS_OP_N, 1001, 64, 2048, &alpha, static_cast<const float*>(input1), 1001, static_cast<const float*>(input0), 2048, &beta, static_cast<float*>(output0), 1001));

}

    void executeImpl(cudaStream_t stream) {
        this->Dot_float_float_float_cuda_lib_Dot_889(cublas_handle, input0, input1, output0);
    }
};


class inception3_Broadcast_float_float_cuda_Broadcast_890_CallKernel : public Kernel {
public:
    inception3_Broadcast_float_float_cuda_Broadcast_890_CallKernel(const dim3 & grids, const dim3 & blocks, unsigned  mem, cudaStream_t  stream, float*  input0, float*  output0, float*  Parameter_0_0, float**  Result_892_0) {
        this->grids = grids, this->blocks = blocks, this->mem = mem, this->stream = stream, this->input0 = input0, this->output0 = output0, this->Parameter_0_0 = Parameter_0_0, this->Result_892_0 = Result_892_0;
        this->kernelName = "inception3_Broadcast_float_float_cuda_Broadcast_890_Call";
        this->Id = 0;
        this->mixable = 0;
    }

    void initParams() override {
        // empty implementation
    }

    void loadKernel() override {
        // Empty implementation
    }

        dim3  grids; dim3  blocks; unsigned  mem; cudaStream_t  stream; float*  input0; float*  output0;
    float*  Parameter_0_0; float**  Result_892_0;
private:

    
std::vector<int> getArgs() override {
    return std::vector<int>();
}

     void Broadcast_float_float_cuda_Broadcast_890_Call(const dim3 &grids, const dim3 &blocks, unsigned mem, cudaStream_t stream, float* input0, float* output0) {
    inception3_Broadcast_float_float_cuda_Broadcast_890<<<grids, blocks, mem, stream>>>(input0, output0);
}

    void executeImpl(cudaStream_t stream) {
        this->Broadcast_float_float_cuda_Broadcast_890_Call(grids, blocks, mem, stream, input0, output0);
    }
};


class inception3_Add_float_float_float_cuda_Add_891_CallKernel : public Kernel {
public:
    inception3_Add_float_float_float_cuda_Add_891_CallKernel(const dim3 & grids, const dim3 & blocks, unsigned  mem, cudaStream_t  stream, float*  input0, float*  input1, float*  output0, float*  Parameter_0_0, float**  Result_892_0) {
        this->grids = grids, this->blocks = blocks, this->mem = mem, this->stream = stream, this->input0 = input0, this->input1 = input1, this->output0 = output0, this->Parameter_0_0 = Parameter_0_0, this->Result_892_0 = Result_892_0;
        this->kernelName = "inception3_Add_float_float_float_cuda_Add_891_Call";
        this->Id = 0;
        this->mixable = 0;
    }

    void initParams() override {
        // empty implementation
    }

    void loadKernel() override {
        // Empty implementation
    }

        dim3  grids; dim3  blocks; unsigned  mem; cudaStream_t  stream; float*  input0; float*  input1; float*  output0;
    float*  Parameter_0_0; float**  Result_892_0;
private:

    
std::vector<int> getArgs() override {
    return std::vector<int>();
}

     void Add_float_float_float_cuda_Add_891_Call(const dim3 &grids, const dim3 &blocks, unsigned mem, cudaStream_t stream, float* input0, float* input1, float* output0) {
    inception3_Add_float_float_float_cuda_Add_891<<<grids, blocks, mem, stream>>>(input0, input1, output0);
}

    void executeImpl(cudaStream_t stream) {
        this->Add_float_float_float_cuda_Add_891_Call(grids, blocks, mem, stream, input0, input1, output0);
    }
};


class inception3_Result_float_float_cuda_lib_Result_892Kernel : public Kernel {
public:
    inception3_Result_float_float_cuda_lib_Result_892Kernel(float*  input0, float**  output0, float*  Parameter_0_0, float**  Result_892_0) {
        this->input0 = input0, this->output0 = output0, this->Parameter_0_0 = Parameter_0_0, this->Result_892_0 = Result_892_0;
        this->kernelName = "inception3_Result_float_float_cuda_lib_Result_892";
        this->Id = 0;
        this->mixable = 0;
    }

    void initParams() override {
        // empty implementation
    }

    void loadKernel() override {
        // Empty implementation
    }

        float*  input0; float**  output0;
    float*  Parameter_0_0; float**  Result_892_0;
private:

    
std::vector<int> getArgs() override {
    return std::vector<int>();
}

    void Result_float_float_cuda_lib_Result_892(float* input0, float** output0)
{
    *output0 = input0;
}

    void executeImpl(cudaStream_t stream) {
        this->Result_float_float_cuda_lib_Result_892(input0, output0);
    }
};
void Inception3::gen_vector(float*  Parameter_0_0, float**  Result_892_0) {
    kernels.emplace_back(new inception3_Reshape_float_float_cuda_Reshape_486_CallKernel(dim3(1, 5588, 64), dim3(16, 16, 1), 0, nullptr, std::move(Parameter_0_0), std::move(inception3_Reshape_486_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_Reshape_float_float_cuda_Reshape_487_CallKernel(dim3(2, 3, 1), dim3(16, 1, 16), 0, nullptr, std::move(inception3_Constant_2_0), std::move(inception3_Reshape_487_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_Convolution_float_float_float_cuda_lib_Convolution_488Kernel(std::move(inception3_cudnn_handle_0), std::move(inception3_Reshape_486_0), std::move(inception3_Reshape_487_0), std::move(inception3_Convolution_488_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_BatchNormInference_float_float_float_float_float_float_cuda_BatchNormInference_489_CallKernel(dim3(2048, 1, 1), dim3(512, 1, 1), 0, nullptr, std::move(inception3_Constant_3_0), std::move(inception3_Constant_4_0), std::move(inception3_Convolution_488_0), std::move(inception3_Constant_5_0), std::move(inception3_Constant_6_0), std::move(inception3_BatchNormInference_489_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_Relu_float_float_cuda_Relu_490_CallKernel(dim3(88804, 1, 1), dim3(512, 1, 1), 0, nullptr, std::move(inception3_BatchNormInference_489_0), std::move(inception3_Relu_490_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_Reshape_float_float_cuda_Reshape_491_CallKernel(dim3(2, 32, 1), dim3(16, 1, 16), 0, nullptr, std::move(inception3_Constant_7_0), std::move(inception3_Reshape_491_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_Convolution_float_float_float_cuda_lib_Convolution_492Kernel(std::move(inception3_cudnn_handle_0), std::move(inception3_Relu_490_0), std::move(inception3_Reshape_491_0), std::move(inception3_Convolution_492_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_BatchNormInference_float_float_float_float_float_float_cuda_BatchNormInference_493_CallKernel(dim3(2048, 1, 1), dim3(512, 1, 1), 0, nullptr, std::move(inception3_Constant_8_0), std::move(inception3_Constant_9_0), std::move(inception3_Convolution_492_0), std::move(inception3_Constant_10_0), std::move(inception3_Constant_11_0), std::move(inception3_BatchNormInference_493_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_Relu_float_float_cuda_Relu_490_CallKernel(dim3(86436, 1, 1), dim3(512, 1, 1), 0, nullptr, std::move(inception3_BatchNormInference_493_0), std::move(inception3_Relu_494_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_Reshape_float_float_cuda_Reshape_495_CallKernel(dim3(4, 32, 1), dim3(16, 1, 16), 0, nullptr, std::move(inception3_Constant_12_0), std::move(inception3_Reshape_495_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_Convolution_float_float_float_cuda_lib_Convolution_496Kernel(std::move(inception3_cudnn_handle_0), std::move(inception3_Relu_494_0), std::move(inception3_Reshape_495_0), std::move(inception3_Convolution_496_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_BatchNormInference_float_float_float_float_float_float_cuda_BatchNormInference_497_CallKernel(dim3(4096, 1, 1), dim3(512, 1, 1), 0, nullptr, std::move(inception3_Constant_13_0), std::move(inception3_Constant_14_0), std::move(inception3_Convolution_496_0), std::move(inception3_Constant_15_0), std::move(inception3_Constant_16_0), std::move(inception3_BatchNormInference_497_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_Relu_float_float_cuda_Relu_490_CallKernel(dim3(172872, 1, 1), dim3(512, 1, 1), 0, nullptr, std::move(inception3_BatchNormInference_497_0), std::move(inception3_Relu_498_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_MaxPool_float_float_cuda_lib_MaxPool_499Kernel(std::move(inception3_cudnn_handle_0), std::move(inception3_Relu_498_0), std::move(inception3_MaxPool_499_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_Reshape_float_float_cuda_Reshape_500_CallKernel(dim3(5, 4, 1), dim3(16, 16, 1), 0, nullptr, std::move(inception3_Constant_17_0), std::move(inception3_Reshape_500_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_Convolution_float_float_float_cuda_lib_Convolution_501Kernel(std::move(inception3_cudnn_handle_0), std::move(inception3_MaxPool_499_0), std::move(inception3_Reshape_500_0), std::move(inception3_Convolution_501_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_BatchNormInference_float_float_float_float_float_float_cuda_BatchNormInference_502_CallKernel(dim3(5120, 1, 1), dim3(512, 1, 1), 0, nullptr, std::move(inception3_Constant_18_0), std::move(inception3_Constant_19_0), std::move(inception3_Convolution_501_0), std::move(inception3_Constant_20_0), std::move(inception3_Constant_21_0), std::move(inception3_BatchNormInference_502_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_Relu_float_float_cuda_Relu_490_CallKernel(dim3(53290, 1, 1), dim3(512, 1, 1), 0, nullptr, std::move(inception3_BatchNormInference_502_0), std::move(inception3_Relu_503_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_Reshape_float_float_cuda_Reshape_504_CallKernel(dim3(12, 80, 1), dim3(16, 1, 16), 0, nullptr, std::move(inception3_Constant_22_0), std::move(inception3_Reshape_504_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_Convolution_float_float_float_cuda_lib_Convolution_505Kernel(std::move(inception3_cudnn_handle_0), std::move(inception3_Relu_503_0), std::move(inception3_Reshape_504_0), std::move(inception3_Convolution_505_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_BatchNormInference_float_float_float_float_float_float_cuda_BatchNormInference_506_CallKernel(dim3(12288, 1, 1), dim3(512, 1, 1), 0, nullptr, std::move(inception3_Constant_23_0), std::move(inception3_Constant_24_0), std::move(inception3_Convolution_505_0), std::move(inception3_Constant_25_0), std::move(inception3_Constant_26_0), std::move(inception3_BatchNormInference_506_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_Relu_float_float_cuda_Relu_490_CallKernel(dim3(120984, 1, 1), dim3(512, 1, 1), 0, nullptr, std::move(inception3_BatchNormInference_506_0), std::move(inception3_Relu_507_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_MaxPool_float_float_cuda_lib_MaxPool_508Kernel(std::move(inception3_cudnn_handle_0), std::move(inception3_Relu_507_0), std::move(inception3_MaxPool_508_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_Reshape_float_float_cuda_Reshape_511_CallKernel(dim3(3, 12, 1), dim3(16, 16, 1), 0, nullptr, std::move(inception3_Constant_32_0), std::move(inception3_Reshape_511_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_Convolution_float_float_float_cuda_lib_Convolution_512Kernel(std::move(inception3_cudnn_handle_0), std::move(inception3_MaxPool_508_0), std::move(inception3_Reshape_511_0), std::move(inception3_Convolution_512_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_BatchNormInference_float_float_float_float_float_float_cuda_BatchNormInference_517_CallKernel(dim3(3072, 1, 1), dim3(512, 1, 1), 0, nullptr, std::move(inception3_Constant_33_0), std::move(inception3_Constant_34_0), std::move(inception3_Convolution_512_0), std::move(inception3_Constant_35_0), std::move(inception3_Constant_36_0), std::move(inception3_BatchNormInference_517_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_Relu_float_float_cuda_Relu_490_CallKernel(dim3(7350, 1, 1), dim3(512, 1, 1), 0, nullptr, std::move(inception3_BatchNormInference_517_0), std::move(inception3_Relu_522_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_Reshape_float_float_cuda_Reshape_525_CallKernel(dim3(4, 48, 2), dim3(16, 1, 16), 0, nullptr, std::move(inception3_Constant_37_0), std::move(inception3_Reshape_525_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_Convolution_float_float_float_cuda_lib_Convolution_526Kernel(std::move(inception3_cudnn_handle_0), std::move(inception3_Relu_522_0), std::move(inception3_Reshape_525_0), std::move(inception3_Convolution_526_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_BatchNormInference_float_float_float_float_float_float_cuda_BatchNormInference_530_CallKernel(dim3(4096, 1, 1), dim3(512, 1, 1), 0, nullptr, std::move(inception3_Constant_38_0), std::move(inception3_Constant_39_0), std::move(inception3_Convolution_526_0), std::move(inception3_Constant_40_0), std::move(inception3_Constant_41_0), std::move(inception3_BatchNormInference_530_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_Relu_float_float_cuda_Relu_490_CallKernel(dim3(9800, 1, 1), dim3(512, 1, 1), 0, nullptr, std::move(inception3_BatchNormInference_530_0), std::move(inception3_Relu_532_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_Reshape_float_float_cuda_Reshape_509_CallKernel(dim3(4, 12, 1), dim3(16, 16, 1), 0, nullptr, std::move(inception3_Constant_27_0), std::move(inception3_Reshape_509_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_Convolution_float_float_float_cuda_lib_Convolution_510Kernel(std::move(inception3_cudnn_handle_0), std::move(inception3_MaxPool_508_0), std::move(inception3_Reshape_509_0), std::move(inception3_Convolution_510_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_BatchNormInference_float_float_float_float_float_float_cuda_BatchNormInference_530_CallKernel(dim3(4096, 1, 1), dim3(512, 1, 1), 0, nullptr, std::move(inception3_Constant_28_0), std::move(inception3_Constant_29_0), std::move(inception3_Convolution_510_0), std::move(inception3_Constant_30_0), std::move(inception3_Constant_31_0), std::move(inception3_BatchNormInference_516_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_Relu_float_float_cuda_Relu_490_CallKernel(dim3(9800, 1, 1), dim3(512, 1, 1), 0, nullptr, std::move(inception3_BatchNormInference_516_0), std::move(inception3_Relu_521_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_AvgPool_float_float_cuda_lib_AvgPool_515Kernel(std::move(inception3_cudnn_handle_0), std::move(inception3_MaxPool_508_0), std::move(inception3_AvgPool_515_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_Reshape_float_float_cuda_Reshape_519_CallKernel(dim3(2, 12, 1), dim3(16, 16, 1), 0, nullptr, std::move(inception3_Constant_57_0), std::move(inception3_Reshape_519_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_Convolution_float_float_float_cuda_lib_Convolution_520Kernel(std::move(inception3_cudnn_handle_0), std::move(inception3_AvgPool_515_0), std::move(inception3_Reshape_519_0), std::move(inception3_Convolution_520_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_BatchNormInference_float_float_float_float_float_float_cuda_BatchNormInference_524_CallKernel(dim3(2048, 1, 1), dim3(512, 1, 1), 0, nullptr, std::move(inception3_Constant_58_0), std::move(inception3_Constant_59_0), std::move(inception3_Convolution_520_0), std::move(inception3_Constant_60_0), std::move(inception3_Constant_61_0), std::move(inception3_BatchNormInference_524_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_Relu_float_float_cuda_Relu_490_CallKernel(dim3(4900, 1, 1), dim3(512, 1, 1), 0, nullptr, std::move(inception3_BatchNormInference_524_0), std::move(inception3_Relu_529_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_Reshape_float_float_cuda_Reshape_509_CallKernel(dim3(4, 12, 1), dim3(16, 16, 1), 0, nullptr, std::move(inception3_Constant_42_0), std::move(inception3_Reshape_513_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_Convolution_float_float_float_cuda_lib_Convolution_510Kernel(std::move(inception3_cudnn_handle_0), std::move(inception3_MaxPool_508_0), std::move(inception3_Reshape_513_0), std::move(inception3_Convolution_514_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_BatchNormInference_float_float_float_float_float_float_cuda_BatchNormInference_530_CallKernel(dim3(4096, 1, 1), dim3(512, 1, 1), 0, nullptr, std::move(inception3_Constant_43_0), std::move(inception3_Constant_44_0), std::move(inception3_Convolution_514_0), std::move(inception3_Constant_45_0), std::move(inception3_Constant_46_0), std::move(inception3_BatchNormInference_518_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_Relu_float_float_cuda_Relu_490_CallKernel(dim3(9800, 1, 1), dim3(512, 1, 1), 0, nullptr, std::move(inception3_BatchNormInference_518_0), std::move(inception3_Relu_523_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_Reshape_float_float_cuda_Reshape_527_CallKernel(dim3(6, 64, 1), dim3(16, 1, 16), 0, nullptr, std::move(inception3_Constant_47_0), std::move(inception3_Reshape_527_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_Convolution_float_float_float_cuda_lib_Convolution_528Kernel(std::move(inception3_cudnn_handle_0), std::move(inception3_Relu_523_0), std::move(inception3_Reshape_527_0), std::move(inception3_Convolution_528_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_BatchNormInference_float_float_float_float_float_float_cuda_BatchNormInference_531_CallKernel(dim3(6144, 1, 1), dim3(512, 1, 1), 0, nullptr, std::move(inception3_Constant_48_0), std::move(inception3_Constant_49_0), std::move(inception3_Convolution_528_0), std::move(inception3_Constant_50_0), std::move(inception3_Constant_51_0), std::move(inception3_BatchNormInference_531_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_Relu_float_float_cuda_Relu_490_CallKernel(dim3(14700, 1, 1), dim3(512, 1, 1), 0, nullptr, std::move(inception3_BatchNormInference_531_0), std::move(inception3_Relu_533_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_Reshape_float_float_cuda_Reshape_534_CallKernel(dim3(6, 96, 1), dim3(16, 1, 16), 0, nullptr, std::move(inception3_Constant_52_0), std::move(inception3_Reshape_534_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_Convolution_float_float_float_cuda_lib_Convolution_535Kernel(std::move(inception3_cudnn_handle_0), std::move(inception3_Relu_533_0), std::move(inception3_Reshape_534_0), std::move(inception3_Convolution_535_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_BatchNormInference_float_float_float_float_float_float_cuda_BatchNormInference_531_CallKernel(dim3(6144, 1, 1), dim3(512, 1, 1), 0, nullptr, std::move(inception3_Constant_53_0), std::move(inception3_Constant_54_0), std::move(inception3_Convolution_535_0), std::move(inception3_Constant_55_0), std::move(inception3_Constant_56_0), std::move(inception3_BatchNormInference_536_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_Relu_float_float_cuda_Relu_490_CallKernel(dim3(14700, 1, 1), dim3(512, 1, 1), 0, nullptr, std::move(inception3_BatchNormInference_536_0), std::move(inception3_Relu_537_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_Concat_float_float_float_float_float_cuda_Concat_538_CallKernel(dim3(39200, 1, 1), dim3(512, 1, 1), 0, nullptr, std::move(inception3_Relu_521_0), std::move(inception3_Relu_532_0), std::move(inception3_Relu_537_0), std::move(inception3_Relu_529_0), std::move(inception3_Concat_538_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_AvgPool_float_float_cuda_lib_AvgPool_545Kernel(std::move(inception3_cudnn_handle_0), std::move(inception3_Concat_538_0), std::move(inception3_AvgPool_545_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_Reshape_float_float_cuda_Reshape_549_CallKernel(dim3(4, 16, 1), dim3(16, 16, 1), 0, nullptr, std::move(inception3_Constant_93_0), std::move(inception3_Reshape_549_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_Convolution_float_float_float_cuda_lib_Convolution_550Kernel(std::move(inception3_cudnn_handle_0), std::move(inception3_AvgPool_545_0), std::move(inception3_Reshape_549_0), std::move(inception3_Convolution_550_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_BatchNormInference_float_float_float_float_float_float_cuda_BatchNormInference_530_CallKernel(dim3(4096, 1, 1), dim3(512, 1, 1), 0, nullptr, std::move(inception3_Constant_94_0), std::move(inception3_Constant_95_0), std::move(inception3_Convolution_550_0), std::move(inception3_Constant_96_0), std::move(inception3_Constant_97_0), std::move(inception3_BatchNormInference_554_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_Relu_float_float_cuda_Relu_490_CallKernel(dim3(9800, 1, 1), dim3(512, 1, 1), 0, nullptr, std::move(inception3_BatchNormInference_554_0), std::move(inception3_Relu_559_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_Reshape_float_float_cuda_Reshape_549_CallKernel(dim3(4, 16, 1), dim3(16, 16, 1), 0, nullptr, std::move(inception3_Constant_78_0), std::move(inception3_Reshape_543_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_Convolution_float_float_float_cuda_lib_Convolution_550Kernel(std::move(inception3_cudnn_handle_0), std::move(inception3_Concat_538_0), std::move(inception3_Reshape_543_0), std::move(inception3_Convolution_544_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_BatchNormInference_float_float_float_float_float_float_cuda_BatchNormInference_530_CallKernel(dim3(4096, 1, 1), dim3(512, 1, 1), 0, nullptr, std::move(inception3_Constant_79_0), std::move(inception3_Constant_80_0), std::move(inception3_Convolution_544_0), std::move(inception3_Constant_81_0), std::move(inception3_Constant_82_0), std::move(inception3_BatchNormInference_548_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_Relu_float_float_cuda_Relu_490_CallKernel(dim3(9800, 1, 1), dim3(512, 1, 1), 0, nullptr, std::move(inception3_BatchNormInference_548_0), std::move(inception3_Relu_553_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_Reshape_float_float_cuda_Reshape_527_CallKernel(dim3(6, 64, 1), dim3(16, 1, 16), 0, nullptr, std::move(inception3_Constant_83_0), std::move(inception3_Reshape_557_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_Convolution_float_float_float_cuda_lib_Convolution_528Kernel(std::move(inception3_cudnn_handle_0), std::move(inception3_Relu_553_0), std::move(inception3_Reshape_557_0), std::move(inception3_Convolution_558_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_BatchNormInference_float_float_float_float_float_float_cuda_BatchNormInference_531_CallKernel(dim3(6144, 1, 1), dim3(512, 1, 1), 0, nullptr, std::move(inception3_Constant_84_0), std::move(inception3_Constant_85_0), std::move(inception3_Convolution_558_0), std::move(inception3_Constant_86_0), std::move(inception3_Constant_87_0), std::move(inception3_BatchNormInference_561_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_Relu_float_float_cuda_Relu_490_CallKernel(dim3(14700, 1, 1), dim3(512, 1, 1), 0, nullptr, std::move(inception3_BatchNormInference_561_0), std::move(inception3_Relu_563_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_Reshape_float_float_cuda_Reshape_534_CallKernel(dim3(6, 96, 1), dim3(16, 1, 16), 0, nullptr, std::move(inception3_Constant_88_0), std::move(inception3_Reshape_564_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_Convolution_float_float_float_cuda_lib_Convolution_535Kernel(std::move(inception3_cudnn_handle_0), std::move(inception3_Relu_563_0), std::move(inception3_Reshape_564_0), std::move(inception3_Convolution_565_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_BatchNormInference_float_float_float_float_float_float_cuda_BatchNormInference_531_CallKernel(dim3(6144, 1, 1), dim3(512, 1, 1), 0, nullptr, std::move(inception3_Constant_89_0), std::move(inception3_Constant_90_0), std::move(inception3_Convolution_565_0), std::move(inception3_Constant_91_0), std::move(inception3_Constant_92_0), std::move(inception3_BatchNormInference_566_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_Relu_float_float_cuda_Relu_490_CallKernel(dim3(14700, 1, 1), dim3(512, 1, 1), 0, nullptr, std::move(inception3_BatchNormInference_566_0), std::move(inception3_Relu_567_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_Reshape_float_float_cuda_Reshape_541_CallKernel(dim3(3, 16, 1), dim3(16, 16, 1), 0, nullptr, std::move(inception3_Constant_68_0), std::move(inception3_Reshape_541_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_Convolution_float_float_float_cuda_lib_Convolution_542Kernel(std::move(inception3_cudnn_handle_0), std::move(inception3_Concat_538_0), std::move(inception3_Reshape_541_0), std::move(inception3_Convolution_542_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_BatchNormInference_float_float_float_float_float_float_cuda_BatchNormInference_517_CallKernel(dim3(3072, 1, 1), dim3(512, 1, 1), 0, nullptr, std::move(inception3_Constant_69_0), std::move(inception3_Constant_70_0), std::move(inception3_Convolution_542_0), std::move(inception3_Constant_71_0), std::move(inception3_Constant_72_0), std::move(inception3_BatchNormInference_547_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_Relu_float_float_cuda_Relu_490_CallKernel(dim3(7350, 1, 1), dim3(512, 1, 1), 0, nullptr, std::move(inception3_BatchNormInference_547_0), std::move(inception3_Relu_552_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_Reshape_float_float_cuda_Reshape_525_CallKernel(dim3(4, 48, 2), dim3(16, 1, 16), 0, nullptr, std::move(inception3_Constant_73_0), std::move(inception3_Reshape_555_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_Convolution_float_float_float_cuda_lib_Convolution_526Kernel(std::move(inception3_cudnn_handle_0), std::move(inception3_Relu_552_0), std::move(inception3_Reshape_555_0), std::move(inception3_Convolution_556_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_BatchNormInference_float_float_float_float_float_float_cuda_BatchNormInference_530_CallKernel(dim3(4096, 1, 1), dim3(512, 1, 1), 0, nullptr, std::move(inception3_Constant_74_0), std::move(inception3_Constant_75_0), std::move(inception3_Convolution_556_0), std::move(inception3_Constant_76_0), std::move(inception3_Constant_77_0), std::move(inception3_BatchNormInference_560_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_Relu_float_float_cuda_Relu_490_CallKernel(dim3(9800, 1, 1), dim3(512, 1, 1), 0, nullptr, std::move(inception3_BatchNormInference_560_0), std::move(inception3_Relu_562_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_Reshape_float_float_cuda_Reshape_549_CallKernel(dim3(4, 16, 1), dim3(16, 16, 1), 0, nullptr, std::move(inception3_Constant_63_0), std::move(inception3_Reshape_539_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_Convolution_float_float_float_cuda_lib_Convolution_550Kernel(std::move(inception3_cudnn_handle_0), std::move(inception3_Concat_538_0), std::move(inception3_Reshape_539_0), std::move(inception3_Convolution_540_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_BatchNormInference_float_float_float_float_float_float_cuda_BatchNormInference_530_CallKernel(dim3(4096, 1, 1), dim3(512, 1, 1), 0, nullptr, std::move(inception3_Constant_64_0), std::move(inception3_Constant_65_0), std::move(inception3_Convolution_540_0), std::move(inception3_Constant_66_0), std::move(inception3_Constant_67_0), std::move(inception3_BatchNormInference_546_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_Relu_float_float_cuda_Relu_490_CallKernel(dim3(9800, 1, 1), dim3(512, 1, 1), 0, nullptr, std::move(inception3_BatchNormInference_546_0), std::move(inception3_Relu_551_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_Concat_float_float_float_float_float_cuda_Concat_568_CallKernel(dim3(44100, 1, 1), dim3(512, 1, 1), 0, nullptr, std::move(inception3_Relu_551_0), std::move(inception3_Relu_562_0), std::move(inception3_Relu_567_0), std::move(inception3_Relu_559_0), std::move(inception3_Concat_568_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_AvgPool_float_float_cuda_lib_AvgPool_575Kernel(std::move(inception3_cudnn_handle_0), std::move(inception3_Concat_568_0), std::move(inception3_AvgPool_575_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_Reshape_float_float_cuda_Reshape_579_CallKernel(dim3(4, 18, 1), dim3(16, 16, 1), 0, nullptr, std::move(inception3_Constant_129_0), std::move(inception3_Reshape_579_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_Convolution_float_float_float_cuda_lib_Convolution_580Kernel(std::move(inception3_cudnn_handle_0), std::move(inception3_AvgPool_575_0), std::move(inception3_Reshape_579_0), std::move(inception3_Convolution_580_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_BatchNormInference_float_float_float_float_float_float_cuda_BatchNormInference_530_CallKernel(dim3(4096, 1, 1), dim3(512, 1, 1), 0, nullptr, std::move(inception3_Constant_130_0), std::move(inception3_Constant_131_0), std::move(inception3_Convolution_580_0), std::move(inception3_Constant_132_0), std::move(inception3_Constant_133_0), std::move(inception3_BatchNormInference_584_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_Relu_float_float_cuda_Relu_490_CallKernel(dim3(9800, 1, 1), dim3(512, 1, 1), 0, nullptr, std::move(inception3_BatchNormInference_584_0), std::move(inception3_Relu_589_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_Reshape_float_float_cuda_Reshape_579_CallKernel(dim3(4, 18, 1), dim3(16, 16, 1), 0, nullptr, std::move(inception3_Constant_114_0), std::move(inception3_Reshape_573_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_Convolution_float_float_float_cuda_lib_Convolution_580Kernel(std::move(inception3_cudnn_handle_0), std::move(inception3_Concat_568_0), std::move(inception3_Reshape_573_0), std::move(inception3_Convolution_574_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_BatchNormInference_float_float_float_float_float_float_cuda_BatchNormInference_530_CallKernel(dim3(4096, 1, 1), dim3(512, 1, 1), 0, nullptr, std::move(inception3_Constant_115_0), std::move(inception3_Constant_116_0), std::move(inception3_Convolution_574_0), std::move(inception3_Constant_117_0), std::move(inception3_Constant_118_0), std::move(inception3_BatchNormInference_578_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_Relu_float_float_cuda_Relu_490_CallKernel(dim3(9800, 1, 1), dim3(512, 1, 1), 0, nullptr, std::move(inception3_BatchNormInference_578_0), std::move(inception3_Relu_583_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_Reshape_float_float_cuda_Reshape_527_CallKernel(dim3(6, 64, 1), dim3(16, 1, 16), 0, nullptr, std::move(inception3_Constant_119_0), std::move(inception3_Reshape_587_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_Convolution_float_float_float_cuda_lib_Convolution_528Kernel(std::move(inception3_cudnn_handle_0), std::move(inception3_Relu_583_0), std::move(inception3_Reshape_587_0), std::move(inception3_Convolution_588_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_BatchNormInference_float_float_float_float_float_float_cuda_BatchNormInference_531_CallKernel(dim3(6144, 1, 1), dim3(512, 1, 1), 0, nullptr, std::move(inception3_Constant_120_0), std::move(inception3_Constant_121_0), std::move(inception3_Convolution_588_0), std::move(inception3_Constant_122_0), std::move(inception3_Constant_123_0), std::move(inception3_BatchNormInference_591_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_Relu_float_float_cuda_Relu_490_CallKernel(dim3(14700, 1, 1), dim3(512, 1, 1), 0, nullptr, std::move(inception3_BatchNormInference_591_0), std::move(inception3_Relu_593_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_Reshape_float_float_cuda_Reshape_534_CallKernel(dim3(6, 96, 1), dim3(16, 1, 16), 0, nullptr, std::move(inception3_Constant_124_0), std::move(inception3_Reshape_594_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_Convolution_float_float_float_cuda_lib_Convolution_535Kernel(std::move(inception3_cudnn_handle_0), std::move(inception3_Relu_593_0), std::move(inception3_Reshape_594_0), std::move(inception3_Convolution_595_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_BatchNormInference_float_float_float_float_float_float_cuda_BatchNormInference_531_CallKernel(dim3(6144, 1, 1), dim3(512, 1, 1), 0, nullptr, std::move(inception3_Constant_125_0), std::move(inception3_Constant_126_0), std::move(inception3_Convolution_595_0), std::move(inception3_Constant_127_0), std::move(inception3_Constant_128_0), std::move(inception3_BatchNormInference_596_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_Relu_float_float_cuda_Relu_490_CallKernel(dim3(14700, 1, 1), dim3(512, 1, 1), 0, nullptr, std::move(inception3_BatchNormInference_596_0), std::move(inception3_Relu_597_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_Reshape_float_float_cuda_Reshape_571_CallKernel(dim3(3, 18, 1), dim3(16, 16, 1), 0, nullptr, std::move(inception3_Constant_104_0), std::move(inception3_Reshape_571_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_Convolution_float_float_float_cuda_lib_Convolution_572Kernel(std::move(inception3_cudnn_handle_0), std::move(inception3_Concat_568_0), std::move(inception3_Reshape_571_0), std::move(inception3_Convolution_572_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_BatchNormInference_float_float_float_float_float_float_cuda_BatchNormInference_517_CallKernel(dim3(3072, 1, 1), dim3(512, 1, 1), 0, nullptr, std::move(inception3_Constant_105_0), std::move(inception3_Constant_106_0), std::move(inception3_Convolution_572_0), std::move(inception3_Constant_107_0), std::move(inception3_Constant_108_0), std::move(inception3_BatchNormInference_577_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_Relu_float_float_cuda_Relu_490_CallKernel(dim3(7350, 1, 1), dim3(512, 1, 1), 0, nullptr, std::move(inception3_BatchNormInference_577_0), std::move(inception3_Relu_582_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_Reshape_float_float_cuda_Reshape_525_CallKernel(dim3(4, 48, 2), dim3(16, 1, 16), 0, nullptr, std::move(inception3_Constant_109_0), std::move(inception3_Reshape_585_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_Convolution_float_float_float_cuda_lib_Convolution_526Kernel(std::move(inception3_cudnn_handle_0), std::move(inception3_Relu_582_0), std::move(inception3_Reshape_585_0), std::move(inception3_Convolution_586_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_BatchNormInference_float_float_float_float_float_float_cuda_BatchNormInference_530_CallKernel(dim3(4096, 1, 1), dim3(512, 1, 1), 0, nullptr, std::move(inception3_Constant_110_0), std::move(inception3_Constant_111_0), std::move(inception3_Convolution_586_0), std::move(inception3_Constant_112_0), std::move(inception3_Constant_113_0), std::move(inception3_BatchNormInference_590_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_Relu_float_float_cuda_Relu_490_CallKernel(dim3(9800, 1, 1), dim3(512, 1, 1), 0, nullptr, std::move(inception3_BatchNormInference_590_0), std::move(inception3_Relu_592_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_Reshape_float_float_cuda_Reshape_579_CallKernel(dim3(4, 18, 1), dim3(16, 16, 1), 0, nullptr, std::move(inception3_Constant_99_0), std::move(inception3_Reshape_569_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_Convolution_float_float_float_cuda_lib_Convolution_580Kernel(std::move(inception3_cudnn_handle_0), std::move(inception3_Concat_568_0), std::move(inception3_Reshape_569_0), std::move(inception3_Convolution_570_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_BatchNormInference_float_float_float_float_float_float_cuda_BatchNormInference_530_CallKernel(dim3(4096, 1, 1), dim3(512, 1, 1), 0, nullptr, std::move(inception3_Constant_100_0), std::move(inception3_Constant_101_0), std::move(inception3_Convolution_570_0), std::move(inception3_Constant_102_0), std::move(inception3_Constant_103_0), std::move(inception3_BatchNormInference_576_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_Relu_float_float_cuda_Relu_490_CallKernel(dim3(9800, 1, 1), dim3(512, 1, 1), 0, nullptr, std::move(inception3_BatchNormInference_576_0), std::move(inception3_Relu_581_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_Concat_float_float_float_float_float_cuda_Concat_568_CallKernel(dim3(44100, 1, 1), dim3(512, 1, 1), 0, nullptr, std::move(inception3_Relu_581_0), std::move(inception3_Relu_592_0), std::move(inception3_Relu_597_0), std::move(inception3_Relu_589_0), std::move(inception3_Concat_598_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_MaxPool_float_float_cuda_lib_MaxPool_603Kernel(std::move(inception3_cudnn_handle_0), std::move(inception3_Concat_598_0), std::move(inception3_MaxPool_603_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_Reshape_float_float_cuda_Reshape_579_CallKernel(dim3(4, 18, 1), dim3(16, 16, 1), 0, nullptr, std::move(inception3_Constant_140_0), std::move(inception3_Reshape_601_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_Convolution_float_float_float_cuda_lib_Convolution_580Kernel(std::move(inception3_cudnn_handle_0), std::move(inception3_Concat_598_0), std::move(inception3_Reshape_601_0), std::move(inception3_Convolution_602_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_BatchNormInference_float_float_float_float_float_float_cuda_BatchNormInference_530_CallKernel(dim3(4096, 1, 1), dim3(512, 1, 1), 0, nullptr, std::move(inception3_Constant_141_0), std::move(inception3_Constant_142_0), std::move(inception3_Convolution_602_0), std::move(inception3_Constant_143_0), std::move(inception3_Constant_144_0), std::move(inception3_BatchNormInference_605_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_Relu_float_float_cuda_Relu_490_CallKernel(dim3(9800, 1, 1), dim3(512, 1, 1), 0, nullptr, std::move(inception3_BatchNormInference_605_0), std::move(inception3_Relu_607_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_Reshape_float_float_cuda_Reshape_527_CallKernel(dim3(6, 64, 1), dim3(16, 1, 16), 0, nullptr, std::move(inception3_Constant_145_0), std::move(inception3_Reshape_608_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_Convolution_float_float_float_cuda_lib_Convolution_528Kernel(std::move(inception3_cudnn_handle_0), std::move(inception3_Relu_607_0), std::move(inception3_Reshape_608_0), std::move(inception3_Convolution_609_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_BatchNormInference_float_float_float_float_float_float_cuda_BatchNormInference_531_CallKernel(dim3(6144, 1, 1), dim3(512, 1, 1), 0, nullptr, std::move(inception3_Constant_146_0), std::move(inception3_Constant_147_0), std::move(inception3_Convolution_609_0), std::move(inception3_Constant_148_0), std::move(inception3_Constant_149_0), std::move(inception3_BatchNormInference_610_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_Relu_float_float_cuda_Relu_490_CallKernel(dim3(14700, 1, 1), dim3(512, 1, 1), 0, nullptr, std::move(inception3_BatchNormInference_610_0), std::move(inception3_Relu_611_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_Reshape_float_float_cuda_Reshape_534_CallKernel(dim3(6, 96, 1), dim3(16, 1, 16), 0, nullptr, std::move(inception3_Constant_150_0), std::move(inception3_Reshape_612_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_Convolution_float_float_float_cuda_lib_Convolution_613Kernel(std::move(inception3_cudnn_handle_0), std::move(inception3_Relu_611_0), std::move(inception3_Reshape_612_0), std::move(inception3_Convolution_613_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_BatchNormInference_float_float_float_float_float_float_cuda_BatchNormInference_614_CallKernel(dim3(6144, 1, 1), dim3(289, 1, 1), 0, nullptr, std::move(inception3_Constant_151_0), std::move(inception3_Constant_152_0), std::move(inception3_Convolution_613_0), std::move(inception3_Constant_153_0), std::move(inception3_Constant_154_0), std::move(inception3_BatchNormInference_614_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_Relu_float_float_cuda_Relu_490_CallKernel(dim3(3468, 1, 1), dim3(512, 1, 1), 0, nullptr, std::move(inception3_BatchNormInference_614_0), std::move(inception3_Relu_615_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_Reshape_float_float_cuda_Reshape_599_CallKernel(dim3(24, 288, 1), dim3(16, 1, 16), 0, nullptr, std::move(inception3_Constant_135_0), std::move(inception3_Reshape_599_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_Convolution_float_float_float_cuda_lib_Convolution_600Kernel(std::move(inception3_cudnn_handle_0), std::move(inception3_Concat_598_0), std::move(inception3_Reshape_599_0), std::move(inception3_Convolution_600_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_BatchNormInference_float_float_float_float_float_float_cuda_BatchNormInference_604_CallKernel(dim3(24576, 1, 1), dim3(289, 1, 1), 0, nullptr, std::move(inception3_Constant_136_0), std::move(inception3_Constant_137_0), std::move(inception3_Convolution_600_0), std::move(inception3_Constant_138_0), std::move(inception3_Constant_139_0), std::move(inception3_BatchNormInference_604_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_Relu_float_float_cuda_Relu_490_CallKernel(dim3(13872, 1, 1), dim3(512, 1, 1), 0, nullptr, std::move(inception3_BatchNormInference_604_0), std::move(inception3_Relu_606_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_Concat_float_float_float_float_cuda_Concat_616_CallKernel(dim3(27744, 1, 1), dim3(512, 1, 1), 0, nullptr, std::move(inception3_Relu_606_0), std::move(inception3_Relu_615_0), std::move(inception3_MaxPool_603_0), std::move(inception3_Concat_616_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_AvgPool_float_float_cuda_lib_AvgPool_623Kernel(std::move(inception3_cudnn_handle_0), std::move(inception3_Concat_616_0), std::move(inception3_AvgPool_623_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_Reshape_float_float_cuda_Reshape_627_CallKernel(dim3(12, 48, 1), dim3(16, 16, 1), 0, nullptr, std::move(inception3_Constant_201_0), std::move(inception3_Reshape_627_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_Convolution_float_float_float_cuda_lib_Convolution_628Kernel(std::move(inception3_cudnn_handle_0), std::move(inception3_AvgPool_623_0), std::move(inception3_Reshape_627_0), std::move(inception3_Convolution_628_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_BatchNormInference_float_float_float_float_float_float_cuda_BatchNormInference_632_CallKernel(dim3(12288, 1, 1), dim3(289, 1, 1), 0, nullptr, std::move(inception3_Constant_202_0), std::move(inception3_Constant_203_0), std::move(inception3_Convolution_628_0), std::move(inception3_Constant_204_0), std::move(inception3_Constant_205_0), std::move(inception3_BatchNormInference_632_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_Relu_float_float_cuda_Relu_490_CallKernel(dim3(6936, 1, 1), dim3(512, 1, 1), 0, nullptr, std::move(inception3_BatchNormInference_632_0), std::move(inception3_Relu_637_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_Reshape_float_float_cuda_Reshape_621_CallKernel(dim3(8, 48, 1), dim3(16, 16, 1), 0, nullptr, std::move(inception3_Constant_176_0), std::move(inception3_Reshape_621_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_Convolution_float_float_float_cuda_lib_Convolution_622Kernel(std::move(inception3_cudnn_handle_0), std::move(inception3_Concat_616_0), std::move(inception3_Reshape_621_0), std::move(inception3_Convolution_622_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_BatchNormInference_float_float_float_float_float_float_cuda_BatchNormInference_626_CallKernel(dim3(8192, 1, 1), dim3(289, 1, 1), 0, nullptr, std::move(inception3_Constant_177_0), std::move(inception3_Constant_178_0), std::move(inception3_Convolution_622_0), std::move(inception3_Constant_179_0), std::move(inception3_Constant_180_0), std::move(inception3_BatchNormInference_626_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_Relu_float_float_cuda_Relu_490_CallKernel(dim3(4624, 1, 1), dim3(512, 1, 1), 0, nullptr, std::move(inception3_BatchNormInference_626_0), std::move(inception3_Relu_631_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_Reshape_float_float_cuda_Reshape_635_CallKernel(dim3(8, 128, 1), dim3(16, 1, 16), 0, nullptr, std::move(inception3_Constant_181_0), std::move(inception3_Reshape_635_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_Convolution_float_float_float_cuda_lib_Convolution_636Kernel(std::move(inception3_cudnn_handle_0), std::move(inception3_Relu_631_0), std::move(inception3_Reshape_635_0), std::move(inception3_Convolution_636_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_BatchNormInference_float_float_float_float_float_float_cuda_BatchNormInference_626_CallKernel(dim3(8192, 1, 1), dim3(289, 1, 1), 0, nullptr, std::move(inception3_Constant_182_0), std::move(inception3_Constant_183_0), std::move(inception3_Convolution_636_0), std::move(inception3_Constant_184_0), std::move(inception3_Constant_185_0), std::move(inception3_BatchNormInference_639_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_Relu_float_float_cuda_Relu_490_CallKernel(dim3(4624, 1, 1), dim3(512, 1, 1), 0, nullptr, std::move(inception3_BatchNormInference_639_0), std::move(inception3_Relu_641_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_Reshape_float_float_cuda_Reshape_635_CallKernel(dim3(8, 128, 1), dim3(16, 1, 16), 0, nullptr, std::move(inception3_Constant_186_0), std::move(inception3_Reshape_644_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_Convolution_float_float_float_cuda_lib_Convolution_645Kernel(std::move(inception3_cudnn_handle_0), std::move(inception3_Relu_641_0), std::move(inception3_Reshape_644_0), std::move(inception3_Convolution_645_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_BatchNormInference_float_float_float_float_float_float_cuda_BatchNormInference_626_CallKernel(dim3(8192, 1, 1), dim3(289, 1, 1), 0, nullptr, std::move(inception3_Constant_187_0), std::move(inception3_Constant_188_0), std::move(inception3_Convolution_645_0), std::move(inception3_Constant_189_0), std::move(inception3_Constant_190_0), std::move(inception3_BatchNormInference_647_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_Relu_float_float_cuda_Relu_490_CallKernel(dim3(4624, 1, 1), dim3(512, 1, 1), 0, nullptr, std::move(inception3_BatchNormInference_647_0), std::move(inception3_Relu_649_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_Reshape_float_float_cuda_Reshape_635_CallKernel(dim3(8, 128, 1), dim3(16, 1, 16), 0, nullptr, std::move(inception3_Constant_191_0), std::move(inception3_Reshape_650_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_Convolution_float_float_float_cuda_lib_Convolution_636Kernel(std::move(inception3_cudnn_handle_0), std::move(inception3_Relu_649_0), std::move(inception3_Reshape_650_0), std::move(inception3_Convolution_651_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_BatchNormInference_float_float_float_float_float_float_cuda_BatchNormInference_626_CallKernel(dim3(8192, 1, 1), dim3(289, 1, 1), 0, nullptr, std::move(inception3_Constant_192_0), std::move(inception3_Constant_193_0), std::move(inception3_Convolution_651_0), std::move(inception3_Constant_194_0), std::move(inception3_Constant_195_0), std::move(inception3_BatchNormInference_652_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_Relu_float_float_cuda_Relu_490_CallKernel(dim3(4624, 1, 1), dim3(512, 1, 1), 0, nullptr, std::move(inception3_BatchNormInference_652_0), std::move(inception3_Relu_653_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_Reshape_float_float_cuda_Reshape_654_CallKernel(dim3(12, 128, 1), dim3(16, 1, 16), 0, nullptr, std::move(inception3_Constant_196_0), std::move(inception3_Reshape_654_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_Convolution_float_float_float_cuda_lib_Convolution_655Kernel(std::move(inception3_cudnn_handle_0), std::move(inception3_Relu_653_0), std::move(inception3_Reshape_654_0), std::move(inception3_Convolution_655_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_BatchNormInference_float_float_float_float_float_float_cuda_BatchNormInference_632_CallKernel(dim3(12288, 1, 1), dim3(289, 1, 1), 0, nullptr, std::move(inception3_Constant_197_0), std::move(inception3_Constant_198_0), std::move(inception3_Convolution_655_0), std::move(inception3_Constant_199_0), std::move(inception3_Constant_200_0), std::move(inception3_BatchNormInference_656_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_Relu_float_float_cuda_Relu_490_CallKernel(dim3(6936, 1, 1), dim3(512, 1, 1), 0, nullptr, std::move(inception3_BatchNormInference_656_0), std::move(inception3_Relu_657_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_Reshape_float_float_cuda_Reshape_621_CallKernel(dim3(8, 48, 1), dim3(16, 16, 1), 0, nullptr, std::move(inception3_Constant_161_0), std::move(inception3_Reshape_619_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_Convolution_float_float_float_cuda_lib_Convolution_622Kernel(std::move(inception3_cudnn_handle_0), std::move(inception3_Concat_616_0), std::move(inception3_Reshape_619_0), std::move(inception3_Convolution_620_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_BatchNormInference_float_float_float_float_float_float_cuda_BatchNormInference_626_CallKernel(dim3(8192, 1, 1), dim3(289, 1, 1), 0, nullptr, std::move(inception3_Constant_162_0), std::move(inception3_Constant_163_0), std::move(inception3_Convolution_620_0), std::move(inception3_Constant_164_0), std::move(inception3_Constant_165_0), std::move(inception3_BatchNormInference_625_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_Relu_float_float_cuda_Relu_490_CallKernel(dim3(4624, 1, 1), dim3(512, 1, 1), 0, nullptr, std::move(inception3_BatchNormInference_625_0), std::move(inception3_Relu_630_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_Reshape_float_float_cuda_Reshape_635_CallKernel(dim3(8, 128, 1), dim3(16, 1, 16), 0, nullptr, std::move(inception3_Constant_166_0), std::move(inception3_Reshape_633_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_Convolution_float_float_float_cuda_lib_Convolution_645Kernel(std::move(inception3_cudnn_handle_0), std::move(inception3_Relu_630_0), std::move(inception3_Reshape_633_0), std::move(inception3_Convolution_634_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_BatchNormInference_float_float_float_float_float_float_cuda_BatchNormInference_626_CallKernel(dim3(8192, 1, 1), dim3(289, 1, 1), 0, nullptr, std::move(inception3_Constant_167_0), std::move(inception3_Constant_168_0), std::move(inception3_Convolution_634_0), std::move(inception3_Constant_169_0), std::move(inception3_Constant_170_0), std::move(inception3_BatchNormInference_638_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_Relu_float_float_cuda_Relu_490_CallKernel(dim3(4624, 1, 1), dim3(512, 1, 1), 0, nullptr, std::move(inception3_BatchNormInference_638_0), std::move(inception3_Relu_640_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_Reshape_float_float_cuda_Reshape_654_CallKernel(dim3(12, 128, 1), dim3(16, 1, 16), 0, nullptr, std::move(inception3_Constant_171_0), std::move(inception3_Reshape_642_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_Convolution_float_float_float_cuda_lib_Convolution_643Kernel(std::move(inception3_cudnn_handle_0), std::move(inception3_Relu_640_0), std::move(inception3_Reshape_642_0), std::move(inception3_Convolution_643_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_BatchNormInference_float_float_float_float_float_float_cuda_BatchNormInference_632_CallKernel(dim3(12288, 1, 1), dim3(289, 1, 1), 0, nullptr, std::move(inception3_Constant_172_0), std::move(inception3_Constant_173_0), std::move(inception3_Convolution_643_0), std::move(inception3_Constant_174_0), std::move(inception3_Constant_175_0), std::move(inception3_BatchNormInference_646_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_Relu_float_float_cuda_Relu_490_CallKernel(dim3(6936, 1, 1), dim3(512, 1, 1), 0, nullptr, std::move(inception3_BatchNormInference_646_0), std::move(inception3_Relu_648_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_Reshape_float_float_cuda_Reshape_627_CallKernel(dim3(12, 48, 1), dim3(16, 16, 1), 0, nullptr, std::move(inception3_Constant_156_0), std::move(inception3_Reshape_617_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_Convolution_float_float_float_cuda_lib_Convolution_628Kernel(std::move(inception3_cudnn_handle_0), std::move(inception3_Concat_616_0), std::move(inception3_Reshape_617_0), std::move(inception3_Convolution_618_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_BatchNormInference_float_float_float_float_float_float_cuda_BatchNormInference_632_CallKernel(dim3(12288, 1, 1), dim3(289, 1, 1), 0, nullptr, std::move(inception3_Constant_157_0), std::move(inception3_Constant_158_0), std::move(inception3_Convolution_618_0), std::move(inception3_Constant_159_0), std::move(inception3_Constant_160_0), std::move(inception3_BatchNormInference_624_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_Relu_float_float_cuda_Relu_490_CallKernel(dim3(6936, 1, 1), dim3(512, 1, 1), 0, nullptr, std::move(inception3_BatchNormInference_624_0), std::move(inception3_Relu_629_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_Concat_float_float_float_float_float_cuda_Concat_658_CallKernel(dim3(27744, 1, 1), dim3(512, 1, 1), 0, nullptr, std::move(inception3_Relu_629_0), std::move(inception3_Relu_648_0), std::move(inception3_Relu_657_0), std::move(inception3_Relu_637_0), std::move(inception3_Concat_658_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_AvgPool_float_float_cuda_lib_AvgPool_623Kernel(std::move(inception3_cudnn_handle_0), std::move(inception3_Concat_658_0), std::move(inception3_AvgPool_665_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_Reshape_float_float_cuda_Reshape_627_CallKernel(dim3(12, 48, 1), dim3(16, 16, 1), 0, nullptr, std::move(inception3_Constant_252_0), std::move(inception3_Reshape_669_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_Convolution_float_float_float_cuda_lib_Convolution_628Kernel(std::move(inception3_cudnn_handle_0), std::move(inception3_AvgPool_665_0), std::move(inception3_Reshape_669_0), std::move(inception3_Convolution_670_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_BatchNormInference_float_float_float_float_float_float_cuda_BatchNormInference_632_CallKernel(dim3(12288, 1, 1), dim3(289, 1, 1), 0, nullptr, std::move(inception3_Constant_253_0), std::move(inception3_Constant_254_0), std::move(inception3_Convolution_670_0), std::move(inception3_Constant_255_0), std::move(inception3_Constant_256_0), std::move(inception3_BatchNormInference_674_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_Relu_float_float_cuda_Relu_490_CallKernel(dim3(6936, 1, 1), dim3(512, 1, 1), 0, nullptr, std::move(inception3_BatchNormInference_674_0), std::move(inception3_Relu_679_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_Reshape_float_float_cuda_Reshape_663_CallKernel(dim3(10, 48, 1), dim3(16, 16, 1), 0, nullptr, std::move(inception3_Constant_227_0), std::move(inception3_Reshape_663_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_Convolution_float_float_float_cuda_lib_Convolution_664Kernel(std::move(inception3_cudnn_handle_0), std::move(inception3_Concat_658_0), std::move(inception3_Reshape_663_0), std::move(inception3_Convolution_664_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_BatchNormInference_float_float_float_float_float_float_cuda_BatchNormInference_668_CallKernel(dim3(10240, 1, 1), dim3(289, 1, 1), 0, nullptr, std::move(inception3_Constant_228_0), std::move(inception3_Constant_229_0), std::move(inception3_Convolution_664_0), std::move(inception3_Constant_230_0), std::move(inception3_Constant_231_0), std::move(inception3_BatchNormInference_668_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_Relu_float_float_cuda_Relu_490_CallKernel(dim3(5780, 1, 1), dim3(512, 1, 1), 0, nullptr, std::move(inception3_BatchNormInference_668_0), std::move(inception3_Relu_673_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_Reshape_float_float_cuda_Reshape_677_CallKernel(dim3(10, 160, 1), dim3(16, 1, 16), 0, nullptr, std::move(inception3_Constant_232_0), std::move(inception3_Reshape_677_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_Convolution_float_float_float_cuda_lib_Convolution_678Kernel(std::move(inception3_cudnn_handle_0), std::move(inception3_Relu_673_0), std::move(inception3_Reshape_677_0), std::move(inception3_Convolution_678_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_BatchNormInference_float_float_float_float_float_float_cuda_BatchNormInference_668_CallKernel(dim3(10240, 1, 1), dim3(289, 1, 1), 0, nullptr, std::move(inception3_Constant_233_0), std::move(inception3_Constant_234_0), std::move(inception3_Convolution_678_0), std::move(inception3_Constant_235_0), std::move(inception3_Constant_236_0), std::move(inception3_BatchNormInference_681_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_Relu_float_float_cuda_Relu_490_CallKernel(dim3(5780, 1, 1), dim3(512, 1, 1), 0, nullptr, std::move(inception3_BatchNormInference_681_0), std::move(inception3_Relu_683_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_Reshape_float_float_cuda_Reshape_677_CallKernel(dim3(10, 160, 1), dim3(16, 1, 16), 0, nullptr, std::move(inception3_Constant_237_0), std::move(inception3_Reshape_686_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_Convolution_float_float_float_cuda_lib_Convolution_687Kernel(std::move(inception3_cudnn_handle_0), std::move(inception3_Relu_683_0), std::move(inception3_Reshape_686_0), std::move(inception3_Convolution_687_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_BatchNormInference_float_float_float_float_float_float_cuda_BatchNormInference_668_CallKernel(dim3(10240, 1, 1), dim3(289, 1, 1), 0, nullptr, std::move(inception3_Constant_238_0), std::move(inception3_Constant_239_0), std::move(inception3_Convolution_687_0), std::move(inception3_Constant_240_0), std::move(inception3_Constant_241_0), std::move(inception3_BatchNormInference_689_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_Relu_float_float_cuda_Relu_490_CallKernel(dim3(5780, 1, 1), dim3(512, 1, 1), 0, nullptr, std::move(inception3_BatchNormInference_689_0), std::move(inception3_Relu_691_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_Reshape_float_float_cuda_Reshape_677_CallKernel(dim3(10, 160, 1), dim3(16, 1, 16), 0, nullptr, std::move(inception3_Constant_242_0), std::move(inception3_Reshape_692_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_Convolution_float_float_float_cuda_lib_Convolution_678Kernel(std::move(inception3_cudnn_handle_0), std::move(inception3_Relu_691_0), std::move(inception3_Reshape_692_0), std::move(inception3_Convolution_693_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_BatchNormInference_float_float_float_float_float_float_cuda_BatchNormInference_668_CallKernel(dim3(10240, 1, 1), dim3(289, 1, 1), 0, nullptr, std::move(inception3_Constant_243_0), std::move(inception3_Constant_244_0), std::move(inception3_Convolution_693_0), std::move(inception3_Constant_245_0), std::move(inception3_Constant_246_0), std::move(inception3_BatchNormInference_694_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_Relu_float_float_cuda_Relu_490_CallKernel(dim3(5780, 1, 1), dim3(512, 1, 1), 0, nullptr, std::move(inception3_BatchNormInference_694_0), std::move(inception3_Relu_695_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_Reshape_float_float_cuda_Reshape_696_CallKernel(dim3(12, 160, 1), dim3(16, 1, 16), 0, nullptr, std::move(inception3_Constant_247_0), std::move(inception3_Reshape_696_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_Convolution_float_float_float_cuda_lib_Convolution_697Kernel(std::move(inception3_cudnn_handle_0), std::move(inception3_Relu_695_0), std::move(inception3_Reshape_696_0), std::move(inception3_Convolution_697_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_BatchNormInference_float_float_float_float_float_float_cuda_BatchNormInference_632_CallKernel(dim3(12288, 1, 1), dim3(289, 1, 1), 0, nullptr, std::move(inception3_Constant_248_0), std::move(inception3_Constant_249_0), std::move(inception3_Convolution_697_0), std::move(inception3_Constant_250_0), std::move(inception3_Constant_251_0), std::move(inception3_BatchNormInference_698_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_Relu_float_float_cuda_Relu_490_CallKernel(dim3(6936, 1, 1), dim3(512, 1, 1), 0, nullptr, std::move(inception3_BatchNormInference_698_0), std::move(inception3_Relu_699_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_Reshape_float_float_cuda_Reshape_663_CallKernel(dim3(10, 48, 1), dim3(16, 16, 1), 0, nullptr, std::move(inception3_Constant_212_0), std::move(inception3_Reshape_661_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_Convolution_float_float_float_cuda_lib_Convolution_664Kernel(std::move(inception3_cudnn_handle_0), std::move(inception3_Concat_658_0), std::move(inception3_Reshape_661_0), std::move(inception3_Convolution_662_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_BatchNormInference_float_float_float_float_float_float_cuda_BatchNormInference_668_CallKernel(dim3(10240, 1, 1), dim3(289, 1, 1), 0, nullptr, std::move(inception3_Constant_213_0), std::move(inception3_Constant_214_0), std::move(inception3_Convolution_662_0), std::move(inception3_Constant_215_0), std::move(inception3_Constant_216_0), std::move(inception3_BatchNormInference_667_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_Relu_float_float_cuda_Relu_490_CallKernel(dim3(5780, 1, 1), dim3(512, 1, 1), 0, nullptr, std::move(inception3_BatchNormInference_667_0), std::move(inception3_Relu_672_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_Reshape_float_float_cuda_Reshape_677_CallKernel(dim3(10, 160, 1), dim3(16, 1, 16), 0, nullptr, std::move(inception3_Constant_217_0), std::move(inception3_Reshape_675_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_Convolution_float_float_float_cuda_lib_Convolution_687Kernel(std::move(inception3_cudnn_handle_0), std::move(inception3_Relu_672_0), std::move(inception3_Reshape_675_0), std::move(inception3_Convolution_676_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_BatchNormInference_float_float_float_float_float_float_cuda_BatchNormInference_668_CallKernel(dim3(10240, 1, 1), dim3(289, 1, 1), 0, nullptr, std::move(inception3_Constant_218_0), std::move(inception3_Constant_219_0), std::move(inception3_Convolution_676_0), std::move(inception3_Constant_220_0), std::move(inception3_Constant_221_0), std::move(inception3_BatchNormInference_680_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_Relu_float_float_cuda_Relu_490_CallKernel(dim3(5780, 1, 1), dim3(512, 1, 1), 0, nullptr, std::move(inception3_BatchNormInference_680_0), std::move(inception3_Relu_682_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_Reshape_float_float_cuda_Reshape_696_CallKernel(dim3(12, 160, 1), dim3(16, 1, 16), 0, nullptr, std::move(inception3_Constant_222_0), std::move(inception3_Reshape_684_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_Convolution_float_float_float_cuda_lib_Convolution_685Kernel(std::move(inception3_cudnn_handle_0), std::move(inception3_Relu_682_0), std::move(inception3_Reshape_684_0), std::move(inception3_Convolution_685_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_BatchNormInference_float_float_float_float_float_float_cuda_BatchNormInference_632_CallKernel(dim3(12288, 1, 1), dim3(289, 1, 1), 0, nullptr, std::move(inception3_Constant_223_0), std::move(inception3_Constant_224_0), std::move(inception3_Convolution_685_0), std::move(inception3_Constant_225_0), std::move(inception3_Constant_226_0), std::move(inception3_BatchNormInference_688_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_Relu_float_float_cuda_Relu_490_CallKernel(dim3(6936, 1, 1), dim3(512, 1, 1), 0, nullptr, std::move(inception3_BatchNormInference_688_0), std::move(inception3_Relu_690_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_Reshape_float_float_cuda_Reshape_627_CallKernel(dim3(12, 48, 1), dim3(16, 16, 1), 0, nullptr, std::move(inception3_Constant_207_0), std::move(inception3_Reshape_659_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_Convolution_float_float_float_cuda_lib_Convolution_628Kernel(std::move(inception3_cudnn_handle_0), std::move(inception3_Concat_658_0), std::move(inception3_Reshape_659_0), std::move(inception3_Convolution_660_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_BatchNormInference_float_float_float_float_float_float_cuda_BatchNormInference_632_CallKernel(dim3(12288, 1, 1), dim3(289, 1, 1), 0, nullptr, std::move(inception3_Constant_208_0), std::move(inception3_Constant_209_0), std::move(inception3_Convolution_660_0), std::move(inception3_Constant_210_0), std::move(inception3_Constant_211_0), std::move(inception3_BatchNormInference_666_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_Relu_float_float_cuda_Relu_490_CallKernel(dim3(6936, 1, 1), dim3(512, 1, 1), 0, nullptr, std::move(inception3_BatchNormInference_666_0), std::move(inception3_Relu_671_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_Concat_float_float_float_float_float_cuda_Concat_658_CallKernel(dim3(27744, 1, 1), dim3(512, 1, 1), 0, nullptr, std::move(inception3_Relu_671_0), std::move(inception3_Relu_690_0), std::move(inception3_Relu_699_0), std::move(inception3_Relu_679_0), std::move(inception3_Concat_700_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_AvgPool_float_float_cuda_lib_AvgPool_623Kernel(std::move(inception3_cudnn_handle_0), std::move(inception3_Concat_700_0), std::move(inception3_AvgPool_707_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_Reshape_float_float_cuda_Reshape_627_CallKernel(dim3(12, 48, 1), dim3(16, 16, 1), 0, nullptr, std::move(inception3_Constant_303_0), std::move(inception3_Reshape_711_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_Convolution_float_float_float_cuda_lib_Convolution_628Kernel(std::move(inception3_cudnn_handle_0), std::move(inception3_AvgPool_707_0), std::move(inception3_Reshape_711_0), std::move(inception3_Convolution_712_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_BatchNormInference_float_float_float_float_float_float_cuda_BatchNormInference_632_CallKernel(dim3(12288, 1, 1), dim3(289, 1, 1), 0, nullptr, std::move(inception3_Constant_304_0), std::move(inception3_Constant_305_0), std::move(inception3_Convolution_712_0), std::move(inception3_Constant_306_0), std::move(inception3_Constant_307_0), std::move(inception3_BatchNormInference_716_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_Relu_float_float_cuda_Relu_490_CallKernel(dim3(6936, 1, 1), dim3(512, 1, 1), 0, nullptr, std::move(inception3_BatchNormInference_716_0), std::move(inception3_Relu_721_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_Reshape_float_float_cuda_Reshape_663_CallKernel(dim3(10, 48, 1), dim3(16, 16, 1), 0, nullptr, std::move(inception3_Constant_278_0), std::move(inception3_Reshape_705_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_Convolution_float_float_float_cuda_lib_Convolution_664Kernel(std::move(inception3_cudnn_handle_0), std::move(inception3_Concat_700_0), std::move(inception3_Reshape_705_0), std::move(inception3_Convolution_706_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_BatchNormInference_float_float_float_float_float_float_cuda_BatchNormInference_668_CallKernel(dim3(10240, 1, 1), dim3(289, 1, 1), 0, nullptr, std::move(inception3_Constant_279_0), std::move(inception3_Constant_280_0), std::move(inception3_Convolution_706_0), std::move(inception3_Constant_281_0), std::move(inception3_Constant_282_0), std::move(inception3_BatchNormInference_710_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_Relu_float_float_cuda_Relu_490_CallKernel(dim3(5780, 1, 1), dim3(512, 1, 1), 0, nullptr, std::move(inception3_BatchNormInference_710_0), std::move(inception3_Relu_715_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_Reshape_float_float_cuda_Reshape_677_CallKernel(dim3(10, 160, 1), dim3(16, 1, 16), 0, nullptr, std::move(inception3_Constant_283_0), std::move(inception3_Reshape_719_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_Convolution_float_float_float_cuda_lib_Convolution_678Kernel(std::move(inception3_cudnn_handle_0), std::move(inception3_Relu_715_0), std::move(inception3_Reshape_719_0), std::move(inception3_Convolution_720_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_BatchNormInference_float_float_float_float_float_float_cuda_BatchNormInference_668_CallKernel(dim3(10240, 1, 1), dim3(289, 1, 1), 0, nullptr, std::move(inception3_Constant_284_0), std::move(inception3_Constant_285_0), std::move(inception3_Convolution_720_0), std::move(inception3_Constant_286_0), std::move(inception3_Constant_287_0), std::move(inception3_BatchNormInference_723_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_Relu_float_float_cuda_Relu_490_CallKernel(dim3(5780, 1, 1), dim3(512, 1, 1), 0, nullptr, std::move(inception3_BatchNormInference_723_0), std::move(inception3_Relu_725_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_Reshape_float_float_cuda_Reshape_677_CallKernel(dim3(10, 160, 1), dim3(16, 1, 16), 0, nullptr, std::move(inception3_Constant_288_0), std::move(inception3_Reshape_728_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_Convolution_float_float_float_cuda_lib_Convolution_687Kernel(std::move(inception3_cudnn_handle_0), std::move(inception3_Relu_725_0), std::move(inception3_Reshape_728_0), std::move(inception3_Convolution_729_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_BatchNormInference_float_float_float_float_float_float_cuda_BatchNormInference_668_CallKernel(dim3(10240, 1, 1), dim3(289, 1, 1), 0, nullptr, std::move(inception3_Constant_289_0), std::move(inception3_Constant_290_0), std::move(inception3_Convolution_729_0), std::move(inception3_Constant_291_0), std::move(inception3_Constant_292_0), std::move(inception3_BatchNormInference_731_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_Relu_float_float_cuda_Relu_490_CallKernel(dim3(5780, 1, 1), dim3(512, 1, 1), 0, nullptr, std::move(inception3_BatchNormInference_731_0), std::move(inception3_Relu_733_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_Reshape_float_float_cuda_Reshape_677_CallKernel(dim3(10, 160, 1), dim3(16, 1, 16), 0, nullptr, std::move(inception3_Constant_293_0), std::move(inception3_Reshape_734_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_Convolution_float_float_float_cuda_lib_Convolution_678Kernel(std::move(inception3_cudnn_handle_0), std::move(inception3_Relu_733_0), std::move(inception3_Reshape_734_0), std::move(inception3_Convolution_735_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_BatchNormInference_float_float_float_float_float_float_cuda_BatchNormInference_668_CallKernel(dim3(10240, 1, 1), dim3(289, 1, 1), 0, nullptr, std::move(inception3_Constant_294_0), std::move(inception3_Constant_295_0), std::move(inception3_Convolution_735_0), std::move(inception3_Constant_296_0), std::move(inception3_Constant_297_0), std::move(inception3_BatchNormInference_736_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_Relu_float_float_cuda_Relu_490_CallKernel(dim3(5780, 1, 1), dim3(512, 1, 1), 0, nullptr, std::move(inception3_BatchNormInference_736_0), std::move(inception3_Relu_737_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_Reshape_float_float_cuda_Reshape_696_CallKernel(dim3(12, 160, 1), dim3(16, 1, 16), 0, nullptr, std::move(inception3_Constant_298_0), std::move(inception3_Reshape_738_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_Convolution_float_float_float_cuda_lib_Convolution_697Kernel(std::move(inception3_cudnn_handle_0), std::move(inception3_Relu_737_0), std::move(inception3_Reshape_738_0), std::move(inception3_Convolution_739_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_BatchNormInference_float_float_float_float_float_float_cuda_BatchNormInference_632_CallKernel(dim3(12288, 1, 1), dim3(289, 1, 1), 0, nullptr, std::move(inception3_Constant_299_0), std::move(inception3_Constant_300_0), std::move(inception3_Convolution_739_0), std::move(inception3_Constant_301_0), std::move(inception3_Constant_302_0), std::move(inception3_BatchNormInference_740_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_Relu_float_float_cuda_Relu_490_CallKernel(dim3(6936, 1, 1), dim3(512, 1, 1), 0, nullptr, std::move(inception3_BatchNormInference_740_0), std::move(inception3_Relu_741_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_Reshape_float_float_cuda_Reshape_663_CallKernel(dim3(10, 48, 1), dim3(16, 16, 1), 0, nullptr, std::move(inception3_Constant_263_0), std::move(inception3_Reshape_703_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_Convolution_float_float_float_cuda_lib_Convolution_664Kernel(std::move(inception3_cudnn_handle_0), std::move(inception3_Concat_700_0), std::move(inception3_Reshape_703_0), std::move(inception3_Convolution_704_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_BatchNormInference_float_float_float_float_float_float_cuda_BatchNormInference_668_CallKernel(dim3(10240, 1, 1), dim3(289, 1, 1), 0, nullptr, std::move(inception3_Constant_264_0), std::move(inception3_Constant_265_0), std::move(inception3_Convolution_704_0), std::move(inception3_Constant_266_0), std::move(inception3_Constant_267_0), std::move(inception3_BatchNormInference_709_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_Relu_float_float_cuda_Relu_490_CallKernel(dim3(5780, 1, 1), dim3(512, 1, 1), 0, nullptr, std::move(inception3_BatchNormInference_709_0), std::move(inception3_Relu_714_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_Reshape_float_float_cuda_Reshape_677_CallKernel(dim3(10, 160, 1), dim3(16, 1, 16), 0, nullptr, std::move(inception3_Constant_268_0), std::move(inception3_Reshape_717_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_Convolution_float_float_float_cuda_lib_Convolution_687Kernel(std::move(inception3_cudnn_handle_0), std::move(inception3_Relu_714_0), std::move(inception3_Reshape_717_0), std::move(inception3_Convolution_718_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_BatchNormInference_float_float_float_float_float_float_cuda_BatchNormInference_668_CallKernel(dim3(10240, 1, 1), dim3(289, 1, 1), 0, nullptr, std::move(inception3_Constant_269_0), std::move(inception3_Constant_270_0), std::move(inception3_Convolution_718_0), std::move(inception3_Constant_271_0), std::move(inception3_Constant_272_0), std::move(inception3_BatchNormInference_722_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_Relu_float_float_cuda_Relu_490_CallKernel(dim3(5780, 1, 1), dim3(512, 1, 1), 0, nullptr, std::move(inception3_BatchNormInference_722_0), std::move(inception3_Relu_724_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_Reshape_float_float_cuda_Reshape_696_CallKernel(dim3(12, 160, 1), dim3(16, 1, 16), 0, nullptr, std::move(inception3_Constant_273_0), std::move(inception3_Reshape_726_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_Convolution_float_float_float_cuda_lib_Convolution_685Kernel(std::move(inception3_cudnn_handle_0), std::move(inception3_Relu_724_0), std::move(inception3_Reshape_726_0), std::move(inception3_Convolution_727_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_BatchNormInference_float_float_float_float_float_float_cuda_BatchNormInference_632_CallKernel(dim3(12288, 1, 1), dim3(289, 1, 1), 0, nullptr, std::move(inception3_Constant_274_0), std::move(inception3_Constant_275_0), std::move(inception3_Convolution_727_0), std::move(inception3_Constant_276_0), std::move(inception3_Constant_277_0), std::move(inception3_BatchNormInference_730_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_Relu_float_float_cuda_Relu_490_CallKernel(dim3(6936, 1, 1), dim3(512, 1, 1), 0, nullptr, std::move(inception3_BatchNormInference_730_0), std::move(inception3_Relu_732_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_Reshape_float_float_cuda_Reshape_627_CallKernel(dim3(12, 48, 1), dim3(16, 16, 1), 0, nullptr, std::move(inception3_Constant_258_0), std::move(inception3_Reshape_701_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_Convolution_float_float_float_cuda_lib_Convolution_628Kernel(std::move(inception3_cudnn_handle_0), std::move(inception3_Concat_700_0), std::move(inception3_Reshape_701_0), std::move(inception3_Convolution_702_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_BatchNormInference_float_float_float_float_float_float_cuda_BatchNormInference_632_CallKernel(dim3(12288, 1, 1), dim3(289, 1, 1), 0, nullptr, std::move(inception3_Constant_259_0), std::move(inception3_Constant_260_0), std::move(inception3_Convolution_702_0), std::move(inception3_Constant_261_0), std::move(inception3_Constant_262_0), std::move(inception3_BatchNormInference_708_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_Relu_float_float_cuda_Relu_490_CallKernel(dim3(6936, 1, 1), dim3(512, 1, 1), 0, nullptr, std::move(inception3_BatchNormInference_708_0), std::move(inception3_Relu_713_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_Concat_float_float_float_float_float_cuda_Concat_658_CallKernel(dim3(27744, 1, 1), dim3(512, 1, 1), 0, nullptr, std::move(inception3_Relu_713_0), std::move(inception3_Relu_732_0), std::move(inception3_Relu_741_0), std::move(inception3_Relu_721_0), std::move(inception3_Concat_742_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_AvgPool_float_float_cuda_lib_AvgPool_623Kernel(std::move(inception3_cudnn_handle_0), std::move(inception3_Concat_742_0), std::move(inception3_AvgPool_749_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_Reshape_float_float_cuda_Reshape_627_CallKernel(dim3(12, 48, 1), dim3(16, 16, 1), 0, nullptr, std::move(inception3_Constant_354_0), std::move(inception3_Reshape_753_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_Convolution_float_float_float_cuda_lib_Convolution_628Kernel(std::move(inception3_cudnn_handle_0), std::move(inception3_AvgPool_749_0), std::move(inception3_Reshape_753_0), std::move(inception3_Convolution_754_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_BatchNormInference_float_float_float_float_float_float_cuda_BatchNormInference_632_CallKernel(dim3(12288, 1, 1), dim3(289, 1, 1), 0, nullptr, std::move(inception3_Constant_355_0), std::move(inception3_Constant_356_0), std::move(inception3_Convolution_754_0), std::move(inception3_Constant_357_0), std::move(inception3_Constant_358_0), std::move(inception3_BatchNormInference_758_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_Relu_float_float_cuda_Relu_490_CallKernel(dim3(6936, 1, 1), dim3(512, 1, 1), 0, nullptr, std::move(inception3_BatchNormInference_758_0), std::move(inception3_Relu_763_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_Reshape_float_float_cuda_Reshape_627_CallKernel(dim3(12, 48, 1), dim3(16, 16, 1), 0, nullptr, std::move(inception3_Constant_329_0), std::move(inception3_Reshape_747_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_Convolution_float_float_float_cuda_lib_Convolution_628Kernel(std::move(inception3_cudnn_handle_0), std::move(inception3_Concat_742_0), std::move(inception3_Reshape_747_0), std::move(inception3_Convolution_748_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_BatchNormInference_float_float_float_float_float_float_cuda_BatchNormInference_632_CallKernel(dim3(12288, 1, 1), dim3(289, 1, 1), 0, nullptr, std::move(inception3_Constant_330_0), std::move(inception3_Constant_331_0), std::move(inception3_Convolution_748_0), std::move(inception3_Constant_332_0), std::move(inception3_Constant_333_0), std::move(inception3_BatchNormInference_752_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_Relu_float_float_cuda_Relu_490_CallKernel(dim3(6936, 1, 1), dim3(512, 1, 1), 0, nullptr, std::move(inception3_BatchNormInference_752_0), std::move(inception3_Relu_757_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_Reshape_float_float_cuda_Reshape_761_CallKernel(dim3(12, 192, 1), dim3(16, 1, 16), 0, nullptr, std::move(inception3_Constant_334_0), std::move(inception3_Reshape_761_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_Convolution_float_float_float_cuda_lib_Convolution_762Kernel(std::move(inception3_cudnn_handle_0), std::move(inception3_Relu_757_0), std::move(inception3_Reshape_761_0), std::move(inception3_Convolution_762_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_BatchNormInference_float_float_float_float_float_float_cuda_BatchNormInference_632_CallKernel(dim3(12288, 1, 1), dim3(289, 1, 1), 0, nullptr, std::move(inception3_Constant_335_0), std::move(inception3_Constant_336_0), std::move(inception3_Convolution_762_0), std::move(inception3_Constant_337_0), std::move(inception3_Constant_338_0), std::move(inception3_BatchNormInference_765_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_Relu_float_float_cuda_Relu_490_CallKernel(dim3(6936, 1, 1), dim3(512, 1, 1), 0, nullptr, std::move(inception3_BatchNormInference_765_0), std::move(inception3_Relu_767_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_Reshape_float_float_cuda_Reshape_761_CallKernel(dim3(12, 192, 1), dim3(16, 1, 16), 0, nullptr, std::move(inception3_Constant_339_0), std::move(inception3_Reshape_770_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_Convolution_float_float_float_cuda_lib_Convolution_771Kernel(std::move(inception3_cudnn_handle_0), std::move(inception3_Relu_767_0), std::move(inception3_Reshape_770_0), std::move(inception3_Convolution_771_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_BatchNormInference_float_float_float_float_float_float_cuda_BatchNormInference_632_CallKernel(dim3(12288, 1, 1), dim3(289, 1, 1), 0, nullptr, std::move(inception3_Constant_340_0), std::move(inception3_Constant_341_0), std::move(inception3_Convolution_771_0), std::move(inception3_Constant_342_0), std::move(inception3_Constant_343_0), std::move(inception3_BatchNormInference_773_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_Relu_float_float_cuda_Relu_490_CallKernel(dim3(6936, 1, 1), dim3(512, 1, 1), 0, nullptr, std::move(inception3_BatchNormInference_773_0), std::move(inception3_Relu_775_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_Reshape_float_float_cuda_Reshape_761_CallKernel(dim3(12, 192, 1), dim3(16, 1, 16), 0, nullptr, std::move(inception3_Constant_344_0), std::move(inception3_Reshape_776_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_Convolution_float_float_float_cuda_lib_Convolution_762Kernel(std::move(inception3_cudnn_handle_0), std::move(inception3_Relu_775_0), std::move(inception3_Reshape_776_0), std::move(inception3_Convolution_777_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_BatchNormInference_float_float_float_float_float_float_cuda_BatchNormInference_632_CallKernel(dim3(12288, 1, 1), dim3(289, 1, 1), 0, nullptr, std::move(inception3_Constant_345_0), std::move(inception3_Constant_346_0), std::move(inception3_Convolution_777_0), std::move(inception3_Constant_347_0), std::move(inception3_Constant_348_0), std::move(inception3_BatchNormInference_778_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_Relu_float_float_cuda_Relu_490_CallKernel(dim3(6936, 1, 1), dim3(512, 1, 1), 0, nullptr, std::move(inception3_BatchNormInference_778_0), std::move(inception3_Relu_779_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_Reshape_float_float_cuda_Reshape_761_CallKernel(dim3(12, 192, 1), dim3(16, 1, 16), 0, nullptr, std::move(inception3_Constant_349_0), std::move(inception3_Reshape_780_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_Convolution_float_float_float_cuda_lib_Convolution_771Kernel(std::move(inception3_cudnn_handle_0), std::move(inception3_Relu_779_0), std::move(inception3_Reshape_780_0), std::move(inception3_Convolution_781_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_BatchNormInference_float_float_float_float_float_float_cuda_BatchNormInference_632_CallKernel(dim3(12288, 1, 1), dim3(289, 1, 1), 0, nullptr, std::move(inception3_Constant_350_0), std::move(inception3_Constant_351_0), std::move(inception3_Convolution_781_0), std::move(inception3_Constant_352_0), std::move(inception3_Constant_353_0), std::move(inception3_BatchNormInference_782_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_Relu_float_float_cuda_Relu_490_CallKernel(dim3(6936, 1, 1), dim3(512, 1, 1), 0, nullptr, std::move(inception3_BatchNormInference_782_0), std::move(inception3_Relu_783_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_Reshape_float_float_cuda_Reshape_627_CallKernel(dim3(12, 48, 1), dim3(16, 16, 1), 0, nullptr, std::move(inception3_Constant_314_0), std::move(inception3_Reshape_745_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_Convolution_float_float_float_cuda_lib_Convolution_628Kernel(std::move(inception3_cudnn_handle_0), std::move(inception3_Concat_742_0), std::move(inception3_Reshape_745_0), std::move(inception3_Convolution_746_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_BatchNormInference_float_float_float_float_float_float_cuda_BatchNormInference_632_CallKernel(dim3(12288, 1, 1), dim3(289, 1, 1), 0, nullptr, std::move(inception3_Constant_315_0), std::move(inception3_Constant_316_0), std::move(inception3_Convolution_746_0), std::move(inception3_Constant_317_0), std::move(inception3_Constant_318_0), std::move(inception3_BatchNormInference_751_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_Relu_float_float_cuda_Relu_490_CallKernel(dim3(6936, 1, 1), dim3(512, 1, 1), 0, nullptr, std::move(inception3_BatchNormInference_751_0), std::move(inception3_Relu_756_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_Reshape_float_float_cuda_Reshape_761_CallKernel(dim3(12, 192, 1), dim3(16, 1, 16), 0, nullptr, std::move(inception3_Constant_319_0), std::move(inception3_Reshape_759_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_Convolution_float_float_float_cuda_lib_Convolution_771Kernel(std::move(inception3_cudnn_handle_0), std::move(inception3_Relu_756_0), std::move(inception3_Reshape_759_0), std::move(inception3_Convolution_760_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_BatchNormInference_float_float_float_float_float_float_cuda_BatchNormInference_632_CallKernel(dim3(12288, 1, 1), dim3(289, 1, 1), 0, nullptr, std::move(inception3_Constant_320_0), std::move(inception3_Constant_321_0), std::move(inception3_Convolution_760_0), std::move(inception3_Constant_322_0), std::move(inception3_Constant_323_0), std::move(inception3_BatchNormInference_764_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_Relu_float_float_cuda_Relu_490_CallKernel(dim3(6936, 1, 1), dim3(512, 1, 1), 0, nullptr, std::move(inception3_BatchNormInference_764_0), std::move(inception3_Relu_766_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_Reshape_float_float_cuda_Reshape_761_CallKernel(dim3(12, 192, 1), dim3(16, 1, 16), 0, nullptr, std::move(inception3_Constant_324_0), std::move(inception3_Reshape_768_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_Convolution_float_float_float_cuda_lib_Convolution_762Kernel(std::move(inception3_cudnn_handle_0), std::move(inception3_Relu_766_0), std::move(inception3_Reshape_768_0), std::move(inception3_Convolution_769_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_BatchNormInference_float_float_float_float_float_float_cuda_BatchNormInference_632_CallKernel(dim3(12288, 1, 1), dim3(289, 1, 1), 0, nullptr, std::move(inception3_Constant_325_0), std::move(inception3_Constant_326_0), std::move(inception3_Convolution_769_0), std::move(inception3_Constant_327_0), std::move(inception3_Constant_328_0), std::move(inception3_BatchNormInference_772_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_Relu_float_float_cuda_Relu_490_CallKernel(dim3(6936, 1, 1), dim3(512, 1, 1), 0, nullptr, std::move(inception3_BatchNormInference_772_0), std::move(inception3_Relu_774_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_Reshape_float_float_cuda_Reshape_627_CallKernel(dim3(12, 48, 1), dim3(16, 16, 1), 0, nullptr, std::move(inception3_Constant_309_0), std::move(inception3_Reshape_743_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_Convolution_float_float_float_cuda_lib_Convolution_628Kernel(std::move(inception3_cudnn_handle_0), std::move(inception3_Concat_742_0), std::move(inception3_Reshape_743_0), std::move(inception3_Convolution_744_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_BatchNormInference_float_float_float_float_float_float_cuda_BatchNormInference_632_CallKernel(dim3(12288, 1, 1), dim3(289, 1, 1), 0, nullptr, std::move(inception3_Constant_310_0), std::move(inception3_Constant_311_0), std::move(inception3_Convolution_744_0), std::move(inception3_Constant_312_0), std::move(inception3_Constant_313_0), std::move(inception3_BatchNormInference_750_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_Relu_float_float_cuda_Relu_490_CallKernel(dim3(6936, 1, 1), dim3(512, 1, 1), 0, nullptr, std::move(inception3_BatchNormInference_750_0), std::move(inception3_Relu_755_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_Concat_float_float_float_float_float_cuda_Concat_658_CallKernel(dim3(27744, 1, 1), dim3(512, 1, 1), 0, nullptr, std::move(inception3_Relu_755_0), std::move(inception3_Relu_774_0), std::move(inception3_Relu_783_0), std::move(inception3_Relu_763_0), std::move(inception3_Concat_784_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_MaxPool_float_float_cuda_lib_MaxPool_789Kernel(std::move(inception3_cudnn_handle_0), std::move(inception3_Concat_784_0), std::move(inception3_MaxPool_789_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_Reshape_float_float_cuda_Reshape_627_CallKernel(dim3(12, 48, 1), dim3(16, 16, 1), 0, nullptr, std::move(inception3_Constant_370_0), std::move(inception3_Reshape_787_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_Convolution_float_float_float_cuda_lib_Convolution_628Kernel(std::move(inception3_cudnn_handle_0), std::move(inception3_Concat_784_0), std::move(inception3_Reshape_787_0), std::move(inception3_Convolution_788_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_BatchNormInference_float_float_float_float_float_float_cuda_BatchNormInference_632_CallKernel(dim3(12288, 1, 1), dim3(289, 1, 1), 0, nullptr, std::move(inception3_Constant_371_0), std::move(inception3_Constant_372_0), std::move(inception3_Convolution_788_0), std::move(inception3_Constant_373_0), std::move(inception3_Constant_374_0), std::move(inception3_BatchNormInference_791_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_Relu_float_float_cuda_Relu_490_CallKernel(dim3(6936, 1, 1), dim3(512, 1, 1), 0, nullptr, std::move(inception3_BatchNormInference_791_0), std::move(inception3_Relu_793_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_Reshape_float_float_cuda_Reshape_761_CallKernel(dim3(12, 192, 1), dim3(16, 1, 16), 0, nullptr, std::move(inception3_Constant_375_0), std::move(inception3_Reshape_796_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_Convolution_float_float_float_cuda_lib_Convolution_771Kernel(std::move(inception3_cudnn_handle_0), std::move(inception3_Relu_793_0), std::move(inception3_Reshape_796_0), std::move(inception3_Convolution_797_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_BatchNormInference_float_float_float_float_float_float_cuda_BatchNormInference_632_CallKernel(dim3(12288, 1, 1), dim3(289, 1, 1), 0, nullptr, std::move(inception3_Constant_376_0), std::move(inception3_Constant_377_0), std::move(inception3_Convolution_797_0), std::move(inception3_Constant_378_0), std::move(inception3_Constant_379_0), std::move(inception3_BatchNormInference_799_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_Relu_float_float_cuda_Relu_490_CallKernel(dim3(6936, 1, 1), dim3(512, 1, 1), 0, nullptr, std::move(inception3_BatchNormInference_799_0), std::move(inception3_Relu_801_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_Reshape_float_float_cuda_Reshape_761_CallKernel(dim3(12, 192, 1), dim3(16, 1, 16), 0, nullptr, std::move(inception3_Constant_380_0), std::move(inception3_Reshape_802_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_Convolution_float_float_float_cuda_lib_Convolution_762Kernel(std::move(inception3_cudnn_handle_0), std::move(inception3_Relu_801_0), std::move(inception3_Reshape_802_0), std::move(inception3_Convolution_803_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_BatchNormInference_float_float_float_float_float_float_cuda_BatchNormInference_632_CallKernel(dim3(12288, 1, 1), dim3(289, 1, 1), 0, nullptr, std::move(inception3_Constant_381_0), std::move(inception3_Constant_382_0), std::move(inception3_Convolution_803_0), std::move(inception3_Constant_383_0), std::move(inception3_Constant_384_0), std::move(inception3_BatchNormInference_804_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_Relu_float_float_cuda_Relu_490_CallKernel(dim3(6936, 1, 1), dim3(512, 1, 1), 0, nullptr, std::move(inception3_BatchNormInference_804_0), std::move(inception3_Relu_805_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_Reshape_float_float_cuda_Reshape_806_CallKernel(dim3(12, 192, 1), dim3(16, 1, 16), 0, nullptr, std::move(inception3_Constant_385_0), std::move(inception3_Reshape_806_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_Convolution_float_float_float_cuda_lib_Convolution_807Kernel(std::move(inception3_cudnn_handle_0), std::move(inception3_Relu_805_0), std::move(inception3_Reshape_806_0), std::move(inception3_Convolution_807_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_BatchNormInference_float_float_float_float_float_float_cuda_BatchNormInference_808_CallKernel(dim3(12288, 1, 1), dim3(64, 1, 1), 0, nullptr, std::move(inception3_Constant_386_0), std::move(inception3_Constant_387_0), std::move(inception3_Convolution_807_0), std::move(inception3_Constant_388_0), std::move(inception3_Constant_389_0), std::move(inception3_BatchNormInference_808_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_Relu_float_float_cuda_Relu_490_CallKernel(dim3(1536, 1, 1), dim3(512, 1, 1), 0, nullptr, std::move(inception3_BatchNormInference_808_0), std::move(inception3_Relu_809_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_Reshape_float_float_cuda_Reshape_627_CallKernel(dim3(12, 48, 1), dim3(16, 16, 1), 0, nullptr, std::move(inception3_Constant_360_0), std::move(inception3_Reshape_785_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_Convolution_float_float_float_cuda_lib_Convolution_628Kernel(std::move(inception3_cudnn_handle_0), std::move(inception3_Concat_784_0), std::move(inception3_Reshape_785_0), std::move(inception3_Convolution_786_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_BatchNormInference_float_float_float_float_float_float_cuda_BatchNormInference_632_CallKernel(dim3(12288, 1, 1), dim3(289, 1, 1), 0, nullptr, std::move(inception3_Constant_361_0), std::move(inception3_Constant_362_0), std::move(inception3_Convolution_786_0), std::move(inception3_Constant_363_0), std::move(inception3_Constant_364_0), std::move(inception3_BatchNormInference_790_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_Relu_float_float_cuda_Relu_490_CallKernel(dim3(6936, 1, 1), dim3(512, 1, 1), 0, nullptr, std::move(inception3_BatchNormInference_790_0), std::move(inception3_Relu_792_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_Reshape_float_float_cuda_Reshape_794_CallKernel(dim3(20, 192, 1), dim3(16, 1, 16), 0, nullptr, std::move(inception3_Constant_365_0), std::move(inception3_Reshape_794_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_Convolution_float_float_float_cuda_lib_Convolution_795Kernel(std::move(inception3_cudnn_handle_0), std::move(inception3_Relu_792_0), std::move(inception3_Reshape_794_0), std::move(inception3_Convolution_795_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_BatchNormInference_float_float_float_float_float_float_cuda_BatchNormInference_798_CallKernel(dim3(20480, 1, 1), dim3(64, 1, 1), 0, nullptr, std::move(inception3_Constant_366_0), std::move(inception3_Constant_367_0), std::move(inception3_Convolution_795_0), std::move(inception3_Constant_368_0), std::move(inception3_Constant_369_0), std::move(inception3_BatchNormInference_798_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_Relu_float_float_cuda_Relu_490_CallKernel(dim3(2560, 1, 1), dim3(512, 1, 1), 0, nullptr, std::move(inception3_BatchNormInference_798_0), std::move(inception3_Relu_800_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_Concat_float_float_float_float_cuda_Concat_810_CallKernel(dim3(10240, 1, 1), dim3(512, 1, 1), 0, nullptr, std::move(inception3_Relu_800_0), std::move(inception3_Relu_809_0), std::move(inception3_MaxPool_789_0), std::move(inception3_Concat_810_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_AvgPool_float_float_cuda_lib_AvgPool_817Kernel(std::move(inception3_cudnn_handle_0), std::move(inception3_Concat_810_0), std::move(inception3_AvgPool_817_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_Reshape_float_float_cuda_Reshape_821_CallKernel(dim3(12, 80, 1), dim3(16, 16, 1), 0, nullptr, std::move(inception3_Constant_431_0), std::move(inception3_Reshape_821_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_Convolution_float_float_float_cuda_lib_Convolution_822Kernel(std::move(inception3_cudnn_handle_0), std::move(inception3_AvgPool_817_0), std::move(inception3_Reshape_821_0), std::move(inception3_Convolution_822_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_BatchNormInference_float_float_float_float_float_float_cuda_BatchNormInference_808_CallKernel(dim3(12288, 1, 1), dim3(64, 1, 1), 0, nullptr, std::move(inception3_Constant_432_0), std::move(inception3_Constant_433_0), std::move(inception3_Convolution_822_0), std::move(inception3_Constant_434_0), std::move(inception3_Constant_435_0), std::move(inception3_BatchNormInference_826_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_Relu_float_float_cuda_Relu_490_CallKernel(dim3(1536, 1, 1), dim3(512, 1, 1), 0, nullptr, std::move(inception3_BatchNormInference_826_0), std::move(inception3_Relu_833_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_Reshape_float_float_cuda_Reshape_815_CallKernel(dim3(28, 80, 1), dim3(16, 16, 1), 0, nullptr, std::move(inception3_Constant_411_0), std::move(inception3_Reshape_815_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_Convolution_float_float_float_cuda_lib_Convolution_816Kernel(std::move(inception3_cudnn_handle_0), std::move(inception3_Concat_810_0), std::move(inception3_Reshape_815_0), std::move(inception3_Convolution_816_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_BatchNormInference_float_float_float_float_float_float_cuda_BatchNormInference_820_CallKernel(dim3(28672, 1, 1), dim3(64, 1, 1), 0, nullptr, std::move(inception3_Constant_412_0), std::move(inception3_Constant_413_0), std::move(inception3_Convolution_816_0), std::move(inception3_Constant_414_0), std::move(inception3_Constant_415_0), std::move(inception3_BatchNormInference_820_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_Relu_float_float_cuda_Relu_490_CallKernel(dim3(3584, 1, 1), dim3(512, 1, 1), 0, nullptr, std::move(inception3_BatchNormInference_820_0), std::move(inception3_Relu_825_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_Reshape_float_float_cuda_Reshape_831_CallKernel(dim3(24, 448, 1), dim3(16, 1, 16), 0, nullptr, std::move(inception3_Constant_416_0), std::move(inception3_Reshape_831_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_Convolution_float_float_float_cuda_lib_Convolution_832Kernel(std::move(inception3_cudnn_handle_0), std::move(inception3_Relu_825_0), std::move(inception3_Reshape_831_0), std::move(inception3_Convolution_832_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_BatchNormInference_float_float_float_float_float_float_cuda_BatchNormInference_836_CallKernel(dim3(24576, 1, 1), dim3(64, 1, 1), 0, nullptr, std::move(inception3_Constant_417_0), std::move(inception3_Constant_418_0), std::move(inception3_Convolution_832_0), std::move(inception3_Constant_419_0), std::move(inception3_Constant_420_0), std::move(inception3_BatchNormInference_836_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_Relu_float_float_cuda_Relu_490_CallKernel(dim3(3072, 1, 1), dim3(512, 1, 1), 0, nullptr, std::move(inception3_BatchNormInference_836_0), std::move(inception3_Relu_839_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_Reshape_float_float_cuda_Reshape_842_CallKernel(dim3(24, 384, 1), dim3(16, 1, 16), 0, nullptr, std::move(inception3_Constant_426_0), std::move(inception3_Reshape_842_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_Convolution_float_float_float_cuda_lib_Convolution_843Kernel(std::move(inception3_cudnn_handle_0), std::move(inception3_Relu_839_0), std::move(inception3_Reshape_842_0), std::move(inception3_Convolution_843_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_BatchNormInference_float_float_float_float_float_float_cuda_BatchNormInference_836_CallKernel(dim3(24576, 1, 1), dim3(64, 1, 1), 0, nullptr, std::move(inception3_Constant_427_0), std::move(inception3_Constant_428_0), std::move(inception3_Convolution_843_0), std::move(inception3_Constant_429_0), std::move(inception3_Constant_430_0), std::move(inception3_BatchNormInference_845_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_Relu_float_float_cuda_Relu_490_CallKernel(dim3(3072, 1, 1), dim3(512, 1, 1), 0, nullptr, std::move(inception3_BatchNormInference_845_0), std::move(inception3_Relu_847_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_Reshape_float_float_cuda_Reshape_842_CallKernel(dim3(24, 384, 1), dim3(16, 1, 16), 0, nullptr, std::move(inception3_Constant_421_0), std::move(inception3_Reshape_840_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_Convolution_float_float_float_cuda_lib_Convolution_841Kernel(std::move(inception3_cudnn_handle_0), std::move(inception3_Relu_839_0), std::move(inception3_Reshape_840_0), std::move(inception3_Convolution_841_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_BatchNormInference_float_float_float_float_float_float_cuda_BatchNormInference_836_CallKernel(dim3(24576, 1, 1), dim3(64, 1, 1), 0, nullptr, std::move(inception3_Constant_422_0), std::move(inception3_Constant_423_0), std::move(inception3_Convolution_841_0), std::move(inception3_Constant_424_0), std::move(inception3_Constant_425_0), std::move(inception3_BatchNormInference_844_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_Relu_float_float_cuda_Relu_490_CallKernel(dim3(3072, 1, 1), dim3(512, 1, 1), 0, nullptr, std::move(inception3_BatchNormInference_844_0), std::move(inception3_Relu_846_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_Reshape_float_float_cuda_Reshape_813_CallKernel(dim3(24, 80, 1), dim3(16, 16, 1), 0, nullptr, std::move(inception3_Constant_396_0), std::move(inception3_Reshape_813_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_Convolution_float_float_float_cuda_lib_Convolution_814Kernel(std::move(inception3_cudnn_handle_0), std::move(inception3_Concat_810_0), std::move(inception3_Reshape_813_0), std::move(inception3_Convolution_814_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_BatchNormInference_float_float_float_float_float_float_cuda_BatchNormInference_836_CallKernel(dim3(24576, 1, 1), dim3(64, 1, 1), 0, nullptr, std::move(inception3_Constant_397_0), std::move(inception3_Constant_398_0), std::move(inception3_Convolution_814_0), std::move(inception3_Constant_399_0), std::move(inception3_Constant_400_0), std::move(inception3_BatchNormInference_819_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_Relu_float_float_cuda_Relu_490_CallKernel(dim3(3072, 1, 1), dim3(512, 1, 1), 0, nullptr, std::move(inception3_BatchNormInference_819_0), std::move(inception3_Relu_824_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_Reshape_float_float_cuda_Reshape_842_CallKernel(dim3(24, 384, 1), dim3(16, 1, 16), 0, nullptr, std::move(inception3_Constant_406_0), std::move(inception3_Reshape_829_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_Convolution_float_float_float_cuda_lib_Convolution_843Kernel(std::move(inception3_cudnn_handle_0), std::move(inception3_Relu_824_0), std::move(inception3_Reshape_829_0), std::move(inception3_Convolution_830_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_BatchNormInference_float_float_float_float_float_float_cuda_BatchNormInference_836_CallKernel(dim3(24576, 1, 1), dim3(64, 1, 1), 0, nullptr, std::move(inception3_Constant_407_0), std::move(inception3_Constant_408_0), std::move(inception3_Convolution_830_0), std::move(inception3_Constant_409_0), std::move(inception3_Constant_410_0), std::move(inception3_BatchNormInference_835_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_Relu_float_float_cuda_Relu_490_CallKernel(dim3(3072, 1, 1), dim3(512, 1, 1), 0, nullptr, std::move(inception3_BatchNormInference_835_0), std::move(inception3_Relu_838_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_Reshape_float_float_cuda_Reshape_842_CallKernel(dim3(24, 384, 1), dim3(16, 1, 16), 0, nullptr, std::move(inception3_Constant_401_0), std::move(inception3_Reshape_827_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_Convolution_float_float_float_cuda_lib_Convolution_841Kernel(std::move(inception3_cudnn_handle_0), std::move(inception3_Relu_824_0), std::move(inception3_Reshape_827_0), std::move(inception3_Convolution_828_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_BatchNormInference_float_float_float_float_float_float_cuda_BatchNormInference_836_CallKernel(dim3(24576, 1, 1), dim3(64, 1, 1), 0, nullptr, std::move(inception3_Constant_402_0), std::move(inception3_Constant_403_0), std::move(inception3_Convolution_828_0), std::move(inception3_Constant_404_0), std::move(inception3_Constant_405_0), std::move(inception3_BatchNormInference_834_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_Relu_float_float_cuda_Relu_490_CallKernel(dim3(3072, 1, 1), dim3(512, 1, 1), 0, nullptr, std::move(inception3_BatchNormInference_834_0), std::move(inception3_Relu_837_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_Reshape_float_float_cuda_Reshape_811_CallKernel(dim3(20, 80, 1), dim3(16, 16, 1), 0, nullptr, std::move(inception3_Constant_391_0), std::move(inception3_Reshape_811_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_Convolution_float_float_float_cuda_lib_Convolution_812Kernel(std::move(inception3_cudnn_handle_0), std::move(inception3_Concat_810_0), std::move(inception3_Reshape_811_0), std::move(inception3_Convolution_812_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_BatchNormInference_float_float_float_float_float_float_cuda_BatchNormInference_798_CallKernel(dim3(20480, 1, 1), dim3(64, 1, 1), 0, nullptr, std::move(inception3_Constant_392_0), std::move(inception3_Constant_393_0), std::move(inception3_Convolution_812_0), std::move(inception3_Constant_394_0), std::move(inception3_Constant_395_0), std::move(inception3_BatchNormInference_818_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_Relu_float_float_cuda_Relu_490_CallKernel(dim3(2560, 1, 1), dim3(512, 1, 1), 0, nullptr, std::move(inception3_BatchNormInference_818_0), std::move(inception3_Relu_823_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_Concat_float_float_float_float_float_float_float_cuda_Concat_848_CallKernel(dim3(16384, 1, 1), dim3(512, 1, 1), 0, nullptr, std::move(inception3_Relu_823_0), std::move(inception3_Relu_837_0), std::move(inception3_Relu_838_0), std::move(inception3_Relu_846_0), std::move(inception3_Relu_847_0), std::move(inception3_Relu_833_0), std::move(inception3_Concat_848_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_MaxPool_float_float_cuda_lib_MaxPool_855Kernel(std::move(inception3_cudnn_handle_0), std::move(inception3_Concat_848_0), std::move(inception3_MaxPool_855_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_Reshape_float_float_cuda_Reshape_859_CallKernel(dim3(12, 128, 1), dim3(16, 16, 1), 0, nullptr, std::move(inception3_Constant_477_0), std::move(inception3_Reshape_859_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_Convolution_float_float_float_cuda_lib_Convolution_860Kernel(std::move(inception3_cudnn_handle_0), std::move(inception3_MaxPool_855_0), std::move(inception3_Reshape_859_0), std::move(inception3_Convolution_860_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_BatchNormInference_float_float_float_float_float_float_cuda_BatchNormInference_808_CallKernel(dim3(12288, 1, 1), dim3(64, 1, 1), 0, nullptr, std::move(inception3_Constant_478_0), std::move(inception3_Constant_479_0), std::move(inception3_Convolution_860_0), std::move(inception3_Constant_480_0), std::move(inception3_Constant_481_0), std::move(inception3_BatchNormInference_864_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_Relu_float_float_cuda_Relu_490_CallKernel(dim3(1536, 1, 1), dim3(512, 1, 1), 0, nullptr, std::move(inception3_BatchNormInference_864_0), std::move(inception3_Relu_871_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_Reshape_float_float_cuda_Reshape_853_CallKernel(dim3(28, 128, 1), dim3(16, 16, 1), 0, nullptr, std::move(inception3_Constant_457_0), std::move(inception3_Reshape_853_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_Convolution_float_float_float_cuda_lib_Convolution_854Kernel(std::move(inception3_cudnn_handle_0), std::move(inception3_Concat_848_0), std::move(inception3_Reshape_853_0), std::move(inception3_Convolution_854_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_BatchNormInference_float_float_float_float_float_float_cuda_BatchNormInference_820_CallKernel(dim3(28672, 1, 1), dim3(64, 1, 1), 0, nullptr, std::move(inception3_Constant_458_0), std::move(inception3_Constant_459_0), std::move(inception3_Convolution_854_0), std::move(inception3_Constant_460_0), std::move(inception3_Constant_461_0), std::move(inception3_BatchNormInference_858_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_Relu_float_float_cuda_Relu_490_CallKernel(dim3(3584, 1, 1), dim3(512, 1, 1), 0, nullptr, std::move(inception3_BatchNormInference_858_0), std::move(inception3_Relu_863_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_Reshape_float_float_cuda_Reshape_831_CallKernel(dim3(24, 448, 1), dim3(16, 1, 16), 0, nullptr, std::move(inception3_Constant_462_0), std::move(inception3_Reshape_869_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_Convolution_float_float_float_cuda_lib_Convolution_832Kernel(std::move(inception3_cudnn_handle_0), std::move(inception3_Relu_863_0), std::move(inception3_Reshape_869_0), std::move(inception3_Convolution_870_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_BatchNormInference_float_float_float_float_float_float_cuda_BatchNormInference_836_CallKernel(dim3(24576, 1, 1), dim3(64, 1, 1), 0, nullptr, std::move(inception3_Constant_463_0), std::move(inception3_Constant_464_0), std::move(inception3_Convolution_870_0), std::move(inception3_Constant_465_0), std::move(inception3_Constant_466_0), std::move(inception3_BatchNormInference_874_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_Relu_float_float_cuda_Relu_490_CallKernel(dim3(3072, 1, 1), dim3(512, 1, 1), 0, nullptr, std::move(inception3_BatchNormInference_874_0), std::move(inception3_Relu_877_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_Reshape_float_float_cuda_Reshape_842_CallKernel(dim3(24, 384, 1), dim3(16, 1, 16), 0, nullptr, std::move(inception3_Constant_472_0), std::move(inception3_Reshape_880_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_Convolution_float_float_float_cuda_lib_Convolution_843Kernel(std::move(inception3_cudnn_handle_0), std::move(inception3_Relu_877_0), std::move(inception3_Reshape_880_0), std::move(inception3_Convolution_881_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_BatchNormInference_float_float_float_float_float_float_cuda_BatchNormInference_836_CallKernel(dim3(24576, 1, 1), dim3(64, 1, 1), 0, nullptr, std::move(inception3_Constant_473_0), std::move(inception3_Constant_474_0), std::move(inception3_Convolution_881_0), std::move(inception3_Constant_475_0), std::move(inception3_Constant_476_0), std::move(inception3_BatchNormInference_883_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_Relu_float_float_cuda_Relu_490_CallKernel(dim3(3072, 1, 1), dim3(512, 1, 1), 0, nullptr, std::move(inception3_BatchNormInference_883_0), std::move(inception3_Relu_885_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_Reshape_float_float_cuda_Reshape_842_CallKernel(dim3(24, 384, 1), dim3(16, 1, 16), 0, nullptr, std::move(inception3_Constant_467_0), std::move(inception3_Reshape_878_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_Convolution_float_float_float_cuda_lib_Convolution_841Kernel(std::move(inception3_cudnn_handle_0), std::move(inception3_Relu_877_0), std::move(inception3_Reshape_878_0), std::move(inception3_Convolution_879_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_BatchNormInference_float_float_float_float_float_float_cuda_BatchNormInference_836_CallKernel(dim3(24576, 1, 1), dim3(64, 1, 1), 0, nullptr, std::move(inception3_Constant_468_0), std::move(inception3_Constant_469_0), std::move(inception3_Convolution_879_0), std::move(inception3_Constant_470_0), std::move(inception3_Constant_471_0), std::move(inception3_BatchNormInference_882_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_Relu_float_float_cuda_Relu_490_CallKernel(dim3(3072, 1, 1), dim3(512, 1, 1), 0, nullptr, std::move(inception3_BatchNormInference_882_0), std::move(inception3_Relu_884_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_Reshape_float_float_cuda_Reshape_851_CallKernel(dim3(24, 128, 1), dim3(16, 16, 1), 0, nullptr, std::move(inception3_Constant_442_0), std::move(inception3_Reshape_851_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_Convolution_float_float_float_cuda_lib_Convolution_852Kernel(std::move(inception3_cudnn_handle_0), std::move(inception3_Concat_848_0), std::move(inception3_Reshape_851_0), std::move(inception3_Convolution_852_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_BatchNormInference_float_float_float_float_float_float_cuda_BatchNormInference_836_CallKernel(dim3(24576, 1, 1), dim3(64, 1, 1), 0, nullptr, std::move(inception3_Constant_443_0), std::move(inception3_Constant_444_0), std::move(inception3_Convolution_852_0), std::move(inception3_Constant_445_0), std::move(inception3_Constant_446_0), std::move(inception3_BatchNormInference_857_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_Relu_float_float_cuda_Relu_490_CallKernel(dim3(3072, 1, 1), dim3(512, 1, 1), 0, nullptr, std::move(inception3_BatchNormInference_857_0), std::move(inception3_Relu_862_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_Reshape_float_float_cuda_Reshape_842_CallKernel(dim3(24, 384, 1), dim3(16, 1, 16), 0, nullptr, std::move(inception3_Constant_452_0), std::move(inception3_Reshape_867_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_Convolution_float_float_float_cuda_lib_Convolution_843Kernel(std::move(inception3_cudnn_handle_0), std::move(inception3_Relu_862_0), std::move(inception3_Reshape_867_0), std::move(inception3_Convolution_868_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_BatchNormInference_float_float_float_float_float_float_cuda_BatchNormInference_836_CallKernel(dim3(24576, 1, 1), dim3(64, 1, 1), 0, nullptr, std::move(inception3_Constant_453_0), std::move(inception3_Constant_454_0), std::move(inception3_Convolution_868_0), std::move(inception3_Constant_455_0), std::move(inception3_Constant_456_0), std::move(inception3_BatchNormInference_873_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_Relu_float_float_cuda_Relu_490_CallKernel(dim3(3072, 1, 1), dim3(512, 1, 1), 0, nullptr, std::move(inception3_BatchNormInference_873_0), std::move(inception3_Relu_876_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_Reshape_float_float_cuda_Reshape_842_CallKernel(dim3(24, 384, 1), dim3(16, 1, 16), 0, nullptr, std::move(inception3_Constant_447_0), std::move(inception3_Reshape_865_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_Convolution_float_float_float_cuda_lib_Convolution_841Kernel(std::move(inception3_cudnn_handle_0), std::move(inception3_Relu_862_0), std::move(inception3_Reshape_865_0), std::move(inception3_Convolution_866_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_BatchNormInference_float_float_float_float_float_float_cuda_BatchNormInference_836_CallKernel(dim3(24576, 1, 1), dim3(64, 1, 1), 0, nullptr, std::move(inception3_Constant_448_0), std::move(inception3_Constant_449_0), std::move(inception3_Convolution_866_0), std::move(inception3_Constant_450_0), std::move(inception3_Constant_451_0), std::move(inception3_BatchNormInference_872_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_Relu_float_float_cuda_Relu_490_CallKernel(dim3(3072, 1, 1), dim3(512, 1, 1), 0, nullptr, std::move(inception3_BatchNormInference_872_0), std::move(inception3_Relu_875_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_Reshape_float_float_cuda_Reshape_849_CallKernel(dim3(20, 128, 1), dim3(16, 16, 1), 0, nullptr, std::move(inception3_Constant_437_0), std::move(inception3_Reshape_849_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_Convolution_float_float_float_cuda_lib_Convolution_850Kernel(std::move(inception3_cudnn_handle_0), std::move(inception3_Concat_848_0), std::move(inception3_Reshape_849_0), std::move(inception3_Convolution_850_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_BatchNormInference_float_float_float_float_float_float_cuda_BatchNormInference_798_CallKernel(dim3(20480, 1, 1), dim3(64, 1, 1), 0, nullptr, std::move(inception3_Constant_438_0), std::move(inception3_Constant_439_0), std::move(inception3_Convolution_850_0), std::move(inception3_Constant_440_0), std::move(inception3_Constant_441_0), std::move(inception3_BatchNormInference_856_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_Relu_float_float_cuda_Relu_490_CallKernel(dim3(2560, 1, 1), dim3(512, 1, 1), 0, nullptr, std::move(inception3_BatchNormInference_856_0), std::move(inception3_Relu_861_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_Concat_float_float_float_float_float_float_float_cuda_Concat_848_CallKernel(dim3(16384, 1, 1), dim3(512, 1, 1), 0, nullptr, std::move(inception3_Relu_861_0), std::move(inception3_Relu_875_0), std::move(inception3_Relu_876_0), std::move(inception3_Relu_884_0), std::move(inception3_Relu_885_0), std::move(inception3_Relu_871_0), std::move(inception3_Concat_886_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_AvgPool_float_float_cuda_lib_AvgPool_887Kernel(std::move(inception3_cudnn_handle_0), std::move(inception3_Concat_886_0), std::move(inception3_AvgPool_887_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_Dot_float_float_float_cuda_lib_Dot_889Kernel(std::move(inception3_cublas_handle_0), std::move(inception3_Reshape_888_0), std::move(inception3_Constant_484_0), std::move(inception3_Dot_889_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_Broadcast_float_float_cuda_Broadcast_890_CallKernel(dim3(1001, 1, 1), dim3(64, 1, 1), 0, nullptr, std::move(inception3_Constant_485_0), std::move(inception3_Broadcast_890_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_Add_float_float_float_cuda_Add_891_CallKernel(dim3(1001, 1, 1), dim3(64, 1, 1), 0, nullptr, std::move(inception3_Dot_889_0), std::move(inception3_Broadcast_890_0), std::move(inception3_Add_891_0), std::move(Parameter_0_0), std::move(Result_892_0)));
    kernels.emplace_back(new inception3_Result_float_float_cuda_lib_Result_892Kernel(std::move(inception3_Add_891_0), std::move(Result_892_0), std::move(Parameter_0_0), std::move(Result_892_0)));
}
